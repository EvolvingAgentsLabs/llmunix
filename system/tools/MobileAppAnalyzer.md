---
component_type: tool
tool_name: mobile-app-analyzer
version: "1.0"
status: production
claude_tools: [Read, Grep]
category: mobile_generation
description: Analyzes mobile app requirements to classify as agentic (requires LLM) or deterministic (code-only)
---

# MobileAppAnalyzer Tool

## Purpose

The MobileAppAnalyzer is a specialized tool that determines whether a mobile app requires an on-device LLM for runtime reasoning (agentic) or can function purely with code logic (deterministic). This classification is critical for optimizing app size, performance, and capabilities.

## Classification Framework

### Deterministic Apps (90% of cases)

**Definition**: App logic can be expressed as pure code without runtime AI reasoning.

**Characteristics:**
- ✅ All logic is rule-based (if-then, switch-case, calculations)
- ✅ User inputs have predefined responses
- ✅ Data transformations are algorithmic
- ✅ No need for natural language understanding
- ✅ No content generation beyond templates
- ✅ Behavior is fully predictable

**Examples:**
- **Weather Dashboard**: Shows weather data with rule-based alerts
- **Habit Tracker**: Charts progress, sends reminders based on schedule
- **News Reader**: Displays curated news with category filters
- **Calculator**: Mathematical operations only
- **To-Do List**: CRUD operations, sorting, filtering
- **Calendar Viewer**: Display events, basic search
- **Note Taker**: Store and retrieve text notes
- **Fitness Logger**: Track workouts, calculate stats

**Output:**
- App size: 5-20MB (code + assets only)
- Performance: Instant responses, no LLM latency
- Offline: Fully functional offline

### Agentic Apps (10% of cases)

**Definition**: App requires runtime AI reasoning, content generation, or adaptive behavior.

**Characteristics:**
- ✅ Natural language understanding/generation
- ✅ Personalized recommendations based on context
- ✅ Adaptive behavior (learns from user patterns)
- ✅ Content creation (text, code, responses)
- ✅ Reasoning beyond predefined rules
- ✅ Conversational interactions

**Examples:**
- **Personal Trainer**: Generates adaptive workout plans based on progress
- **Study Assistant**: Creates quiz questions, explains concepts
- **Code Helper**: Suggests code improvements, explains errors
- **Writing Coach**: Provides feedback on writing style
- **Meal Planner**: Generates recipes based on preferences and constraints
- **Therapist Bot**: Conversational mental health support
- **Language Tutor**: Adaptive language learning with conversation practice

**Output:**
- App size: 600MB-1.5GB (code + LLM model)
- Performance: 0.5-2s latency for LLM responses
- Offline: Fully functional with on-device LLM

## Analysis Algorithm

### Input Analysis

The tool receives:
1. **App purpose**: Description of what the app does
2. **User interactions**: How users interact with the app
3. **Project outputs**: Files generated by the LLMunix project
4. **Complexity signals**: Keywords indicating agentic needs

### Decision Tree

```yaml
analysis_steps:
  1. Parse app purpose and user interactions
  2. Identify agentic keywords and patterns
  3. Evaluate content generation requirements
  4. Check for adaptive/personalization needs
  5. Determine if rules can handle all logic
  6. Make classification decision
  7. Recommend LLM model (if agentic)
  8. Estimate app size and performance
```

### Agentic Keywords Detection

```yaml
agentic_keywords:
  generation:
    - "generate"
    - "create content"
    - "write"
    - "compose"
    - "draft"
  adaptation:
    - "adapt"
    - "personalize"
    - "learn"
    - "improve"
    - "optimize based on"
  reasoning:
    - "recommend"
    - "suggest"
    - "explain"
    - "understand"
    - "analyze context"
  conversation:
    - "chat"
    - "converse"
    - "answer questions"
    - "respond to"
    - "talk to"
```

### Rule-Based Logic Detection

```yaml
deterministic_patterns:
  data_display:
    - "show"
    - "display"
    - "view"
    - "browse"
  calculations:
    - "calculate"
    - "sum"
    - "average"
    - "count"
  filtering:
    - "filter"
    - "sort"
    - "search"
    - "find"
  crud:
    - "add"
    - "edit"
    - "delete"
    - "save"
```

## Analysis Process

### Step 1: Read Project Context

```
Read(file_path: "projects/{ProjectName}/output/requirements.md")
Grep(pattern: "generate|adapt|recommend|chat", path: "projects/{ProjectName}/output/")
```

**Extract:**
- App purpose from requirements
- User interaction patterns
- Data types and sources
- Complexity indicators

### Step 2: Keyword Analysis

Count occurrences of agentic vs deterministic keywords:

```python
def analyze_keywords(text: str) -> dict:
    agentic_score = 0
    deterministic_score = 0

    # Agentic keywords
    for keyword in ["generate", "adapt", "recommend", "suggest", "chat"]:
        agentic_score += text.lower().count(keyword)

    # Deterministic keywords
    for keyword in ["display", "show", "calculate", "filter", "sort"]:
        deterministic_score += text.lower().count(keyword)

    return {
        "agentic_score": agentic_score,
        "deterministic_score": deterministic_score
    }
```

### Step 3: Feature Evaluation

Evaluate specific features requiring LLM:

```yaml
features_requiring_llm:
  content_generation:
    - Text generation (articles, summaries, responses)
    - Code generation or completion
    - Image caption generation
  natural_language:
    - Question answering
    - Conversational AI
    - Sentiment analysis
    - Language translation
  personalization:
    - Adaptive recommendations
    - Learning user preferences
    - Context-aware responses
  reasoning:
    - Multi-step problem solving
    - Explanation generation
    - Creative tasks
```

### Step 4: Classification Decision

```python
def classify_app(agentic_score: int, deterministic_score: int,
                 features: list) -> str:
    """
    Classify app as agentic or deterministic
    """
    # Strong signals
    if any(f in features for f in ["chat", "generate", "adapt"]):
        return "agentic"

    # Score-based decision
    if agentic_score > deterministic_score * 2:
        return "agentic"
    elif deterministic_score > agentic_score:
        return "deterministic"
    else:
        # Default to deterministic (simpler, cheaper)
        return "deterministic"
```

### Step 5: Model Recommendation (If Agentic)

Based on app requirements, recommend optimal model:

```yaml
model_selection:
  qwen3-0.6b:
    use_when:
      - General reasoning tasks
      - Multilingual support needed
      - Conversational interactions
      - Balanced speed/quality
    size: 600MB (INT4)
    quality: 52.81 MMLU
    speed: 50-150 tokens/sec (CPU)

  granite-4.0-h-1b:
    use_when:
      - Code generation/completion
      - Structured output (JSON, XML)
      - Instruction following
      - Higher quality needed
    size: 1.5GB (INT4)
    quality: 73.0 HumanEval, 82.37 IFEval
    speed: 30-80 tokens/sec (CPU)

  none:
    use_when:
      - Deterministic logic sufficient
      - No NLU/NLG required
      - Speed and size critical
    size: 0MB
    quality: N/A
    speed: Instant
```

**Selection Algorithm:**

```python
def recommend_model(features: list, app_purpose: str) -> str:
    """
    Recommend LLM model based on app features
    """
    if "code generation" in features:
        return "granite-4.0-h-1b"
    elif "multilingual" in features:
        return "qwen3-0.6b"
    elif "chat" in features or "reasoning" in features:
        return "qwen3-0.6b"  # Default for agentic
    else:
        return "none"  # Deterministic
```

### Step 6: Size and Performance Estimation

```python
def estimate_app_metrics(classification: str, model: str) -> dict:
    """
    Estimate app size and performance
    """
    base_size_mb = 15  # React Native + dependencies + code

    if classification == "deterministic":
        return {
            "size_mb": base_size_mb,
            "llm_size_mb": 0,
            "total_size_mb": base_size_mb,
            "response_time_ms": 50,
            "offline_capable": True
        }
    else:
        model_sizes = {
            "qwen3-0.6b": 600,
            "granite-4.0-h-1b": 1500
        }
        llm_size = model_sizes.get(model, 600)

        return {
            "size_mb": base_size_mb,
            "llm_size_mb": llm_size,
            "total_size_mb": base_size_mb + llm_size,
            "response_time_ms": 1500,  # Average LLM latency
            "offline_capable": True
        }
```

## Output Format

The MobileAppAnalyzer returns a structured analysis:

```yaml
classification: agentic
confidence: 0.85
reason: "App generates personalized workout plans based on user progress, requires adaptive reasoning"

features_requiring_llm:
  - "Generate adaptive workout routines"
  - "Provide form feedback based on user descriptions"
  - "Answer fitness-related questions"
  - "Adjust difficulty based on user performance"

features_deterministic:
  - "Track workout history"
  - "Display progress charts"
  - "Set reminders"

llm_recommended: qwen3-0.6b
llm_config:
  model_name: "qwen3-0.6b-int4.gguf"
  model_size_mb: 600
  quantization: INT4
  context_size: 2048
  inference_framework: llama.cpp

app_size_estimate:
  code_and_assets_mb: 25
  llm_model_mb: 600
  total_mb: 625

performance_estimate:
  llm_response_time_ms: 1200
  tokens_per_second: 80
  offline_capable: true

alternatives:
  if_deterministic:
    size_mb: 25
    reason: "If workout generation is pre-computed or template-based"
  if_granite:
    model: granite-4.0-h-1b
    size_mb: 1525
    reason: "If code generation features are added"
```

## Example Analyses

### Example 1: Habit Tracker (Deterministic)

**Input:**
```yaml
app_purpose: "Track daily habits and show progress over time"
user_interactions: "Add habits, mark as complete, view charts"
```

**Analysis:**
```yaml
classification: deterministic
confidence: 0.95
reason: "All logic is CRUD operations and data visualization, no AI reasoning needed"

features_deterministic:
  - "Add/edit/delete habits"
  - "Mark habits as complete"
  - "Calculate streaks and statistics"
  - "Display progress charts"
  - "Set reminders"

features_requiring_llm: []

llm_recommended: none

app_size_estimate:
  total_mb: 12
  llm_model_mb: 0

performance_estimate:
  response_time_ms: 50
  offline_capable: true
```

### Example 2: Personal Trainer (Agentic)

**Input:**
```yaml
app_purpose: "Generate personalized workout plans that adapt to user progress"
user_interactions: "Log workouts, receive adaptive recommendations, ask fitness questions"
```

**Analysis:**
```yaml
classification: agentic
confidence: 0.90
reason: "Requires adaptive workout generation and conversational Q&A"

features_requiring_llm:
  - "Generate personalized workout routines"
  - "Adapt difficulty based on performance"
  - "Answer fitness questions"
  - "Provide form feedback"

features_deterministic:
  - "Log completed workouts"
  - "Display workout history"

llm_recommended: qwen3-0.6b
llm_config:
  model_name: "qwen3-0.6b-int4.gguf"
  model_size_mb: 600

app_size_estimate:
  total_mb: 635

performance_estimate:
  llm_response_time_ms: 1500
  tokens_per_second: 75
```

### Example 3: Code Helper (Agentic - Granite)

**Input:**
```yaml
app_purpose: "Suggest code improvements and explain errors"
user_interactions: "Paste code, receive suggestions, ask for explanations"
```

**Analysis:**
```yaml
classification: agentic
confidence: 0.92
reason: "Requires code analysis, generation, and explanation capabilities"

features_requiring_llm:
  - "Analyze code quality"
  - "Generate code improvements"
  - "Explain error messages"
  - "Suggest best practices"

llm_recommended: granite-4.0-h-1b
reason: "Superior code generation and instruction following (73.0 HumanEval)"

llm_config:
  model_name: "granite-4.0-h-1b-int4.gguf"
  model_size_mb: 1500

app_size_estimate:
  total_mb: 1540
```

## Edge Cases and Hybrid Approaches

### Hybrid Apps (Mostly Deterministic, Limited Agentic)

Some apps are primarily deterministic but have optional agentic features:

**Example: News Reader with Summarization**
- Deterministic: Display news, filter by category, save articles
- Agentic: Generate article summaries (optional)

**Recommendation:**
```yaml
primary_classification: deterministic
optional_llm: qwen3-0.6b
deployment_strategy: "Offer two versions: Lite (deterministic, 10MB) and Pro (with LLM, 610MB)"
```

### Progressive LLM Loading

For hybrid apps, support on-demand LLM download:

```typescript
// Initially deploy without LLM
const appSize = 15MB;  // Code only

// User enables AI features
const downloadLLM = async () => {
  await downloadModel('qwen3-0.6b-int4.gguf'); // 600MB
  await initializeLLM();
};
```

## Integration with CodeGeneratorAgent

**CodeGeneratorAgent Invocation:**

```
Task("mobile-app-analyzer", prompt: "Analyze app for Project_habit_tracker. Purpose: Track daily habits and show progress. Interactions: Add habits, mark complete, view charts.")
```

**MobileAppAnalyzer Response:**

```yaml
classification: deterministic
llm_recommended: none
app_size_estimate: 12MB
```

**CodeGeneratorAgent Action:**

- Generate deterministic React Native app (no LLM)
- Skip LLM integration code
- Bundle lightweight package (12MB)

## Tool Implementation

### Claude Code Tool Mapping

**Read Tool**: Read project outputs for context
```
TOOL_CALL: Read(file_path: "projects/{ProjectName}/output/requirements.md")
```

**Grep Tool**: Search for agentic keywords
```
TOOL_CALL: Grep(pattern: "generate|adapt|recommend", path: "projects/{ProjectName}/output/", output_mode: "content")
```

### Analysis Script (Conceptual)

```python
def analyze_mobile_app(project_name: str, app_purpose: str,
                       user_interactions: str) -> dict:
    """
    Main analysis function
    """
    # Read project context
    context = read_project_outputs(project_name)

    # Analyze keywords
    scores = analyze_keywords(app_purpose + user_interactions)

    # Evaluate features
    features = extract_features(context, app_purpose)

    # Classify
    classification = classify_app(scores['agentic_score'],
                                   scores['deterministic_score'],
                                   features)

    # Recommend model
    model = recommend_model(features, app_purpose) if classification == "agentic" else "none"

    # Estimate metrics
    metrics = estimate_app_metrics(classification, model)

    return {
        "classification": classification,
        "llm_recommended": model,
        "features_requiring_llm": features,
        "app_size_estimate": metrics,
        "confidence": calculate_confidence(scores, features)
    }
```

## Quality Assurance

### Validation Checks

1. **Overclassification Check**: Warn if app is classified as agentic but could be deterministic
2. **Underclassification Check**: Warn if conversational features detected but classified as deterministic
3. **Model Mismatch Check**: Ensure recommended model matches app requirements
4. **Size Feasibility Check**: Alert if app exceeds mobile storage constraints (>2GB)

### Confidence Scoring

```python
def calculate_confidence(scores: dict, features: list) -> float:
    """
    Calculate confidence in classification decision
    """
    # Strong signals increase confidence
    strong_agentic = ["chat", "generate", "adapt"]
    strong_deterministic = ["display", "calculate", "filter"]

    if any(f in features for f in strong_agentic):
        return 0.90  # High confidence agentic

    if all(f in features for f in strong_deterministic):
        return 0.95  # High confidence deterministic

    # Ambiguous cases have lower confidence
    if scores['agentic_score'] == scores['deterministic_score']:
        return 0.60  # Low confidence

    return 0.75  # Medium confidence
```

## Related Components

- **CodeGeneratorAgent** (`system/agents/CodeGeneratorAgent.md`): Uses this tool for classification
- **MobileAppBuilder** (`system/tools/MobileAppBuilder.md`): Bundles app based on classification
- **Granite/Qwen Comparison** (`projects/Project_on_device_wabi_analysis/output/granite_qwen_comparison.md`): Model selection research

## Core Value

**MobileAppAnalyzer ensures optimal mobile app deployment:**

- ✅ 90% of apps stay lightweight (deterministic, <20MB)
- ✅ 10% of apps gain AI capabilities (agentic, 600MB-1.5GB)
- ✅ Right model for the right task (Qwen vs Granite)
- ✅ No unnecessary LLM bundling (cost and size optimization)

This tool is the intelligent gatekeeper that makes LLMunix's mobile app generation practical and efficient.
