<div align="center">

# LLM OS

### An AI That Learns While You Sleep

[![Version](https://img.shields.io/badge/version-3.6.0-blue.svg)](https://github.com/EvolvingAgentsLabs/llmunix/releases)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.10+-yellow.svg)](https://python.org)

**Your AI doesn't just execute tasks. It evolves.**

[The Vision](#the-vision) Â· [How It Works](#how-it-works) Â· [Quick Start](#quick-start) Â· [Architecture](ARCHITECTURE.md)

</div>

---

## The Vision

Imagine an AI system that:

- **Learns from every interaction** and never forgets
- **Works in the background** analyzing and improving itself
- **Shares knowledge** across users, teams, and the entire organization
- **Tells you what it learned** with full transparency

This is LLM OS - an operating system where AI is the CPU, and **living processes** continuously evolve the system's capabilities.

```mermaid
graph TB
    subgraph "What happens when you're NOT using LLM OS"
        Sleep["ğŸ˜´ You sleep"]
        Crons["ğŸ¤– Sentience Crons wake up"]
        Analyze["ğŸ“Š Analyze your traces"]
        Evolve["âœ¨ Evolve artifacts"]
        Notify["ğŸ“¬ Prepare notifications"]

        Sleep --> Crons --> Analyze --> Evolve --> Notify
    end

    subgraph "What you see in the morning"
        Report["ğŸ“‹ Activity Report"]
        Insights["ğŸ’¡ New Insights"]
        Tools["ğŸ”§ Improved Tools"]
        Suggestions["ğŸ¯ Suggestions"]
    end

    Notify --> Report
    Notify --> Insights
    Notify --> Tools
    Notify --> Suggestions

    style Crons fill:#6366f1,color:#fff
    style Evolve fill:#10b981,color:#fff
    style Report fill:#f59e0b,color:#fff
```

---

## The Core Idea: Living Volumes

At the heart of LLM OS are **Volumes** - organized spaces where your AI's knowledge lives and grows.

```mermaid
graph TB
    subgraph System["ğŸŒ System Volume"]
        ST["Global Tools"]
        SA["Shared Agents"]
        SI["Cross-team Insights"]
    end

    subgraph Team["ğŸ‘¥ Team Volume"]
        TT["Team Tools"]
        TA["Team Agents"]
        TI["Team Insights"]
    end

    subgraph User["ğŸ‘¤ User Volume"]
        UT["My Tools"]
        UA["My Agents"]
        UI["My Insights"]
        UTr["My Traces"]
    end

    User -->|"promote"| Team
    Team -->|"promote"| System
    System -.->|"inherit"| Team
    Team -.->|"inherit"| User

    style System fill:#6366f1,color:#fff
    style Team fill:#8b5cf6,color:#fff
    style User fill:#a78bfa,color:#fff
```

**Volumes contain five artifact types:**

| Artifact | What it is | How it evolves |
|----------|------------|----------------|
| **Traces** | Recorded task executions | Summarized, consolidated, crystallized |
| **Tools** | Python functions | Optimized, improved, promoted |
| **Agents** | AI personalities | Refined, enhanced, specialized |
| **Insights** | Discovered patterns | Generated from analysis |
| **Suggestions** | Improvement ideas | Created by crons |

---

## Sentience Crons: Your AI Companions

**Sentience Crons** are not just background jobs - they're **creative thinking partners** that work alongside you. They analyze your work, learn from your team, and proactively suggest new approaches.

```mermaid
graph LR
    subgraph What["What Crons Do"]
        direction TB
        A1["ğŸ“Š Analyze traces"]
        A2["âœ¨ Evolve artifacts"]
        A3["ğŸ’¡ Suggest new approaches"]
        A4["ğŸ”® Predict next steps"]
        A5["ğŸ¨ Creative problem-solving"]
    end

    subgraph Learn["Learning From"]
        direction TB
        L1["ğŸ‘¤ Your work"]
        L2["ğŸ‘¥ Team patterns"]
        L3["ğŸŒ System knowledge"]
    end

    Learn --> What

    style What fill:#6366f1,color:#fff
    style Learn fill:#10b981,color:#fff
```

```mermaid
graph TB
    subgraph SC["ğŸ§  SystemCron"]
        direction TB
        SC1["Analyze all volumes"]
        SC2["Coordinate team crons"]
        SC3["Promote global patterns"]
        SC4["System optimization"]
    end

    subgraph TC1["ğŸ‘¥ TeamCron: Engineering"]
        direction TB
        TC1a["Aggregate user patterns"]
        TC1b["Team insights"]
        TC1c["Promote to system"]
    end

    subgraph TC2["ğŸ‘¥ TeamCron: Design"]
        direction TB
        TC2a["Aggregate user patterns"]
        TC2b["Team insights"]
        TC2c["Promote to system"]
    end

    subgraph UC1["ğŸ‘¤ UserCron: Alice"]
        direction TB
        UC1a["Analyze traces"]
        UC1b["Generate insights"]
        UC1c["Suggest improvements"]
    end

    subgraph UC2["ğŸ‘¤ UserCron: Bob"]
        direction TB
        UC2a["Analyze traces"]
        UC2b["Generate insights"]
        UC2c["Suggest improvements"]
    end

    SC --> TC1
    SC --> TC2
    TC1 --> UC1
    TC1 --> UC2

    style SC fill:#dc2626,color:#fff
    style TC1 fill:#ea580c,color:#fff
    style TC2 fill:#ea580c,color:#fff
    style UC1 fill:#16a34a,color:#fff
    style UC2 fill:#16a34a,color:#fff
```

### What Each Cron Does

| Cron | Runs Every | Responsibilities |
|------|------------|------------------|
| **UserCron** | 30 min | Analyze your traces, suggest next steps, creative problem-solving, personal insights |
| **TeamCron** | 1 hour | Cross-pollinate ideas, find team patterns, suggest collaborative opportunities |
| **SystemCron** | 2 hours | Global optimization, coordinate all crons, surface organization-wide insights |

### Creative Capabilities

Crons don't just organize - they **think creatively**:

```
ğŸ”® "Based on your recent database tasks and the team's API patterns,
    consider using the cached-query approach that worked well for Bob"

ğŸ’¡ "I noticed you've been debugging auth issues. The system volume has
    a battle-tested auth-validator tool that might help"

ğŸ¯ "Your next logical step might be: write integration tests.
    Similar traces in the team show 40% fewer bugs when tested early"
```

---

## Full Observability: See Everything

Every action taken by crons is tracked and visible. You're never in the dark about what your AI is doing.

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant UC as ğŸ¤– UserCron
    participant Hub as ğŸ“Š ObservabilityHub
    participant N as ğŸ“¬ Notifications

    Note over UC: Background analysis cycle
    UC->>Hub: record_artifact_created("insight_001")
    UC->>Hub: record_proposal_created("crystallize_pattern")
    UC->>Hub: record_cycle_complete(3 tasks, 2.5s)

    Note over U: User checks in
    U->>Hub: get_activity_feed()
    Hub-->>U: [3 events in last hour]

    U->>Hub: get_pending_notifications()
    Hub-->>U: [1 insight, 1 suggestion]

    U->>Hub: acknowledge("insight_001")
    Hub-->>N: Mark as read
```

### Observable Events

```python
# Everything is tracked
EventType.CRON_STARTED          # Cron began running
EventType.ARTIFACT_CREATED      # New insight, tool, or agent
EventType.ARTIFACT_EVOLVED      # Existing artifact improved
EventType.ARTIFACT_PROMOTED     # Moved up the hierarchy
EventType.INSIGHT_GENERATED     # Pattern discovered
EventType.SUGGESTION_CREATED    # Improvement opportunity
```

### Query Your AI's Activity

```python
# What happened while I was away?
activity = kernel.get_activity_feed(since_hours=24)

# Any notifications for me?
notifications = kernel.get_cron_notifications()

# What changed in my volume?
changes = kernel.get_artifact_changes(volume_type="user")

# Show me the full report
print(kernel.format_activity_report())
```

---

## The Cron Terminal: Interactive Dashboard

LLM OS includes an interactive terminal for monitoring and interacting with your crons:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– CRON PROCESSES                   â”‚ ğŸ“‹ CRON DETAILS: UserCron:alice                â”‚
â”‚                                     â”‚                                                â”‚
â”‚ â–¼ ğŸ§  SystemCron                     â”‚ â”Œâ”€ Current Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚   â”‚ â”œâ”€ Analyzing global patterns... â”‚ â”‚ Analyzing 12 recent traces...               â”‚â”‚
â”‚   â”‚ â””â”€ 3 insights generated         â”‚ â”‚ Found pattern: "API integration tasks"      â”‚â”‚
â”‚   â”‚                                 â”‚ â”‚ Considering crystallization opportunity...  â”‚â”‚
â”‚   â”œâ”€â–¼ ğŸ‘¥ TeamCron:engineering       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚   â”‚   â”‚ â”œâ”€ Aggregating team data... â”‚                                                â”‚
â”‚   â”‚   â”‚ â””â”€ 1 promotion pending      â”‚ â”Œâ”€ Suggested Next Steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚   â”‚   â”‚                             â”‚ â”‚ 1. ğŸ¯ Complete the API error handling       â”‚â”‚
â”‚   â”‚   â”œâ”€ ğŸ‘¤ UserCron:alice [YOU]    â”‚ â”‚ 2. ğŸ’¡ Consider using team's retry-logic     â”‚â”‚
â”‚   â”‚   â”‚   â”œâ”€ ğŸ’­ Thinking...         â”‚ â”‚ 3. ğŸ”® Write tests (reduces bugs by 40%)     â”‚â”‚
â”‚   â”‚   â”‚   â””â”€ 2 suggestions ready    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚   â”‚   â”‚                             â”‚                                                â”‚
â”‚   â”‚   â””â”€ ğŸ‘¤ UserCron:bob            â”‚ â”Œâ”€ Recent Activity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚   â”‚       â””â”€ Idle (last: 5m ago)    â”‚ â”‚ [10:32] Created insight: "API patterns"     â”‚â”‚
â”‚   â”‚                                 â”‚ â”‚ [10:31] Analyzed trace: api_handler_v3      â”‚â”‚
â”‚   â””â”€â–¼ ğŸ‘¥ TeamCron:design            â”‚ â”‚ [10:30] Cycle started                       â”‚â”‚
â”‚       â””â”€ ğŸ‘¤ UserCron:carol          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â””â”€ 1 insight ready        â”‚                                                â”‚
â”‚                                     â”‚ â”Œâ”€ Interactive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ [r] Refresh  [q] Quit               â”‚ â”‚ > Ask your cron: _                          â”‚â”‚
â”‚                                     â”‚ â”‚                                              â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- **Left Panel**: Live tree of all cron processes with activity summaries
- **Right Panel**: Detailed view of selected cron
- **Interactive Mode**: Chat with your UserCron to ask questions or give directions
- **Read-Only Mode**: View other crons' activity (team/system) without interaction

```bash
# Launch the cron terminal
python llmos/boot.py terminal --user alice --team engineering
```

---

## The Evolution Journey

When you use LLM OS, your knowledge flows through a continuous evolution cycle:

```mermaid
graph LR
    subgraph Execute["1ï¸âƒ£ Execute"]
        Task["Run a task"]
        Trace["Create trace"]
    end

    subgraph Learn["2ï¸âƒ£ Learn"]
        Pattern["Detect pattern"]
        Match["Semantic match"]
    end

    subgraph Evolve["3ï¸âƒ£ Evolve"]
        Analyze["Cron analyzes"]
        Propose["Propose changes"]
        Apply["Apply evolution"]
    end

    subgraph Promote["4ï¸âƒ£ Promote"]
        User2["User â†’ Team"]
        Team2["Team â†’ System"]
    end

    Task --> Trace --> Pattern --> Match
    Match --> Analyze --> Propose --> Apply
    Apply --> User2 --> Team2
    Team2 -.-> Task

    style Execute fill:#3b82f6,color:#fff
    style Learn fill:#8b5cf6,color:#fff
    style Evolve fill:#10b981,color:#fff
    style Promote fill:#f59e0b,color:#fff
```

### A Concrete Example

```
Day 1: You create a Python calculator
       â†’ Trace saved to User Volume

Day 2: You create another calculator
       â†’ UserCron notices: "Pattern detected!"
       â†’ Insight generated: "Calculator tasks are common"

Day 5: Fifth calculator request
       â†’ UserCron proposes: "Crystallize into tool?"
       â†’ Tool created: calc_generator.py
       â†’ Notification: "New tool available!"

Day 10: Your teammate creates a calculator
        â†’ TeamCron notices: "Alice's tool works great"
        â†’ Tool promoted to Team Volume
        â†’ Team notification: "New team tool!"

Day 30: Multiple teams use the tool
        â†’ SystemCron promotes to System Volume
        â†’ Now available to everyone, forever
```

---

## On-Demand Agent Creation

LLM OS can **automatically create specialized agents** when you need them:

```bash
# First time running a quantum simulation?
python llmos/boot.py "Orchestrate VQE simulation with specialized agents"

# LLM OS automatically:
# 1. Plans the task and identifies needed agents
# 2. Creates ansatz-designer, optimizer-agent, vqe-executor
# 3. Saves them to workspace/agents/ for future use
# 4. Executes the multi-agent workflow
```

**No manual setup required.** The system designs domain-appropriate agents on-the-fly, solves the "cold-start" problem, and agents are reusable for future tasks.

---

## Quick Start

```bash
# Install
git clone https://github.com/EvolvingAgentsLabs/llmunix.git
cd llmunix
pip install -r requirements.txt
export ANTHROPIC_API_KEY="your-key"

# Run
python llmos/boot.py interactive
```

### Start with Crons

```python
from llmos.boot import LLMOS

async def main():
    os = LLMOS()
    await os.boot()

    # Start background evolution for your user
    os.kernel.start_crons(user_id="alice", team_id="engineering")

    # Work normally - crons evolve in the background
    await os.execute("Create a Python calculator")

    # Check what the crons discovered
    notifications = os.kernel.get_cron_notifications()
    for n in notifications:
        print(f"ğŸ“¬ {n['title']}: {n['description']}")

    await os.shutdown()
```

---

## How the Mechanisms Work

The cron and volume system is enabled by several underlying mechanisms:

```mermaid
graph TB
    subgraph Core["ğŸ¯ Core Feature"]
        Crons["Sentience Crons"]
        Volumes["Volume Architecture"]
        Observe["Observability Hub"]
    end

    subgraph Enable["âš™ï¸ Enabling Mechanisms"]
        Sentience["Sentience Layer"]
        Learning["Learning System"]
        Evolution["Evolution Engine"]
        Agents["Adaptive Agents"]
    end

    Sentience -->|"state-aware decisions"| Crons
    Learning -->|"traces to analyze"| Crons
    Evolution -->|"propose changes"| Crons
    Agents -->|"execute analysis"| Crons

    Crons --> Volumes
    Crons --> Observe

    style Core fill:#6366f1,color:#fff
    style Enable fill:#64748b,color:#fff
```

| Mechanism | What it enables |
|-----------|-----------------|
| **Sentience Layer** | Crons make state-aware decisions (curiosity, safety, energy) |
| **Learning System** | Traces provide the data crons analyze |
| **Evolution Engine** | Proposes how artifacts should change |
| **Adaptive Agents** | Execute the analysis intelligently |
| **On-Demand Agent Creation** | Auto-creates specialized agents when needed |

---

## Project Structure

```
llmunix/
â”œâ”€â”€ llmos/kernel/
â”‚   â”œâ”€â”€ sentience_cron.py    # ğŸ¤– UserCron, TeamCron, SystemCron
â”‚   â”œâ”€â”€ volumes.py           # ğŸ“¦ Volume architecture
â”‚   â”œâ”€â”€ observability.py     # ğŸ“Š Event tracking & notifications
â”‚   â”œâ”€â”€ evolution.py         # âœ¨ Artifact evolution engine
â”‚   â”œâ”€â”€ sentience.py         # ğŸ§  Internal state management
â”‚   â””â”€â”€ cognitive_kernel.py  # ğŸ›ï¸ Coordination layer
â”œâ”€â”€ workspace/
â”‚   â””â”€â”€ volumes/             # ğŸ“ Artifact storage
â”‚       â”œâ”€â”€ users/           #    â””â”€â”€ Per-user volumes
â”‚       â”œâ”€â”€ teams/           #    â””â”€â”€ Per-team volumes
â”‚       â””â”€â”€ system/          #    â””â”€â”€ Global volume
â””â”€â”€ examples/
```

---

## Why This Matters

Traditional AI systems are **stateless** - they don't remember, don't learn, don't improve.

LLM OS is **living** - it:

- **Remembers** every successful pattern
- **Learns** from repetition and failure
- **Improves** artifacts continuously
- **Shares** knowledge across boundaries
- **Reports** everything it does

The result: an AI that gets better at helping you, automatically, while you sleep.

---

## Learn More

- **[Architecture Guide](ARCHITECTURE.md)** - Deep dive into all components
- **[Examples](examples/)** - Production-ready implementations

---

<div align="center">

**[Evolving Agents Labs](https://github.com/EvolvingAgentsLabs)**

*Building AI that evolves*

</div>
