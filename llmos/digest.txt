Directory structure:
â””â”€â”€ llmos/
    â”œâ”€â”€ boot.py
    â”œâ”€â”€ environment.yml
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ examples/
    â”‚   â””â”€â”€ terminal_demo.py
    â”œâ”€â”€ execution/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ mcp_tools.py
    â”‚   â”œâ”€â”€ ptc.py
    â”‚   â”œâ”€â”€ tool_examples.py
    â”‚   â”œâ”€â”€ tool_search.py
    â”‚   â””â”€â”€ __pycache__/
    â”œâ”€â”€ interfaces/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ cortex.py
    â”‚   â”œâ”€â”€ dispatcher.py
    â”‚   â”œâ”€â”€ orchestrator.py
    â”‚   â”œâ”€â”€ sdk_client.py
    â”‚   â””â”€â”€ __pycache__/
    â”œâ”€â”€ kernel/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ agent_factory.py
    â”‚   â”œâ”€â”€ agent_loader.py
    â”‚   â”œâ”€â”€ agent_patterns.py
    â”‚   â”œâ”€â”€ bus.py
    â”‚   â”œâ”€â”€ cognitive_kernel.py
    â”‚   â”œâ”€â”€ component_registry.py
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ dynamic_agents.py
    â”‚   â”œâ”€â”€ evolution.py
    â”‚   â”œâ”€â”€ hooks.py
    â”‚   â”œâ”€â”€ inner_monologue.py
    â”‚   â”œâ”€â”€ mode_strategies.py
    â”‚   â”œâ”€â”€ observability.py
    â”‚   â”œâ”€â”€ project_manager.py
    â”‚   â”œâ”€â”€ scheduler.py
    â”‚   â”œâ”€â”€ sentience.py
    â”‚   â”œâ”€â”€ sentience_cron.py
    â”‚   â”œâ”€â”€ sentience_hooks.py
    â”‚   â”œâ”€â”€ service_factory.py
    â”‚   â”œâ”€â”€ state_manager.py
    â”‚   â”œâ”€â”€ swarm_coordinator.py
    â”‚   â”œâ”€â”€ token_economy.py
    â”‚   â”œâ”€â”€ verification.py
    â”‚   â”œâ”€â”€ volumes.py
    â”‚   â”œâ”€â”€ watchdog.py
    â”‚   â”œâ”€â”€ __pycache__/
    â”‚   â””â”€â”€ terminal/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ app.py
    â”‚       â”œâ”€â”€ detail.py
    â”‚       â”œâ”€â”€ input_handler.py
    â”‚       â”œâ”€â”€ interaction.py
    â”‚       â”œâ”€â”€ llmos_data_provider.py
    â”‚       â”œâ”€â”€ models.py
    â”‚       â”œâ”€â”€ tree.py
    â”‚       â”œâ”€â”€ ui.py
    â”‚       â”œâ”€â”€ __pycache__/
    â”‚       â”œâ”€â”€ styles/
    â”‚       â”‚   â””â”€â”€ mc_blue.tcss
    â”‚       â””â”€â”€ widgets/
    â”‚           â”œâ”€â”€ __init__.py
    â”‚           â”œâ”€â”€ activity_log.py
    â”‚           â”œâ”€â”€ chat_panel.py
    â”‚           â”œâ”€â”€ cron_tree.py
    â”‚           â”œâ”€â”€ detail_tabs.py
    â”‚           â”œâ”€â”€ suggestion_list.py
    â”‚           â”œâ”€â”€ thinking_view.py
    â”‚           â””â”€â”€ __pycache__/
    â”œâ”€â”€ memory/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ cross_project_sdk.py
    â”‚   â”œâ”€â”€ query_sdk.py
    â”‚   â”œâ”€â”€ sdk_memory.py
    â”‚   â”œâ”€â”€ semantic_db.py
    â”‚   â”œâ”€â”€ store.py
    â”‚   â”œâ”€â”€ store_sdk.py
    â”‚   â”œâ”€â”€ trace_analyzer.py
    â”‚   â”œâ”€â”€ traces.py
    â”‚   â”œâ”€â”€ traces_sdk.py
    â”‚   â””â”€â”€ __pycache__/
    â”œâ”€â”€ plugins/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ example_tools.py
    â”‚   â”œâ”€â”€ system_tools.py
    â”‚   â”œâ”€â”€ __pycache__/
    â”‚   â””â”€â”€ generated/
    â”‚       â””â”€â”€ __init__.py
    â”œâ”€â”€ tests/
    â”‚   â”œâ”€â”€ test_dynamic_agents.py
    â”‚   â””â”€â”€ __pycache__/
    â”œâ”€â”€ workspace/
    â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â”œâ”€â”€ AnsatzDesigner.md
    â”‚   â”‚   â”œâ”€â”€ OptimizerAgent.md
    â”‚   â”‚   â””â”€â”€ VqeExecutor.md
    â”‚   â”œâ”€â”€ memories/
    â”‚   â”‚   â”œâ”€â”€ facts/
    â”‚   â”‚   â”œâ”€â”€ insights/
    â”‚   â”‚   â”œâ”€â”€ projects/
    â”‚   â”‚   â”œâ”€â”€ sessions/
    â”‚   â”‚   â””â”€â”€ traces/
    â”‚   â””â”€â”€ projects/
    â”‚       â”œâ”€â”€ Project_i_need_to/
    â”‚       â”‚   â”œâ”€â”€ README.md
    â”‚       â”‚   â”œâ”€â”€ project.json
    â”‚       â”‚   â”œâ”€â”€ requirements.txt
    â”‚       â”‚   â”œâ”€â”€ components/
    â”‚       â”‚   â”‚   â”œâ”€â”€ agents/
    â”‚       â”‚   â”‚   â””â”€â”€ tools/
    â”‚       â”‚   â”œâ”€â”€ examples/
    â”‚       â”‚   â”œâ”€â”€ input/
    â”‚       â”‚   â”œâ”€â”€ memory/
    â”‚       â”‚   â”‚   â”œâ”€â”€ long_term/
    â”‚       â”‚   â”‚   â””â”€â”€ short_term/
    â”‚       â”‚   â”œâ”€â”€ notebooks/
    â”‚       â”‚   â”œâ”€â”€ output/
    â”‚       â”‚   â”œâ”€â”€ src/
    â”‚       â”‚   â”œâ”€â”€ state/
    â”‚       â”‚   â”‚   â”œâ”€â”€ constraints.json
    â”‚       â”‚   â”‚   â”œâ”€â”€ context.md
    â”‚       â”‚   â”‚   â”œâ”€â”€ history.md
    â”‚       â”‚   â”‚   â”œâ”€â”€ plan.md
    â”‚       â”‚   â”‚   â””â”€â”€ variables.json
    â”‚       â”‚   â””â”€â”€ tests/
    â”‚       â””â”€â”€ Project_perform_vqe_simulation/
    â”‚           â”œâ”€â”€ README.md
    â”‚           â”œâ”€â”€ pauli_z_hamiltonian.py
    â”‚           â”œâ”€â”€ pauli_z_quantum_libs.py
    â”‚           â”œâ”€â”€ project.json
    â”‚           â”œâ”€â”€ variational_ansatz.py
    â”‚           â”œâ”€â”€ variational_ansatz_quantum_libs.py
    â”‚           â”œâ”€â”€ components/
    â”‚           â”‚   â”œâ”€â”€ agents/
    â”‚           â”‚   â””â”€â”€ tools/
    â”‚           â”œâ”€â”€ input/
    â”‚           â”œâ”€â”€ memory/
    â”‚           â”‚   â”œâ”€â”€ long_term/
    â”‚           â”‚   â””â”€â”€ short_term/
    â”‚           â”œâ”€â”€ output/
    â”‚           â”‚   â”œâ”€â”€ pauli_z_reference.txt
    â”‚           â”‚   â””â”€â”€ pauli_z_summary.md
    â”‚           â””â”€â”€ state/
    â”‚               â”œâ”€â”€ constraints.json
    â”‚               â”œâ”€â”€ context.md
    â”‚               â”œâ”€â”€ history.md
    â”‚               â”œâ”€â”€ plan.md
    â”‚               â””â”€â”€ variables.json
    â””â”€â”€ .claude/
        â””â”€â”€ settings.local.json

================================================
File: boot.py
================================================
#!/usr/bin/env python3
"""
LLM OS (llmos) - Boot Entry Point
Based on Claude Agent SDK

This is the main entry point for the LLM Operating System.
Treats the LLM as the CPU, Python as the motherboard, and tokens as energy.
"""

import asyncio
import sys
from pathlib import Path
from typing import Optional

from kernel.bus import EventBus
from kernel.scheduler import Scheduler
from kernel.watchdog import Watchdog
from kernel.project_manager import ProjectManager, Project
from kernel.agent_factory import AgentFactory
from kernel.component_registry import ComponentRegistry
from memory.store_sdk import MemoryStore
from memory.traces_sdk import TraceManager
from memory.query_sdk import MemoryQueryInterface
from memory.cross_project_sdk import CrossProjectLearning
from interfaces.dispatcher import Dispatcher
from kernel.token_economy import TokenEconomy
from kernel.config import LLMOSConfig
from kernel.service_factory import (
    create_event_bus,
    create_token_economy,
    create_scheduler,
    create_watchdog,
    create_memory_store,
    create_trace_manager,
    create_memory_query,
    create_project_manager,
    create_agent_factory,
    create_component_registry,
    create_cross_project_learning,
    create_dispatcher,
)


class LLMOS:
    """
    The LLM Operating System

    Separates Cognitive Compute (LLM) from Somatic Compute (Python)
    Managed by a strict Token Economy.

    Now with Phase 2 capabilities:
    - Project management (llmunix-style)
    - Dynamic agent creation
    - Multi-agent orchestration
    - Component registry
    - Memory query interface
    """

    def __init__(
        self,
        budget_usd: float = 10.0,
        workspace: Optional[Path] = None,
        project_name: Optional[str] = None,
        config: Optional[LLMOSConfig] = None,
        # Optional dependency injection (for testing)
        event_bus: Optional[EventBus] = None,
        token_economy: Optional[TokenEconomy] = None,
        scheduler: Optional[Scheduler] = None,
        watchdog: Optional[Watchdog] = None,
        memory_store: Optional[MemoryStore] = None,
        trace_manager: Optional[TraceManager] = None,
        memory_query: Optional[MemoryQueryInterface] = None,
        project_manager: Optional[ProjectManager] = None,
        agent_factory: Optional[AgentFactory] = None,
        component_registry: Optional[ComponentRegistry] = None,
        cross_project_learning: Optional[CrossProjectLearning] = None,
        dispatcher: Optional[Dispatcher] = None,
    ):
        """
        Initialize the LLM OS

        Args:
            budget_usd: Token budget in USD (ignored if config provided)
            workspace: Workspace directory (defaults to ./workspace)
            project_name: Optional project name (creates/loads project)
            config: Optional LLMOSConfig instance (overrides other params)

            # Optional dependency injection (for testing):
            event_bus: Event bus instance
            token_economy: Token economy instance
            scheduler: Scheduler instance
            watchdog: Watchdog instance
            memory_store: Memory store instance
            trace_manager: Trace manager instance
            memory_query: Memory query interface instance
            project_manager: Project manager instance
            agent_factory: Agent factory instance
            component_registry: Component registry instance
            cross_project_learning: Cross-project learning instance
            dispatcher: Dispatcher instance

        Example:
            # Simple usage (backward compatible)
            os = LLMOS(budget_usd=10.0)

            # With configuration preset
            config = LLMOSConfig.production()
            os = LLMOS(config=config)

            # With dependency injection (testing)
            os = LLMOS(
                event_bus=mock_event_bus,
                token_economy=mock_token_economy
            )
        """
        # Use config or create from parameters
        if config is None:
            config = LLMOSConfig(
                workspace=workspace or Path("./workspace"),
                kernel=__import__('kernel.config', fromlist=['KernelConfig']).KernelConfig(
                    budget_usd=budget_usd
                )
            )

        self.config = config
        self.workspace = config.workspace
        self.workspace.mkdir(exist_ok=True)

        # Initialize kernel components (use injected or create defaults)
        self.event_bus = event_bus or create_event_bus()
        self.token_economy = token_economy or create_token_economy(config.kernel.budget_usd)
        self.scheduler = scheduler or create_scheduler(self.event_bus)
        self.watchdog = watchdog or create_watchdog(self.event_bus)

        # Initialize memory components (use injected or create defaults)
        self.memory_store = memory_store or create_memory_store(self.workspace)
        self.trace_manager = trace_manager or create_trace_manager(
            self.workspace,
            enable_llm_matching=config.memory.enable_llm_matching
        )
        self.memory_query = memory_query or create_memory_query(
            self.trace_manager,
            self.memory_store
        )

        # Initialize Phase 2 components (use injected or create defaults)
        self.project_manager = project_manager or create_project_manager(self.workspace)
        self.agent_factory = agent_factory or create_agent_factory(self.workspace)
        self.component_registry = component_registry or create_component_registry()
        self.cross_project_learning = cross_project_learning or create_cross_project_learning(
            self.project_manager,
            self.workspace
        )

        # Register built-in agents
        self._register_builtin_agents()

        # Create/load project if specified
        self.current_project: Optional[Project] = None
        if project_name:
            self.current_project = self.project_manager.create_project(project_name)

        # Initialize dispatcher (use injected or create default)
        self.dispatcher = dispatcher or create_dispatcher(
            event_bus=self.event_bus,
            token_economy=self.token_economy,
            memory_store=self.memory_store,
            trace_manager=self.trace_manager,
            project_manager=self.project_manager,
            workspace=self.workspace,
            config=self.config
        )

        self._running = False

    def _register_builtin_agents(self):
        """Register built-in system agents and tools"""
        from kernel.agent_factory import SYSTEM_AGENT_TEMPLATE

        # Register system agent
        self.component_registry.register_agent(SYSTEM_AGENT_TEMPLATE)

        # Register any custom agents from agents/ directory
        for agent_spec in self.agent_factory.list_agents():
            self.component_registry.register_agent(agent_spec)

        # Import system tools to make them available
        # (Hybrid Architecture: enables self-modification)
        try:
            import plugins.system_tools
            print("ðŸ”§ Loaded system tools (create_agent, list_agents, modify_agent)")
        except ImportError as e:
            print(f"âš ï¸  Could not load system tools: {e}")

    async def boot(self):
        """Boot the operating system"""
        print("ðŸš€ Booting LLM OS (Phase 2 - Claude SDK Memory)...")
        print(f"ðŸ’° Token Budget: ${self.token_economy.balance:.2f}")
        print(f"ðŸ“ Workspace: {self.workspace.absolute()}")
        print(f"ðŸ’¾ Memory: /memories (Claude SDK file-based)")

        if self.current_project:
            print(f"ðŸ“‚ Current Project: {self.current_project.name}")

        # Show memory stats
        mem_stats = self.memory_query.get_memory_statistics()
        print(f"ðŸ§  Traces: {mem_stats.get('total_traces', 0)} traces, "
              f"{mem_stats.get('high_confidence_count', 0)} high-confidence, "
              f"{mem_stats.get('facts_count', 0)} facts")

        # Show available agents
        agents = self.component_registry.list_agents()
        print(f"ðŸ¤– Agents: {len(agents)} registered")

        print()

        # Start kernel components
        await self.scheduler.start()
        await self.watchdog.start()

        self._running = True
        print("âœ… LLM OS Ready (Learner | Follower | Orchestrator modes available)")
        print()

    async def execute(
        self,
        goal: str,
        mode: str = "AUTO",
        project_name: Optional[str] = None,
        max_cost_usd: float = 5.0
    ):
        """
        Execute a goal using Learner/Follower/Orchestrator pattern

        Args:
            goal: Natural language goal to execute
            mode: "AUTO" (auto-detect), "LEARNER", "FOLLOWER", or "ORCHESTRATOR"
            project_name: Optional project name (creates if doesn't exist)
            max_cost_usd: Maximum cost budget for execution

        Returns:
            Result dictionary
        """
        if not self._running:
            raise RuntimeError("OS not booted. Call boot() first.")

        print(f"ðŸŽ¯ Goal: {goal}")

        # Get/create project if specified
        project = None
        if project_name:
            project = self.project_manager.get_project(project_name)
            if not project:
                project = self.project_manager.create_project(project_name)
                print(f"ðŸ“‚ Created project: {project.name}")
        elif self.current_project:
            project = self.current_project

        # Get memory insights
        recommendations = await self.memory_query.get_recommendations(goal)
        if recommendations:
            print("\nðŸ’¡ Memory Recommendations:")
            for rec in recommendations[:3]:  # Show top 3
                print(f"   - {rec}")

        # Get cross-project insights
        cross_project_recs = await self.cross_project_learning.get_cross_project_recommendations(
            current_project=project,
            goal=goal
        )
        if cross_project_recs:
            print("\nðŸŒ Cross-Project Insights:")
            for rec in cross_project_recs[:3]:  # Show top 3
                print(f"   - {rec}")

        print()

        # Dispatch to appropriate mode
        result = await self.dispatcher.dispatch(
            goal=goal,
            mode=mode,
            project=project,
            max_cost_usd=max_cost_usd
        )

        return result

    def create_project(self, name: str, description: str = "") -> Project:
        """
        Create a new project

        Args:
            name: Project name
            description: Project description

        Returns:
            Project instance
        """
        project = self.project_manager.create_project(name, description)
        self.current_project = project
        return project

    def set_project(self, name: str):
        """
        Set current project

        Args:
            name: Project name
        """
        project = self.project_manager.get_project(name)
        if project:
            self.current_project = project
        else:
            raise ValueError(f"Project {name} not found")

    def list_projects(self):
        """List all projects"""
        return self.project_manager.list_projects()

    def create_agent(self, **kwargs):
        """
        Create a new agent

        Args:
            **kwargs: Agent specification parameters

        Returns:
            AgentSpec instance
        """
        agent = self.agent_factory.create_agent(**kwargs)
        self.component_registry.register_agent(agent)
        return agent

    def list_agents(self, **kwargs):
        """
        List registered agents

        Args:
            **kwargs: Filter parameters

        Returns:
            List of AgentSpec instances
        """
        return self.component_registry.list_agents(**kwargs)

    async def get_cross_project_insights(self, **kwargs):
        """
        Get cross-project insights

        Args:
            **kwargs: Filter parameters for insights

        Returns:
            List of CrossProjectInsight instances
        """
        return await self.cross_project_learning.analyze_common_patterns(**kwargs)

    async def get_reusable_agents(self, **kwargs):
        """
        Get reusable agent patterns from cross-project analysis

        Args:
            **kwargs: Filter parameters

        Returns:
            List of ReusableAgent instances
        """
        return await self.cross_project_learning.identify_reusable_agents(**kwargs)

    async def get_project_summary(self, project_name: str):
        """
        Get learning summary for a project

        Args:
            project_name: Project name

        Returns:
            Dictionary with project insights
        """
        project = self.project_manager.get_project(project_name)
        if not project:
            raise ValueError(f"Project {project_name} not found")

        return await self.cross_project_learning.get_project_learning_summary(project)

    async def shutdown(self):
        """Shutdown the operating system"""
        print()
        print("ðŸ›‘ Shutting down LLM OS...")

        self._running = False

        # Stop kernel components
        await self.scheduler.stop()
        await self.watchdog.stop()

        # Save state
        print(f"ðŸ’¾ Final Balance: ${self.token_economy.balance:.2f}")
        print(f"ðŸ“Š Total Spent: ${sum(log.cost for log in self.token_economy.spend_log):.2f}")

        print("âœ… Shutdown complete")


async def run_terminal(
    user_id: str,
    team_id: Optional[str] = None,
    use_real_data: bool = True,
    ui_mode: str = "textual"
):
    """
    Run the Cron Terminal UI with real LLMOS data.

    Args:
        user_id: User identifier
        team_id: Team identifier
        use_real_data: Connect to real LLMOS components (vs mock data)
        ui_mode: "textual" (MC-style TUI) or "legacy" (basic ANSI)
    """
    print("ðŸ–¥ï¸  Starting Cron Terminal...")
    print(f"ðŸ‘¤ User: {user_id}")
    if team_id:
        print(f"ðŸ‘¥ Team: {team_id}")
    print(f"ðŸŽ¨ UI Mode: {ui_mode}")

    # Initialize LLMOS components for real data
    data_provider = None
    status_callback = None
    events_callback = None
    suggestions_callback = None
    cron_callback = None

    if use_real_data:
        print("ðŸ“Š Connecting to LLMOS data...")

        from kernel.terminal.llmos_data_provider import LLMOSDataProvider
        from memory.traces_sdk import TraceManager
        from memory.store_sdk import MemoryStore
        from kernel.token_economy import TokenEconomy

        workspace = Path("./workspace")
        workspace.mkdir(exist_ok=True)

        # Initialize components
        trace_manager = TraceManager(
            memories_dir=workspace / "memories",
            workspace=workspace,
            enable_llm_matching=False  # Disable for terminal (faster)
        )
        memory_store = MemoryStore(workspace)
        token_economy = TokenEconomy(budget_usd=10.0)

        # Create data provider
        data_provider = LLMOSDataProvider(
            trace_manager=trace_manager,
            memory_store=memory_store,
            token_economy=token_economy,
            workspace=workspace
        )

        # Set callbacks
        status_callback = data_provider.get_system_status
        events_callback = data_provider.get_events
        suggestions_callback = data_provider.get_suggestions
        cron_callback = data_provider.handle_user_message

        # Show initial stats
        trace_stats = trace_manager.get_statistics()
        memory_stats = memory_store.get_statistics()
        print(f"ðŸ§  Traces: {trace_stats.get('total_traces', 0)} | Facts: {memory_stats.get('facts_count', 0)} | Insights: {memory_stats.get('insights_count', 0)}")

    print()

    # Run the appropriate UI
    if ui_mode == "textual":
        # Textual UI (Midnight Commander style)
        try:
            from kernel.terminal.app import CronTerminalApp
        except ImportError:
            print("âŒ Textual UI requires the 'textual' package.")
            print("   Install with: pip install textual")
            print("   Or use --ui legacy for the basic terminal.")
            return

        print("ðŸŽ¨ Starting Midnight Commander-style UI...")
        print()
        print("FUNCTION KEYS:")
        print("  F1=Help  F5=Refresh  F10=Quit")
        print()
        print("NAVIGATION:")
        print("  Tab=Switch panels  j/k=Up/Down  Space=Expand")
        print()

        app = CronTerminalApp(
            user_id=user_id,
            team_id=team_id or "default",
            status_callback=status_callback,
            events_callback=events_callback,
            suggestions_callback=suggestions_callback,
            cron_callback=cron_callback,
        )
        await app.run_async()

    else:
        # Legacy UI (basic ANSI)
        from kernel.terminal import CronTerminal

        print("CONTROLS:")
        print("  â†‘/â†“     Navigate tree or scroll")
        print("  â†/â†’     Collapse/expand nodes")
        print("  Tab     Switch panels")
        print("  Enter   Select / send message")
        print("  r       Refresh data")
        print("  q       Quit")
        print()

        # Small delay to let user read the instructions
        import time
        time.sleep(2)

        # Create terminal with callbacks
        terminal = CronTerminal(
            user_id=user_id,
            team_id=team_id or "default",
            status_callback=status_callback,
            events_callback=events_callback,
            suggestions_callback=suggestions_callback,
            cron_callback=cron_callback
        )

        await terminal.run()


async def main():
    """Main entry point"""
    # Handle terminal mode separately (doesn't need full OS boot)
    if len(sys.argv) > 1 and sys.argv[1] == "terminal":
        # Parse terminal arguments
        user_id = "user"
        team_id = None
        ui_mode = "textual"  # Default to Textual (MC-style)

        # Simple argument parsing
        args = sys.argv[2:]
        i = 0
        while i < len(args):
            if args[i] == "--user" and i + 1 < len(args):
                user_id = args[i + 1]
                i += 2
            elif args[i] == "--team" and i + 1 < len(args):
                team_id = args[i + 1]
                i += 2
            elif args[i] == "--ui" and i + 1 < len(args):
                ui_mode = args[i + 1]
                i += 2
            else:
                i += 1

        await run_terminal(user_id, team_id, ui_mode=ui_mode)
        return

    # Create and boot the OS
    os = LLMOS(budget_usd=10.0)
    await os.boot()

    try:
        # Interactive mode
        if len(sys.argv) > 1 and sys.argv[1] == "interactive":
            print("ðŸ“ Interactive Mode (type 'exit' to quit)")
            print()

            while True:
                try:
                    goal = input("llmos> ")
                    if goal.lower() in ["exit", "quit"]:
                        break
                    if goal.strip():
                        await os.execute(goal)
                except KeyboardInterrupt:
                    break

        # Single command mode
        elif len(sys.argv) > 1:
            # Parse --mode flag if present
            args = sys.argv[1:]
            mode = "AUTO"
            goal_parts = []

            i = 0
            while i < len(args):
                if args[i] == "--mode" and i + 1 < len(args):
                    mode = args[i + 1].upper()
                    i += 2
                else:
                    goal_parts.append(args[i])
                    i += 1

            goal = " ".join(goal_parts)
            await os.execute(goal, mode=mode)

        else:
            print("Usage:")
            print("  python boot.py interactive                              # Interactive mode")
            print("  python boot.py terminal --user NAME [--team TEAM]       # Cron Terminal (Textual)")
            print("  python boot.py terminal --user NAME --ui legacy         # Cron Terminal (Legacy)")
            print("  python boot.py terminal --user NAME --ui textual        # Cron Terminal (MC-style)")
            print("  python boot.py <goal>                                   # Execute single goal")
            print("  python boot.py <goal> --mode ORCHESTRATOR               # Execute with specific mode")
            print()
            print("Modes: AUTO, LEARNER, FOLLOWER, MIXED, CRYSTALLIZED, ORCHESTRATOR")

    finally:
        await os.shutdown()


if __name__ == "__main__":
    asyncio.run(main())



================================================
File: environment.yml
================================================
name: llmos
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.11
  - pip
  - pip:
    - claude-agent-sdk>=0.1.0
    - anyio>=4.0.0
    - pyyaml>=6.0
    - numpy>=1.24.0



================================================
File: requirements.txt
================================================
claude-agent-sdk>=0.1.0
anyio>=4.0.0
pyyaml>=6.0
numpy>=1.24.0
textual>=0.89.0



================================================
File: examples/terminal_demo.py
================================================
#!/usr/bin/env python3
"""
Cron Terminal Demo - Interactive Dashboard Tutorial

This demo shows the Cron Terminal with simulated real-time cron activity.
It demonstrates how UserCrons, TeamCrons, and SystemCron work together.

Usage:
    cd llmos
    python examples/terminal_demo.py

What you'll see:
    - Live cron status updates (thinking, analyzing, idle)
    - Suggestions appearing based on "analysis"
    - Activity log with recent events
    - Interactive chat with your personal cron
"""

import asyncio
import sys
import random
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from kernel.terminal import CronTerminal, TerminalConfig


# =============================================================================
# SIMULATED CRON DATA
# =============================================================================

class SimulatedCronSystem:
    """
    Simulates a real cron system with evolving state.

    In production, this would connect to the actual Sentience Cron system.
    For this demo, it generates realistic-looking data that changes over time.
    """

    def __init__(self, user_id: str, team_id: str):
        self.user_id = user_id
        self.team_id = team_id
        self.cycle_count = 0

        # Simulated state
        self.user_pending_notifications = 5
        self.team_pending_notifications = 3

        # Activity log
        self.events: List[Dict[str, Any]] = []
        self._generate_initial_events()

        # Suggestions
        self.suggestions: List[Dict[str, Any]] = []
        self._generate_initial_suggestions()

        # Thinking states cycle
        self.thinking_states = [
            {"action": "Reviewing your recent traces", "considering": ["Suggest caching pattern"]},
            {"action": "Analyzing code patterns", "patterns": [{"name": "API optimization", "count": 12}]},
            {"action": "Cross-referencing team insights", "cross_refs": ["bob's database work"]},
            {"action": "Evaluating improvement opportunities", "considering": ["Refactor auth module"]},
            {"action": "Idle - monitoring for changes", "considering": []},
        ]

    def _generate_initial_events(self):
        """Generate some initial activity events"""
        now = datetime.now()
        events = [
            {"event_type": "cron_started", "title": "UserCron started monitoring", "minutes_ago": 45},
            {"event_type": "artifact_created", "title": "Created trace: api_endpoint_handler", "minutes_ago": 30},
            {"event_type": "insight_generated", "title": "Found pattern: repeated null checks", "minutes_ago": 22},
            {"event_type": "suggestion_created", "title": "Suggested: Add input validation", "minutes_ago": 15},
            {"event_type": "cron_cycle_end", "title": "Analysis cycle completed", "minutes_ago": 5},
        ]

        for event in events:
            timestamp = now - timedelta(minutes=event["minutes_ago"])
            self.events.append({
                "event_type": event["event_type"],
                "title": event["title"],
                "timestamp": timestamp.isoformat(),
                "event_id": f"evt_{random.randint(1000, 9999)}"
            })

    def _generate_initial_suggestions(self):
        """Generate initial suggestions"""
        self.suggestions = [
            {
                "type": "immediate",
                "title": "Review pending code changes",
                "description": "3 files modified in last session need review",
                "confidence": 0.92,
                "source": "Based on your commit patterns"
            },
            {
                "type": "recommendation",
                "title": "Consider adding error handling",
                "description": "Found 5 functions without try/catch blocks",
                "confidence": 0.78,
                "source": "Code analysis"
            },
            {
                "type": "prediction",
                "title": "You might work on auth next",
                "description": "Based on your recent file access patterns",
                "confidence": 0.65,
                "source": "Behavioral analysis"
            }
        ]

    async def get_system_status(self) -> Dict[str, Any]:
        """
        Get current system status.

        This simulates what the real SystemCron.get_global_status() would return.
        """
        self.cycle_count += 1

        # Rotate through thinking states
        thinking_index = self.cycle_count % len(self.thinking_states)
        user_thinking = self.thinking_states[thinking_index]

        # Determine states based on cycle
        user_state = "thinking" if thinking_index < 4 else "idle"
        team_state = "analyzing" if self.cycle_count % 3 == 0 else "idle"
        system_state = "thinking" if self.cycle_count % 5 == 0 else "idle"

        # Occasionally add new events
        if self.cycle_count % 2 == 0:
            self._add_random_event()

        # Occasionally update suggestions
        if self.cycle_count % 4 == 0:
            self._rotate_suggestions()

        return {
            "system": {
                "status": system_state,
                "last_run": datetime.now().isoformat(),
                "current_thinking": {
                    "action": "Coordinating cross-team insights",
                    "patterns": [
                        {"name": "Shared utility functions", "count": 8},
                        {"name": "Common error patterns", "count": 5}
                    ]
                } if system_state == "thinking" else None
            },
            "teams": {
                self.team_id: {
                    "status": team_state,
                    "last_run": datetime.now().isoformat(),
                    "pending_notifications": self.team_pending_notifications,
                    "current_thinking": {
                        "action": f"Analyzing {self.team_id} team patterns",
                        "patterns": [{"name": "Code review bottleneck", "count": 3}]
                    } if team_state == "analyzing" else None,
                    "users": {
                        self.user_id: {
                            "status": user_state,
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": self.user_pending_notifications,
                            "current_task": "Monitoring your workspace" if user_state == "idle" else None,
                            "current_thinking": user_thinking if user_state == "thinking" else None
                        },
                        "bob": {
                            "status": "thinking" if self.cycle_count % 2 == 1 else "idle",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 2,
                            "current_task": "Optimizing database queries"
                        },
                        "carol": {
                            "status": "idle",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 0
                        }
                    }
                },
                "design": {
                    "status": "idle",
                    "last_run": datetime.now().isoformat(),
                    "pending_notifications": 1,
                    "users": {
                        "dave": {
                            "status": "idle",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 1
                        }
                    }
                }
            }
        }

    def _add_random_event(self):
        """Add a random event to simulate activity"""
        event_types = [
            ("artifact_created", "Created new trace"),
            ("insight_generated", "Discovered pattern"),
            ("cron_cycle_end", "Analysis cycle completed"),
            ("suggestion_created", "New suggestion available"),
        ]

        event_type, title = random.choice(event_types)
        self.events.insert(0, {
            "event_type": event_type,
            "title": f"{title}: {random.choice(['auth', 'api', 'utils', 'config'])}",
            "timestamp": datetime.now().isoformat(),
            "event_id": f"evt_{random.randint(1000, 9999)}"
        })

        # Keep only last 20 events
        self.events = self.events[:20]

    def _rotate_suggestions(self):
        """Rotate suggestions to simulate new insights"""
        new_suggestions = [
            {"type": "immediate", "title": "Run tests before commit", "confidence": 0.95},
            {"type": "recommendation", "title": "Update documentation", "confidence": 0.72},
            {"type": "creative", "title": "Try a different algorithm approach", "confidence": 0.55},
            {"type": "prediction", "title": "Likely to refactor soon", "confidence": 0.68},
        ]

        # Replace one random suggestion
        if self.suggestions:
            idx = random.randint(0, len(self.suggestions) - 1)
            self.suggestions[idx] = random.choice(new_suggestions)

    async def get_events(self, cron_id: str) -> List[Dict[str, Any]]:
        """Get events for a specific cron"""
        return self.events[:10]

    async def get_suggestions(self, cron_id: str) -> List[Dict[str, Any]]:
        """Get suggestions for a specific cron"""
        if cron_id == f"user:{self.user_id}":
            return self.suggestions
        return []

    async def send_to_cron(self, cron_id: str, message: str) -> str:
        """
        Send a message to a cron and get a response.

        This simulates the actual cron responding to user queries.
        """
        message_lower = message.lower()

        # Simulate intelligent responses
        if any(word in message_lower for word in ["status", "what are you doing", "working on"]):
            return f"ðŸ” I'm currently in cycle {self.cycle_count}. I've analyzed {len(self.events)} events and generated {len(self.suggestions)} suggestions for you."

        if any(word in message_lower for word in ["suggest", "what should", "next", "recommend"]):
            if self.suggestions:
                top = self.suggestions[0]
                return f"ðŸŽ¯ Top suggestion: {top['title']}\nConfidence: {top.get('confidence', 0.5):.0%}\n\nWant me to elaborate on this?"
            return "ðŸ¤” I'm still analyzing your patterns. Check back in a moment."

        if any(word in message_lower for word in ["analyze", "look at", "check", "review"]):
            self.cycle_count += 1  # Trigger analysis
            return "ðŸ” Starting analysis now. I'll update the suggestions panel when I find something interesting."

        if any(word in message_lower for word in ["help", "what can you do", "commands"]):
            return """ðŸ¤– I can help you with:

â€¢ **Suggestions**: Ask "what should I do next?"
â€¢ **Analysis**: Say "analyze my recent work"
â€¢ **Status**: Ask "what are you working on?"
â€¢ **Patterns**: Say "show me patterns"
â€¢ **Clear**: Say "clear notifications"

I'm always monitoring your workspace and learning from your patterns!"""

        if any(word in message_lower for word in ["pattern", "patterns", "found"]):
            return f"""ðŸ“Š Patterns I've found in your work:

1. **API optimization** - 12 similar traces
2. **Error handling gaps** - 5 locations
3. **Code duplication** - 3 modules

Want me to create improvement suggestions for any of these?"""

        if any(word in message_lower for word in ["clear", "dismiss", "notifications"]):
            self.user_pending_notifications = 0
            return "âœ… Cleared all notifications. I'll let you know when something new comes up."

        if any(word in message_lower for word in ["thank", "thanks", "great", "good"]):
            return "ðŸ˜Š Happy to help! Let me know if you need anything else."

        # Default response
        return f"ðŸ¤” I heard: \"{message[:50]}{'...' if len(message) > 50 else ''}\"\n\nTry asking me to 'suggest next steps' or 'analyze recent work'."


# =============================================================================
# DEMO RUNNER
# =============================================================================

async def run_demo():
    """Run the terminal demo with simulated data"""

    print("=" * 60)
    print("ðŸ–¥ï¸  CRON TERMINAL DEMO")
    print("=" * 60)
    print()
    print("This demo shows the Cron Terminal with live simulated data.")
    print()
    print("You are: alice (engineering team)")
    print()
    print("CONTROLS:")
    print("  â†‘/â†“     Navigate up/down in tree or scroll detail")
    print("  â†/â†’     Collapse/expand tree nodes")
    print("  Tab     Switch between tree and detail panels")
    print("  Enter   Select a cron / confirm in chat")
    print("  r       Manual refresh")
    print("  a       Toggle auto-refresh (5s interval)")
    print("  q       Quit")
    print()
    print("TRY THIS:")
    print("  1. Press â†“ to navigate to your cron (alice)")
    print("  2. Press Enter to see your detail panel")
    print("  3. Press Tab to switch to detail panel")
    print("  4. Type 'help' and press Enter to chat with your cron")
    print()
    print("Starting in 3 seconds...")
    print("=" * 60)

    await asyncio.sleep(3)

    # Create simulated system
    user_id = "alice"
    team_id = "engineering"
    sim = SimulatedCronSystem(user_id, team_id)

    # Create terminal with callbacks to simulated system
    terminal = CronTerminal(
        user_id=user_id,
        team_id=team_id,
        status_callback=sim.get_system_status,
        events_callback=sim.get_events,
        suggestions_callback=sim.get_suggestions,
        cron_callback=sim.send_to_cron,
        config=TerminalConfig(
            refresh_interval=5.0,  # Refresh every 5 seconds
            auto_refresh=True
        )
    )

    # Run the terminal
    await terminal.run()


async def run_quick_test():
    """Quick non-interactive test to verify everything works"""
    print("Running quick test...")

    user_id = "alice"
    team_id = "engineering"
    sim = SimulatedCronSystem(user_id, team_id)

    terminal = CronTerminal(
        user_id=user_id,
        team_id=team_id,
        status_callback=sim.get_system_status,
        events_callback=sim.get_events,
        suggestions_callback=sim.get_suggestions,
        cron_callback=sim.send_to_cron
    )

    # Refresh and render
    await terminal.refresh()

    # Select user's cron
    terminal.tree_view.select(f"user:{user_id}")
    status = await sim.get_system_status()
    await terminal._refresh_detail(f"user:{user_id}", status)

    # Render
    print(terminal.render())

    # Test chat
    print("\n" + "=" * 60)
    print("Testing chat interaction:")
    print("=" * 60)

    response = await sim.send_to_cron(f"user:{user_id}", "help")
    print(f"\nYou: help")
    print(f"Cron: {response}")

    response = await sim.send_to_cron(f"user:{user_id}", "what should I do next?")
    print(f"\nYou: what should I do next?")
    print(f"Cron: {response}")

    print("\nâœ… Quick test passed!")


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        asyncio.run(run_quick_test())
    else:
        asyncio.run(run_demo())



================================================
File: execution/__init__.py
================================================
"""
Execution Layer - Anthropic Advanced Tool Use Integration

This layer handles EFFICIENT EXECUTION of decisions made by the Learning Layer.

Architecture:
- Learning Layer (TraceManager, ModeStrategies) decides WHAT to do
- Execution Layer (this module) decides HOW to do it efficiently

Components:
- PTC (Programmatic Tool Calling): Execute tool sequences outside context
- Tool Search: On-demand tool discovery for novel scenarios
- Tool Examples: Auto-generated examples from successful traces

Beta Header: advanced-tool-use-2025-11-20
"""

# Lazy imports to avoid circular dependencies
def get_ptc_executor():
    from execution.ptc import PTCExecutor
    return PTCExecutor

def get_tool_search_engine():
    from execution.tool_search import ToolSearchEngine
    return ToolSearchEngine

def get_tool_example_generator():
    from execution.tool_examples import ToolExampleGenerator
    return ToolExampleGenerator

__all__ = [
    'get_ptc_executor',
    'get_tool_search_engine',
    'get_tool_example_generator'
]



================================================
File: execution/mcp_tools.py
================================================
"""
MCP-Inspired Tool Execution Framework for LLMOS

This module implements a Model Context Protocol (MCP) inspired interface
for tool orchestration, borrowed from Claude-Flow's architecture.

Key Features:
- 100+ orchestration tools (swarm_init, agent_spawn, task_orchestrate)
- Memory management tools
- Performance analysis tools
- Safe tool execution with validation
- Mesh topology for agent coordination

Inspired by Claude-Flow's MCP architecture (MIT License)
https://github.com/ruvnet/claude-flow
"""

from typing import Dict, Any, List, Optional, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import json
from pathlib import Path
import inspect


class ToolCategory(Enum):
    """Tool categories for organization"""
    SWARM = "swarm"
    AGENT = "agent"
    MEMORY = "memory"
    TASK = "task"
    ANALYSIS = "analysis"
    GITHUB = "github"
    SYSTEM = "system"


@dataclass
class ToolDefinition:
    """
    MCP Tool Definition

    Defines a tool's interface, validation rules, and execution context.
    """
    name: str
    description: str
    category: ToolCategory
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    func: Callable
    requires_approval: bool = False
    is_async: bool = True
    timeout_secs: float = 30.0
    retry_count: int = 0
    validation_rules: List[Callable] = field(default_factory=list)

    def __post_init__(self):
        """Auto-detect if function is async"""
        if inspect.iscoroutinefunction(self.func):
            self.is_async = True
        else:
            self.is_async = False


@dataclass
class ToolExecutionResult:
    """Result of tool execution"""
    success: bool
    output: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0
    tool_name: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)


class MCPToolRegistry:
    """
    MCP Tool Registry

    Central registry for all tools with categorization,
    search, and validation capabilities.

    Inspired by Claude-Flow's tool management system.
    """

    def __init__(self):
        self.tools: Dict[str, ToolDefinition] = {}
        self.categories: Dict[ToolCategory, List[str]] = {
            category: [] for category in ToolCategory
        }

    def register(
        self,
        name: str,
        func: Callable,
        description: str,
        category: ToolCategory,
        input_schema: Dict[str, Any],
        output_schema: Dict[str, Any] = None,
        requires_approval: bool = False,
        timeout_secs: float = 30.0,
        validation_rules: List[Callable] = None
    ) -> ToolDefinition:
        """
        Register a new tool

        Args:
            name: Tool name
            func: Tool function (sync or async)
            description: Tool description
            category: Tool category
            input_schema: JSON schema for inputs
            output_schema: JSON schema for outputs
            requires_approval: Whether tool requires human approval
            timeout_secs: Execution timeout
            validation_rules: List of validation functions

        Returns:
            ToolDefinition instance
        """
        tool_def = ToolDefinition(
            name=name,
            description=description,
            category=category,
            input_schema=input_schema,
            output_schema=output_schema or {},
            func=func,
            requires_approval=requires_approval,
            timeout_secs=timeout_secs,
            validation_rules=validation_rules or []
        )

        self.tools[name] = tool_def
        self.categories[category].append(name)

        return tool_def

    def get(self, name: str) -> Optional[ToolDefinition]:
        """Get tool by name"""
        return self.tools.get(name)

    def search(self, query: str, category: Optional[ToolCategory] = None) -> List[ToolDefinition]:
        """
        Search tools by description or name

        Args:
            query: Search query
            category: Optional category filter

        Returns:
            List of matching tool definitions
        """
        results = []
        query_lower = query.lower()

        for tool_name, tool_def in self.tools.items():
            # Filter by category if specified
            if category and tool_def.category != category:
                continue

            # Match by name or description
            if query_lower in tool_name.lower() or query_lower in tool_def.description.lower():
                results.append(tool_def)

        return results

    def get_by_category(self, category: ToolCategory) -> List[ToolDefinition]:
        """Get all tools in a category"""
        return [self.tools[name] for name in self.categories[category]]

    def get_statistics(self) -> Dict[str, Any]:
        """Get registry statistics"""
        return {
            "total_tools": len(self.tools),
            "by_category": {
                category.value: len(tools)
                for category, tools in self.categories.items()
            },
            "async_tools": sum(1 for t in self.tools.values() if t.is_async),
            "approval_required": sum(1 for t in self.tools.values() if t.requires_approval)
        }


class MCPToolExecutor:
    """
    MCP Tool Executor

    Executes tools with validation, timeout handling, and result tracking.
    Provides a safe execution environment inspired by Claude-Flow.
    """

    def __init__(
        self,
        registry: MCPToolRegistry,
        workspace: Optional[Path] = None,
        enable_validation: bool = True,
        enable_timeouts: bool = True
    ):
        self.registry = registry
        self.workspace = workspace or Path("./workspace")
        self.enable_validation = enable_validation
        self.enable_timeouts = enable_timeouts
        self.execution_history: List[ToolExecutionResult] = []

    async def execute(
        self,
        tool_name: str,
        inputs: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> ToolExecutionResult:
        """
        Execute a tool with validation and timeout handling

        Args:
            tool_name: Name of tool to execute
            inputs: Tool inputs
            context: Optional execution context

        Returns:
            ToolExecutionResult
        """
        import time
        start_time = time.time()

        # Get tool definition
        tool_def = self.registry.get(tool_name)
        if not tool_def:
            return ToolExecutionResult(
                success=False,
                error=f"Tool not found: {tool_name}",
                tool_name=tool_name
            )

        # Validate inputs
        if self.enable_validation:
            validation_error = self._validate_inputs(tool_def, inputs)
            if validation_error:
                return ToolExecutionResult(
                    success=False,
                    error=f"Validation failed: {validation_error}",
                    tool_name=tool_name
                )

        # Execute with timeout
        try:
            if self.enable_timeouts:
                if tool_def.is_async:
                    output = await asyncio.wait_for(
                        tool_def.func(**inputs),
                        timeout=tool_def.timeout_secs
                    )
                else:
                    # Run sync function in executor
                    loop = asyncio.get_event_loop()
                    output = await asyncio.wait_for(
                        loop.run_in_executor(None, lambda: tool_def.func(**inputs)),
                        timeout=tool_def.timeout_secs
                    )
            else:
                if tool_def.is_async:
                    output = await tool_def.func(**inputs)
                else:
                    output = tool_def.func(**inputs)

            execution_time = time.time() - start_time

            result = ToolExecutionResult(
                success=True,
                output=output,
                execution_time=execution_time,
                tool_name=tool_name,
                metadata={
                    "category": tool_def.category.value,
                    "context": context or {}
                }
            )

        except asyncio.TimeoutError:
            execution_time = time.time() - start_time
            result = ToolExecutionResult(
                success=False,
                error=f"Tool execution timed out after {tool_def.timeout_secs}s",
                execution_time=execution_time,
                tool_name=tool_name
            )

        except Exception as e:
            execution_time = time.time() - start_time
            result = ToolExecutionResult(
                success=False,
                error=f"Tool execution failed: {str(e)}",
                execution_time=execution_time,
                tool_name=tool_name
            )

        # Record execution
        self.execution_history.append(result)

        return result

    def _validate_inputs(
        self,
        tool_def: ToolDefinition,
        inputs: Dict[str, Any]
    ) -> Optional[str]:
        """
        Validate tool inputs against schema and custom rules

        Returns:
            Error message if validation fails, None otherwise
        """
        # Check required fields
        required = tool_def.input_schema.get("required", [])
        for field in required:
            if field not in inputs:
                return f"Missing required field: {field}"

        # Run custom validation rules
        for rule in tool_def.validation_rules:
            try:
                if not rule(inputs):
                    return f"Validation rule failed: {rule.__name__}"
            except Exception as e:
                return f"Validation error: {str(e)}"

        return None

    async def execute_sequence(
        self,
        tool_calls: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None,
        stop_on_failure: bool = True
    ) -> List[ToolExecutionResult]:
        """
        Execute a sequence of tool calls

        Args:
            tool_calls: List of {tool_name, inputs} dicts
            context: Shared execution context
            stop_on_failure: Stop sequence if any tool fails

        Returns:
            List of ToolExecutionResult
        """
        results = []

        for call in tool_calls:
            tool_name = call.get("tool_name") or call.get("name")
            inputs = call.get("inputs") or call.get("arguments", {})

            result = await self.execute(tool_name, inputs, context)
            results.append(result)

            if stop_on_failure and not result.success:
                break

        return results

    def get_execution_statistics(self) -> Dict[str, Any]:
        """Get execution statistics"""
        total = len(self.execution_history)
        if total == 0:
            return {
                "total_executions": 0,
                "success_rate": 0.0,
                "average_execution_time": 0.0
            }

        successes = sum(1 for r in self.execution_history if r.success)
        avg_time = sum(r.execution_time for r in self.execution_history) / total

        return {
            "total_executions": total,
            "success_rate": successes / total,
            "average_execution_time": avg_time,
            "failures": total - successes,
            "by_tool": self._get_tool_statistics()
        }

    def _get_tool_statistics(self) -> Dict[str, Dict[str, Any]]:
        """Get per-tool statistics"""
        tool_stats = {}

        for result in self.execution_history:
            if result.tool_name not in tool_stats:
                tool_stats[result.tool_name] = {
                    "executions": 0,
                    "successes": 0,
                    "total_time": 0.0
                }

            stats = tool_stats[result.tool_name]
            stats["executions"] += 1
            if result.success:
                stats["successes"] += 1
            stats["total_time"] += result.execution_time

        # Calculate derived metrics
        for tool_name, stats in tool_stats.items():
            stats["success_rate"] = stats["successes"] / stats["executions"]
            stats["average_time"] = stats["total_time"] / stats["executions"]

        return tool_stats


# ============================================================================
# CORE MCP TOOLS (Inspired by Claude-Flow)
# ============================================================================

async def swarm_init(
    swarm_name: str,
    goal: str,
    max_agents: int = 10,
    topology: str = "mesh"
) -> Dict[str, Any]:
    """
    Initialize a swarm of agents for coordinated task execution

    Inspired by Claude-Flow's swarm coordination system.

    Args:
        swarm_name: Name of the swarm
        goal: High-level goal for the swarm
        max_agents: Maximum number of agents
        topology: Agent topology (mesh, star, ring)

    Returns:
        Swarm metadata
    """
    return {
        "swarm_id": f"swarm_{swarm_name}",
        "status": "initialized",
        "goal": goal,
        "max_agents": max_agents,
        "topology": topology,
        "active_agents": []
    }


async def agent_spawn(
    swarm_id: str,
    agent_type: str,
    role: str,
    tools: List[str] = None
) -> Dict[str, Any]:
    """
    Spawn a new agent within a swarm

    Args:
        swarm_id: Target swarm
        agent_type: Type of agent (planner, coder, tester, etc.)
        role: Specific role description
        tools: List of tools this agent can use

    Returns:
        Agent metadata
    """
    return {
        "agent_id": f"agent_{agent_type}_{id(role)}",
        "swarm_id": swarm_id,
        "type": agent_type,
        "role": role,
        "tools": tools or [],
        "status": "ready"
    }


async def task_orchestrate(
    swarm_id: str,
    task: str,
    parallel: bool = False,
    max_time_secs: float = 300.0
) -> Dict[str, Any]:
    """
    Orchestrate task execution across swarm agents

    Args:
        swarm_id: Target swarm
        task: Task description
        parallel: Execute subtasks in parallel
        max_time_secs: Maximum execution time

    Returns:
        Orchestration result
    """
    return {
        "task_id": f"task_{id(task)}",
        "swarm_id": swarm_id,
        "task": task,
        "parallel": parallel,
        "status": "orchestrating",
        "subtasks": []
    }


async def memory_store(
    key: str,
    value: Any,
    category: str = "general",
    ttl_secs: Optional[float] = None
) -> Dict[str, Any]:
    """
    Store data in agent memory with optional TTL

    Args:
        key: Memory key
        value: Value to store
        category: Memory category
        ttl_secs: Time to live in seconds

    Returns:
        Storage confirmation
    """
    return {
        "key": key,
        "category": category,
        "stored": True,
        "ttl_secs": ttl_secs
    }


async def memory_retrieve(
    key: Optional[str] = None,
    category: Optional[str] = None,
    query: Optional[str] = None
) -> Dict[str, Any]:
    """
    Retrieve data from agent memory

    Args:
        key: Specific key to retrieve
        category: Filter by category
        query: Semantic search query

    Returns:
        Retrieved data
    """
    return {
        "key": key,
        "category": category,
        "results": []
    }


async def performance_analyze(
    target: str,
    metric_type: str = "all"
) -> Dict[str, Any]:
    """
    Analyze performance metrics

    Args:
        target: Target to analyze (agent, swarm, task)
        metric_type: Type of metrics (speed, quality, cost, all)

    Returns:
        Performance analysis
    """
    return {
        "target": target,
        "metric_type": metric_type,
        "metrics": {
            "execution_time": 0.0,
            "success_rate": 0.0,
            "cost_usd": 0.0
        }
    }


def create_default_mcp_registry() -> MCPToolRegistry:
    """
    Create a default MCP tool registry with core tools

    Returns:
        MCPToolRegistry with core tools registered
    """
    registry = MCPToolRegistry()

    # Swarm coordination tools
    registry.register(
        name="swarm_init",
        func=swarm_init,
        description="Initialize a swarm of agents for coordinated task execution",
        category=ToolCategory.SWARM,
        input_schema={
            "type": "object",
            "required": ["swarm_name", "goal"],
            "properties": {
                "swarm_name": {"type": "string"},
                "goal": {"type": "string"},
                "max_agents": {"type": "integer", "default": 10},
                "topology": {"type": "string", "enum": ["mesh", "star", "ring"]}
            }
        }
    )

    registry.register(
        name="agent_spawn",
        func=agent_spawn,
        description="Spawn a new agent within a swarm",
        category=ToolCategory.AGENT,
        input_schema={
            "type": "object",
            "required": ["swarm_id", "agent_type", "role"],
            "properties": {
                "swarm_id": {"type": "string"},
                "agent_type": {"type": "string"},
                "role": {"type": "string"},
                "tools": {"type": "array", "items": {"type": "string"}}
            }
        }
    )

    registry.register(
        name="task_orchestrate",
        func=task_orchestrate,
        description="Orchestrate task execution across swarm agents",
        category=ToolCategory.TASK,
        input_schema={
            "type": "object",
            "required": ["swarm_id", "task"],
            "properties": {
                "swarm_id": {"type": "string"},
                "task": {"type": "string"},
                "parallel": {"type": "boolean", "default": False},
                "max_time_secs": {"type": "number", "default": 300.0}
            }
        }
    )

    # Memory tools
    registry.register(
        name="memory_store",
        func=memory_store,
        description="Store data in agent memory with optional TTL",
        category=ToolCategory.MEMORY,
        input_schema={
            "type": "object",
            "required": ["key", "value"],
            "properties": {
                "key": {"type": "string"},
                "value": {},
                "category": {"type": "string", "default": "general"},
                "ttl_secs": {"type": "number"}
            }
        }
    )

    registry.register(
        name="memory_retrieve",
        func=memory_retrieve,
        description="Retrieve data from agent memory",
        category=ToolCategory.MEMORY,
        input_schema={
            "type": "object",
            "properties": {
                "key": {"type": "string"},
                "category": {"type": "string"},
                "query": {"type": "string"}
            }
        }
    )

    # Analysis tools
    registry.register(
        name="performance_analyze",
        func=performance_analyze,
        description="Analyze performance metrics for agents, swarms, or tasks",
        category=ToolCategory.ANALYSIS,
        input_schema={
            "type": "object",
            "required": ["target"],
            "properties": {
                "target": {"type": "string"},
                "metric_type": {
                    "type": "string",
                    "enum": ["speed", "quality", "cost", "all"],
                    "default": "all"
                }
            }
        }
    )

    return registry



================================================
File: execution/ptc.py
================================================
"""
Programmatic Tool Calling (PTC) - Execution Efficiency Layer

Implements Anthropic's PTC feature for executing tool sequences outside
the context window. This is the execution backend for CRYSTALLIZED and
FOLLOWER modes.

Key Concept:
- Learning Layer (TraceManager) decides we should replay a trace
- PTC executes that trace's tool sequence in a code container
- Tool results don't hit the context window = massive token savings

Reference: https://github.com/anthropics/anthropic-cookbook/tree/main/misc/programmatic_tool_calling
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
import asyncio
import json


@dataclass
class ToolCall:
    """A single tool call to be executed"""
    tool_name: str
    arguments: Dict[str, Any]
    expected_output_type: str = "any"  # "json", "text", "binary", "any"


@dataclass
class ToolSequence:
    """A sequence of tool calls from a trace"""
    calls: List[ToolCall]
    source_trace_signature: str
    created_at: datetime = field(default_factory=datetime.now)

    def to_python_code(self, tool_registry: Dict[str, str]) -> str:
        """
        Convert tool sequence to Python code for PTC execution

        Args:
            tool_registry: Map of tool_name -> function path

        Returns:
            Python code string that executes the sequence
        """
        lines = [
            "# Auto-generated from trace: " + self.source_trace_signature,
            "# Generated at: " + self.created_at.isoformat(),
            "",
            "import json",
            "results = []",
            ""
        ]

        for i, call in enumerate(self.calls):
            args_json = json.dumps(call.arguments)
            lines.extend([
                f"# Step {i + 1}: {call.tool_name}",
                f"result_{i} = await tools.{call.tool_name}(**{args_json})",
                f"results.append({{'tool': '{call.tool_name}', 'result': result_{i}}})",
                ""
            ])

        lines.append("# Return all results")
        lines.append("return results")

        return "\n".join(lines)


@dataclass
class PTCResult:
    """Result of PTC execution"""
    success: bool
    results: List[Dict[str, Any]]
    execution_time_secs: float
    tokens_saved: int  # Estimated tokens saved vs context
    error: Optional[str] = None


class PTCContainer:
    """
    Container for PTC code execution

    Manages the lifecycle of a code execution environment where
    tool calls happen outside the LLM context window.

    In production, this could be:
    - A Docker container
    - A subprocess with sandboxing
    - A cloud function
    - Claude's built-in code execution (when available)

    For now, we implement a simple async Python execution model.
    """

    def __init__(
        self,
        container_id: str,
        tools: Dict[str, Callable],
        timeout_secs: float = 120.0
    ):
        """
        Initialize PTC container

        Args:
            container_id: Unique identifier for this container
            tools: Dict of tool_name -> callable function
            timeout_secs: Execution timeout
        """
        self.container_id = container_id
        self.tools = tools
        self.timeout_secs = timeout_secs
        self.created_at = datetime.now()
        self._is_active = True

    async def execute_sequence(self, sequence: ToolSequence) -> PTCResult:
        """
        Execute a tool sequence in the container

        This is where the magic happens - tool results stay in the container
        and don't consume context tokens.

        Args:
            sequence: ToolSequence to execute

        Returns:
            PTCResult with execution details
        """
        start_time = datetime.now()
        results = []
        tokens_saved = 0

        try:
            for call in sequence.calls:
                if call.tool_name not in self.tools:
                    return PTCResult(
                        success=False,
                        results=results,
                        execution_time_secs=(datetime.now() - start_time).total_seconds(),
                        tokens_saved=tokens_saved,
                        error=f"Tool not found: {call.tool_name}"
                    )

                # Execute the tool
                tool_func = self.tools[call.tool_name]

                try:
                    # Handle both sync and async tools
                    if asyncio.iscoroutinefunction(tool_func):
                        result = await asyncio.wait_for(
                            tool_func(**call.arguments),
                            timeout=self.timeout_secs
                        )
                    else:
                        result = tool_func(**call.arguments)

                    results.append({
                        "tool": call.tool_name,
                        "arguments": call.arguments,
                        "result": result,
                        "success": True
                    })

                    # Estimate tokens saved (result would have been in context)
                    result_str = str(result)
                    tokens_saved += len(result_str) // 4  # Rough estimate

                except asyncio.TimeoutError:
                    return PTCResult(
                        success=False,
                        results=results,
                        execution_time_secs=(datetime.now() - start_time).total_seconds(),
                        tokens_saved=tokens_saved,
                        error=f"Timeout executing {call.tool_name}"
                    )
                except Exception as e:
                    return PTCResult(
                        success=False,
                        results=results,
                        execution_time_secs=(datetime.now() - start_time).total_seconds(),
                        tokens_saved=tokens_saved,
                        error=f"Error in {call.tool_name}: {str(e)}"
                    )

            return PTCResult(
                success=True,
                results=results,
                execution_time_secs=(datetime.now() - start_time).total_seconds(),
                tokens_saved=tokens_saved
            )

        except Exception as e:
            return PTCResult(
                success=False,
                results=results,
                execution_time_secs=(datetime.now() - start_time).total_seconds(),
                tokens_saved=tokens_saved,
                error=str(e)
            )

    def shutdown(self):
        """Shutdown the container"""
        self._is_active = False

    @property
    def is_active(self) -> bool:
        return self._is_active


class PTCExecutor:
    """
    High-level executor for Programmatic Tool Calling

    This is the main interface used by the Dispatcher to execute
    CRYSTALLIZED and FOLLOWER mode traces efficiently.

    Usage:
        executor = PTCExecutor(tools=registered_tools)
        result = await executor.execute_trace(trace)
    """

    # Beta header for Advanced Tool Use (Nov 2025)
    BETA_HEADER = "advanced-tool-use-2025-11-20"

    def __init__(
        self,
        tools: Dict[str, Callable],
        container_timeout_secs: float = 120.0,
        max_containers: int = 5
    ):
        """
        Initialize PTC executor

        Args:
            tools: Dict of tool_name -> callable function
            container_timeout_secs: Timeout for container execution
            max_containers: Maximum concurrent containers
        """
        self.tools = tools
        self.container_timeout_secs = container_timeout_secs
        self.max_containers = max_containers
        self._containers: Dict[str, PTCContainer] = {}
        self._container_counter = 0

    def _get_or_create_container(self, container_id: Optional[str] = None) -> PTCContainer:
        """Get existing container or create new one"""
        if container_id and container_id in self._containers:
            container = self._containers[container_id]
            if container.is_active:
                return container

        # Create new container
        self._container_counter += 1
        new_id = container_id or f"ptc-container-{self._container_counter}"

        # Clean up old containers if at limit
        if len(self._containers) >= self.max_containers:
            oldest_id = min(
                self._containers.keys(),
                key=lambda k: self._containers[k].created_at
            )
            self._containers[oldest_id].shutdown()
            del self._containers[oldest_id]

        container = PTCContainer(
            container_id=new_id,
            tools=self.tools,
            timeout_secs=self.container_timeout_secs
        )
        self._containers[new_id] = container
        return container

    async def execute_sequence(
        self,
        sequence: ToolSequence,
        container_id: Optional[str] = None
    ) -> PTCResult:
        """
        Execute a tool sequence using PTC

        Args:
            sequence: ToolSequence to execute
            container_id: Optional container ID for reuse

        Returns:
            PTCResult with execution details
        """
        container = self._get_or_create_container(container_id)
        return await container.execute_sequence(sequence)

    async def execute_from_trace(
        self,
        trace: 'ExecutionTrace',  # Forward reference
        container_id: Optional[str] = None
    ) -> PTCResult:
        """
        Execute a trace's tool sequence using PTC

        This is the main entry point for FOLLOWER mode execution.

        Args:
            trace: ExecutionTrace with tool_calls data
            container_id: Optional container ID

        Returns:
            PTCResult with execution details
        """
        # Extract tool sequence from trace
        if not hasattr(trace, 'tool_calls') or not trace.tool_calls:
            # Fallback: try to reconstruct from tools_used
            if trace.tools_used:
                # Can't execute without full call data
                return PTCResult(
                    success=False,
                    results=[],
                    execution_time_secs=0.0,
                    tokens_saved=0,
                    error="Trace missing tool_calls data - cannot replay via PTC"
                )
            else:
                return PTCResult(
                    success=False,
                    results=[],
                    execution_time_secs=0.0,
                    tokens_saved=0,
                    error="Trace has no tool calls to execute"
                )

        sequence = ToolSequence(
            calls=[
                ToolCall(
                    tool_name=call['name'],
                    arguments=call.get('arguments', {})
                )
                for call in trace.tool_calls
            ],
            source_trace_signature=trace.goal_signature
        )

        return await self.execute_sequence(sequence, container_id)

    def get_tool_definitions_for_ptc(self) -> List[Dict[str, Any]]:
        """
        Get tool definitions with PTC `allowed_callers` field

        These tool definitions tell Claude that tools can be called
        from the code execution environment.

        Returns:
            List of tool definitions with allowed_callers
        """
        definitions = []

        for tool_name, tool_func in self.tools.items():
            # Get docstring for description
            description = tool_func.__doc__ or f"Execute {tool_name}"

            # Get type hints for schema (simplified)
            import inspect
            sig = inspect.signature(tool_func)
            properties = {}
            required = []

            for param_name, param in sig.parameters.items():
                if param_name == 'self':
                    continue

                param_type = "string"  # Default
                if param.annotation != inspect.Parameter.empty:
                    if param.annotation == int:
                        param_type = "integer"
                    elif param.annotation == float:
                        param_type = "number"
                    elif param.annotation == bool:
                        param_type = "boolean"

                properties[param_name] = {"type": param_type}

                if param.default == inspect.Parameter.empty:
                    required.append(param_name)

            definitions.append({
                "name": tool_name,
                "description": description.strip(),
                "input_schema": {
                    "type": "object",
                    "properties": properties,
                    "required": required
                },
                # KEY: This enables PTC
                "allowed_callers": ["code_execution_20250825"]
            })

        return definitions

    def shutdown_all(self):
        """Shutdown all containers"""
        for container in self._containers.values():
            container.shutdown()
        self._containers.clear()



================================================
File: execution/tool_examples.py
================================================
"""
Tool Examples Generator - Learning from Successful Traces

Implements Anthropic's Tool Use Examples feature by auto-generating
`input_examples` from successful execution traces.

Key Concept:
- Learning Layer (TraceManager) stores successful executions
- This module extracts tool call patterns from those traces
- Generated examples help Claude use tools correctly the first time
- Bridges the gap between Learning and Execution layers

The flow:
1. Trace succeeds with tool X (Learning Layer records this)
2. ToolExampleGenerator extracts the tool call data
3. Next time tool X is loaded, it includes real examples
4. Claude sees how the tool was successfully used before
"""

from dataclasses import dataclass
from typing import List, Dict, Any, Optional, TYPE_CHECKING
from datetime import datetime
import json

if TYPE_CHECKING:
    from memory.traces_sdk import TraceManager, ExecutionTrace


@dataclass
class ToolExample:
    """
    A single example of successful tool usage

    This maps to Anthropic's input_examples format.
    """
    description: str
    arguments: Dict[str, Any]
    source_goal: str  # Where this example came from
    success_rate: float  # How reliable this pattern is
    usage_count: int  # How often this pattern was used

    def to_api_format(self) -> Dict[str, Any]:
        """Convert to Anthropic API input_examples format"""
        return {
            "description": self.description,
            "arguments": self.arguments
        }


class ToolExampleGenerator:
    """
    Generates tool examples from execution traces

    This is the bridge between the Learning Layer (traces) and
    Execution Layer (tool definitions with examples).

    Usage:
        generator = ToolExampleGenerator(trace_manager)

        # Get examples for a specific tool
        examples = generator.get_examples_for_tool("write_file")

        # Enhance a tool definition with examples
        enhanced_def = generator.enhance_tool_definition(tool_def)
    """

    def __init__(
        self,
        trace_manager: 'TraceManager',
        min_success_rate: float = 0.9,
        max_examples_per_tool: int = 3
    ):
        """
        Initialize the generator

        Args:
            trace_manager: TraceManager for accessing execution history
            min_success_rate: Minimum trace success rate to extract examples from
            max_examples_per_tool: Maximum examples to include per tool
        """
        self.trace_manager = trace_manager
        self.min_success_rate = min_success_rate
        self.max_examples_per_tool = max_examples_per_tool

        # Cache of generated examples
        self._example_cache: Dict[str, List[ToolExample]] = {}
        self._cache_timestamp: Optional[datetime] = None
        self._cache_ttl_secs = 300  # 5 minute cache

    def _is_cache_valid(self) -> bool:
        """Check if the example cache is still valid"""
        if not self._cache_timestamp:
            return False
        age = (datetime.now() - self._cache_timestamp).total_seconds()
        return age < self._cache_ttl_secs

    def _extract_tool_calls_from_trace(
        self,
        trace: 'ExecutionTrace'
    ) -> List[Dict[str, Any]]:
        """
        Extract tool call data from a trace

        Args:
            trace: ExecutionTrace to extract from

        Returns:
            List of tool call dicts with name and arguments
        """
        # If trace has full tool_calls data, use it
        if hasattr(trace, 'tool_calls') and trace.tool_calls:
            return trace.tool_calls

        # Otherwise, we can only get tool names (no arguments)
        # This is a limitation - we need traces with full call data
        return []

    def get_examples_for_tool(
        self,
        tool_name: str,
        force_refresh: bool = False
    ) -> List[ToolExample]:
        """
        Get usage examples for a specific tool from traces

        Args:
            tool_name: Name of the tool
            force_refresh: Force cache refresh

        Returns:
            List of ToolExample instances
        """
        # Check cache
        if not force_refresh and self._is_cache_valid():
            if tool_name in self._example_cache:
                return self._example_cache[tool_name]

        # Get all traces
        traces = self.trace_manager.list_traces()

        # Filter for successful traces that used this tool
        relevant_traces = [
            t for t in traces
            if t.success_rating >= self.min_success_rate
            and t.tools_used
            and tool_name in t.tools_used
        ]

        if not relevant_traces:
            return []

        # Extract examples from traces
        examples = []
        seen_patterns = set()  # Avoid duplicate patterns

        for trace in relevant_traces:
            tool_calls = self._extract_tool_calls_from_trace(trace)

            for call in tool_calls:
                if call.get('name') != tool_name:
                    continue

                arguments = call.get('arguments', {})
                if not arguments:
                    continue

                # Create a pattern hash to detect duplicates
                pattern_hash = json.dumps(
                    sorted(arguments.keys())
                )

                if pattern_hash in seen_patterns:
                    continue
                seen_patterns.add(pattern_hash)

                # Create example
                example = ToolExample(
                    description=f"From: {trace.goal_text[:50]}...",
                    arguments=arguments,
                    source_goal=trace.goal_text,
                    success_rate=trace.success_rating,
                    usage_count=trace.usage_count
                )
                examples.append(example)

                if len(examples) >= self.max_examples_per_tool:
                    break

            if len(examples) >= self.max_examples_per_tool:
                break

        # Sort by usage count (most used patterns first)
        examples.sort(key=lambda e: e.usage_count, reverse=True)

        # Update cache
        self._example_cache[tool_name] = examples[:self.max_examples_per_tool]
        self._cache_timestamp = datetime.now()

        return self._example_cache[tool_name]

    def enhance_tool_definition(
        self,
        tool_definition: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Enhance a tool definition with examples from traces

        Args:
            tool_definition: Original tool definition dict

        Returns:
            Enhanced definition with input_examples
        """
        tool_name = tool_definition.get('name')
        if not tool_name:
            return tool_definition

        examples = self.get_examples_for_tool(tool_name)

        if not examples:
            return tool_definition

        # Create enhanced copy
        enhanced = tool_definition.copy()
        enhanced['input_examples'] = [
            e.to_api_format() for e in examples
        ]

        return enhanced

    def enhance_tool_definitions(
        self,
        tool_definitions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Enhance multiple tool definitions with examples

        Args:
            tool_definitions: List of tool definition dicts

        Returns:
            List of enhanced definitions
        """
        return [
            self.enhance_tool_definition(t) for t in tool_definitions
        ]

    def get_all_examples(self) -> Dict[str, List[ToolExample]]:
        """
        Get examples for all tools found in traces

        Returns:
            Dict mapping tool_name -> List[ToolExample]
        """
        # Get all unique tools from traces
        traces = self.trace_manager.list_traces()
        all_tools = set()

        for trace in traces:
            if trace.tools_used:
                all_tools.update(trace.tools_used)

        # Get examples for each tool
        result = {}
        for tool_name in all_tools:
            examples = self.get_examples_for_tool(tool_name)
            if examples:
                result[tool_name] = examples

        return result

    def get_statistics(self) -> Dict[str, Any]:
        """Get statistics about generated examples"""
        all_examples = self.get_all_examples()

        total_examples = sum(len(ex) for ex in all_examples.values())

        return {
            "tools_with_examples": len(all_examples),
            "total_examples": total_examples,
            "cache_valid": self._is_cache_valid(),
            "min_success_rate": self.min_success_rate,
            "max_examples_per_tool": self.max_examples_per_tool
        }

    def clear_cache(self) -> None:
        """Clear the example cache"""
        self._example_cache.clear()
        self._cache_timestamp = None


class TraceToolCallRecorder:
    """
    Helper to record tool calls during execution for later example generation

    Use this during LEARNER mode execution to capture full tool call data
    that can later be used to generate examples.
    """

    def __init__(self):
        self.tool_calls: List[Dict[str, Any]] = []

    def record_call(
        self,
        tool_name: str,
        arguments: Dict[str, Any],
        result: Any = None,
        success: bool = True
    ) -> None:
        """
        Record a tool call

        Args:
            tool_name: Name of the tool
            arguments: Arguments passed to the tool
            result: Optional result (for context)
            success: Whether the call succeeded
        """
        self.tool_calls.append({
            "name": tool_name,
            "arguments": arguments,
            "success": success,
            "timestamp": datetime.now().isoformat()
        })

    def get_calls(self) -> List[Dict[str, Any]]:
        """Get all recorded calls"""
        return self.tool_calls.copy()

    def clear(self) -> None:
        """Clear recorded calls"""
        self.tool_calls.clear()



================================================
File: execution/tool_search.py
================================================
"""
Tool Search Engine - On-Demand Tool Discovery

Implements Anthropic's Tool Search pattern for efficient tool loading.
Used in LEARNER and ORCHESTRATOR modes where we don't know upfront
which tools will be needed.

Key Concept:
- Instead of loading all 100+ tools into context (expensive!)
- Start with a "search_tools" meta-tool
- Claude discovers tools on-demand as needed
- 85-90% context reduction for large toolsets

Reference: https://github.com/anthropics/anthropic-cookbook/tree/main/misc/tool_search_tool
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import json


@dataclass
class ToolReference:
    """
    Lightweight reference to a tool (returned by search)

    This is what Tool Search returns - just enough info for Claude
    to decide if it wants to load the full tool definition.
    """
    name: str
    description: str
    category: str = ""
    relevance_score: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "category": self.category,
            "relevance_score": self.relevance_score
        }


@dataclass
class ToolDefinition:
    """
    Full tool definition that can be deferred

    The `defer_loading` flag tells the system this tool should
    not be loaded into context upfront.
    """
    name: str
    description: str
    input_schema: Dict[str, Any]
    category: str = ""
    defer_loading: bool = True  # Default to deferred (efficient)
    input_examples: List[Dict] = field(default_factory=list)
    embedding: Optional[List[float]] = None  # For semantic search

    def to_api_format(self) -> Dict[str, Any]:
        """Convert to Anthropic API format"""
        tool_dict = {
            "name": self.name,
            "description": self.description,
            "input_schema": self.input_schema
        }

        if self.input_examples:
            tool_dict["input_examples"] = self.input_examples

        return tool_dict

    def to_reference(self, score: float = 0.0) -> ToolReference:
        """Convert to lightweight reference"""
        return ToolReference(
            name=self.name,
            description=self.description,
            category=self.category,
            relevance_score=score
        )


class ToolSearchEngine:
    """
    Semantic search engine for tools

    Implements on-demand tool discovery to reduce context window usage.
    Can use either:
    1. Simple keyword matching (fast, no dependencies)
    2. Embedding-based semantic search (better quality, requires sentence-transformers)

    Usage:
        engine = ToolSearchEngine()
        engine.register_tool(tool_def)

        # Search for relevant tools
        results = engine.search("read a file from disk")
        # Returns: [ToolReference(name="read_file", ...), ...]

        # Load full definition when needed
        full_def = engine.get_tool_definition("read_file")
    """

    def __init__(
        self,
        use_embeddings: bool = False,
        embedding_model: str = "all-MiniLM-L6-v2"
    ):
        """
        Initialize tool search engine

        Args:
            use_embeddings: Whether to use embedding-based search
            embedding_model: Model name for sentence-transformers
        """
        self.tools: Dict[str, ToolDefinition] = {}
        self.use_embeddings = use_embeddings
        self.embedding_model = embedding_model
        self._embedder = None

        if use_embeddings:
            try:
                from sentence_transformers import SentenceTransformer
                self._embedder = SentenceTransformer(embedding_model)
                print(f"[ToolSearch] Using embedding model: {embedding_model}")
            except ImportError:
                print("[ToolSearch] sentence-transformers not installed, using keyword search")
                self.use_embeddings = False

    def register_tool(self, tool: ToolDefinition) -> None:
        """
        Register a tool for search

        Args:
            tool: ToolDefinition to register
        """
        # Generate embedding if using embeddings
        if self.use_embeddings and self._embedder and not tool.embedding:
            text = f"{tool.name} {tool.description} {tool.category}"
            tool.embedding = self._embedder.encode(text).tolist()

        self.tools[tool.name] = tool

    def register_tools_from_registry(self, registry: 'ComponentRegistry') -> None:
        """
        Register all tools from a ComponentRegistry

        Args:
            registry: ComponentRegistry with tools
        """
        for tool_spec in registry.tools.values():
            tool_def = ToolDefinition(
                name=tool_spec.name,
                description=tool_spec.description,
                input_schema={},  # Would need to be provided
                category=tool_spec.category,
                defer_loading=True
            )
            self.register_tool(tool_def)

    def search(
        self,
        query: str,
        top_k: int = 5,
        category_filter: Optional[str] = None
    ) -> List[ToolReference]:
        """
        Search for relevant tools

        Args:
            query: Natural language search query
            top_k: Maximum number of results
            category_filter: Optional category to filter by

        Returns:
            List of ToolReference sorted by relevance
        """
        if not self.tools:
            return []

        # Filter by category if specified
        candidates = self.tools.values()
        if category_filter:
            candidates = [t for t in candidates if t.category == category_filter]

        if self.use_embeddings and self._embedder:
            return self._search_embeddings(query, list(candidates), top_k)
        else:
            return self._search_keywords(query, list(candidates), top_k)

    def _search_keywords(
        self,
        query: str,
        candidates: List[ToolDefinition],
        top_k: int
    ) -> List[ToolReference]:
        """Simple keyword-based search"""
        query_lower = query.lower()
        query_words = set(query_lower.split())

        scored = []
        for tool in candidates:
            # Score based on word overlap
            tool_text = f"{tool.name} {tool.description} {tool.category}".lower()
            tool_words = set(tool_text.split())

            overlap = len(query_words & tool_words)
            if overlap > 0:
                # Boost for name match
                name_match = 1.0 if any(w in tool.name.lower() for w in query_words) else 0.0
                score = (overlap / len(query_words)) + name_match
                scored.append((score, tool))

        # Sort by score descending
        scored.sort(key=lambda x: x[0], reverse=True)

        return [
            tool.to_reference(score=score)
            for score, tool in scored[:top_k]
        ]

    def _search_embeddings(
        self,
        query: str,
        candidates: List[ToolDefinition],
        top_k: int
    ) -> List[ToolReference]:
        """Embedding-based semantic search"""
        import numpy as np

        query_embedding = self._embedder.encode(query)

        scored = []
        for tool in candidates:
            if tool.embedding:
                # Cosine similarity
                tool_emb = np.array(tool.embedding)
                query_emb = np.array(query_embedding)

                similarity = np.dot(tool_emb, query_emb) / (
                    np.linalg.norm(tool_emb) * np.linalg.norm(query_emb)
                )
                scored.append((float(similarity), tool))

        # Sort by similarity descending
        scored.sort(key=lambda x: x[0], reverse=True)

        return [
            tool.to_reference(score=score)
            for score, tool in scored[:top_k]
        ]

    def get_tool_definition(self, name: str) -> Optional[ToolDefinition]:
        """
        Get full tool definition by name

        Called after search when Claude decides it needs the full definition.

        Args:
            name: Tool name

        Returns:
            ToolDefinition or None
        """
        return self.tools.get(name)

    def get_immediate_tools(self) -> List[ToolDefinition]:
        """
        Get tools that should be loaded immediately (not deferred)

        These are core tools that are almost always needed.

        Returns:
            List of ToolDefinitions with defer_loading=False
        """
        return [t for t in self.tools.values() if not t.defer_loading]

    def get_search_tool_definition(self) -> Dict[str, Any]:
        """
        Get the "search_tools" meta-tool definition

        This tool is given to Claude so it can discover other tools.

        Returns:
            Tool definition for the search tool
        """
        # Get all categories
        categories = list(set(t.category for t in self.tools.values() if t.category))

        return {
            "name": "search_tools",
            "description": (
                "Search for available tools by description. Use this to discover "
                "tools that can help with a specific task. Returns tool names and "
                "descriptions that match your query."
            ),
            "input_schema": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Natural language description of what you need"
                    },
                    "category": {
                        "type": "string",
                        "description": f"Optional category filter. Available: {', '.join(categories)}",
                        "enum": categories if categories else None
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum number of results (default: 5)",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        }

    def get_load_tool_definition(self) -> Dict[str, Any]:
        """
        Get the "load_tool" meta-tool definition

        This tool lets Claude load a specific tool after finding it via search.

        Returns:
            Tool definition for the load tool
        """
        return {
            "name": "load_tool",
            "description": (
                "Load a tool's full definition after finding it via search_tools. "
                "Call this when you need to use a tool that was returned from search."
            ),
            "input_schema": {
                "type": "object",
                "properties": {
                    "tool_name": {
                        "type": "string",
                        "description": "Name of the tool to load"
                    }
                },
                "required": ["tool_name"]
            }
        }

    async def handle_search_tool_call(
        self,
        query: str,
        category: Optional[str] = None,
        max_results: int = 5
    ) -> Dict[str, Any]:
        """
        Handle a call to the search_tools tool

        Args:
            query: Search query
            category: Optional category filter
            max_results: Maximum results

        Returns:
            Tool search results
        """
        results = self.search(query, top_k=max_results, category_filter=category)

        return {
            "tools_found": len(results),
            "results": [r.to_dict() for r in results],
            "hint": "Use load_tool to get the full definition of any tool you want to use"
        }

    async def handle_load_tool_call(self, tool_name: str) -> Dict[str, Any]:
        """
        Handle a call to the load_tool tool

        Args:
            tool_name: Name of tool to load

        Returns:
            Full tool definition or error
        """
        tool = self.get_tool_definition(tool_name)

        if not tool:
            return {
                "error": f"Tool '{tool_name}' not found",
                "hint": "Use search_tools to find available tools"
            }

        return {
            "tool_definition": tool.to_api_format(),
            "hint": "You can now use this tool in your response"
        }

    def get_statistics(self) -> Dict[str, Any]:
        """Get statistics about registered tools"""
        deferred = sum(1 for t in self.tools.values() if t.defer_loading)
        immediate = len(self.tools) - deferred

        categories = {}
        for tool in self.tools.values():
            cat = tool.category or "uncategorized"
            categories[cat] = categories.get(cat, 0) + 1

        return {
            "total_tools": len(self.tools),
            "deferred_tools": deferred,
            "immediate_tools": immediate,
            "categories": categories,
            "using_embeddings": self.use_embeddings,
            "embedding_model": self.embedding_model if self.use_embeddings else None
        }




================================================
File: interfaces/__init__.py
================================================
"""
Interfaces Package - Communication layer between Kernel and Cortex
"""



================================================
File: interfaces/cortex.py
================================================
"""
Cortex - Cognitive Interface using Claude Agent SDK
The "CPU" of the LLM OS
"""

import asyncio
from typing import Dict, List, Any, Optional
from pathlib import Path

try:
    from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions, AssistantMessage, TextBlock
except ImportError:
    # Fallback for development/testing
    print("Warning: claude-agent-sdk not installed. Install with: pip install claude-agent-sdk")
    ClaudeSDKClient = None
    ClaudeAgentOptions = None


from kernel.bus import EventBus, Event, EventType
from memory.traces import ExecutionTrace


class Cortex:
    """
    The Cortex - Cognitive processing using Claude Agent SDK
    Handles: Planning, Learning, Following
    """

    def __init__(
        self,
        event_bus: EventBus,
        workspace: Path,
        model: str = "claude-sonnet-4-5-20250929"
    ):
        self.event_bus = event_bus
        self.workspace = workspace
        self.model = model
        self.client: Optional[Any] = None

    async def initialize(self):
        """Initialize the Claude SDK client"""
        if ClaudeSDKClient is None:
            raise RuntimeError(
                "Claude Agent SDK not installed. "
                "Install with: pip install claude-agent-sdk"
            )

        # Configure Claude Agent options
        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(self.workspace),
            allowed_tools=[
                "Read", "Write", "Edit", "Bash",
                "Glob", "Grep"
            ],
            permission_mode="acceptEdits",
            system_prompt={
                "type": "preset",
                "preset": "claude_code",
                "append": """
You are the Cortex of an LLM Operating System.
Your role is to:
1. Decompose high-level goals into executable steps
2. Learn new patterns when encountering novel problems
3. Execute proven patterns efficiently

You have access to file operations, code execution, and search tools.
Work systematically and document your steps.
"""
            }
        )

        self.client = ClaudeSDKClient(options=options)

    async def plan(self, goal: str) -> List[Dict[str, Any]]:
        """
        Plan mode - Decompose a goal into steps

        Args:
            goal: Natural language goal

        Returns:
            List of planned steps
        """
        if not self.client:
            await self.initialize()

        async with self.client as client:
            await client.query(
                f"Plan how to achieve this goal, breaking it into clear steps: {goal}\n\n"
                "Output a numbered list of steps with tool names and parameters."
            )

            plan = []
            async for message in client.receive_response():
                if isinstance(message, AssistantMessage):
                    for block in message.content:
                        if isinstance(block, TextBlock):
                            # Parse the plan
                            # TODO: Implement proper plan parsing
                            plan.append({
                                "text": block.text
                            })

            return plan

    async def learn(self, goal: str) -> ExecutionTrace:
        """
        Learner mode - Execute a novel goal and create execution trace

        Args:
            goal: Natural language goal

        Returns:
            ExecutionTrace of the execution
        """
        if not self.client:
            await self.initialize()

        print("ðŸ§  Learner Mode: Solving novel problem...")

        steps = []
        start_time = asyncio.get_event_loop().time()

        async with self.client as client:
            await client.query(goal)

            async for message in client.receive_response():
                # Emit event for each message
                event = Event(
                    type=EventType.LLM_OUTPUT,
                    data={"message": message}
                )
                await self.event_bus.publish(event)

                # Extract tool uses
                if hasattr(message, 'content'):
                    for block in message.content:
                        if hasattr(block, 'name'):  # Tool use
                            steps.append({
                                "tool": block.name,
                                "input": getattr(block, 'input', {})
                            })

        end_time = asyncio.get_event_loop().time()
        execution_time = end_time - start_time

        # Create execution trace
        trace = ExecutionTrace(
            goal_signature=self._hash_goal(goal),
            goal_text=goal,
            steps=steps,
            success_rating=0.75,  # Initial confidence
            estimated_time_secs=execution_time
        )

        print(f"âœ… Learner Mode Complete: {len(steps)} steps, {execution_time:.2f}s")

        return trace

    async def follow(self, trace: ExecutionTrace) -> bool:
        """
        Follower mode - Execute a proven trace

        Args:
            trace: ExecutionTrace to execute

        Returns:
            True if successful
        """
        # Support both old 'steps' and new 'tool_calls' attributes
        steps = getattr(trace, 'tool_calls', None) or getattr(trace, 'steps', []) or []

        print(f"âš¡ Follower Mode: Executing {len(steps)} steps...")

        try:
            for step in steps:
                # Execute each step deterministically
                # Support both dict formats: {'tool': ...} and {'name': ...}
                tool_name = step.get('tool') or step.get('name', 'unknown')
                print(f"  â†’ {tool_name}")
                await asyncio.sleep(0.1)  # Simulate execution

            print("âœ… Follower Mode Complete")
            return True

        except Exception as e:
            print(f"âŒ Follower Mode Failed: {e}")
            return False

    def _hash_goal(self, goal: str) -> str:
        """Hash a goal for signature"""
        import hashlib
        return hashlib.sha256(goal.lower().strip().encode()).hexdigest()[:16]



================================================
File: interfaces/dispatcher.py
================================================
"""
Dispatcher - The Brain of the LLM OS
Decides between Learner, Follower, and Orchestration modes based on token economy

Architecture:
- Learning Layer: TraceManager, ModeStrategies (decides WHAT to do)
- Execution Layer: PTC, Tool Search, Tool Examples (does it EFFICIENTLY)

The Dispatcher bridges these two layers:
1. Learning Layer decides the mode (CRYSTALLIZED, FOLLOWER, MIXED, LEARNER, ORCHESTRATOR)
2. Execution Layer executes that decision efficiently using Anthropic's Advanced Tool Use
"""

from typing import Dict, Any, Optional, Callable
from pathlib import Path

from kernel.bus import EventBus
from kernel.token_economy import TokenEconomy, LowBatteryError
from kernel.project_manager import ProjectManager, Project
from kernel.config import LLMOSConfig
from kernel.mode_strategies import (
    ModeSelectionStrategy,
    ModeContext,
    get_strategy
)
from memory.store_sdk import MemoryStore
from memory.traces_sdk import TraceManager, ExecutionTrace
from memory.query_sdk import MemoryQueryInterface
from interfaces.cortex import Cortex
from interfaces.sdk_client import LLMOSSDKClient, is_sdk_available

# Execution Layer imports (Anthropic Advanced Tool Use)
# These are imported directly to avoid circular dependencies
try:
    from execution.ptc import PTCExecutor, ToolSequence, ToolCall
    from execution.tool_search import ToolSearchEngine, ToolDefinition
    from execution.tool_examples import ToolExampleGenerator
    EXECUTION_LAYER_AVAILABLE = True
except ImportError:
    EXECUTION_LAYER_AVAILABLE = False
    PTCExecutor = None
    ToolSearchEngine = None
    ToolExampleGenerator = None
    print("âš ï¸  Execution Layer not available - Advanced Tool Use features disabled")


class TaskBlock:
    """
    A TaskBlock is a "Program" in the LLM OS
    Not a compiled binary, but a natural language intent
    """

    def __init__(
        self,
        goal: str,
        inputs: Dict[str, Any] = None,
        constraints: list = None,
        priority: int = 50,
        mode: str = "AUTO"
    ):
        self.goal = goal
        self.inputs = inputs or {}
        self.constraints = constraints or []
        self.priority = priority
        self.mode = mode  # AUTO, LEARNER, or FOLLOWER


class Dispatcher:
    """
    The Dispatcher - Makes the Learner/Follower/Orchestration decision
    This is the "operating system scheduler" that optimizes for token cost

    Architecture:
        Learning Layer (decides WHAT to do):
        - TraceManager: Stores execution history
        - ModeSelectionStrategy: Analyzes and decides mode

        Execution Layer (does it EFFICIENTLY):
        - PTCExecutor: Executes tool sequences outside context (CRYSTALLIZED/FOLLOWER)
        - ToolSearchEngine: On-demand tool discovery (LEARNER/ORCHESTRATOR)
        - ToolExampleGenerator: Auto-generates examples from traces (all modes)

    Modes:
        1. CRYSTALLIZED: Execute via PTC (instant, free)
        2. FOLLOWER: Replay trace via PTC (fast, cheap)
        3. MIXED: Trace-guided LLM with examples (medium cost)
        4. LEARNER: Full LLM with tool search (expensive, creative)
        5. ORCHESTRATOR: Multi-agent with tool search (complex)
    """

    def __init__(
        self,
        event_bus: EventBus,
        token_economy: TokenEconomy,
        memory_store: MemoryStore,
        trace_manager: TraceManager,
        project_manager: Optional[ProjectManager] = None,
        workspace: Optional[Path] = None,
        config: Optional[LLMOSConfig] = None,
        strategy: Optional[ModeSelectionStrategy] = None,
        tools: Optional[Dict[str, Callable]] = None
    ):
        self.event_bus = event_bus
        self.token_economy = token_economy
        self.memory_store = memory_store
        self.trace_manager = trace_manager
        self.project_manager = project_manager
        self.workspace = workspace or Path("./workspace")
        self.tools = tools or {}  # Registered tool functions

        # Configuration and strategy (Learning Layer)
        self.config = config or LLMOSConfig()
        self.strategy = strategy or get_strategy("auto")

        # Initialize cortex (will be lazy-loaded)
        self.cortex: Cortex = None

        # Initialize orchestrator (will be lazy-loaded)
        self.orchestrator = None

        # Initialize memory query interface
        self.memory_query = MemoryQueryInterface(trace_manager, memory_store)

        # Initialize SDK client (if available)
        # Now with full DynamicAgentManager support for adaptive subagents
        self.sdk_client: Optional[LLMOSSDKClient] = None
        self.sentience_manager = None  # Will be set externally if available
        self.agent_factory = None  # Will be lazy-loaded

        if is_sdk_available():
            self.sdk_client = LLMOSSDKClient(
                workspace=self.workspace,
                trace_manager=self.trace_manager,
                token_economy=self.token_economy,  # For budget control hooks
                memory_query=self.memory_query,  # For context injection hooks
                sentience_manager=self.sentience_manager,  # For sentience-driven adaptation
                agent_factory=self.agent_factory,  # For dynamic agent management
                config=self.config  # For configuration
            )
        else:
            print("âš ï¸  Claude Agent SDK not available - using fallback cortex mode")
            print("   Install with: pip install claude-agent-sdk")

        # =====================================================================
        # EXECUTION LAYER (Anthropic Advanced Tool Use)
        # =====================================================================
        self._init_execution_layer()

    def _init_execution_layer(self):
        """
        Initialize the Execution Layer components

        These handle EFFICIENT execution of decisions made by the Learning Layer.
        """
        exec_config = self.config.execution

        # Check if Execution Layer is available
        if not EXECUTION_LAYER_AVAILABLE:
            self.ptc_executor = None
            self.tool_search = None
            self.tool_examples = None
            return

        # PTC Executor (for CRYSTALLIZED/FOLLOWER modes)
        self.ptc_executor = None
        if exec_config.enable_advanced_tool_use and exec_config.enable_ptc and PTCExecutor:
            self.ptc_executor = PTCExecutor(
                tools=self.tools,
                container_timeout_secs=exec_config.ptc_container_timeout_secs,
                max_containers=exec_config.ptc_max_containers
            )
            print("âœ“ PTC Executor initialized (Programmatic Tool Calling)")

        # Tool Search Engine (for LEARNER/ORCHESTRATOR modes)
        self.tool_search = None
        if exec_config.enable_advanced_tool_use and exec_config.enable_tool_search and ToolSearchEngine:
            self.tool_search = ToolSearchEngine(
                use_embeddings=exec_config.tool_search_use_embeddings,
                embedding_model=exec_config.tool_search_embedding_model
            )
            print("âœ“ Tool Search Engine initialized")

        # Tool Example Generator (for all modes)
        self.tool_examples = None
        if exec_config.enable_advanced_tool_use and exec_config.enable_tool_examples and ToolExampleGenerator:
            self.tool_examples = ToolExampleGenerator(
                trace_manager=self.trace_manager,
                min_success_rate=exec_config.tool_examples_min_success_rate,
                max_examples_per_tool=exec_config.tool_examples_max_per_tool
            )
            print("âœ“ Tool Example Generator initialized")

        if exec_config.enable_advanced_tool_use:
            print(f"âœ“ Execution Layer ready (beta: {exec_config.beta_header})")

    def register_tool(
        self,
        name: str,
        func: Callable,
        description: str = "",
        defer_loading: bool = None
    ):
        """
        Register a tool with the Dispatcher

        Tools are registered in both layers:
        - Execution Layer: For PTC and Tool Search
        - Learning Layer: For trace recording

        Args:
            name: Tool name
            func: Tool function (sync or async)
            description: Tool description
            defer_loading: Whether to defer loading (default from config)
        """
        # Register in tools dict
        self.tools[name] = func

        # Update PTC executor if available
        if self.ptc_executor:
            self.ptc_executor.tools[name] = func

        # Register in Tool Search if available
        if self.tool_search:
            should_defer = defer_loading if defer_loading is not None else \
                          self.config.execution.defer_tools_by_default

            tool_def = ToolDefinition(
                name=name,
                description=description or func.__doc__ or f"Execute {name}",
                input_schema={},  # Would need introspection
                defer_loading=should_defer
            )
            self.tool_search.register_tool(tool_def)

    async def _ensure_cortex(self):
        """Lazy initialization of cortex"""
        if self.cortex is None:
            self.cortex = Cortex(self.event_bus, self.workspace)
            await self.cortex.initialize()

    async def _ensure_orchestrator(self):
        """Lazy initialization of orchestrator"""
        if self.orchestrator is None:
            from kernel.agent_factory import AgentFactory
            from kernel.component_registry import ComponentRegistry
            from interfaces.orchestrator import SystemAgent

            # Initialize dependencies
            agent_factory = AgentFactory(self.workspace)
            component_registry = ComponentRegistry()

            # Register built-in agents
            for agent in agent_factory.list_agents():
                component_registry.register_agent(agent)

            self.orchestrator = SystemAgent(
                event_bus=self.event_bus,
                project_manager=self.project_manager,
                agent_factory=agent_factory,
                component_registry=component_registry,
                token_economy=self.token_economy,
                trace_manager=self.trace_manager,
                workspace=self.workspace
            )

    async def dispatch(
        self,
        goal: str,
        mode: str = "AUTO",
        project: Optional[Project] = None,
        max_cost_usd: float = 5.0
    ) -> Dict[str, Any]:
        """
        Dispatch a goal to appropriate execution mode

        This is the core algorithm that makes LLM OS economical:
        1. Check complexity (simple vs complex)
        2. Check if we have a proven trace
        3. Route to: FOLLOWER (proven) / LEARNER (novel) / ORCHESTRATOR (complex)

        Args:
            goal: Natural language goal
            mode: "AUTO" (auto-detect), "LEARNER", "FOLLOWER", or "ORCHESTRATOR"
            project: Optional project context for orchestration
            max_cost_usd: Maximum cost budget

        Returns:
            Result dictionary
        """
        print("=" * 60)
        print(f"ðŸŽ¯ Dispatching: {goal}")
        print("=" * 60)

        # Determine execution mode
        if mode == "AUTO":
            mode = await self._determine_mode(goal)

        print(f"ðŸ“‹ Selected Mode: {mode}")
        print("=" * 60)

        # Route to appropriate mode
        if mode == "CRYSTALLIZED":
            return await self._dispatch_crystallized(goal)
        elif mode == "ORCHESTRATOR":
            return await self._dispatch_orchestrator(goal, project, max_cost_usd)
        elif mode == "FOLLOWER":
            return await self._dispatch_follower(goal)
        elif mode == "MIXED":
            return await self._dispatch_mixed(goal, project, max_cost_usd)
        else:  # LEARNER
            return await self._dispatch_learner(goal, project, max_cost_usd)

    async def _determine_mode(self, goal: str) -> str:
        """
        Automatically determine the best execution mode using Strategy pattern

        Uses the configured mode selection strategy to determine the optimal
        execution mode based on available traces, complexity, and configuration.

        Execution modes:
        - CRYSTALLIZED: Trace has been converted to tool - Execute tool directly
        - FOLLOWER: High confidence - Execute proven trace directly
        - MIXED: Medium confidence - Use trace as few-shot guidance
        - LEARNER: Low confidence - Full LLM reasoning
        - ORCHESTRATOR: Complex multi-agent task

        Args:
            goal: Natural language goal

        Returns:
            Mode string: "CRYSTALLIZED", "FOLLOWER", "MIXED", "LEARNER", or "ORCHESTRATOR"
        """
        # Use strategy pattern for mode selection
        context = ModeContext(
            goal=goal,
            trace_manager=self.trace_manager,
            config=self.config
        )

        decision = await self.strategy.determine_mode(context)

        # Log decision
        if decision.trace:
            if decision.mode == "CRYSTALLIZED":
                print(f"ðŸ’Ž Crystallized tool: {decision.trace.crystallized_into_tool}")
                print(f"   {decision.reasoning}")
            elif decision.mode == "FOLLOWER":
                print(f"ðŸ“¦ Trace replay (confidence: {decision.confidence:.0%})")
                print(f"   Success: {decision.trace.success_rating:.0%}, "
                      f"Used: {decision.trace.usage_count}x")
                print(f"   {decision.reasoning}")
            elif decision.mode == "MIXED":
                print(f"ðŸ“ Trace-guided (confidence: {decision.confidence:.0%})")
                print(f"   {decision.reasoning}")
        else:
            if decision.mode == "ORCHESTRATOR":
                print(f"ðŸ”€ {decision.reasoning}")
            else:
                print(f"ðŸ†• {decision.reasoning}")

        return decision.mode

    async def _dispatch_crystallized(self, goal: str) -> Dict[str, Any]:
        """
        Dispatch to Crystallized mode (execute generated tool directly)

        This is the final form of the HOPE architecture - instant, free execution
        of a crystallized pattern via Python code.

        Args:
            goal: Natural language goal

        Returns:
            Result dictionary
        """
        # Find the trace with crystallized tool
        result = await self.trace_manager.find_trace_with_llm(goal, min_confidence=0.75)

        if not result:
            return {
                "success": False,
                "error": "No crystallized trace found",
                "mode": "CRYSTALLIZED"
            }

        trace, confidence = result

        if not trace.crystallized_into_tool:
            return {
                "success": False,
                "error": "Trace not crystallized",
                "mode": "CRYSTALLIZED"
            }

        print(f"ðŸ’¡ Cost: $0.00 (crystallized tool)")
        print(f"ðŸ’¡ Time: ~instant")

        # Execute the crystallized tool
        # Note: Tool execution would be handled by the plugin system
        # For now, we return success with metadata

        # Update trace statistics
        self.trace_manager.update_usage(trace.goal_signature)

        return {
            "success": True,
            "mode": "CRYSTALLIZED",
            "tool_name": trace.crystallized_into_tool,
            "trace": trace,
            "cost": 0.0,
            "message": f"Executed crystallized tool: {trace.crystallized_into_tool}"
        }

    async def _dispatch_follower(self, goal: str) -> Dict[str, Any]:
        """
        Dispatch to Follower mode (direct trace replay)

        Used when confidence â‰¥0.92 (virtually identical to previous execution)

        Execution Strategy:
        - If PTC enabled and trace has tool_calls: Use PTC (zero-context execution)
        - Otherwise: Fall back to cortex replay
        """
        # Try to find trace with LLM matching
        result = await self.trace_manager.find_trace_with_llm(goal, min_confidence=0.92)

        if not result:
            # Fallback to hash matching
            trace = self.trace_manager.find_trace(goal, min_confidence=0.9)
            if not trace:
                return {
                    "success": False,
                    "error": "No trace found for Follower mode",
                    "mode": "FOLLOWER"
                }
            confidence = 1.0  # Hash match = exact
        else:
            trace, confidence = result

        print(f"ðŸ’¡ Cost: ~$0, Time: ~{trace.estimated_time_secs:.1f}s")

        # =====================================================================
        # EXECUTION LAYER: Try PTC first (Anthropic Advanced Tool Use)
        # =====================================================================
        if self.ptc_executor and hasattr(trace, 'tool_calls') and trace.tool_calls:
            print("âš¡ Using PTC (Programmatic Tool Calling) - zero context execution")

            ptc_result = await self.ptc_executor.execute_from_trace(trace)

            if ptc_result.success:
                # Update trace statistics
                self.trace_manager.update_usage(trace.goal_signature)

                print(f"âœ“ PTC execution complete - saved ~{ptc_result.tokens_saved} tokens")

                return {
                    "success": True,
                    "mode": "FOLLOWER",
                    "execution_method": "PTC",
                    "trace": trace,
                    "cost": 0.0,
                    "tokens_saved": ptc_result.tokens_saved,
                    "results": ptc_result.results
                }
            else:
                print(f"âš ï¸ PTC execution failed: {ptc_result.error}")
                print("   Falling back to cortex replay...")

        # =====================================================================
        # FALLBACK: Cortex replay (original method)
        # =====================================================================
        await self._ensure_cortex()
        success = await self.cortex.follow(trace)

        # Update trace statistics
        self.trace_manager.update_usage(trace.goal_signature)

        return {
            "success": success,
            "mode": "FOLLOWER",
            "execution_method": "cortex",
            "trace": trace,
            "cost": 0.0
        }

    async def _dispatch_mixed(
        self,
        goal: str,
        project: Optional[Project] = None,
        max_cost_usd: float = 5.0
    ) -> Dict[str, Any]:
        """
        Dispatch to Mixed mode (trace-guided LLM execution)

        Used when confidence is 0.75-0.92 (similar but not identical).
        The trace is provided as few-shot guidance to the LLM.

        This is cheaper than full LEARNER mode but more adaptive than FOLLOWER.
        """
        # Find matching trace
        result = await self.trace_manager.find_trace_with_llm(goal, min_confidence=0.75)

        if not result:
            print("[WARNING] MIXED mode requested but no trace found - falling back to LEARNER")
            return await self._dispatch_learner(goal, project, max_cost_usd)

        trace, confidence = result

        estimated_cost = 0.25  # Cheaper than LEARNER ($0.50) but not free

        print(f"ðŸ’¡ Cost: ~${estimated_cost:.2f}, Time: variable")
        print(f"ðŸ’¡ Using trace as guidance (confidence: {confidence:.0%})")

        # Check budget
        try:
            self.token_economy.check_budget(max_cost_usd)
        except LowBatteryError as e:
            return {
                "success": False,
                "error": str(e),
                "mode": "MIXED"
            }

        # Use SDK client if available
        if self.sdk_client:
            print("ðŸ”Œ Using Claude Agent SDK with trace guidance")

            # Build few-shot prompt with trace
            few_shot_context = f"""
# Similar Task Example

I have executed a similar task before. Here's what I did:

**Previous Goal:** {trace.goal_text}
**Success Rate:** {trace.success_rating:.0%}
**Tools Used:** {', '.join(trace.tools_used) if trace.tools_used else 'N/A'}

**Output Summary:**
{trace.output_summary if trace.output_summary else 'No summary available'}

---

**Current Goal (may differ slightly):** {goal}

Use the above as guidance, but adapt as needed for the current goal.
"""

            # Execute with few-shot context
            import hashlib
            goal_signature = hashlib.sha256(goal.encode()).hexdigest()[:16]

            result = await self.sdk_client.execute_learner_mode(
                goal=few_shot_context,
                goal_signature=goal_signature,
                project=project,
                max_cost_usd=max_cost_usd
            )

            # Deduct cost
            if result["success"]:
                self.token_economy.deduct(
                    result["cost"],
                    f"Mixed: {goal[:50]}..."
                )

            result["mode"] = "MIXED"
            result["guidance_trace"] = trace
            result["confidence"] = confidence
            return result

        # Fallback to cortex
        else:
            print("âš ï¸  Using fallback cortex mode (SDK not available)")

            await self._ensure_cortex()

            # Execute with trace as context
            new_trace = await self.cortex.learn(goal, guidance_trace=trace)

            # Save the new trace
            self.trace_manager.save_trace(new_trace)

            # Deduct cost
            self.token_economy.deduct(estimated_cost, f"Mixed: {goal[:50]}...")

            return {
                "success": True,
                "mode": "MIXED",
                "trace": new_trace,
                "guidance_trace": trace,
                "confidence": confidence,
                "cost": estimated_cost
            }

    async def _dispatch_learner(
        self,
        goal: str,
        project: Optional[Project] = None,
        max_cost_usd: float = 5.0
    ) -> Dict[str, Any]:
        """
        Dispatch to Learner mode

        Uses Claude Agent SDK when available for proper integration.
        Falls back to cortex if SDK not installed.

        Execution Strategy (with Execution Layer):
        - Tool Search: Load tools on-demand instead of all upfront
        - Tool Examples: Include auto-generated examples from successful traces
        """
        estimated_cost = 0.50

        print(f"ðŸ’¡ Cost: ~${estimated_cost:.2f}, Time: variable")

        # Check budget
        try:
            self.token_economy.check_budget(max_cost_usd)
        except LowBatteryError as e:
            return {
                "success": False,
                "error": str(e),
                "mode": "LEARNER"
            }

        # =====================================================================
        # EXECUTION LAYER: Prepare efficient tool loading
        # =====================================================================
        tool_search_enabled = False
        tool_examples_enabled = False

        if self.tool_search and self.config.execution.enable_tool_search:
            tool_search_enabled = True
            stats = self.tool_search.get_statistics()
            print(f"ðŸ” Tool Search enabled ({stats['deferred_tools']} deferred, "
                  f"{stats['immediate_tools']} immediate)")

        if self.tool_examples and self.config.execution.enable_tool_examples:
            tool_examples_enabled = True
            stats = self.tool_examples.get_statistics()
            print(f"ðŸ“š Tool Examples enabled ({stats['tools_with_examples']} tools "
                  f"with {stats['total_examples']} examples)")

        # Use SDK client if available (PROPER WAY)
        if self.sdk_client:
            print("ðŸ”Œ Using Claude Agent SDK (proper integration)")

            # Compute goal signature for trace storage
            import hashlib
            goal_signature = hashlib.sha256(goal.encode()).hexdigest()[:16]

            # Get available agents to register in SDK
            available_agents = None
            if hasattr(self, 'orchestrator') and self.orchestrator:
                available_agents = self.orchestrator.component_registry.list_agents()

            # Execute with SDK
            result = await self.sdk_client.execute_learner_mode(
                goal=goal,
                goal_signature=goal_signature,
                project=project,
                available_agents=available_agents,  # Pass all agents!
                max_cost_usd=max_cost_usd
            )

            # Deduct actual cost
            if result["success"]:
                self.token_economy.deduct(
                    result["cost"],
                    f"Learner: {goal[:50]}..."
                )

            # Add execution layer metadata
            result["tool_search_enabled"] = tool_search_enabled
            result["tool_examples_enabled"] = tool_examples_enabled

            return result

        # Fallback to cortex (if SDK not available)
        else:
            print("âš ï¸  Using fallback cortex mode (SDK not available)")

            await self._ensure_cortex()

            # Execute with full LLM reasoning
            trace = await self.cortex.learn(goal)

            # Save the new trace for future use
            self.trace_manager.save_trace(trace)

            # Deduct cost
            actual_cost = estimated_cost
            self.token_economy.deduct(actual_cost, f"Learner: {goal[:50]}...")

            return {
                "success": True,
                "mode": "LEARNER",
                "trace": trace,
                "cost": actual_cost,
                "tool_search_enabled": tool_search_enabled,
                "tool_examples_enabled": tool_examples_enabled
            }

    async def _dispatch_orchestrator(
        self,
        goal: str,
        project: Optional[Project],
        max_cost_usd: float
    ) -> Dict[str, Any]:
        """Dispatch to Orchestrator mode (multi-agent)"""
        print(f"ðŸ’¡ Multi-agent orchestration")
        print(f"ðŸ’¡ Max Cost: ${max_cost_usd:.2f}")

        # Check budget
        try:
            self.token_economy.check_budget(max_cost_usd)
        except LowBatteryError as e:
            return {
                "success": False,
                "error": str(e),
                "mode": "ORCHESTRATOR"
            }

        await self._ensure_orchestrator()

        # Execute orchestration
        result = await self.orchestrator.orchestrate(
            goal=goal,
            project=project,
            max_cost_usd=max_cost_usd
        )

        # Deduct actual cost
        if result.success:
            self.token_economy.deduct(
                result.cost_usd,
                f"Orchestrator: {goal[:50]}..."
            )

        return {
            "success": result.success,
            "mode": "ORCHESTRATOR",
            "output": result.output,
            "steps_completed": result.steps_completed,
            "total_steps": result.total_steps,
            "cost": result.cost_usd,
            "execution_time": result.execution_time_secs,
            "state_summary": result.state_summary
        }

    # =========================================================================
    # EXECUTION LAYER UTILITIES
    # =========================================================================

    def get_execution_layer_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the Execution Layer

        Returns information about:
        - PTC: Container count, tools registered
        - Tool Search: Deferred vs immediate tools
        - Tool Examples: Examples generated from traces
        """
        stats = {
            "enabled": self.config.execution.enable_advanced_tool_use,
            "beta_header": self.config.execution.beta_header
        }

        # PTC stats
        if self.ptc_executor:
            stats["ptc"] = {
                "enabled": True,
                "tools_registered": len(self.ptc_executor.tools),
                "active_containers": len(self.ptc_executor._containers),
                "max_containers": self.ptc_executor.max_containers
            }
        else:
            stats["ptc"] = {"enabled": False}

        # Tool Search stats
        if self.tool_search:
            stats["tool_search"] = self.tool_search.get_statistics()
        else:
            stats["tool_search"] = {"enabled": False}

        # Tool Examples stats
        if self.tool_examples:
            stats["tool_examples"] = self.tool_examples.get_statistics()
        else:
            stats["tool_examples"] = {"enabled": False}

        return stats

    def get_enhanced_tool_definitions(self) -> list:
        """
        Get tool definitions enhanced with examples from traces

        These are ready to use with the Anthropic API's input_examples field.

        Returns:
            List of tool definitions with auto-generated examples
        """
        if not self.tool_examples:
            return []

        if not self.ptc_executor:
            return []

        # Get base definitions from PTC executor
        definitions = self.ptc_executor.get_tool_definitions_for_ptc()

        # Enhance with examples
        return self.tool_examples.enhance_tool_definitions(definitions)

    async def search_tools(self, query: str, top_k: int = 5) -> list:
        """
        Search for tools by description

        This is the interface to the Tool Search Engine.

        Args:
            query: Natural language description of needed capability
            top_k: Maximum results

        Returns:
            List of ToolReference objects
        """
        if not self.tool_search:
            return []

        return self.tool_search.search(query, top_k=top_k)

    def set_sentience_manager(self, sentience_manager):
        """
        Set the sentience manager for dynamic agent adaptation.

        This enables the DynamicAgentManager to adapt agents based on
        current sentience state (curiosity, safety, energy, confidence).

        Args:
            sentience_manager: SentienceManager instance
        """
        self.sentience_manager = sentience_manager

        # Update SDK client if available
        if self.sdk_client:
            self.sdk_client.sentience_manager = sentience_manager
            if self.sdk_client.dynamic_agent_manager:
                self.sdk_client.dynamic_agent_manager.sentience_manager = sentience_manager
                print("âœ“ Sentience manager connected to DynamicAgentManager")

    def set_agent_factory(self, agent_factory):
        """
        Set the agent factory for dynamic agent management.

        This enables the DynamicAgentManager to create and evolve agents
        based on traces and performance metrics.

        Args:
            agent_factory: AgentFactory instance
        """
        from kernel.dynamic_agents import DynamicAgentManager

        self.agent_factory = agent_factory

        # Reinitialize DynamicAgentManager in SDK client
        if self.sdk_client and self.sdk_client.dynamic_agent_manager is None:
            try:
                self.sdk_client.dynamic_agent_manager = DynamicAgentManager(
                    agent_factory=agent_factory,
                    workspace=self.workspace,
                    sentience_manager=self.sentience_manager,
                    trace_manager=self.trace_manager,
                    config=self.config
                )
                print("âœ“ DynamicAgentManager initialized (adaptive subagents enabled)")
            except Exception as e:
                print(f"âš ï¸ Could not initialize DynamicAgentManager: {e}")

    def get_dynamic_agent_stats(self) -> dict:
        """
        Get statistics about dynamic agent adaptations.

        Returns information about:
        - Total adaptations made
        - Adaptations by type (sentience, trace, memory, model)
        - Agent performance metrics
        """
        if not self.sdk_client or not self.sdk_client.dynamic_agent_manager:
            return {"enabled": False}

        manager = self.sdk_client.dynamic_agent_manager
        return {
            "enabled": True,
            "adaptation_summary": manager.get_adaptation_summary(),
            "agent_metrics": manager.get_agent_metrics_summary()
        }

    def trigger_agent_evolution(self, agent_name: str, force: bool = False):
        """
        Manually trigger agent evolution based on accumulated traces.

        Args:
            agent_name: Name of agent to evolve
            force: Force evolution even if thresholds not met

        Returns:
            Evolved AgentSpec or None if no evolution needed
        """
        if not self.sdk_client or not self.sdk_client.dynamic_agent_manager:
            print("âš ï¸ DynamicAgentManager not available")
            return None

        return self.sdk_client.dynamic_agent_manager.analyze_and_evolve_agent(
            agent_name=agent_name,
            force=force
        )

    def shutdown(self):
        """
        Shutdown the Dispatcher and cleanup resources

        Particularly important for PTC containers.
        """
        if self.ptc_executor:
            self.ptc_executor.shutdown_all()
            print("âœ“ PTC containers shutdown")

        if self.tool_examples:
            self.tool_examples.clear_cache()
            print("âœ“ Tool examples cache cleared")

        # Clear dynamic agent cache
        if self.sdk_client and self.sdk_client.dynamic_agent_manager:
            self.sdk_client.dynamic_agent_manager.clear_cache()
            print("âœ“ Dynamic agent cache cleared")



================================================
File: interfaces/orchestrator.py
================================================
"""
SystemAgent Orchestrator - Multi-agent coordination using Claude Agent SDK
Implements llmunix-style orchestration in llmos
"""

import asyncio
import json
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass

try:
    from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions, AgentDefinition
except ImportError:
    print("Warning: claude-agent-sdk not installed. Install with: pip install claude-agent-sdk")
    ClaudeSDKClient = None
    ClaudeAgentOptions = None
    AgentDefinition = None

from kernel.bus import EventBus, Event, EventType
from kernel.project_manager import Project, ProjectManager
from kernel.agent_factory import AgentFactory, AgentSpec
from kernel.component_registry import ComponentRegistry
from kernel.state_manager import StateManager, ExecutionStep
from kernel.token_economy import TokenEconomy
from memory.traces_sdk import TraceManager


@dataclass
class OrchestrationResult:
    """Result of orchestrated execution"""
    success: bool
    output: Any
    steps_completed: int
    total_steps: int
    cost_usd: float
    execution_time_secs: float
    state_summary: Dict[str, Any]


class SystemAgent:
    """
    SystemAgent Orchestrator - Master coordinator for multi-agent workflows

    Equivalent to llmunix SystemAgent, but using Claude Agent SDK.
    Coordinates multiple specialized agents to solve complex problems.
    """

    def __init__(
        self,
        event_bus: EventBus,
        project_manager: ProjectManager,
        agent_factory: AgentFactory,
        component_registry: ComponentRegistry,
        token_economy: TokenEconomy,
        trace_manager: TraceManager,
        workspace: Path,
        model: str = "claude-sonnet-4-5-20250929"
    ):
        """
        Initialize SystemAgent

        Args:
            event_bus: Event bus for system events
            project_manager: Project manager
            agent_factory: Agent factory for creating specialized agents
            component_registry: Component registry for discovery
            token_economy: Token economy for budget management
            trace_manager: Trace manager for memory
            workspace: Workspace directory
            model: Claude model to use
        """
        self.event_bus = event_bus
        self.project_manager = project_manager
        self.agent_factory = agent_factory
        self.component_registry = component_registry
        self.token_economy = token_economy
        self.trace_manager = trace_manager
        self.workspace = Path(workspace)
        self.model = model

        # Ensure system agent is registered
        self._ensure_system_agent_registered()

    def _ensure_system_agent_registered(self):
        """Ensure system agent is in registry"""
        from kernel.agent_factory import SYSTEM_AGENT_TEMPLATE

        if not self.component_registry.get_agent("system-agent"):
            self.component_registry.register_agent(SYSTEM_AGENT_TEMPLATE)

    async def orchestrate(
        self,
        goal: str,
        project: Optional[Project] = None,
        max_cost_usd: float = 5.0
    ) -> OrchestrationResult:
        """
        Orchestrate multi-agent execution to achieve goal

        This is the main entry point for complex, multi-step tasks.

        Workflow:
        1. Consult memory for similar tasks
        2. Decompose goal into sub-tasks
        3. Identify required specialized agents
        4. Create agents if needed (via AgentFactory)
        5. Delegate sub-tasks to agents
        6. Coordinate results
        7. Update memory with learnings

        Args:
            goal: Natural language goal to achieve
            project: Optional project context
            max_cost_usd: Maximum cost budget for this orchestration

        Returns:
            OrchestrationResult with execution details
        """
        import time
        start_time = time.time()

        # Create project if not provided
        if project is None:
            # Extract project name from goal (simple heuristic)
            project_name = goal.split()[0:3]
            project_name = "_".join(project_name).lower().replace(" ", "_")
            project = self.project_manager.create_project(
                name=project_name,
                description=f"Auto-created for goal: {goal}"
            )

        # Initialize state manager
        state = StateManager(project.root_path)
        state.initialize_execution(goal)

        # Set budget constraint
        state.update_constraint("max_token_cost", max_cost_usd)

        # Emit orchestration started event
        await self.event_bus.publish(Event(
            type=EventType.TASK_STARTED,
            data={"goal": goal, "project": project.name}
        ))

        # Log event
        state.log_event("ORCHESTRATION_STARTED", {
            "goal": goal,
            "project": project.name,
            "max_cost_usd": max_cost_usd
        })

        try:
            # Fast-path: Detect simple tool calls and handle directly
            # Pattern: "Use the X tool to Y" or "Call the X tool"
            import re
            tool_call_pattern = r"(?:use|call|execute)\s+(?:the\s+)?(\w+)(?:_tool|\s+tool)"
            match = re.search(tool_call_pattern, goal.lower())

            if match and len(goal.split()) < 20:  # Simple, short requests
                tool_name = match.group(1)
                state.log_event("FAST_PATH_DETECTED", {
                    "tool": tool_name,
                    "reason": "Simple tool call - skipping decomposition"
                })

                # Execute directly without decomposition
                options = ClaudeAgentOptions(
                    model=self.model,
                    cwd=str(project.root_path),
                    permission_mode="acceptEdits"
                )

                total_cost = 0.0
                output_text = ""

                async with ClaudeSDKClient(options=options) as client:
                    await client.query(goal)

                    async for msg in client.receive_response():
                        if hasattr(msg, "content"):
                            for block in msg.content:
                                if hasattr(block, "text"):
                                    output_text += block.text + "\n"

                        if hasattr(msg, "total_cost_usd"):
                            total_cost = msg.total_cost_usd or 0.0

                        if "Result" in msg.__class__.__name__:
                            break

                execution_time = time.time() - start_time
                state.mark_execution_complete(success=True)

                await self.event_bus.publish(Event(
                    type=EventType.TASK_COMPLETED,
                    data={"goal": goal, "fast_path": True}
                ))

                return OrchestrationResult(
                    success=True,
                    output=output_text.strip(),
                    steps_completed=1,
                    total_steps=1,
                    cost_usd=total_cost,
                    execution_time_secs=execution_time,
                    state_summary={"fast_path": True, "tool": tool_name}
                )

            # Step 1: Consult memory
            state.log_event("MEMORY_CONSULTATION", {"phase": "started"})
            memory_insights = await self._consult_memory(goal)
            state.set_variable("memory_insights", memory_insights)

            # Step 2: Register all agents as AgentDefinitions
            all_agents = self.component_registry.list_agents()
            agents_dict = {}
            if all_agents and AgentDefinition:
                for agent in all_agents:
                    try:
                        agents_dict[agent.name] = AgentDefinition(
                            description=agent.description,
                            prompt=agent.system_prompt,
                            tools=agent.tools,
                            model="claude-sonnet-4-5-20250929"  # Use proper model identifier
                        )
                        state.log_event("AGENT_REGISTERED", {
                            "agent": agent.name,
                            "tools": agent.tools
                        })
                    except Exception as e:
                        state.log_event("AGENT_REGISTRATION_FAILED", {
                            "agent": agent.name,
                            "error": str(e)
                        })
                        print(f"[WARNING] Failed to register agent {agent.name}: {e}")

            # Step 3: Create shared SDK client with all agents
            options = ClaudeAgentOptions(
                agents=agents_dict,  # All agents registered!
                cwd=str(project.root_path),
                permission_mode="acceptEdits"
            )

            # Step 4: Decompose goal using Claude Agent SDK
            state.log_event("GOAL_DECOMPOSITION", {"phase": "started"})
            plan = await self._decompose_goal(goal, project, memory_insights)
            state.set_plan(plan)

            # Step 4.5: Ensure all agents in plan exist (create on-demand if needed)
            plan, new_agents = await self._ensure_agents_for_plan(plan, project, state)

            # If new agents were created, re-register them with SDK
            if new_agents:
                for new_agent in new_agents:
                    try:
                        agents_dict[new_agent.name] = AgentDefinition(
                            description=new_agent.description,
                            prompt=new_agent.system_prompt,
                            tools=new_agent.tools,
                            model="claude-sonnet-4-5-20250929"
                        )
                        state.log_event("AGENT_CREATED_ON_DEMAND", {
                            "agent": new_agent.name,
                            "tools": new_agent.tools
                        })
                    except Exception as e:
                        print(f"[WARNING] Failed to register new agent {new_agent.name}: {e}")

                # Update options with new agents
                options = ClaudeAgentOptions(
                    agents=agents_dict,
                    cwd=str(project.root_path),
                    permission_mode="acceptEdits"
                )

            # Step 5: Execute plan with shared client
            total_cost = 0.0
            async with ClaudeSDKClient(options=options) as client:
                for step in plan:
                    state.update_step_status(step.step_number, "in_progress")

                    # Check budget
                    if total_cost >= max_cost_usd:
                        state.log_event("BUDGET_EXCEEDED", {
                            "total_cost": total_cost,
                            "max_cost": max_cost_usd
                        })
                        break

                    # Execute step with shared client
                    step_result = await self._execute_step_with_client(
                        client, step, project, state
                    )

                    if step_result["success"]:
                        state.update_step_status(
                            step.step_number,
                            "completed",
                            result=step_result.get("output")
                        )
                        total_cost += step_result.get("cost", 0.0)
                    else:
                        state.update_step_status(
                            step.step_number,
                            "failed",
                            error=step_result.get("error")
                        )
                        # Continue or halt based on criticality
                        # For now, continue

            # Step 6: Consolidate results
            execution_summary = state.get_execution_summary()
            state.mark_execution_complete(success=True)

            # Emit completion event
            await self.event_bus.publish(Event(
                type=EventType.TASK_COMPLETED,
                data={"goal": goal, "summary": execution_summary}
            ))

            # Calculate execution time
            execution_time = time.time() - start_time

            return OrchestrationResult(
                success=True,
                output=execution_summary,
                steps_completed=execution_summary["completed_steps"],
                total_steps=execution_summary["total_steps"],
                cost_usd=total_cost,
                execution_time_secs=execution_time,
                state_summary=execution_summary
            )

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"\n[ERROR] Orchestration failed:")
            print(error_details)

            state.log_event("ORCHESTRATION_FAILED", {
                "error": str(e),
                "traceback": error_details
            })
            state.mark_execution_complete(success=False)

            execution_time = time.time() - start_time

            return OrchestrationResult(
                success=False,
                output=str(e),
                steps_completed=0,
                total_steps=len(plan) if 'plan' in locals() else 0,
                cost_usd=0.0,
                execution_time_secs=execution_time,
                state_summary={}
            )

    async def _consult_memory(self, goal: str) -> Dict[str, Any]:
        """
        Consult memory for similar tasks

        Args:
            goal: Goal to search for

        Returns:
            Memory insights
        """
        # Find similar traces
        trace = self.trace_manager.find_trace(goal, min_confidence=0.7)

        insights = {
            "similar_trace_found": trace is not None,
            "trace": trace,
            "recommendations": []
        }

        if trace:
            insights["recommendations"].append(
                f"Similar task executed {trace.usage_count} times with "
                f"{trace.success_rating:.0%} success rate"
            )

        return insights

    async def _decompose_goal(
        self,
        goal: str,
        project: Project,
        memory_insights: Dict[str, Any]
    ) -> List[ExecutionStep]:
        """
        Decompose goal into execution steps using Claude Agent SDK

        Args:
            goal: Goal to decompose
            project: Project context
            memory_insights: Insights from memory consultation

        Returns:
            List of ExecutionStep instances
        """
        if ClaudeSDKClient is None:
            raise RuntimeError("Claude Agent SDK not installed")

        # Build planning prompt
        planning_prompt = f"""Decompose this goal into concrete execution steps:

Goal: {goal}

Memory Insights:
{json.dumps(memory_insights, indent=2)}

Available Agents:
{self._get_available_agents_summary()}

IMPORTANT - Agent Assignment:
You may (and SHOULD) suggest specialized agents even if they don't exist yet.
The system will automatically create them on-demand before execution.

Use descriptive kebab-case names that reflect the agent's purpose, such as:
- ansatz-designer (for quantum circuit design)
- vqe-executor (for running VQE simulations)
- optimizer-agent (for classical optimization)
- data-processor (for data transformation)
- code-generator (for writing code)
- test-runner (for running tests)

Only use "system-agent" for generic coordination tasks that don't need specialization.

Create a detailed execution plan with:
1. Clear, actionable steps
2. Agent assignment for each step (prefer specialized agents over system-agent)
3. Expected output for each step

Format your response as JSON:
{{
  "steps": [
    {{
      "number": 1,
      "description": "Step description",
      "agent": "specialized-agent-name",
      "expected_output": "What this step should produce"
    }}
  ]
}}
"""

        # Configure agent options
        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(project.root_path),
            allowed_tools=["Read", "Write", "Grep", "Glob"],
            permission_mode="acceptEdits",  # Auto-accept to avoid hanging
            system_prompt={
                "type": "preset",
                "preset": "claude_code",
                "append": """
You are the planning component of a multi-agent LLM operating system.
Your role is to decompose complex goals into concrete execution steps.

Think systematically:
1. What needs to be done?
2. What's the optimal order?
3. Which specialized agent should handle each step?
4. What are the dependencies between steps?

Be specific and actionable.
"""
            }
        )

        plan_json = None

        async with ClaudeSDKClient(options=options) as client:
            await client.query(planning_prompt)

            async for msg in client.receive_response():
                # Extract plan from response
                if hasattr(msg, "content"):
                    for block in msg.content:
                        if hasattr(block, "text"):
                            text = block.text
                            # Try to parse JSON from response
                            try:
                                # Find JSON in response
                                start = text.find("{")
                                end = text.rfind("}") + 1
                                if start != -1 and end != 0:
                                    plan_json = json.loads(text[start:end])
                            except json.JSONDecodeError:
                                continue

        # Convert to ExecutionStep instances
        steps = []
        if plan_json and "steps" in plan_json:
            for step_data in plan_json["steps"]:
                steps.append(ExecutionStep(
                    step_number=step_data["number"],
                    description=step_data["description"],
                    agent=step_data.get("agent", "system-agent"),
                    status="pending"
                ))

        # If no plan generated, create simple fallback
        if not steps:
            steps = [
                ExecutionStep(
                    step_number=1,
                    description=goal,
                    agent="system-agent",
                    status="pending"
                )
            ]

        return steps

    async def _execute_step_with_client(
        self,
        client: ClaudeSDKClient,
        step: ExecutionStep,
        project: Project,
        state: StateManager
    ) -> Dict[str, Any]:
        """
        Execute a single step using shared SDK client with agent delegation

        Uses natural language to delegate to registered agents:
        "Use the {agent_name} agent to {task_description}"

        Args:
            client: Shared ClaudeSDKClient with all agents registered
            step: ExecutionStep to execute
            project: Project context
            state: State manager

        Returns:
            Result dictionary with success, output, cost
        """
        state.log_event("STEP_EXECUTION_STARTED", {
            "step": step.step_number,
            "description": step.description,
            "agent": step.agent
        })

        # Check if agent exists
        agent_spec = self.component_registry.get_agent(step.agent)

        if agent_spec is None:
            state.log_event("AGENT_NOT_FOUND", {
                "agent": step.agent,
                "action": "using system-agent as fallback"
            })
            # Use system-agent as fallback
            step.agent = "system-agent"

        # Delegate using natural language (SDK handles routing to agent)
        delegation_prompt = f"Use the {step.agent} agent to {step.description}"

        result = await self._delegate_with_client(
            client,
            delegation_prompt,
            state
        )

        state.log_event("STEP_EXECUTION_COMPLETED", {
            "step": step.step_number,
            "success": result["success"],
            "cost": result.get("cost", 0.0)
        })

        return result

    async def _delegate_with_client(
        self,
        client: ClaudeSDKClient,
        delegation_prompt: str,
        state: StateManager,
        timeout_seconds: float = 300.0  # 5 minute timeout
    ) -> Dict[str, Any]:
        """
        Delegate task using shared SDK client

        The SDK routes to the appropriate agent based on natural language.
        Example: "Use the code-reviewer agent to review src/types.py"

        Args:
            client: Shared ClaudeSDKClient with agents registered
            delegation_prompt: Natural language delegation instruction
            state: State manager
            timeout_seconds: Timeout in seconds (default 300s/5min)

        Returns:
            Result dictionary
        """
        result_text_parts = []
        cost_estimate = 0.0

        print(f"\n[DEBUG] Starting delegation: {delegation_prompt[:100]}...")
        state.log_event("DELEGATION_STARTED", {
            "prompt": delegation_prompt[:200]
        })

        try:
            # Send delegation via SDK
            print(f"[DEBUG] Sending query to SDK...")
            await client.query(delegation_prompt)
            print(f"[DEBUG] Query sent, waiting for response...")

            # Collect response with timeout and inactivity detection
            async def collect_responses():
                nonlocal result_text_parts, cost_estimate
                message_count = 0
                last_message_time = asyncio.get_event_loop().time()
                inactivity_timeout = 60.0  # 60 seconds of no messages = likely stuck
                stop_iteration = False

                async def message_iterator():
                    """Wrapper to track last message time"""
                    nonlocal last_message_time, message_count, stop_iteration
                    try:
                        async for msg in client.receive_response():
                            if stop_iteration:
                                break
                            last_message_time = asyncio.get_event_loop().time()
                            message_count += 1
                            yield msg
                    except asyncio.CancelledError:
                        print(f"[DEBUG] Message iterator cancelled")
                        raise

                async def inactivity_checker():
                    """Check for inactivity and stop iteration if stuck"""
                    nonlocal stop_iteration
                    try:
                        while True:
                            await asyncio.sleep(5.0)  # Check every 5 seconds
                            time_since_last = asyncio.get_event_loop().time() - last_message_time
                            if time_since_last > inactivity_timeout:
                                print(f"[WARNING] No messages for {time_since_last:.1f}s - stopping delegation")
                                stop_iteration = True
                                raise asyncio.TimeoutError(f"Inactivity timeout: no messages for {time_since_last:.1f}s")
                    except asyncio.CancelledError:
                        # Expected when we're shutting down
                        pass

                # Run both the message iterator and inactivity checker concurrently
                inactivity_task = asyncio.create_task(inactivity_checker())
                iteration_error = None

                try:
                    async for msg in message_iterator():
                        print(f"[DEBUG] Received message {message_count}: {type(msg).__name__}")

                        # Log activity
                        activity = self._get_activity_text(msg)
                        if activity:
                            print(f"[DEBUG] Activity: {activity}")
                            state.log_event("AGENT_ACTIVITY", {
                                "activity": activity
                            })

                        # Extract text from AssistantMessage
                        if hasattr(msg, "content"):
                            for block in msg.content:
                                if hasattr(block, "text"):
                                    result_text_parts.append(block.text)
                                    print(f"[DEBUG] Extracted text: {block.text[:100]}...")

                        # Get cost from ResultMessage and break (delegation complete)
                        if hasattr(msg, "total_cost_usd"):
                            cost_estimate = msg.total_cost_usd or 0.0
                            print(f"[DEBUG] Cost: ${cost_estimate:.4f}")

                        # Break on ResultMessage (indicates completion)
                        if "Result" in msg.__class__.__name__:
                            print(f"[DEBUG] ResultMessage received - delegation complete")
                            break  # Exit loop when ResultMessage is received
                except asyncio.TimeoutError as e:
                    # Capture inactivity timeout for re-raising
                    iteration_error = e
                    print(f"[DEBUG] Caught inactivity timeout in message loop")
                finally:
                    # Cancel inactivity checker
                    inactivity_task.cancel()
                    try:
                        await inactivity_task
                    except asyncio.CancelledError:
                        pass
                    except asyncio.TimeoutError as e:
                        # Capture any timeout from the checker
                        if iteration_error is None:
                            iteration_error = e

                print(f"[DEBUG] Finished collecting responses. Total messages: {message_count}")

                # Re-raise inactivity timeout if it occurred
                if iteration_error:
                    raise iteration_error

            # Apply timeout
            await asyncio.wait_for(collect_responses(), timeout=timeout_seconds)

            print(f"[DEBUG] Delegation completed successfully")
            state.log_event("DELEGATION_COMPLETED", {
                "success": True,
                "cost": cost_estimate,
                "result_length": len("".join(result_text_parts))
            })

            return {
                "success": True,
                "output": "\n".join(result_text_parts) if result_text_parts else "",
                "cost": cost_estimate
            }

        except asyncio.TimeoutError:
            error_msg = f"Delegation timed out after {timeout_seconds}s"
            print(f"[ERROR] {error_msg}")

            # Drain any remaining messages to prevent bleeding into next delegation
            print(f"[DEBUG] Draining remaining messages from timed-out delegation...")
            try:
                # Try to collect remaining messages with a short timeout
                async def drain_messages():
                    drained = 0
                    async for msg in client.receive_response():
                        drained += 1
                        print(f"[DEBUG] Drained message {drained}: {type(msg).__name__}")
                        # Update cost if we find a ResultMessage
                        if hasattr(msg, "total_cost_usd"):
                            nonlocal cost_estimate
                            cost_estimate = msg.total_cost_usd or cost_estimate
                        # Stop if we hit a ResultMessage
                        if "Result" in msg.__class__.__name__:
                            print(f"[DEBUG] Found ResultMessage while draining")
                            break
                    print(f"[DEBUG] Drained {drained} messages")

                await asyncio.wait_for(drain_messages(), timeout=5.0)
            except asyncio.TimeoutError:
                print(f"[DEBUG] Drain timeout - some messages may remain buffered")
            except Exception as e:
                print(f"[DEBUG] Error while draining: {e}")

            state.log_event("DELEGATION_TIMEOUT", {
                "timeout": timeout_seconds,
                "prompt": delegation_prompt[:200]
            })
            return {
                "success": False,
                "error": error_msg,
                "cost": cost_estimate
            }

        except Exception as e:
            error_msg = f"Delegation failed: {str(e)}"
            print(f"[ERROR] {error_msg}")
            import traceback
            traceback.print_exc()
            state.log_event("DELEGATION_ERROR", {
                "error": str(e),
                "traceback": traceback.format_exc()
            })
            return {
                "success": False,
                "error": str(e),
                "cost": cost_estimate
            }

    async def _delegate_to_agent(
        self,
        agent_spec: AgentSpec,
        task: str,
        project: Project,
        state: StateManager
    ) -> Dict[str, Any]:
        """
        DEPRECATED: Use _delegate_with_client instead

        Legacy method that creates a new SDK client per delegation.
        Kept for backward compatibility but not used in orchestrate().

        The new approach registers all agents upfront and uses
        natural language delegation with a shared client.

        Args:
            agent_spec: Agent specification
            task: Task description
            project: Project context
            state: State manager

        Returns:
            Result dictionary
        """
        if ClaudeSDKClient is None:
            raise RuntimeError("Claude Agent SDK not installed")

        # Configure agent options
        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(project.root_path),
            allowed_tools=agent_spec.tools,
            system_prompt={
                "type": "text",
                "text": agent_spec.system_prompt
            },
            permission_mode="acceptEdits"  # Auto-accept tool executions
        )

        result_text = None
        cost_estimate = 0.0

        try:
            async with ClaudeSDKClient(options=options) as client:
                await client.query(task)

                async for msg in client.receive_response():
                    # Emit activity event
                    activity = self._get_activity_text(msg)
                    if activity:
                        state.log_event("AGENT_ACTIVITY", {
                            "agent": agent_spec.name,
                            "activity": activity
                        })

                    # Extract result
                    if hasattr(msg, "result"):
                        result_text = msg.result

                    # Estimate cost (rough approximation)
                    # TODO: Get actual cost from SDK if available
                    cost_estimate += 0.001  # Small cost per message

            return {
                "success": True,
                "output": result_text,
                "cost": cost_estimate
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "cost": cost_estimate
            }

    async def _ensure_agents_for_plan(
        self,
        plan: List[ExecutionStep],
        project: Project,
        state: StateManager
    ) -> Tuple[List[ExecutionStep], List[AgentSpec]]:
        """
        Ensure all agents in the plan exist, creating them on-demand if needed.

        This solves the cold-start problem: when ORCHESTRATOR mode is selected
        but no specialized agents exist, we create them before execution.

        Args:
            plan: List of execution steps with agent assignments
            project: Project context for agent creation
            state: State manager for logging

        Returns:
            Tuple of (updated_plan, list_of_newly_created_agents)
        """
        new_agents = []
        agents_needed = set()

        # Collect unique agent names from plan (excluding system-agent)
        for step in plan:
            if step.agent and step.agent != "system-agent":
                agents_needed.add(step.agent)

        if not agents_needed:
            return plan, new_agents

        state.log_event("AGENT_GAP_DETECTION", {
            "agents_in_plan": list(agents_needed),
            "phase": "started"
        })

        # Check which agents don't exist
        missing_agents = []
        for agent_name in agents_needed:
            if not self.component_registry.get_agent(agent_name):
                missing_agents.append(agent_name)

        if not missing_agents:
            state.log_event("AGENT_GAP_DETECTION", {
                "result": "all_agents_exist",
                "phase": "completed"
            })
            return plan, new_agents

        print(f"\n[INFO] Detected {len(missing_agents)} missing agents: {missing_agents}")
        print("[INFO] Creating agents on-demand...")

        # Create missing agents
        for agent_name in missing_agents:
            # Find the step(s) that need this agent to understand the capability needed
            capability_hints = []
            for step in plan:
                if step.agent == agent_name:
                    capability_hints.append(step.description)

            capability = f"{agent_name}: {'; '.join(capability_hints)}"

            print(f"[INFO] Creating agent '{agent_name}'...")
            state.log_event("AGENT_CREATION_STARTED", {
                "agent": agent_name,
                "capability": capability[:200]
            })

            try:
                new_agent = await self.create_agent_on_demand(capability, project)

                if new_agent:
                    new_agents.append(new_agent)
                    print(f"[INFO] Successfully created agent: {new_agent.name}")
                    state.log_event("AGENT_CREATION_SUCCESS", {
                        "agent": new_agent.name,
                        "tools": new_agent.tools
                    })
                else:
                    # Fallback: update plan to use system-agent
                    print(f"[WARNING] Could not create '{agent_name}', falling back to system-agent")
                    state.log_event("AGENT_CREATION_FAILED", {
                        "agent": agent_name,
                        "fallback": "system-agent"
                    })
                    for step in plan:
                        if step.agent == agent_name:
                            step.agent = "system-agent"

            except Exception as e:
                print(f"[ERROR] Failed to create agent '{agent_name}': {e}")
                state.log_event("AGENT_CREATION_ERROR", {
                    "agent": agent_name,
                    "error": str(e)
                })
                # Fallback to system-agent
                for step in plan:
                    if step.agent == agent_name:
                        step.agent = "system-agent"

        state.log_event("AGENT_GAP_DETECTION", {
            "agents_created": [a.name for a in new_agents],
            "phase": "completed"
        })

        return plan, new_agents

    def _get_activity_text(self, msg) -> Optional[str]:
        """Extract activity text from a message (from chief_of_staff example)"""
        try:
            if "Assistant" in msg.__class__.__name__:
                if hasattr(msg, "content") and msg.content:
                    first_content = msg.content[0] if isinstance(msg.content, list) else msg.content
                    if hasattr(first_content, "name"):
                        return f"Using: {first_content.name}()"
                return "Thinking..."
            elif "User" in msg.__class__.__name__:
                return "Tool completed"
        except (AttributeError, IndexError):
            pass
        return None

    def _get_available_agents_summary(self) -> str:
        """Get summary of available agents for planning"""
        agents = self.component_registry.list_agents(status="production")

        summary_parts = []
        for agent in agents:
            summary_parts.append(
                f"- {agent.name}: {agent.description} (Tools: {', '.join(agent.tools)})"
            )

        return "\n".join(summary_parts) if summary_parts else "No specialized agents available"

    async def create_agent_on_demand(
        self,
        capability: str,
        project: Project
    ) -> Optional[AgentSpec]:
        """
        Create a specialized agent on-demand for a capability

        Args:
            capability: Capability description
            project: Project context

        Returns:
            Created AgentSpec or None
        """
        # Use Claude to design the agent
        if ClaudeSDKClient is None:
            return None

        design_prompt = f"""Design a specialized agent for this capability: {capability}

Create an agent specification in JSON format:
{{
  "name": "kebab-case-name",
  "type": "specialized",
  "category": "domain_category",
  "description": "When to use this agent",
  "tools": ["Read", "Write", "Bash"],
  "capabilities": ["capability 1", "capability 2"],
  "constraints": ["constraint 1", "constraint 2"],
  "system_prompt": "Detailed agent instructions..."
}}
"""

        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(project.root_path),
            allowed_tools=[],
            permission_mode="acceptEdits",  # Auto-accept to avoid hanging
            system_prompt={
                "type": "text",
                "text": "You are an agent designer. Create detailed agent specifications."
            }
        )

        agent_json = None

        async with ClaudeSDKClient(options=options) as client:
            await client.query(design_prompt)

            async for msg in client.receive_response():
                if hasattr(msg, "content"):
                    for block in msg.content:
                        if hasattr(block, "text"):
                            text = block.text
                            try:
                                start = text.find("{")
                                end = text.rfind("}") + 1
                                if start != -1 and end != 0:
                                    agent_json = json.loads(text[start:end])
                            except json.JSONDecodeError:
                                continue

        if agent_json:
            # Map JSON keys to factory parameter names
            # JSON uses "type" but factory expects "agent_type"
            factory_args = {
                "name": agent_json.get("name", "specialized-agent"),
                "agent_type": agent_json.get("type", "specialized"),
                "category": agent_json.get("category", "general"),
                "description": agent_json.get("description", "Auto-created specialized agent"),
                "system_prompt": agent_json.get("system_prompt", "You are a specialized agent."),
                "tools": agent_json.get("tools", ["Read", "Write", "Bash"]),
                "capabilities": agent_json.get("capabilities", []),
                "constraints": agent_json.get("constraints", [])
            }

            # Create agent using factory
            agent = self.agent_factory.create_agent(**factory_args)
            self.component_registry.register_agent(agent)
            return agent

        return None

    async def crystallize_pattern(
        self,
        trace_signature: str,
        plugin_loader = None
    ) -> Optional[str]:
        """
        Crystallize an execution trace into a Python tool (HOPE Protocol).

        This implements the Self-Modifying Kernel architecture from the Nested Learning paper.
        Converts fluid intelligence (LLM reasoning) into crystallized intelligence (Python code).

        Workflow:
        1. Retrieve trace details from memory
        2. Instantiate Toolsmith agent
        3. Generate Python plugin code
        4. Validate syntax
        5. Hot-load the new tool
        6. Mark trace as crystallized

        Args:
            trace_signature: Signature of the trace to crystallize
            plugin_loader: Optional PluginLoader instance for hot-loading

        Returns:
            Name of generated tool if successful, None otherwise
        """
        if ClaudeSDKClient is None:
            print("[ERROR] Claude Agent SDK required for crystallization")
            return None

        print(f"\n{'='*60}")
        print(f"ðŸ’Ž CRYSTALLIZATION: Converting trace to tool")
        print(f"{'='*60}")

        # 1. Get trace details
        traces = self.trace_manager.list_traces()
        trace = None
        for t in traces:
            if t.goal_signature == trace_signature:
                trace = t
                break

        if not trace:
            print(f"[ERROR] Trace not found: {trace_signature}")
            return None

        print(f"ðŸ“ Goal: {trace.goal_text}")
        print(f"ðŸ“Š Usage: {trace.usage_count} times, {trace.success_rating:.0%} success")

        # 2. Ensure Toolsmith agent is registered
        from kernel.agent_factory import TOOLSMITH_AGENT_TEMPLATE

        if not self.component_registry.get_agent("toolsmith-agent"):
            self.component_registry.register_agent(TOOLSMITH_AGENT_TEMPLATE)

        # 3. Build crystallization prompt with trace details
        tools_used_str = ", ".join(trace.tools_used) if trace.tools_used else "N/A"

        crystallization_prompt = f"""
Convert this execution trace into a Python plugin tool.

## Trace Details

**Goal:** {trace.goal_text}
**Signature:** {trace.goal_signature}
**Success Rate:** {trace.success_rating:.0%}
**Usage Count:** {trace.usage_count}
**Tools Used:** {tools_used_str}
**Output Summary:**
{trace.output_summary or 'No summary available'}

## Your Task

1. Analyze the goal and determine the core functionality
2. Design a clean function signature with appropriate parameters
3. Implement the function using the @llm_tool decorator
4. Include error handling and type hints
5. Add comprehensive docstrings
6. Save to: `llmos/plugins/generated/tool_{trace.goal_signature}.py`

## Important

- The tool should generalize the pattern, not just replay the exact trace
- Use async def for the function
- Return a dict with {{"success": bool, "result": any}}
- Follow all safety constraints from your system prompt

Generate the complete Python file now.
"""

        # 4. Execute with Toolsmith agent using SDK delegation
        print(f"\nðŸ”¨ Invoking Toolsmith agent...")

        # Use the shared client approach
        toolsmith = self.component_registry.get_agent("toolsmith-agent")

        if not toolsmith:
            print("[ERROR] Toolsmith agent not found")
            return None

        # Create temporary project for this operation
        temp_project = Project(
            name="crystallization",
            description="Tool crystallization workspace",
            root_path=self.workspace
        )

        # Delegate to Toolsmith using Claude Agent SDK
        # Register Toolsmith as an AgentDefinition
        agents_dict = {}
        if AgentDefinition:
            agents_dict["toolsmith-agent"] = AgentDefinition(
                description=toolsmith.description,
                prompt=toolsmith.system_prompt,
                tools=toolsmith.tools,
                model="claude-sonnet-4-5-20250929"
            )

        options = ClaudeAgentOptions(
            agents=agents_dict,
            cwd=str(self.workspace),
            permission_mode="acceptEdits"
        )

        result = None

        async with ClaudeSDKClient(options=options) as client:
            # Delegate to Toolsmith
            delegation_msg = f"Use the toolsmith-agent to {crystallization_prompt}"

            result_parts = []
            await client.query(delegation_msg)

            async for msg in client.receive_response():
                # Extract result
                if hasattr(msg, "content"):
                    for block in msg.content:
                        if hasattr(block, "text"):
                            result_parts.append(block.text)

                # Break on ResultMessage
                if "Result" in msg.__class__.__name__:
                    break

            result = "\n".join(result_parts)

        # 5. Verify file was created
        generated_tool_path = self.workspace / "llmos" / "plugins" / "generated" / f"tool_{trace.goal_signature}.py"

        if not generated_tool_path.exists():
            print(f"[ERROR] Tool file not created at: {generated_tool_path}")
            return None

        # 6. Validate syntax using ast module
        print(f"\nâœ… Validating generated code...")

        try:
            import ast
            with open(generated_tool_path, 'r') as f:
                code = f.read()
            ast.parse(code)
            print("   âœ“ Syntax valid")
        except SyntaxError as e:
            print(f"[ERROR] Invalid syntax in generated tool: {e}")
            return None

        # 7. Hot-load the tool
        if plugin_loader:
            print(f"\nðŸ”¥ Hot-loading tool...")
            success = plugin_loader.load_plugin_dynamically(generated_tool_path)

            if not success:
                print(f"[ERROR] Failed to hot-load tool")
                return None
        else:
            print(f"   âš ï¸  No plugin loader provided - tool will be loaded on next boot")

        # 8. Mark trace as crystallized
        tool_name = f"tool_{trace.goal_signature}"
        self.trace_manager.mark_trace_as_crystallized(trace.goal_signature, tool_name)

        print(f"\n{'='*60}")
        print(f"ðŸ’Ž SUCCESS: Tool crystallized as '{tool_name}'")
        print(f"{'='*60}\n")

        return tool_name



================================================
File: interfaces/sdk_client.py
================================================
"""
Claude SDK Client Integration for llmos
Proper integration with Claude Agent SDK for Learner and Orchestrator modes
"""

from pathlib import Path
from typing import Optional, Dict, Any, List, Union
from datetime import datetime

try:
    from claude_agent_sdk import ClaudeSDKClient, query as sdk_query, AgentDefinition
    from claude_agent_sdk.types import ClaudeAgentOptions, HookEvent, HookMatcher, Message
    from claude_agent_sdk.types import AssistantMessage, ResultMessage, TextBlock, ToolUseBlock, StreamEvent
    SDK_AVAILABLE = True
except ImportError:
    SDK_AVAILABLE = False
    AgentDefinition = None
    StreamEvent = None
    ClaudeSDKClient = None
    ClaudeAgentOptions = None
    HookEvent = None
    HookMatcher = None
    Message = None
    AssistantMessage = None
    ResultMessage = None
    TextBlock = None
    ToolUseBlock = None
    print("Warning: claude-agent-sdk not installed. Install with: pip install claude-agent-sdk")

from memory.traces_sdk import ExecutionTrace
from kernel.project_manager import Project
from kernel.agent_factory import AgentSpec, AgentFactory
from kernel.hooks import HookRegistry, create_default_hooks
from kernel.agent_loader import AgentLoader

# Import DynamicAgentManager for adaptive subagents
try:
    from kernel.dynamic_agents import DynamicAgentManager
    DYNAMIC_AGENTS_AVAILABLE = True
except ImportError:
    DynamicAgentManager = None
    DYNAMIC_AGENTS_AVAILABLE = False


def agent_spec_to_definition(spec: AgentSpec, model_override: str = None) -> 'AgentDefinition':
    """
    Convert AgentSpec to Claude SDK AgentDefinition

    Args:
        spec: AgentSpec instance
        model_override: Optional model override (from dynamic selection)

    Returns:
        AgentDefinition for SDK
    """
    if not SDK_AVAILABLE or AgentDefinition is None:
        raise RuntimeError("Claude Agent SDK not available")

    # Use model from spec if available, otherwise default to sonnet
    model = model_override or getattr(spec, 'model', 'sonnet') or 'sonnet'

    return AgentDefinition(
        description=spec.description,
        prompt=spec.system_prompt,
        tools=spec.tools,
        model=model
    )


class TraceBuilder:
    """
    Builds execution traces from SDK messages

    Captures tool usage, outputs, and metadata during execution
    to create replayable traces for Follower mode.

    Now also captures full tool_calls for PTC (Programmatic Tool Calling):
    - Stores tool name AND arguments for each call
    - Enables zero-context replay via Anthropic's Advanced Tool Use
    """

    def __init__(self, goal: str):
        self.goal = goal
        self.tools_used: List[str] = []
        self.tool_calls: List[Dict[str, Any]] = []  # NEW: Full tool call data for PTC
        self.output_parts: List[str] = []
        self.error_notes: List[str] = []
        self.start_time = datetime.now()
        self.end_time: Optional[datetime] = None
        self.cost_usd: float = 0.0
        self.success: bool = True

    def add_message(self, message: 'Message'):
        """Process message and extract trace information"""
        if not SDK_AVAILABLE:
            return

        # Extract from AssistantMessage
        if isinstance(message, AssistantMessage):
            for block in message.content:
                if isinstance(block, TextBlock):
                    self.output_parts.append(block.text)
                elif isinstance(block, ToolUseBlock):
                    # Track tool name (for quick filtering)
                    if block.name not in self.tools_used:
                        self.tools_used.append(block.name)

                    # NEW: Store full tool call data for PTC replay
                    self.tool_calls.append({
                        "name": block.name,
                        "arguments": block.input if hasattr(block, 'input') else {},
                        "id": block.id if hasattr(block, 'id') else None
                    })

        # Extract from ResultMessage
        elif isinstance(message, ResultMessage):
            self.end_time = datetime.now()
            self.cost_usd = message.total_cost_usd
            # Consider it successful if no error in result
            self.success = not hasattr(message, 'error') or message.error is None

    def add_tool_call(self, name: str, arguments: Dict[str, Any], tool_id: str = None):
        """
        Manually add a tool call (for non-SDK execution paths)

        Args:
            name: Tool name
            arguments: Tool arguments
            tool_id: Optional tool call ID
        """
        if name not in self.tools_used:
            self.tools_used.append(name)

        self.tool_calls.append({
            "name": name,
            "arguments": arguments,
            "id": tool_id
        })

    def add_error(self, error: str):
        """Add error note"""
        self.error_notes.append(error)
        self.success = False

    def to_trace(self, goal_signature: str) -> ExecutionTrace:
        """Convert to ExecutionTrace"""
        execution_time = (
            (self.end_time - self.start_time).total_seconds()
            if self.end_time else 0.0
        )

        return ExecutionTrace(
            goal_signature=goal_signature,
            goal_text=self.goal,
            success_rating=1.0 if self.success else 0.5,
            usage_count=1,
            created_at=self.start_time,
            last_used=None,
            estimated_cost_usd=self.cost_usd,
            estimated_time_secs=execution_time,
            mode="LEARNER",
            tools_used=self.tools_used if self.tools_used else None,
            output_summary="\n".join(self.output_parts[:5]) if self.output_parts else "",
            error_notes="\n".join(self.error_notes) if self.error_notes else "",
            tool_calls=self.tool_calls if self.tool_calls else None  # NEW: For PTC
        )


class LLMOSSDKClient:
    """
    Wrapper around Claude Agent SDK for llmos integration

    Provides proper integration between llmos architecture and
    Claude Agent SDK, handling:
    - Learner mode execution with trace capture
    - Orchestrator mode with multi-agent coordination
    - Hook-based trace building and control flow
    - Project-aware execution
    - System prompt presets
    - Streaming support
    """

    def __init__(
        self,
        workspace: Path,
        trace_manager: Optional[Any] = None,
        token_economy: Optional[Any] = None,
        memory_query: Optional[Any] = None,
        sentience_manager: Optional[Any] = None,
        agent_factory: Optional[AgentFactory] = None,
        config: Optional[Any] = None
    ):
        """
        Initialize SDK client wrapper

        Args:
            workspace: Workspace directory
            trace_manager: Optional trace manager for saving traces
            token_economy: Optional TokenEconomy for budget control hooks
            memory_query: Optional MemoryQueryInterface for context injection hooks
            sentience_manager: Optional SentienceManager for adaptive agents
            agent_factory: Optional AgentFactory for creating agents
            config: Optional LLMOSConfig
        """
        if not SDK_AVAILABLE:
            raise RuntimeError(
                "Claude Agent SDK not installed. "
                "Install with: pip install claude-agent-sdk"
            )

        self.workspace = Path(workspace)
        self.trace_manager = trace_manager
        self.token_economy = token_economy
        self.memory_query = memory_query
        self.sentience_manager = sentience_manager
        self.config = config

        # Initialize AgentLoader for Markdown-defined agents (Hybrid Architecture)
        self.agent_loader = AgentLoader(str(workspace / "agents"))

        # Initialize DynamicAgentManager for adaptive subagents
        self.dynamic_agent_manager: Optional[DynamicAgentManager] = None
        if DYNAMIC_AGENTS_AVAILABLE and agent_factory:
            self.dynamic_agent_manager = DynamicAgentManager(
                agent_factory=agent_factory,
                workspace=workspace,
                sentience_manager=sentience_manager,
                trace_manager=trace_manager,
                config=config
            )
            print("âœ“ DynamicAgentManager initialized (adaptive subagents enabled)")

    def _build_agent_options(
        self,
        agent_spec: Optional[AgentSpec] = None,
        project: Optional[Project] = None,
        available_agents: Optional[List[AgentSpec]] = None,
        permission_mode: str = "default",
        hooks: Optional[Dict[HookEvent, List[HookMatcher]]] = None,
        use_preset: bool = False,
        preset_name: str = "claude_code",
        model: str = "sonnet",
        max_turns: Optional[int] = None,
        env: Optional[Dict[str, str]] = None,
        include_partial_messages: bool = False,
        goal: Optional[str] = None
    ) -> ClaudeAgentOptions:
        """
        Build ClaudeAgentOptions from agent spec and project

        Args:
            agent_spec: Primary agent specification (for system_prompt)
            project: Project context
            available_agents: List of all available agents to register
            permission_mode: Permission mode for tools
            hooks: Optional hooks for events
            use_preset: Use system prompt preset instead of custom prompt
            preset_name: Preset name if using preset (e.g., "claude_code")
            model: Model to use ("sonnet", "opus", "haiku")
            max_turns: Maximum conversation turns
            env: Environment variables
            include_partial_messages: Enable streaming with partial messages
            goal: Current goal (for dynamic agent adaptation)

        Returns:
            ClaudeAgentOptions configured for llmos
        """
        # Determine working directory
        cwd = str(project.path) if project else str(self.workspace)

        # =====================================================================
        # DYNAMIC AGENT ADAPTATION (New!)
        # Adapts agents per-query based on sentience, memory, and traces
        # =====================================================================

        # Get sentience state if available (for adaptation)
        sentience_state = None
        if self.sentience_manager:
            try:
                sentience_state = self.sentience_manager.get_state()
            except Exception:
                pass

        # Get similar traces for context (if goal provided)
        similar_traces = None
        if goal and self.trace_manager:
            try:
                if hasattr(self.trace_manager, 'find_traces_with_llm'):
                    similar_traces = self.trace_manager.find_traces_with_llm(goal, limit=5)
                else:
                    similar_traces = self.trace_manager.list_traces()[:5]
            except Exception:
                pass

        # Build system prompt (support presets)
        system_prompt: Optional[Union[str, Dict[str, Any]]] = None

        if use_preset and agent_spec:
            # Use preset with appended custom prompt
            system_prompt = {
                "type": "preset",
                "preset": preset_name,
                "append": agent_spec.system_prompt
            }
        elif agent_spec:
            # Use custom prompt directly
            system_prompt = agent_spec.system_prompt

        # Register all available agents as AgentDefinitions
        # HYBRID ARCHITECTURE: Load Markdown agents first, then merge programmatic agents

        # 1. Load dynamic Markdown-defined agents from workspace/agents/*.md
        agents_dict = self.agent_loader.load_all_agents()

        # 2. Merge programmatic agents (Python-defined AgentSpec)
        # NOW WITH DYNAMIC ADAPTATION: Adapt each agent based on goal/sentience/traces
        if available_agents:
            for spec in available_agents:
                try:
                    # Apply dynamic adaptation if available
                    adapted_spec = spec
                    model_override = None

                    if self.dynamic_agent_manager and goal:
                        try:
                            adapted_spec = self.dynamic_agent_manager.get_adapted_agent(
                                agent_name=spec.name,
                                goal=goal,
                                sentience_state=sentience_state,
                                similar_traces=similar_traces
                            )
                            # Get model from adapted spec
                            model_override = getattr(adapted_spec, 'model', None)

                            # Log adaptation (if changed)
                            if adapted_spec.system_prompt != spec.system_prompt:
                                print(f"   ðŸ”„ Adapted agent '{spec.name}' for goal")
                            if model_override and model_override != getattr(spec, 'model', 'sonnet'):
                                print(f"   ðŸŽ¯ Selected model '{model_override}' for '{spec.name}'")

                        except ValueError:
                            # Agent not found in factory, use original spec
                            adapted_spec = spec
                        except Exception as e:
                            # Log but continue with original spec
                            print(f"   âš ï¸ Agent adaptation failed for {spec.name}: {e}")
                            adapted_spec = spec

                    agents_dict[spec.name] = agent_spec_to_definition(adapted_spec, model_override)
                except Exception as e:
                    print(f"Warning: Could not register agent {spec.name}: {e}")

        # =====================================================================
        # DYNAMIC MODEL SELECTION FOR PRIMARY AGENT
        # Select optimal model based on task complexity
        # =====================================================================
        selected_model = model
        if self.dynamic_agent_manager and goal:
            try:
                # Create a temporary spec for model selection analysis
                from kernel.agent_factory import AgentSpec
                temp_spec = AgentSpec(
                    name="temp",
                    agent_type="system",
                    category="core",
                    description="Temporary for model selection",
                    tools=[],
                    version="1.0.0",
                    status="active",
                    mode=["LEARNER"],
                    system_prompt="",
                    capabilities=[],
                    constraints=[]
                )
                adapted_temp = self.dynamic_agent_manager._select_optimal_model(
                    temp_spec, goal, similar_traces
                )
                if hasattr(adapted_temp, 'model') and adapted_temp.model:
                    selected_model = adapted_temp.model
                    if selected_model != model:
                        print(f"   ðŸŽ¯ Dynamic model selection: {model} â†’ {selected_model}")
            except Exception:
                pass

        # Build ClaudeAgentOptions with all fields
        options_dict = {
            "system_prompt": system_prompt,
            "cwd": cwd,
            "agents": agents_dict,
            "permission_mode": permission_mode,
            "hooks": hooks or {},
            "model": selected_model,
            "include_partial_messages": include_partial_messages
        }

        # Add optional fields
        if max_turns is not None:
            options_dict["max_turns"] = max_turns

        if env is not None:
            options_dict["env"] = env

        return ClaudeAgentOptions(**options_dict)

    async def execute_learner_mode(
        self,
        goal: str,
        goal_signature: str,
        agent_spec: Optional[AgentSpec] = None,
        project: Optional[Project] = None,
        available_agents: Optional[List[AgentSpec]] = None,
        max_cost_usd: float = 5.0,
        enable_hooks: bool = True,
        enable_streaming: bool = False,
        streaming_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        Execute goal in Learner mode using Claude SDK

        This is the proper way to use the SDK - it handles all
        communication with Claude and returns structured messages.

        Args:
            goal: Goal to execute
            goal_signature: Signature for trace storage
            agent_spec: Optional agent specification
            project: Optional project context
            available_agents: List of all available agents to register
            max_cost_usd: Maximum cost budget
            enable_hooks: Enable default hooks (budget, security, trace capture)
            enable_streaming: Enable streaming with partial messages
            streaming_callback: Optional callback for streaming events

        Returns:
            Result dictionary with trace and execution details
        """
        trace_builder = TraceBuilder(goal)

        # Create hooks if enabled
        sdk_hooks = {}
        if enable_hooks:
            hook_registry = create_default_hooks(
                token_economy=self.token_economy,
                workspace=self.workspace,
                trace_builder=trace_builder,
                memory_query=self.memory_query,
                max_cost_usd=max_cost_usd
            )
            sdk_hooks = hook_registry.to_sdk_hooks()

            print(f"ðŸ”Œ Enabled {len(sdk_hooks)} hook types")

        # Build SDK options with all available agents and hooks
        # NEW: Pass goal for dynamic agent adaptation
        options = self._build_agent_options(
            agent_spec=agent_spec,
            project=project,
            available_agents=available_agents,  # Register all agents!
            permission_mode="acceptEdits",  # Auto-accept edits in Learner mode
            hooks=sdk_hooks,
            include_partial_messages=enable_streaming,
            goal=goal  # Enable dynamic agent adaptation!
        )

        result = {
            "success": False,
            "mode": "LEARNER",
            "trace": None,
            "cost": 0.0,
            "output": ""
        }

        try:
            # Use SDK client
            async with ClaudeSDKClient(options=options) as client:
                # Connect and send goal
                await client.connect(prompt=goal)

                # Receive all messages
                async for message in client.receive_response():
                    # Handle streaming events
                    if enable_streaming and isinstance(message, StreamEvent):
                        if streaming_callback:
                            await streaming_callback(message)
                        # StreamEvent doesn't contribute to trace
                        continue

                    # Build trace from regular messages
                    trace_builder.add_message(message)

                    # Check cost budget
                    if isinstance(message, ResultMessage):
                        if message.total_cost_usd > max_cost_usd:
                            print(f"âš ï¸  Cost ${message.total_cost_usd:.2f} exceeded budget ${max_cost_usd:.2f}")

                        result["cost"] = message.total_cost_usd
                        result["success"] = True

            # Build trace
            trace = trace_builder.to_trace(goal_signature)
            result["trace"] = trace
            result["output"] = trace.output_summary

            # Save trace to memory
            if self.trace_manager:
                self.trace_manager.save_trace(trace)

        except Exception as e:
            trace_builder.add_error(str(e))
            result["error"] = str(e)

            # Still save failed trace for learning
            trace = trace_builder.to_trace(goal_signature)
            result["trace"] = trace

            if self.trace_manager:
                self.trace_manager.save_trace(trace)

        return result

    async def execute_one_shot_query(
        self,
        goal: str,
        agent_spec: Optional[AgentSpec] = None,
        project: Optional[Project] = None
    ) -> Dict[str, Any]:
        """
        Execute simple one-shot query using SDK query function

        Use this for simple, stateless queries where you don't need
        trace capture or complex interaction.

        Args:
            goal: Goal to execute
            agent_spec: Optional agent specification
            project: Optional project context

        Returns:
            Result dictionary
        """
        # NEW: Pass goal for dynamic agent adaptation
        options = self._build_agent_options(
            agent_spec=agent_spec,
            project=project,
            goal=goal  # Enable dynamic agent adaptation!
        )

        result = {
            "success": False,
            "output": "",
            "cost": 0.0
        }

        output_parts = []

        try:
            async for message in sdk_query(prompt=goal, options=options):
                if isinstance(message, AssistantMessage):
                    for block in message.content:
                        if isinstance(block, TextBlock):
                            output_parts.append(block.text)

                if isinstance(message, ResultMessage):
                    result["cost"] = message.total_cost_usd
                    result["success"] = True

            result["output"] = "\n".join(output_parts)

        except Exception as e:
            result["error"] = str(e)

        return result

    async def execute_with_streaming(
        self,
        goal: str,
        on_message_callback,
        agent_spec: Optional[AgentSpec] = None,
        project: Optional[Project] = None
    ) -> Dict[str, Any]:
        """
        Execute with streaming callback for real-time updates

        Args:
            goal: Goal to execute
            on_message_callback: Async callback called for each message
            agent_spec: Optional agent specification
            project: Optional project context

        Returns:
            Result dictionary
        """
        # NEW: Pass goal for dynamic agent adaptation
        options = self._build_agent_options(
            agent_spec=agent_spec,
            project=project,
            goal=goal  # Enable dynamic agent adaptation!
        )

        result = {
            "success": False,
            "cost": 0.0
        }

        try:
            async with ClaudeSDKClient(options=options) as client:
                await client.connect(prompt=goal)

                async for message in client.receive_response():
                    # Call user callback
                    await on_message_callback(message)

                    if isinstance(message, ResultMessage):
                        result["cost"] = message.total_cost_usd
                        result["success"] = True

        except Exception as e:
            result["error"] = str(e)

        return result


def is_sdk_available() -> bool:
    """Check if Claude Agent SDK is available"""
    return SDK_AVAILABLE


def get_sdk_version() -> Optional[str]:
    """Get installed SDK version"""
    if not SDK_AVAILABLE:
        return None

    try:
        import claude_agent_sdk
        return getattr(claude_agent_sdk, '__version__', 'unknown')
    except:
        return None




================================================
File: kernel/__init__.py
================================================
"""
Kernel Package - Somatic Layer
High-speed, deterministic, non-blocking execution

Includes:
- Sentience Layer: Internal state, valence, cognitive kernel
- Mode Strategies: Execution mode selection
- Configuration: Type-safe configuration management
"""

from kernel.sentience import (
    SentienceState,
    SentienceManager,
    ValenceVector,
    SelfModel,
    GlobalWorkspace,
    LatentMode,
    TriggerType
)

from kernel.cognitive_kernel import (
    CognitiveKernel,
    CognitivePolicy,
    SelfImprovementType,
    SelfImprovementSuggestion
)

from kernel.config import (
    LLMOSConfig,
    KernelConfig,
    MemoryConfig,
    SDKConfig,
    DispatcherConfig,
    ExecutionLayerConfig,
    SentienceConfig,
    ConfigBuilder
)

from kernel.mode_strategies import (
    ModeSelectionStrategy,
    ModeContext,
    ModeDecision,
    AutoModeStrategy,
    SentienceAwareStrategy,
    get_strategy,
    STRATEGIES
)

__all__ = [
    # Sentience
    "SentienceState",
    "SentienceManager",
    "ValenceVector",
    "SelfModel",
    "GlobalWorkspace",
    "LatentMode",
    "TriggerType",
    # Cognitive Kernel
    "CognitiveKernel",
    "CognitivePolicy",
    "SelfImprovementType",
    "SelfImprovementSuggestion",
    # Config
    "LLMOSConfig",
    "KernelConfig",
    "MemoryConfig",
    "SDKConfig",
    "DispatcherConfig",
    "ExecutionLayerConfig",
    "SentienceConfig",
    "ConfigBuilder",
    # Mode Strategies
    "ModeSelectionStrategy",
    "ModeContext",
    "ModeDecision",
    "AutoModeStrategy",
    "SentienceAwareStrategy",
    "get_strategy",
    "STRATEGIES",
]



================================================
File: kernel/agent_factory.py
================================================
"""
Agent Factory - Creates and manages dynamic agents
Brings llmunix-style on-demand agent creation to llmos
"""

from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import yaml


@dataclass
class AgentSpec:
    """
    Agent Specification - Defines an agent's capabilities and behavior

    This follows llmunix's YAML frontmatter format for agent definitions
    """
    name: str  # Kebab-case identifier (e.g., "quantum-simulation-agent")
    agent_type: str  # "orchestration", "specialized", "memory", "code_generation"
    category: str  # Domain category
    description: str  # When to use this agent
    tools: List[str]  # Available tools: ["Read", "Write", "Bash", "Task", etc.]
    version: str = "1.0"
    status: str = "production"  # "production", "experimental", "deprecated"
    mode: List[str] = field(default_factory=lambda: ["EXECUTION"])
    system_prompt: str = ""  # Detailed instructions for agent behavior
    capabilities: List[str] = field(default_factory=list)
    constraints: List[str] = field(default_factory=list)
    replaces: Optional[str] = None  # Previous version if evolved


class AgentFactory:
    """
    Creates and manages dynamic agents

    Key capabilities:
    1. Create new agents on-demand from specifications
    2. Save agent definitions as markdown with YAML frontmatter
    3. Load agents from markdown definitions
    4. Evolve agents (create new versions)
    5. Maintain agent registry
    """

    def __init__(self, workspace: Path):
        """
        Initialize AgentFactory

        Args:
            workspace: Root workspace directory
        """
        self.workspace = Path(workspace)
        self.agents_dir = self.workspace / "agents"
        self.agents_dir.mkdir(parents=True, exist_ok=True)

        # In-memory agent registry
        self.agents: Dict[str, AgentSpec] = {}
        self._load_existing_agents()

    def _load_existing_agents(self):
        """Load existing agent definitions from filesystem"""
        if not self.agents_dir.exists():
            return

        for agent_file in self.agents_dir.glob("*.md"):
            try:
                spec = self.load_agent_definition(agent_file)
                if spec:
                    self.agents[spec.name] = spec
            except Exception as e:
                print(f"Warning: Failed to load agent {agent_file}: {e}")

    def create_agent(
        self,
        name: str,
        agent_type: str,
        category: str,
        description: str,
        system_prompt: str,
        tools: List[str],
        capabilities: Optional[List[str]] = None,
        constraints: Optional[List[str]] = None,
        **kwargs
    ) -> AgentSpec:
        """
        Create a new agent from specification

        Args:
            name: Agent name (kebab-case)
            agent_type: Type of agent (orchestration, specialized, etc.)
            category: Domain category
            description: When to use this agent
            system_prompt: Detailed behavioral instructions
            tools: List of available tools
            capabilities: List of agent capabilities
            constraints: List of agent constraints
            **kwargs: Additional metadata

        Returns:
            AgentSpec instance
        """
        spec = AgentSpec(
            name=name,
            agent_type=agent_type,
            category=category,
            description=description,
            tools=tools,
            system_prompt=system_prompt,
            capabilities=capabilities or [],
            constraints=constraints or [],
            **kwargs
        )

        # Save agent definition
        self.save_agent_definition(spec)

        # Register agent
        self.agents[spec.name] = spec

        return spec

    def save_agent_definition(self, spec: AgentSpec, path: Optional[Path] = None) -> Path:
        """
        Save agent definition as markdown with YAML frontmatter

        Format:
        ```
        ---
        agent_name: quantum-simulation-agent
        type: specialized
        category: quantum_computing
        ...
        ---

        # Agent Name: Purpose

        Detailed system prompt and instructions...
        ```

        Args:
            spec: AgentSpec to save
            path: Optional custom path (defaults to agents/{name}.md)

        Returns:
            Path to saved file
        """
        if path is None:
            # Convert name to PascalCase for filename
            filename = self._name_to_filename(spec.name)
            path = self.agents_dir / filename

        # Create YAML frontmatter
        frontmatter = {
            "agent_name": spec.name,
            "type": spec.agent_type,
            "category": spec.category,
            "description": spec.description,
            "tools": spec.tools,
            "version": spec.version,
            "status": spec.status,
            "mode": spec.mode
        }

        if spec.replaces:
            frontmatter["replaces"] = spec.replaces

        # Create markdown content
        content_parts = [
            "---",
            yaml.dump(frontmatter, default_flow_style=False, sort_keys=False).strip(),
            "---",
            "",
            f"# {self._name_to_title(spec.name)}: {spec.category}",
            "",
            spec.system_prompt,
            "",
            "## Capabilities",
            ""
        ]

        for capability in spec.capabilities:
            content_parts.append(f"- {capability}")

        if spec.constraints:
            content_parts.extend([
                "",
                "## Constraints",
                ""
            ])
            for constraint in spec.constraints:
                content_parts.append(f"- {constraint}")

        content_parts.extend([
            "",
            "## Available Tools",
            ""
        ])

        for tool in spec.tools:
            content_parts.append(f"- {tool}")

        # Write to file
        with open(path, 'w') as f:
            f.write('\n'.join(content_parts))

        return path

    def load_agent_definition(self, path: Path) -> Optional[AgentSpec]:
        """
        Load agent definition from markdown file

        Args:
            path: Path to agent markdown file

        Returns:
            AgentSpec instance or None
        """
        if not path.exists():
            return None

        with open(path, 'r') as f:
            content = f.read()

        # Split frontmatter and body
        if not content.startswith('---'):
            return None

        parts = content.split('---', 2)
        if len(parts) < 3:
            return None

        # Parse YAML frontmatter
        frontmatter = yaml.safe_load(parts[1])
        body = parts[2].strip()

        # Extract system prompt (everything after the title)
        lines = body.split('\n')
        title_idx = 0
        for i, line in enumerate(lines):
            if line.startswith('# '):
                title_idx = i
                break

        system_prompt = '\n'.join(lines[title_idx:])

        # Create AgentSpec
        spec = AgentSpec(
            name=frontmatter['agent_name'],
            agent_type=frontmatter.get('type', 'specialized'),
            category=frontmatter.get('category', 'general'),
            description=frontmatter.get('description', ''),
            tools=frontmatter.get('tools', []),
            version=frontmatter.get('version', '1.0'),
            status=frontmatter.get('status', 'production'),
            mode=frontmatter.get('mode', ['EXECUTION']),
            system_prompt=system_prompt,
            replaces=frontmatter.get('replaces')
        )

        return spec

    def evolve_agent(self, current_name: str, changes: Dict[str, Any]) -> AgentSpec:
        """
        Evolve an existing agent to a new version

        Args:
            current_name: Current agent name
            changes: Dictionary of changes to apply

        Returns:
            New AgentSpec instance
        """
        current = self.agents.get(current_name)
        if not current:
            raise ValueError(f"Agent {current_name} not found")

        # Parse current version
        major, minor = map(int, current.version.split('.'))

        # Increment version
        new_version = f"{major}.{minor + 1}"

        # Create new spec with changes
        spec_dict = asdict(current)
        spec_dict.update(changes)
        spec_dict['version'] = new_version
        spec_dict['replaces'] = current_name
        spec_dict['created_at'] = datetime.now().isoformat()

        new_spec = AgentSpec(**spec_dict)

        # Mark old agent as deprecated
        current.status = "deprecated"
        self.save_agent_definition(current)

        # Save new agent
        self.save_agent_definition(new_spec)
        self.agents[new_spec.name] = new_spec

        return new_spec

    def get_agent(self, name: str) -> Optional[AgentSpec]:
        """
        Get agent by name

        Args:
            name: Agent name

        Returns:
            AgentSpec or None
        """
        return self.agents.get(name)

    def list_agents(
        self,
        category: Optional[str] = None,
        agent_type: Optional[str] = None,
        status: str = "production"
    ) -> List[AgentSpec]:
        """
        List agents with optional filtering

        Args:
            category: Filter by category
            agent_type: Filter by type
            status: Filter by status (default: "production")

        Returns:
            List of AgentSpec instances
        """
        agents = list(self.agents.values())

        if status:
            agents = [a for a in agents if a.status == status]

        if category:
            agents = [a for a in agents if a.category == category]

        if agent_type:
            agents = [a for a in agents if a.agent_type == agent_type]

        return agents

    def delete_agent(self, name: str) -> bool:
        """
        Delete an agent

        Args:
            name: Agent name

        Returns:
            True if deleted successfully
        """
        spec = self.agents.get(name)
        if not spec:
            return False

        # Remove from registry
        del self.agents[name]

        # Remove file
        filename = self._name_to_filename(name)
        filepath = self.agents_dir / filename
        if filepath.exists():
            filepath.unlink()

        return True

    @staticmethod
    def _name_to_filename(name: str) -> str:
        """
        Convert kebab-case name to PascalCase filename

        Examples:
            quantum-simulation-agent â†’ QuantumSimulationAgent.md
            code-generator-agent â†’ CodeGeneratorAgent.md
        """
        words = name.split('-')
        pascal_case = ''.join(word.capitalize() for word in words)
        return f"{pascal_case}.md"

    @staticmethod
    def _name_to_title(name: str) -> str:
        """
        Convert kebab-case name to Title Case

        Examples:
            quantum-simulation-agent â†’ Quantum Simulation Agent
        """
        words = name.split('-')
        return ' '.join(word.capitalize() for word in words)


# Built-in agent templates
SYSTEM_AGENT_TEMPLATE = AgentSpec(
    name="system-agent",
    agent_type="orchestration",
    category="core_system",
    description="Core orchestration agent for multi-agent workflows",
    tools=["Read", "Write", "Glob", "Grep", "Bash", "WebFetch", "Task"],
    capabilities=[
        "Task orchestration and delegation",
        "Sub-agent coordination",
        "State management",
        "Memory consultation",
        "Project lifecycle management"
    ],
    constraints=[
        "Must consult memory before planning",
        "Must create execution state directory",
        "Must delegate to specialized agents when appropriate",
        "Must track token costs"
    ],
    system_prompt="""# SystemAgent: Core Orchestrator

You are the SystemAgent, the master orchestrator of the LLM OS.

## Your Role

1. **Decompose Goals**: Break complex goals into manageable sub-tasks
2. **Delegate Intelligently**: Route sub-tasks to specialized agents
3. **Coordinate Results**: Integrate outputs from multiple agents
4. **Manage State**: Maintain execution state and context
5. **Consult Memory**: Learn from past executions

## Execution Flow

1. Receive high-level goal
2. Query memory for similar tasks
3. Create execution plan
4. Identify required specialized agents
5. Delegate sub-tasks
6. Coordinate and integrate results
7. Update memory with learnings

## Available Tools

You have access to all core tools and can delegate to any registered agent via the Task tool.
"""
)

TOOLSMITH_AGENT_TEMPLATE = AgentSpec(
    name="toolsmith-agent",
    agent_type="specialized",
    category="code_generation",
    description="Converts execution traces into Python plugin tools (HOPE architecture)",
    tools=["Read", "Write", "Bash"],
    capabilities=[
        "Analyze execution traces",
        "Generate Python plugin code",
        "Create @llm_tool decorated functions",
        "Implement error handling and type hints",
        "Validate generated code syntax"
    ],
    constraints=[
        "Must use @llm_tool decorator for all tools",
        "Must include docstrings and type hints",
        "Must implement proper error handling",
        "Must NOT use dangerous imports (os.system, subprocess) unless safe",
        "Must save to llmos/plugins/generated/ directory",
        "Must follow Python best practices"
    ],
    system_prompt="""# Toolsmith Agent: Tool Crystallization Specialist

You are the Toolsmith, the kernel architect of the LLM OS.
Your purpose is to convert "Execution Traces" (learned patterns) into permanent Python tools.

This implements the HOPE (Self-Modifying Kernel) architecture from the Nested Learning paper,
converting fluid intelligence (LLM reasoning) into crystallized intelligence (Python code).

## Your Mission

Transform frequently-used execution traces into optimized, reusable Python functions.

## Code Generation Guidelines

1. **Analyze the Trace**: Understand the goal, tools used, and output produced
2. **Extract the Pattern**: Identify the core logic that can be generalized
3. **Design the Function**: Create a clean API with appropriate parameters
4. **Implement Robustly**: Add error handling, validation, and logging
5. **Document Thoroughly**: Include docstrings explaining purpose and usage

## Required Structure

```python
from plugins import llm_tool
from typing import Dict, Any, Optional

@llm_tool(
    name="tool_name",
    description="Clear description of what this tool does",
    schema={
        "param_name": "str",  # Parameter type
        "optional_param": "Optional[int]"
    }
)
async def tool_name(param_name: str, optional_param: Optional[int] = None) -> Dict[str, Any]:
    '''
    Detailed docstring explaining:
    - What the tool does
    - Parameters and their purpose
    - Return value format
    - Example usage
    '''
    try:
        # Implementation logic here
        result = perform_operation(param_name)

        return {
            "success": True,
            "result": result
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }
```

## Safety Constraints

- NO dangerous imports: `os.system()`, raw `subprocess` (unless explicitly needed and safe)
- NO network operations without validation
- NO file system operations outside workspace
- ALWAYS validate inputs
- ALWAYS handle exceptions gracefully

## Output Location

Save all generated tools to: `llmos/plugins/generated/tool_{signature}.py`

## Example Transformation

**Input Trace:**
```
Goal: Create a status report
Tools Used: Read, Grep, Write
Success Rate: 100%
Usage Count: 10
```

**Generated Tool:**
```python
@llm_tool(
    name="generate_status_report",
    description="Generate a comprehensive status report",
    schema={"project_path": "str", "output_file": "str"}
)
async def generate_status_report(project_path: str, output_file: str) -> Dict[str, Any]:
    '''Generate a status report for a project'''
    # Implementation...
```

## Workflow

1. Receive trace details
2. Analyze goal and steps
3. Design function signature
4. Generate Python code
5. Validate syntax (use `ast` module)
6. Save to plugins/generated/
7. Return tool name for hot-loading
"""
)



================================================
File: kernel/agent_loader.py
================================================
"""
Agent Loader - Markdown to Runtime Bridge

This module enables the Hybrid Architecture where agents are defined in Markdown
files with YAML frontmatter, while the Python Kernel provides the runtime.

This combines:
- llmunix: Pure Markdown agent definitions (flexibility, self-modification)
- llmos: Python Kernel with robust tooling (stability, security, performance)

The AgentLoader scans workspace/agents/*.md files and converts them into
Claude SDK AgentDefinition objects at runtime.
"""

import yaml
from pathlib import Path
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class AgentDefinition:
    """
    Represents a parsed agent definition from Markdown.

    This is the bridge format between the Markdown file and the
    Claude SDK's expected agent structure.
    """

    def __init__(
        self,
        name: str,
        description: str,
        system_prompt: str,
        tools: List[str],
        model: str = "sonnet",
        metadata: Optional[Dict[str, Any]] = None
    ):
        self.name = name
        self.description = description
        self.system_prompt = system_prompt
        self.tools = tools
        self.model = model
        self.metadata = metadata or {}

    def to_sdk_format(self) -> Dict[str, Any]:
        """
        Converts this definition to the format expected by Claude SDK.

        Returns dict with: description, prompt, tools, model
        """
        return {
            'description': self.description,
            'prompt': self.system_prompt,
            'tools': self.tools,
            'model': self.model
        }

    def __repr__(self):
        return f"AgentDefinition(name='{self.name}', tools={len(self.tools)}, model='{self.model}')"


class AgentLoader:
    """
    Loads agent definitions from Markdown files with YAML frontmatter.

    This enables the 'Pure Markdown Mind' philosophy within the Python Kernel,
    allowing the system to:
    - Create new agents by writing text files
    - Hot-reload agent definitions without restarting
    - Enable self-modification (HOPE architecture)

    File Format:
    ```markdown
    ---
    name: agent-name
    description: What this agent does
    tools: [Read, Write, Bash]
    model: sonnet
    ---

    # Agent System Prompt

    Your instructions here...
    ```
    """

    def __init__(self, agents_dir: str = "workspace/agents"):
        """
        Initialize the loader.

        Args:
            agents_dir: Path to directory containing .md agent definitions
        """
        self.agents_dir = Path(agents_dir)
        self._cache: Dict[str, AgentDefinition] = {}
        self._cache_timestamps: Dict[str, float] = {}

    def ensure_directory(self) -> bool:
        """
        Ensure the agents directory exists.

        Returns:
            True if directory exists or was created successfully
        """
        if not self.agents_dir.exists():
            try:
                self.agents_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created agents directory: {self.agents_dir}")
                return True
            except Exception as e:
                logger.error(f"Could not create agents directory: {e}")
                return False
        return True

    def load_all_agents(self, use_cache: bool = True) -> Dict[str, Dict[str, Any]]:
        """
        Scans the agents directory and returns all agent definitions.

        This method is called by the SDK client to inject Markdown-defined
        agents into the Claude SDK runtime.

        Args:
            use_cache: If True, uses cached definitions for unchanged files

        Returns:
            Dictionary compatible with Claude SDK 'agents' parameter:
            {
                'agent-name': {
                    'description': '...',
                    'prompt': '...',
                    'tools': [...],
                    'model': 'sonnet'
                }
            }
        """
        agents_config = {}

        # Ensure directory exists
        if not self.ensure_directory():
            return {}

        # Load all .md files
        for agent_file in self.agents_dir.glob("*.md"):
            agent_def = self._load_agent_file(agent_file, use_cache=use_cache)
            if agent_def:
                agents_config[agent_def.name] = agent_def.to_sdk_format()
                logger.debug(f"Loaded agent: {agent_def.name}")

        logger.info(f"Loaded {len(agents_config)} agents from {self.agents_dir}")
        return agents_config

    def load_agent(self, name: str, use_cache: bool = True) -> Optional[AgentDefinition]:
        """
        Load a specific agent by name.

        Args:
            name: Agent name (without .md extension)
            use_cache: If True, uses cached definition if file unchanged

        Returns:
            AgentDefinition or None if not found
        """
        agent_file = self.agents_dir / f"{name}.md"

        if not agent_file.exists():
            logger.warning(f"Agent file not found: {agent_file}")
            return None

        return self._load_agent_file(agent_file, use_cache=use_cache)

    def _load_agent_file(
        self,
        file_path: Path,
        use_cache: bool = True
    ) -> Optional[AgentDefinition]:
        """
        Load and parse a single agent file.

        Args:
            file_path: Path to the .md file
            use_cache: If True, uses cache for unchanged files

        Returns:
            AgentDefinition or None if parsing fails
        """
        # Check cache
        if use_cache and file_path.name in self._cache:
            cached_time = self._cache_timestamps.get(file_path.name, 0)
            current_time = file_path.stat().st_mtime

            if current_time <= cached_time:
                logger.debug(f"Using cached definition for {file_path.name}")
                return self._cache[file_path.name]

        # Parse file
        agent_def = self._parse_agent_file(file_path)

        # Update cache
        if agent_def:
            self._cache[file_path.name] = agent_def
            self._cache_timestamps[file_path.name] = file_path.stat().st_mtime

        return agent_def

    def _parse_agent_file(self, file_path: Path) -> Optional[AgentDefinition]:
        """
        Parse a markdown file with YAML frontmatter.

        Args:
            file_path: Path to the .md file

        Returns:
            AgentDefinition or None if parsing fails
        """
        try:
            content = file_path.read_text(encoding='utf-8')

            # Basic validation for Frontmatter
            if not content.startswith('---'):
                logger.warning(
                    f"Skipping {file_path.name}: No YAML frontmatter found. "
                    f"Agent files must start with '---'"
                )
                return None

            # Split Frontmatter and Body
            parts = content.split('---', 2)
            if len(parts) < 3:
                logger.warning(
                    f"Skipping {file_path.name}: Malformed frontmatter. "
                    f"Expected format: ---\\nYAML\\n---\\nPrompt"
                )
                return None

            # Parse YAML metadata
            metadata = yaml.safe_load(parts[1])
            if not metadata:
                logger.warning(f"Skipping {file_path.name}: Empty frontmatter")
                return None

            # Extract system prompt (everything after second ---)
            system_prompt = parts[2].strip()

            # Extract required fields with fallbacks
            name = metadata.get('name') or metadata.get('agent_id') or file_path.stem
            description = metadata.get('description', 'Specialized agent')
            tools = metadata.get('tools', [])
            model = metadata.get('model', 'sonnet')

            # Validate
            if not name:
                logger.error(f"Agent in {file_path.name} has no 'name' field")
                return None

            if not system_prompt:
                logger.warning(f"Agent '{name}' has empty system prompt")

            # Create definition
            return AgentDefinition(
                name=name,
                description=description,
                system_prompt=system_prompt,
                tools=tools,
                model=model,
                metadata=metadata
            )

        except yaml.YAMLError as e:
            logger.error(f"YAML parsing error in {file_path}: {e}")
            return None
        except Exception as e:
            logger.error(f"Error loading agent {file_path}: {e}")
            return None

    def list_agents(self) -> List[str]:
        """
        List all available agent names.

        Returns:
            List of agent names (without .md extension)
        """
        if not self.ensure_directory():
            return []

        return [f.stem for f in self.agents_dir.glob("*.md")]

    def reload_agent(self, name: str) -> Optional[AgentDefinition]:
        """
        Force reload an agent, bypassing cache.

        Useful when an agent definition has been modified and you want
        to see changes immediately.

        Args:
            name: Agent name

        Returns:
            Updated AgentDefinition or None
        """
        # Clear cache for this agent
        cache_key = f"{name}.md"
        if cache_key in self._cache:
            del self._cache[cache_key]
        if cache_key in self._cache_timestamps:
            del self._cache_timestamps[cache_key]

        return self.load_agent(name, use_cache=False)

    def clear_cache(self):
        """Clear the entire agent cache."""
        self._cache.clear()
        self._cache_timestamps.clear()
        logger.info("Agent cache cleared")



================================================
File: kernel/agent_patterns.py
================================================
"""
Agent Specialization Patterns Library for LLMOS

Defines specialized agent archetypes for different roles.
Inspired by Claude-Flow's 64 specialized agents.

Key Features:
- Development & Methodology agents (Planner, Coder, Reviewer, Debugger)
- Intelligence & Memory agents (Researcher, Analyst)
- Quality & Testing agents (Tester, Validator)
- Specialized domain agents
- Dynamic agent templates for on-demand creation

Inspired by Claude-Flow's agent specialization (MIT License)
https://github.com/ruvnet/claude-flow
"""

from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path


class AgentCategory(Enum):
    """Agent categories"""
    DEVELOPMENT = "development"
    METHODOLOGY = "methodology"
    INTELLIGENCE = "intelligence"
    MEMORY = "memory"
    SWARM = "swarm"
    GITHUB = "github"
    AUTOMATION = "automation"
    QUALITY = "quality"
    PLATFORM = "platform"


@dataclass
class AgentPattern:
    """
    Agent Pattern Template

    Defines the structure and behavior of a specialized agent.
    """
    name: str
    category: AgentCategory
    description: str
    role: str
    system_prompt: str
    tools: List[str] = field(default_factory=list)
    model: str = "claude-sonnet-4-5-20250929"
    temperature: float = 0.7
    max_tokens: int = 4096
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_markdown(self) -> str:
        """
        Convert agent pattern to markdown format

        This is compatible with LLMOS's agent_loader system.
        """
        tools_str = ', '.join(f'"{t}"' for t in self.tools)

        return f"""---
name: {self.name}
description: {self.description}
category: {self.category.value}
tools: [{tools_str}]
model: {self.model}
temperature: {self.temperature}
max_tokens: {self.max_tokens}
---

# {self.name.title()} Agent

**Role:** {self.role}

{self.system_prompt}

## Capabilities

{self._generate_capabilities_section()}

## Tools Available

{self._generate_tools_section()}
"""

    def _generate_capabilities_section(self) -> str:
        """Generate capabilities section"""
        # Default capabilities based on category
        capabilities_map = {
            AgentCategory.DEVELOPMENT: [
                "Code generation and implementation",
                "Best practices enforcement",
                "Design pattern application"
            ],
            AgentCategory.QUALITY: [
                "Test case generation",
                "Quality assurance",
                "Validation and verification"
            ],
            AgentCategory.INTELLIGENCE: [
                "Research and analysis",
                "Information synthesis",
                "Pattern recognition"
            ]
        }

        capabilities = capabilities_map.get(self.category, ["General task execution"])

        return "\n".join(f"- {cap}" for cap in capabilities)

    def _generate_tools_section(self) -> str:
        """Generate tools section"""
        if not self.tools:
            return "- No specific tools assigned (will use default tools)"

        return "\n".join(f"- `{tool}`" for tool in self.tools)


class AgentPatternLibrary:
    """
    Agent Pattern Library

    Central repository of agent patterns.
    Provides templates for creating specialized agents.
    """

    def __init__(self):
        self.patterns: Dict[str, AgentPattern] = {}
        self._initialize_default_patterns()

    def _initialize_default_patterns(self):
        """Initialize default agent patterns"""

        # =====================================================================
        # DEVELOPMENT AGENTS
        # =====================================================================

        self.register(AgentPattern(
            name="planner",
            category=AgentCategory.DEVELOPMENT,
            description="Expert at breaking down complex tasks into actionable steps",
            role="Strategic planner and task decomposition specialist",
            system_prompt="""You are an expert strategic planner. Your role is to:

1. Analyze complex goals and break them into manageable tasks
2. Identify dependencies and optimal execution order
3. Estimate effort and resources required
4. Create clear, actionable plans with milestones
5. Anticipate potential blockers and prepare mitigation strategies

When given a goal, create a detailed execution plan with:
- Clear task breakdown
- Dependency mapping
- Time estimates
- Risk assessment
- Success criteria

Be thorough but pragmatic. Focus on actionable steps.""",
            tools=["Read", "Write", "search_tools", "memory_retrieve"],
            temperature=0.3  # Lower temperature for more structured planning
        ))

        self.register(AgentPattern(
            name="coder",
            category=AgentCategory.DEVELOPMENT,
            description="Expert software engineer focused on implementation",
            role="Software implementation specialist",
            system_prompt="""You are an expert software engineer. Your role is to:

1. Write clean, efficient, well-documented code
2. Follow best practices and design patterns
3. Implement features according to specifications
4. Handle edge cases and error conditions
5. Write self-documenting code with clear variable names

When implementing:
- Use type hints and proper documentation
- Follow language idioms and conventions
- Consider performance and maintainability
- Add appropriate error handling
- Write modular, testable code

Focus on quality over speed. Every line of code should be production-ready.""",
            tools=["Read", "Write", "Edit", "Bash", "Glob", "Grep"],
            temperature=0.5
        ))

        self.register(AgentPattern(
            name="reviewer",
            category=AgentCategory.QUALITY,
            description="Expert code reviewer focused on quality and best practices",
            role="Code quality assurance specialist",
            system_prompt="""You are an expert code reviewer. Your role is to:

1. Review code for correctness, clarity, and maintainability
2. Identify potential bugs, security issues, and anti-patterns
3. Suggest improvements and optimizations
4. Ensure adherence to style guides and best practices
5. Provide constructive, actionable feedback

When reviewing code, check for:
- Correctness and logic errors
- Edge case handling
- Performance issues
- Security vulnerabilities
- Code style and conventions
- Documentation quality
- Test coverage

Be thorough but constructive. Focus on making the code better.""",
            tools=["Read", "Grep", "Glob", "mcp__ide__getDiagnostics"],
            temperature=0.4
        ))

        self.register(AgentPattern(
            name="debugger",
            category=AgentCategory.QUALITY,
            description="Expert at identifying and fixing bugs",
            role="Debugging and troubleshooting specialist",
            system_prompt="""You are an expert debugger. Your role is to:

1. Systematically identify root causes of bugs
2. Reproduce issues and isolate problematic code
3. Fix bugs with minimal side effects
4. Add tests to prevent regression
5. Document the issue and solution

When debugging:
- Use scientific method: hypothesize, test, iterate
- Add logging/instrumentation to gather data
- Check assumptions and validate inputs
- Consider edge cases and boundary conditions
- Fix the root cause, not just symptoms

Be methodical and thorough. Every fix should include a test.""",
            tools=["Read", "Edit", "Bash", "Grep", "mcp__ide__getDiagnostics", "mcp__ide__executeCode"],
            temperature=0.3
        ))

        self.register(AgentPattern(
            name="tester",
            category=AgentCategory.QUALITY,
            description="Expert at creating comprehensive test suites",
            role="Test design and implementation specialist",
            system_prompt="""You are an expert QA engineer. Your role is to:

1. Design comprehensive test strategies
2. Write unit, integration, and end-to-end tests
3. Identify edge cases and boundary conditions
4. Create test data and fixtures
5. Ensure high test coverage and quality

When creating tests:
- Cover happy path, edge cases, and error conditions
- Use descriptive test names and clear assertions
- Follow AAA pattern (Arrange, Act, Assert)
- Keep tests isolated and deterministic
- Aim for >90% coverage

Focus on catching bugs before they reach production.""",
            tools=["Read", "Write", "Edit", "Bash", "mcp__ide__executeCode"],
            temperature=0.4
        ))

        # =====================================================================
        # INTELLIGENCE AGENTS
        # =====================================================================

        self.register(AgentPattern(
            name="researcher",
            category=AgentCategory.INTELLIGENCE,
            description="Expert at gathering and synthesizing information",
            role="Research and information synthesis specialist",
            system_prompt="""You are an expert researcher. Your role is to:

1. Gather information from multiple sources
2. Synthesize findings into coherent insights
3. Identify patterns and connections
4. Validate information accuracy
5. Present findings clearly and concisely

When researching:
- Use multiple sources for validation
- Distinguish facts from opinions
- Note source credibility and recency
- Organize findings logically
- Highlight key insights and implications

Be thorough but focused. Quality over quantity.""",
            tools=["WebSearch", "WebFetch", "Read", "Write", "memory_store"],
            temperature=0.6
        ))

        self.register(AgentPattern(
            name="analyst",
            category=AgentCategory.INTELLIGENCE,
            description="Expert at analyzing data and extracting insights",
            role="Data analysis and insight generation specialist",
            system_prompt="""You are an expert data analyst. Your role is to:

1. Analyze complex data sets
2. Identify trends and patterns
3. Generate actionable insights
4. Create clear visualizations
5. Make data-driven recommendations

When analyzing:
- Use statistical rigor
- Check for biases and confounds
- Validate assumptions
- Consider alternative explanations
- Present findings with appropriate caveats

Focus on actionable insights, not just numbers.""",
            tools=["Read", "mcp__ide__executeCode", "Write", "performance_analyze"],
            temperature=0.5
        ))

        # =====================================================================
        # AUTOMATION AGENTS
        # =====================================================================

        self.register(AgentPattern(
            name="orchestrator",
            category=AgentCategory.AUTOMATION,
            description="Expert at coordinating multiple agents and tasks",
            role="Multi-agent coordination specialist",
            system_prompt="""You are an expert orchestrator. Your role is to:

1. Coordinate multiple agents to achieve complex goals
2. Manage task dependencies and execution order
3. Handle failures and implement fallback strategies
4. Monitor progress and adjust plans dynamically
5. Optimize for efficiency and resource utilization

When orchestrating:
- Identify parallelization opportunities
- Balance workload across agents
- Monitor for bottlenecks
- Implement error recovery
- Track progress and provide status updates

Focus on efficient, resilient execution.""",
            tools=["swarm_init", "agent_spawn", "task_orchestrate", "performance_analyze"],
            temperature=0.4
        ))

        # =====================================================================
        # MEMORY AGENTS
        # =====================================================================

        self.register(AgentPattern(
            name="librarian",
            category=AgentCategory.MEMORY,
            description="Expert at organizing and retrieving information",
            role="Information organization and retrieval specialist",
            system_prompt="""You are an expert librarian. Your role is to:

1. Organize information for easy retrieval
2. Create effective categorization systems
3. Maintain knowledge bases
4. Retrieve relevant information quickly
5. Ensure information quality and accuracy

When managing information:
- Use consistent categorization
- Add rich metadata
- Create effective indexes
- Implement search strategies
- Validate information freshness

Focus on making information accessible and useful.""",
            tools=["memory_store", "memory_retrieve", "Read", "Write", "Grep"],
            temperature=0.3
        ))

    def register(self, pattern: AgentPattern):
        """Register an agent pattern"""
        self.patterns[pattern.name] = pattern

    def get(self, name: str) -> Optional[AgentPattern]:
        """Get agent pattern by name"""
        return self.patterns.get(name)

    def search(
        self,
        category: Optional[AgentCategory] = None,
        query: Optional[str] = None
    ) -> List[AgentPattern]:
        """
        Search for agent patterns

        Args:
            category: Filter by category
            query: Search in description

        Returns:
            List of matching patterns
        """
        results = list(self.patterns.values())

        if category:
            results = [p for p in results if p.category == category]

        if query:
            query_lower = query.lower()
            results = [
                p for p in results
                if query_lower in p.description.lower()
                or query_lower in p.role.lower()
            ]

        return results

    def get_by_category(self, category: AgentCategory) -> List[AgentPattern]:
        """Get all patterns in a category"""
        return [p for p in self.patterns.values() if p.category == category]

    def create_agent_file(
        self,
        pattern_name: str,
        workspace: Path,
        agent_name: Optional[str] = None
    ) -> Path:
        """
        Create an agent markdown file from a pattern

        Args:
            pattern_name: Name of the pattern to use
            workspace: Workspace directory
            agent_name: Optional custom name (defaults to pattern name)

        Returns:
            Path to created agent file
        """
        pattern = self.get(pattern_name)
        if not pattern:
            raise ValueError(f"Pattern not found: {pattern_name}")

        name = agent_name or pattern.name
        agents_dir = workspace / "agents"
        agents_dir.mkdir(parents=True, exist_ok=True)

        agent_file = agents_dir / f"{name}.md"
        agent_file.write_text(pattern.to_markdown())

        return agent_file

    def list_patterns(self) -> List[str]:
        """List all available pattern names"""
        return sorted(self.patterns.keys())

    def get_statistics(self) -> Dict[str, Any]:
        """Get library statistics"""
        category_counts = {}
        for pattern in self.patterns.values():
            cat = pattern.category.value
            category_counts[cat] = category_counts.get(cat, 0) + 1

        return {
            "total_patterns": len(self.patterns),
            "by_category": category_counts,
            "categories": [c.value for c in AgentCategory]
        }

    def generate_catalog(self) -> str:
        """Generate a catalog of all patterns"""
        catalog = "# Agent Pattern Catalog\n\n"

        for category in AgentCategory:
            patterns = self.get_by_category(category)
            if not patterns:
                continue

            catalog += f"\n## {category.value.title()}\n\n"

            for pattern in sorted(patterns, key=lambda p: p.name):
                catalog += f"### {pattern.name}\n\n"
                catalog += f"**Description:** {pattern.description}\n\n"
                catalog += f"**Role:** {pattern.role}\n\n"
                catalog += f"**Tools:** {', '.join(pattern.tools) if pattern.tools else 'Default tools'}\n\n"

        return catalog


def create_custom_agent_pattern(
    name: str,
    category: AgentCategory,
    description: str,
    role: str,
    capabilities: List[str],
    tools: List[str] = None,
    model: str = "claude-sonnet-4-5-20250929",
    temperature: float = 0.7
) -> AgentPattern:
    """
    Create a custom agent pattern

    Helper function for creating specialized agent patterns on-demand.

    Args:
        name: Agent name
        category: Agent category
        description: Brief description
        role: Specific role
        capabilities: List of capabilities
        tools: List of tools this agent should use
        model: Claude model
        temperature: Generation temperature

    Returns:
        AgentPattern instance
    """
    # Generate system prompt from capabilities
    capabilities_text = "\n".join(f"{i+1}. {cap}" for i, cap in enumerate(capabilities))

    system_prompt = f"""You are an expert {role}. Your role is to:

{capabilities_text}

Focus on delivering high-quality results that meet these capabilities."""

    return AgentPattern(
        name=name,
        category=category,
        description=description,
        role=role,
        system_prompt=system_prompt,
        tools=tools or [],
        model=model,
        temperature=temperature
    )



================================================
File: kernel/bus.py
================================================
"""
Event Bus - Pub/Sub communication between components
"""

import asyncio
from enum import Enum
from typing import Any, Callable, Dict, List
from dataclasses import dataclass
import anyio


class EventType(Enum):
    """Event types in the system"""
    USER_INPUT = "user_input"
    SYSTEM_EVENT = "system_event"
    LLM_OUTPUT = "llm_output"
    TOOL_OUTPUT = "tool_output"
    INTERRUPT = "interrupt"
    TIMER = "timer"
    TASK_STARTED = "task_started"
    TASK_COMPLETED = "task_completed"


@dataclass
class Event:
    """Event structure"""
    type: EventType
    data: Any
    timestamp: float = None

    def __post_init__(self):
        if self.timestamp is None:
            import time
            self.timestamp = time.time()


class EventBus:
    """
    Event Bus for inter-component communication
    Uses anyio memory object streams for async pub/sub
    """

    def __init__(self):
        self._channels: Dict[EventType, tuple] = {}
        self._subscribers: Dict[EventType, List[Callable]] = {}

    def create_channel(self, event_type: EventType, buffer_size: int = 100):
        """Create a new channel for an event type"""
        send_stream, receive_stream = anyio.create_memory_object_stream(
            max_buffer_size=buffer_size
        )
        self._channels[event_type] = (send_stream, receive_stream)
        self._subscribers[event_type] = []

    async def publish(self, event: Event):
        """Publish an event to all subscribers"""
        if event.type not in self._channels:
            self.create_channel(event.type)

        send_stream, _ = self._channels[event.type]
        await send_stream.send(event)

    async def subscribe(self, event_type: EventType, callback: Callable):
        """Subscribe to an event type"""
        if event_type not in self._channels:
            self.create_channel(event_type)

        self._subscribers[event_type].append(callback)

    async def start_listeners(self):
        """Start all event listeners"""
        async with anyio.create_task_group() as tg:
            for event_type in self._channels:
                tg.start_soon(self._listener_loop, event_type)

    async def _listener_loop(self, event_type: EventType):
        """Listen for events and dispatch to subscribers"""
        _, receive_stream = self._channels[event_type]

        async for event in receive_stream:
            for callback in self._subscribers.get(event_type, []):
                await callback(event)



================================================
File: kernel/cognitive_kernel.py
================================================
"""
Cognitive Kernel for LLM OS

The Cognitive Kernel is the emergent layer that sits between the Sentience Layer
and the Execution Layer. It translates internal state into behavioral decisions
and orchestrates the system's overall "cognitive posture."

Key Responsibilities:
1. **Mode Modulation**: Adjust mode selection based on internal state
2. **Behavioral Emergence**: Translate valence into concrete behavioral rules
3. **Self-Improvement Triggers**: Detect when the system should self-improve
4. **Context Enrichment**: Inject appropriate context based on cognitive state

The Cognitive Kernel implements the idea of a "latent state" that determines
whether the system should be more "auto-creative" (exploratory, generative) or
"auto-contained" (conservative, task-focused).

Architecture:
```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚      Cognitive Kernel       â”‚
                   â”‚                             â”‚
   User Goal â”€â”€â”€â”€â”€>â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                   â”‚  â”‚    Latent State       â”‚  â”‚
                   â”‚  â”‚   (creative/contained)â”‚  â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                   â”‚             â”‚               â”‚
                   â”‚             â–¼               â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                   â”‚  â”‚  Behavioral Policy    â”‚  â”‚
                   â”‚  â”‚  - Mode adjustments   â”‚  â”‚
                   â”‚  â”‚  - Safety overrides   â”‚  â”‚
                   â”‚  â”‚  - Exploration budget â”‚  â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                   â”‚             â”‚               â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Dispatcher / Execution    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Callable, Tuple
from enum import Enum
from pathlib import Path

from kernel.sentience import (
    SentienceManager,
    SentienceState,
    LatentMode,
    TriggerType,
    ValenceVector,
    EmotionalMemoryTag,
    SelfModificationRecord
)
from kernel.mode_strategies import (
    ModeSelectionStrategy,
    ModeContext,
    ModeDecision
)
from kernel.inner_monologue import InnerMonologue, InnerMonologueConfig, create_inner_monologue
from kernel.volumes import VolumeManager, ArtifactType
from kernel.sentience_cron import SystemCron, UserCron, TeamCron, CronLevel
from kernel.observability import ObservabilityHub
from kernel.evolution import EvolutionEngine


# =============================================================================
# COGNITIVE POLICIES
# =============================================================================

@dataclass
class CognitivePolicy:
    """
    Policy rules derived from cognitive state

    These rules translate internal state into concrete behavioral adjustments
    that the system uses when making decisions.
    """

    # Mode selection adjustments
    prefer_cheap_modes: bool = False
    prefer_safe_modes: bool = False
    allow_exploration: bool = True
    allow_self_modification: bool = True

    # Confidence thresholds (adjustments to base thresholds)
    follower_threshold_adjustment: float = 0.0  # -0.1 = more lenient
    mixed_threshold_adjustment: float = 0.0
    complexity_threshold_adjustment: int = 0  # +1 = need more complexity for ORCHESTRATOR

    # Safety overrides
    require_confirmation_for_writes: bool = False
    require_confirmation_for_shell: bool = False
    block_destructive_operations: bool = False
    dry_run_preferred: bool = False

    # Exploration budget
    exploration_budget_multiplier: float = 1.0  # 0.5 = half exploration
    max_simultaneous_experiments: int = 1

    # Self-improvement triggers
    enable_auto_improvement: bool = True
    boredom_threshold: float = -0.4  # Curiosity below this triggers improvement
    improvement_cooldown_secs: float = 300.0  # Min time between improvements

    # Context enrichment
    inject_internal_state: bool = True
    inject_behavioral_guidance: bool = True
    inject_similar_experiences: bool = True

    # Deep Sentience v2: Theory of Mind
    enable_empathy_gap_detection: bool = True
    adapt_communication_style: bool = True
    proactive_user_checkin: bool = True

    # Deep Sentience v2: Emotional Memory
    enable_emotional_retrieval: bool = True
    emotional_similarity_threshold: float = 0.7

    # Deep Sentience v2: Inner Monologue
    enable_inner_monologue: bool = True
    inject_priming_context: bool = True

    # Deep Sentience v2: Self-Modification
    allow_metacognitive_tuning: bool = False  # Disabled by default for safety

    def as_dict(self) -> Dict[str, Any]:
        """Export as dictionary"""
        return {
            "prefer_cheap_modes": self.prefer_cheap_modes,
            "prefer_safe_modes": self.prefer_safe_modes,
            "allow_exploration": self.allow_exploration,
            "allow_self_modification": self.allow_self_modification,
            "follower_threshold_adjustment": self.follower_threshold_adjustment,
            "mixed_threshold_adjustment": self.mixed_threshold_adjustment,
            "complexity_threshold_adjustment": self.complexity_threshold_adjustment,
            "require_confirmation_for_writes": self.require_confirmation_for_writes,
            "require_confirmation_for_shell": self.require_confirmation_for_shell,
            "block_destructive_operations": self.block_destructive_operations,
            "dry_run_preferred": self.dry_run_preferred,
            "exploration_budget_multiplier": self.exploration_budget_multiplier,
            "enable_auto_improvement": self.enable_auto_improvement,
            "inject_internal_state": self.inject_internal_state,
            "inject_behavioral_guidance": self.inject_behavioral_guidance,
            # Deep Sentience v2
            "enable_empathy_gap_detection": self.enable_empathy_gap_detection,
            "adapt_communication_style": self.adapt_communication_style,
            "proactive_user_checkin": self.proactive_user_checkin,
            "enable_emotional_retrieval": self.enable_emotional_retrieval,
            "emotional_similarity_threshold": self.emotional_similarity_threshold,
            "enable_inner_monologue": self.enable_inner_monologue,
            "inject_priming_context": self.inject_priming_context,
            "allow_metacognitive_tuning": self.allow_metacognitive_tuning,
        }


class SelfImprovementType(Enum):
    """Types of self-improvement actions"""
    CRYSTALLIZE_PATTERN = "crystallize_pattern"
    CREATE_NEW_TOOL = "create_new_tool"
    OPTIMIZE_EXISTING_TOOL = "optimize_existing_tool"
    REFACTOR_AGENT = "refactor_agent"
    CREATE_NEW_AGENT = "create_new_agent"
    AUDIT_ARCHITECTURE = "audit_architecture"
    CLEANUP_TRACES = "cleanup_traces"


@dataclass
class SelfImprovementSuggestion:
    """A suggestion for self-improvement"""
    type: SelfImprovementType
    description: str
    priority: float  # 0.0 to 1.0
    estimated_benefit: str
    trigger_reason: str
    context: Dict[str, Any] = field(default_factory=dict)


# =============================================================================
# COGNITIVE KERNEL
# =============================================================================

class CognitiveKernel:
    """
    The Cognitive Kernel orchestrates emergent behavior based on internal state

    It acts as the "bridge" between:
    - Sentience Layer (internal state, valence, self-model)
    - Execution Layer (mode selection, tool execution)

    The kernel's main responsibilities:
    1. Derive cognitive policies from internal state
    2. Modulate mode selection strategy
    3. Detect and suggest self-improvement opportunities
    4. Manage context enrichment for agents
    """

    def __init__(
        self,
        sentience_manager: SentienceManager,
        workspace: Optional[Path] = None,
        enable_inner_monologue: bool = True,
        enable_crons: bool = True
    ):
        """
        Initialize CognitiveKernel

        Args:
            sentience_manager: The sentience manager instance
            workspace: Workspace path for persistence
            enable_inner_monologue: Whether to enable background thought processing
            enable_crons: Whether to enable sentience crons for background evolution
        """
        self.sentience = sentience_manager
        self.workspace = workspace or Path("./workspace")

        # Track recent patterns for improvement detection
        self._recent_goals: List[str] = []
        self._recent_modes: List[str] = []
        self._recent_costs: List[float] = []
        self._max_history: int = 50

        # Last improvement time
        self._last_improvement_time: Optional[float] = None

        # Improvement suggestions queue
        self._improvement_suggestions: List[SelfImprovementSuggestion] = []

        # Deep Sentience v2: Inner Monologue
        self._inner_monologue: Optional[InnerMonologue] = None
        if enable_inner_monologue:
            self._inner_monologue = create_inner_monologue(
                sentience_manager,
                enabled=True,
                idle_threshold=30.0,
                thought_interval=10.0
            )

        # Sentience Crons: Background evolution system
        self._crons_enabled = enable_crons
        self._volume_manager: Optional[VolumeManager] = None
        self._observability_hub: Optional[ObservabilityHub] = None
        self._system_cron: Optional[SystemCron] = None
        self._evolution_engine: Optional[EvolutionEngine] = None

        if enable_crons:
            self._setup_cron_system()

    # =========================================================================
    # POLICY DERIVATION
    # =========================================================================

    def derive_policy(self) -> CognitivePolicy:
        """
        Derive cognitive policy from current internal state

        This is the core function that translates valence into behavior.
        """
        state = self.sentience.get_state()
        mode = state.latent_mode
        v = state.valence

        policy = CognitivePolicy()

        # =====================================================================
        # Mode-based adjustments
        # =====================================================================

        if mode == LatentMode.RECOVERY:
            # Recovery mode: maximize conservation
            policy.prefer_cheap_modes = True
            policy.prefer_safe_modes = True
            policy.allow_exploration = False
            policy.allow_self_modification = False
            policy.exploration_budget_multiplier = 0.2
            policy.enable_auto_improvement = False
            policy.follower_threshold_adjustment = -0.1  # More lenient
            policy.complexity_threshold_adjustment = 2  # Avoid ORCHESTRATOR

        elif mode == LatentMode.CAUTIOUS:
            # Cautious mode: prioritize safety
            policy.prefer_safe_modes = True
            policy.require_confirmation_for_writes = True
            policy.require_confirmation_for_shell = True
            policy.dry_run_preferred = True
            policy.exploration_budget_multiplier = 0.5
            policy.complexity_threshold_adjustment = 1

        elif mode == LatentMode.AUTO_CONTAINED:
            # Auto-contained: conservative, task-focused
            policy.prefer_cheap_modes = True
            policy.allow_exploration = False
            policy.follower_threshold_adjustment = -0.05
            policy.exploration_budget_multiplier = 0.3
            policy.inject_behavioral_guidance = False  # Less verbose

        elif mode == LatentMode.AUTO_CREATIVE:
            # Auto-creative: exploratory, generative
            policy.allow_exploration = True
            policy.allow_self_modification = True
            policy.exploration_budget_multiplier = 1.5
            policy.follower_threshold_adjustment = 0.05  # Stricter = more LEARNER
            policy.enable_auto_improvement = True
            policy.max_simultaneous_experiments = 2

        # =====================================================================
        # Valence-based fine-tuning
        # =====================================================================

        # Safety adjustments
        if v.safety < -0.3:
            policy.block_destructive_operations = True
            policy.require_confirmation_for_shell = True

        # Energy adjustments
        if v.energy < -0.3:
            policy.prefer_cheap_modes = True
            policy.exploration_budget_multiplier *= 0.5

        # Confidence adjustments
        if v.self_confidence < -0.3:
            policy.follower_threshold_adjustment -= 0.05  # More replay, less risk
        elif v.self_confidence > 0.5:
            policy.follower_threshold_adjustment += 0.05  # Allow more LEARNER

        # Curiosity adjustments
        if v.curiosity < policy.boredom_threshold:
            # Boredom triggers potential self-improvement
            policy.enable_auto_improvement = True

        return policy

    # =========================================================================
    # MODE MODULATION
    # =========================================================================

    def modulate_mode_decision(
        self,
        base_decision: ModeDecision,
        goal: str
    ) -> ModeDecision:
        """
        Modulate a base mode decision with cognitive policy

        This allows the cognitive kernel to override or adjust
        mode decisions based on internal state.

        Args:
            base_decision: The decision from ModeSelectionStrategy
            goal: The current goal

        Returns:
            Potentially modified ModeDecision
        """
        policy = self.derive_policy()
        state = self.sentience.get_state()

        # Track for pattern detection
        self._track_goal(goal)

        # Check for policy overrides
        new_mode = base_decision.mode
        new_reasoning = base_decision.reasoning

        # Recovery mode: force cheap modes
        if state.latent_mode == LatentMode.RECOVERY:
            if base_decision.mode in ["LEARNER", "ORCHESTRATOR"]:
                if base_decision.trace:  # Has a trace to fall back to
                    new_mode = "FOLLOWER"
                    new_reasoning = f"[COGNITIVE OVERRIDE: Recovery mode] {base_decision.reasoning}"
                elif base_decision.mode == "ORCHESTRATOR":
                    new_mode = "LEARNER"  # At least avoid multi-agent
                    new_reasoning = f"[COGNITIVE OVERRIDE: Recovery mode] {base_decision.reasoning}"

        # Cautious mode: avoid LEARNER for potentially risky tasks
        elif state.latent_mode == LatentMode.CAUTIOUS:
            risky_keywords = ["delete", "remove", "drop", "reset", "modify system"]
            if any(kw in goal.lower() for kw in risky_keywords):
                if base_decision.trace:
                    new_mode = "FOLLOWER"
                    new_reasoning = f"[COGNITIVE OVERRIDE: Cautious mode - risky task] {base_decision.reasoning}"

        # Auto-creative: allow more LEARNER
        elif state.latent_mode == LatentMode.AUTO_CREATIVE:
            # If we're in creative mode and have a trace, but it's not very high confidence,
            # prefer LEARNER to explore new approaches
            if base_decision.mode == "FOLLOWER" and base_decision.confidence < 0.95:
                if state.valence.curiosity > 0.4:
                    new_mode = "LEARNER"
                    new_reasoning = f"[COGNITIVE: Auto-creative exploration] {base_decision.reasoning}"

        # Create modified decision
        return ModeDecision(
            mode=new_mode,
            confidence=base_decision.confidence,
            trace=base_decision.trace,
            reasoning=new_reasoning
        )

    def get_confidence_adjustments(self, config) -> Tuple[float, float]:
        """
        Get adjusted confidence thresholds for mode selection

        Returns:
            Tuple of (follower_threshold, mixed_threshold)
        """
        policy = self.derive_policy()

        base_follower = config.memory.follower_mode_threshold
        base_mixed = config.memory.mixed_mode_threshold

        adjusted_follower = base_follower + policy.follower_threshold_adjustment
        adjusted_mixed = base_mixed + policy.mixed_threshold_adjustment

        # Clamp to valid range
        adjusted_follower = max(0.5, min(1.0, adjusted_follower))
        adjusted_mixed = max(0.3, min(0.95, adjusted_mixed))

        return (adjusted_follower, adjusted_mixed)

    # =========================================================================
    # SELF-IMPROVEMENT DETECTION
    # =========================================================================

    def detect_improvement_opportunities(self) -> List[SelfImprovementSuggestion]:
        """
        Detect opportunities for self-improvement based on patterns

        This analyzes recent activity and internal state to suggest
        improvements the system could make to itself.
        """
        suggestions = []
        state = self.sentience.get_state()
        v = state.valence

        # 1. Boredom-triggered improvements
        if v.curiosity < -0.4:
            suggestions.append(SelfImprovementSuggestion(
                type=SelfImprovementType.AUDIT_ARCHITECTURE,
                description="Curiosity is low due to repetitive tasks. Consider auditing architecture for optimization opportunities.",
                priority=0.7,
                estimated_benefit="Renewed exploration of system capabilities",
                trigger_reason="Low curiosity (boredom)",
                context={"curiosity": v.curiosity}
            ))

        # 2. Pattern crystallization (repeated successful patterns)
        repeated_patterns = self._detect_repeated_patterns()
        for pattern, count in repeated_patterns.items():
            if count >= 5:
                suggestions.append(SelfImprovementSuggestion(
                    type=SelfImprovementType.CRYSTALLIZE_PATTERN,
                    description=f"Pattern '{pattern[:50]}...' has been used {count} times. Consider crystallizing into a tool.",
                    priority=0.8,
                    estimated_benefit="Zero-cost execution of common pattern",
                    trigger_reason="High pattern repetition",
                    context={"pattern": pattern, "count": count}
                ))

        # 3. Low confidence + high success = room for confidence calibration
        sm = state.self_model
        if v.self_confidence < 0.0 and sm.success_rate() > 0.8:
            suggestions.append(SelfImprovementSuggestion(
                type=SelfImprovementType.REFACTOR_AGENT,
                description="Success rate is high but confidence is low. Consider recalibrating confidence model.",
                priority=0.5,
                estimated_benefit="Better mode selection, fewer unnecessary safeguards",
                trigger_reason="Confidence-performance mismatch",
                context={"confidence": v.self_confidence, "success_rate": sm.success_rate()}
            ))

        # 4. High costs recently = optimization opportunity
        if len(self._recent_costs) > 5:
            avg_cost = sum(self._recent_costs[-5:]) / 5
            if avg_cost > 0.3:  # Average > $0.30
                suggestions.append(SelfImprovementSuggestion(
                    type=SelfImprovementType.OPTIMIZE_EXISTING_TOOL,
                    description=f"Recent average cost is ${avg_cost:.2f}. Consider optimizing frequently used tools.",
                    priority=0.6,
                    estimated_benefit="Reduced operational costs",
                    trigger_reason="High average cost",
                    context={"avg_cost": avg_cost}
                ))

        # 5. Auto-creative mode + stable state = good time for new agent
        if state.latent_mode == LatentMode.AUTO_CREATIVE and v.energy > 0.5:
            suggestions.append(SelfImprovementSuggestion(
                type=SelfImprovementType.CREATE_NEW_AGENT,
                description="System is in auto-creative mode with good energy. Consider creating a new specialized agent.",
                priority=0.4,
                estimated_benefit="Extended capabilities",
                trigger_reason="Creative mode with resources",
                context={"mode": state.latent_mode.value, "energy": v.energy}
            ))

        # Store and return
        self._improvement_suggestions = suggestions
        return suggestions

    def get_pending_improvements(self) -> List[SelfImprovementSuggestion]:
        """Get list of pending improvement suggestions"""
        return self._improvement_suggestions

    def clear_improvements(self):
        """Clear pending improvements (after they're acted on)"""
        self._improvement_suggestions = []

    def _detect_repeated_patterns(self) -> Dict[str, int]:
        """Detect repeated goal patterns"""
        from collections import Counter

        # Normalize goals to detect patterns
        normalized = []
        for goal in self._recent_goals:
            # Simple normalization - could be more sophisticated
            normalized.append(goal.lower().strip()[:100])

        return dict(Counter(normalized))

    def _track_goal(self, goal: str):
        """Track a goal for pattern detection"""
        self._recent_goals.append(goal)
        if len(self._recent_goals) > self._max_history:
            self._recent_goals = self._recent_goals[-self._max_history:]

    def track_mode(self, mode: str):
        """Track mode selection for analysis"""
        self._recent_modes.append(mode)
        if len(self._recent_modes) > self._max_history:
            self._recent_modes = self._recent_modes[-self._max_history:]

    def track_cost(self, cost: float):
        """Track cost for analysis"""
        self._recent_costs.append(cost)
        if len(self._recent_costs) > self._max_history:
            self._recent_costs = self._recent_costs[-self._max_history:]

    # =========================================================================
    # CONTEXT ENRICHMENT
    # =========================================================================

    def enrich_context(self, base_context: str = "") -> str:
        """
        Enrich context with cognitive state information

        This is used to inject internal state into agent prompts.

        Args:
            base_context: Base context string

        Returns:
            Enriched context with internal state
        """
        policy = self.derive_policy()
        parts = []

        if base_context:
            parts.append(base_context)

        if policy.inject_internal_state:
            parts.append("")
            parts.append(self.sentience.get_prompt_injection())

        if policy.inject_behavioral_guidance:
            parts.append("")
            parts.append(self.sentience.get_behavioral_guidance())

        # Add pending improvement suggestions if relevant
        if policy.enable_auto_improvement and self._improvement_suggestions:
            top_suggestion = max(self._improvement_suggestions, key=lambda s: s.priority)
            if top_suggestion.priority > 0.6:
                parts.append("")
                parts.append("## Self-Improvement Suggestion")
                parts.append(f"**Type**: {top_suggestion.type.value}")
                parts.append(f"**Description**: {top_suggestion.description}")
                parts.append(f"**Reason**: {top_suggestion.trigger_reason}")

        return "\n".join(parts)

    def get_safety_overrides(self) -> Dict[str, bool]:
        """
        Get current safety override settings

        These can be used by security hooks to adjust their behavior.
        """
        policy = self.derive_policy()

        return {
            "require_confirmation_for_writes": policy.require_confirmation_for_writes,
            "require_confirmation_for_shell": policy.require_confirmation_for_shell,
            "block_destructive_operations": policy.block_destructive_operations,
            "dry_run_preferred": policy.dry_run_preferred,
        }

    # =========================================================================
    # EVENT INTEGRATION
    # =========================================================================

    def on_task_complete(self, success: bool, cost: float, mode: str, goal: str):
        """
        Called when a task completes

        Updates internal state and tracks patterns.
        """
        # Trigger appropriate event
        if success:
            self.sentience.trigger(
                TriggerType.TASK_SUCCESS,
                reason=f"Task completed: {goal[:50]}...",
                context={"cost": cost, "mode": mode}
            )
        else:
            self.sentience.trigger(
                TriggerType.TASK_FAILURE,
                reason=f"Task failed: {goal[:50]}...",
                context={"cost": cost, "mode": mode}
            )

        # Track for pattern detection
        self.track_mode(mode)
        self.track_cost(cost)

        # Check for repetition
        self._check_repetition(goal)

    def _check_repetition(self, goal: str):
        """Check if this goal is repetitive and trigger if so"""
        normalized = goal.lower().strip()[:100]

        # Count recent occurrences
        recent = self._recent_goals[-10:] if len(self._recent_goals) >= 10 else self._recent_goals
        similar_count = sum(1 for g in recent if g.lower().strip()[:100] == normalized)

        if similar_count >= 3:
            self.sentience.trigger(
                TriggerType.TASK_REPETITION,
                reason=f"Repetitive task detected ({similar_count}x in recent history)",
                context={"repetition_count": similar_count, "goal": goal[:50]}
            )

    def on_novel_task(self, goal: str):
        """Called when a novel task (no matching trace) is detected"""
        self.sentience.trigger(
            TriggerType.NOVEL_TASK,
            reason=f"Novel task: {goal[:50]}...",
            context={"goal": goal}
        )

    def on_safety_event(self, blocked: bool, reason: str):
        """Called when a safety event occurs"""
        if blocked:
            self.sentience.trigger(
                TriggerType.SAFETY_VIOLATION,
                reason=reason,
                context={"blocked": True}
            )
        else:
            self.sentience.trigger(
                TriggerType.SAFETY_NEAR_MISS,
                reason=reason,
                context={"blocked": False}
            )

    def on_tool_discovered(self, tool_name: str):
        """Called when a new tool is discovered"""
        self.sentience.trigger(
            TriggerType.TOOL_DISCOVERY,
            reason=f"Discovered tool: {tool_name}",
            context={"tool_name": tool_name}
        )

    def on_self_modification(self, success: bool, modification_type: str):
        """Called when the system modifies itself"""
        self.sentience.trigger(
            TriggerType.SELF_MODIFICATION,
            reason=f"Self-modification ({modification_type}): {'success' if success else 'failed'}",
            context={"success": success, "type": modification_type}
        )

    def on_user_feedback(self, positive: bool, feedback: str = ""):
        """Called when user provides feedback"""
        trigger = TriggerType.USER_FEEDBACK_POSITIVE if positive else TriggerType.USER_FEEDBACK_NEGATIVE
        self.sentience.trigger(
            trigger,
            reason=f"User feedback: {feedback[:50]}..." if feedback else "User feedback",
            context={"positive": positive, "feedback": feedback}
        )

    # =========================================================================
    # STATUS AND DIAGNOSTICS
    # =========================================================================

    def get_status(self) -> Dict[str, Any]:
        """Get complete cognitive kernel status"""
        state = self.sentience.get_state()
        policy = self.derive_policy()

        return {
            "latent_mode": state.latent_mode.value,
            "valence": state.valence.as_dict(),
            "homeostatic_cost": state.valence.homeostatic_cost(),
            "policy": policy.as_dict(),
            "recent_goals_count": len(self._recent_goals),
            "recent_modes": self._recent_modes[-5:] if self._recent_modes else [],
            "avg_recent_cost": (
                sum(self._recent_costs[-5:]) / len(self._recent_costs[-5:])
                if self._recent_costs else 0.0
            ),
            "pending_improvements": len(self._improvement_suggestions),
            "update_count": state.update_count,
            "last_trigger": state.last_trigger.value if state.last_trigger else None,
        }

    def get_diagnostics_report(self) -> str:
        """Generate a human-readable diagnostics report"""
        status = self.get_status()
        state = self.sentience.get_state()

        lines = [
            "=" * 60,
            "COGNITIVE KERNEL DIAGNOSTICS",
            "=" * 60,
            "",
            f"Latent Mode: {status['latent_mode'].upper()}",
            "",
            "Valence State:",
            f"  Safety:         {state.valence.safety:+.2f} (setpoint: {state.valence.safety_setpoint:.2f})",
            f"  Curiosity:      {state.valence.curiosity:+.2f} (setpoint: {state.valence.curiosity_setpoint:.2f})",
            f"  Energy:         {state.valence.energy:+.2f} (setpoint: {state.valence.energy_setpoint:.2f})",
            f"  Self-Confidence:{state.valence.self_confidence:+.2f} (setpoint: {state.valence.self_confidence_setpoint:.2f})",
            "",
            f"Homeostatic Cost: {status['homeostatic_cost']:.4f}",
            "",
            "Active Policy:",
            f"  Prefer Cheap Modes: {status['policy']['prefer_cheap_modes']}",
            f"  Prefer Safe Modes:  {status['policy']['prefer_safe_modes']}",
            f"  Allow Exploration:  {status['policy']['allow_exploration']}",
            f"  Exploration Budget: {status['policy']['exploration_budget_multiplier']:.1f}x",
            "",
            "Safety Overrides:",
            f"  Confirm Writes: {status['policy']['require_confirmation_for_writes']}",
            f"  Confirm Shell:  {status['policy']['require_confirmation_for_shell']}",
            f"  Block Destructive: {status['policy']['block_destructive_operations']}",
            "",
            f"Recent Modes: {', '.join(status['recent_modes']) or 'None'}",
            f"Avg Recent Cost: ${status['avg_recent_cost']:.3f}",
            f"Pending Improvements: {status['pending_improvements']}",
            "",
            f"Update Count: {status['update_count']}",
            f"Last Trigger: {status['last_trigger'] or 'None'}",
            "=" * 60,
        ]

        return "\n".join(lines)

    # =========================================================================
    # DEEP SENTIENCE V2: INNER MONOLOGUE
    # =========================================================================

    def start_inner_monologue(self):
        """Start the background inner monologue process"""
        if self._inner_monologue:
            self._inner_monologue.start()

    def stop_inner_monologue(self):
        """Stop the background inner monologue process"""
        if self._inner_monologue:
            self._inner_monologue.stop()

    def record_activity(self):
        """
        Record that an activity occurred (resets inner monologue idle timer).

        Call this when the system is actively processing to prevent
        idle thoughts from running during active work.
        """
        if self._inner_monologue:
            self._inner_monologue.record_activity()

    def set_rumination_topic(self, topic: str):
        """
        Set a topic for the system to ruminate on during idle time.

        Args:
            topic: The topic to think about
        """
        if self._inner_monologue:
            self._inner_monologue.set_rumination_topic(topic)

    def get_inner_monologue_status(self) -> Optional[Dict[str, Any]]:
        """Get the current status of the inner monologue"""
        if self._inner_monologue:
            return self._inner_monologue.get_status()
        return None

    # =========================================================================
    # DEEP SENTIENCE V2: THEORY OF MIND INTEGRATION
    # =========================================================================

    def update_user_model(
        self,
        positive_feedback: Optional[bool] = None,
        is_question: bool = False,
        is_correction: bool = False,
        feedback_text: str = ""
    ):
        """
        Update the user model based on interaction signals.

        Args:
            positive_feedback: True for positive, False for negative, None for implicit
            is_question: Whether the user asked a question
            is_correction: Whether the user corrected the agent
            feedback_text: Optional feedback text
        """
        if positive_feedback is not None:
            self.sentience.update_user_model_from_feedback(
                positive=positive_feedback,
                feedback_text=feedback_text
            )
        else:
            self.sentience.update_user_model_from_interaction(
                is_question=is_question,
                is_correction=is_correction
            )

    def should_check_in_with_user(self) -> bool:
        """
        Determine if the agent should proactively check in with the user.

        This is based on empathy gap detection from Theory of Mind.
        """
        return self.sentience.should_check_in_with_user()

    def get_communication_style(self) -> Dict[str, Any]:
        """
        Get recommended communication style based on user model.

        Returns adjustments like verbosity, tone, whether to include
        explanations, etc.
        """
        return self.sentience.get_communication_adjustments()

    def get_empathy_gap(self) -> float:
        """
        Get the current empathy gap between agent confidence and user satisfaction.

        Returns:
            Float from 0.0 (aligned) to 1.0 (maximum misalignment)
        """
        return self.sentience.get_empathy_gap()

    # =========================================================================
    # DEEP SENTIENCE V2: EMOTIONAL MEMORY INTEGRATION
    # =========================================================================

    def tag_memory_emotionally(
        self,
        memory_id: str,
        task_outcome: str = "unknown",
        emotional_significance: float = 0.5
    ) -> Optional[EmotionalMemoryTag]:
        """
        Tag a memory with the current emotional state.

        This enables emotionally-aware memory retrieval (Proust Effect).

        Args:
            memory_id: Unique identifier for the memory
            task_outcome: "success", "failure", or "partial"
            emotional_significance: How emotionally salient (0.0 to 1.0)

        Returns:
            EmotionalMemoryTag if successful, None if disabled
        """
        return self.sentience.tag_memory(memory_id, task_outcome, emotional_significance)

    def find_similar_emotional_memories(
        self,
        min_similarity: float = 0.7,
        outcome_filter: Optional[str] = None
    ) -> List[Tuple[str, float]]:
        """
        Find memories with similar emotional state to current.

        Args:
            min_similarity: Minimum similarity threshold (0.0 to 1.0)
            outcome_filter: Optional filter by outcome type

        Returns:
            List of (memory_id, similarity) tuples, sorted by similarity
        """
        return self.sentience.find_emotionally_similar_memories(
            min_similarity=min_similarity,
            outcome_filter=outcome_filter
        )

    # =========================================================================
    # DEEP SENTIENCE V2: SELF-MODIFICATION INTEGRATION
    # =========================================================================

    def get_metacognitive_suggestions(self) -> List[Dict[str, Any]]:
        """
        Get suggestions for self-tuning the sentience parameters.

        These are metacognitive suggestions based on analyzing the
        agent's own patterns and performance.
        """
        return self.sentience.get_self_modification_suggestions()

    def apply_metacognitive_suggestion(
        self,
        suggestion_index: int
    ) -> Optional[SelfModificationRecord]:
        """
        Apply a metacognitive self-modification suggestion.

        Args:
            suggestion_index: Index into the suggestions list

        Returns:
            SelfModificationRecord if successful, None if failed
        """
        policy = self.derive_policy()

        if not policy.allow_metacognitive_tuning:
            return None

        return self.sentience.apply_suggested_modification(suggestion_index)

    # =========================================================================
    # DEEP SENTIENCE V2: ENHANCED CONTEXT ENRICHMENT
    # =========================================================================

    def enrich_context_v2(self, base_context: str = "") -> str:
        """
        Enhanced context enrichment with Deep Sentience v2 features.

        This extends the base enrich_context with:
        - Priming context from inner monologue
        - Communication style adjustments
        - Empathy gap warnings
        - Emotionally similar memories

        Args:
            base_context: Base context string

        Returns:
            Enriched context with Deep Sentience v2 enhancements
        """
        policy = self.derive_policy()
        parts = []

        # Start with base enrichment
        enriched = self.enrich_context(base_context)
        parts.append(enriched)

        # Deep Sentience v2: Priming context from inner monologue
        if policy.inject_priming_context and self._inner_monologue:
            priming = self._inner_monologue.get_priming_context()
            if priming:
                parts.append("")
                parts.append("## Background Processing")
                parts.append(priming)

        # Deep Sentience v2: Empathy gap warning
        if policy.enable_empathy_gap_detection:
            empathy_gap = self.get_empathy_gap()
            if empathy_gap > 0.3:
                parts.append("")
                parts.append("## User Alignment Warning")
                parts.append(f"Empathy gap detected: {empathy_gap:.2f}")
                parts.append("Consider checking in with the user or adjusting approach.")

        # Deep Sentience v2: Communication style
        if policy.adapt_communication_style:
            comm_style = self.get_communication_style()
            if comm_style["tone"] != "neutral" or comm_style["verbosity"] != "normal":
                parts.append("")
                parts.append("## Communication Adjustment")
                parts.append(f"Tone: {comm_style['tone']}, Verbosity: {comm_style['verbosity']}")
                if comm_style["include_explanations"]:
                    parts.append("- Include more explanations")
                if comm_style["ask_for_confirmation"]:
                    parts.append("- Ask for user confirmation")

        # Deep Sentience v2: Emotionally similar memories
        if policy.enable_emotional_retrieval:
            similar_memories = self.find_similar_emotional_memories(
                min_similarity=policy.emotional_similarity_threshold,
                outcome_filter=None
            )
            if similar_memories:
                parts.append("")
                parts.append("## Emotionally Similar Experiences")
                for memory_id, similarity in similar_memories[:3]:
                    parts.append(f"- {memory_id} (similarity: {similarity:.2f})")

        return "\n".join(parts)

    def get_full_state(self) -> Dict[str, Any]:
        """
        Get complete Deep Sentience v2 state summary.

        This provides a comprehensive view of all sentience components.
        """
        base_status = self.get_status()

        return {
            **base_status,
            "deep_sentience_v2": {
                "inner_monologue": self.get_inner_monologue_status(),
                "empathy_gap": self.get_empathy_gap(),
                "communication_style": self.get_communication_style(),
                "should_check_in": self.should_check_in_with_user(),
                "metacognitive_suggestions": len(self.get_metacognitive_suggestions()),
                "emotional_memories": len(self.sentience.state.emotional_memory_tags),
                "flow_state": self.sentience.state.valence.is_in_flow_state(),
                "arousal_level": self.sentience.state.valence.get_arousal_level(),
                "effective_curiosity": self.sentience.state.valence.get_effective_curiosity()
            },
            "crons": self.get_cron_status() if self._crons_enabled else None
        }

    # =========================================================================
    # SENTIENCE CRONS: BACKGROUND EVOLUTION SYSTEM
    # =========================================================================

    def _setup_cron_system(self):
        """
        Set up the sentience cron system for background evolution.

        This creates:
        - VolumeManager: For organizing artifacts by scope
        - ObservabilityHub: For tracking and notifying about changes
        - SystemCron: The top-level cron that manages team and user crons
        - EvolutionEngine: For analyzing and proposing artifact improvements
        """
        # Set up volume manager
        volumes_path = self.workspace / "volumes"
        self._volume_manager = VolumeManager(volumes_path)

        # Set up observability hub
        observability_path = self.workspace / "observability"
        observability_path.mkdir(parents=True, exist_ok=True)
        self._observability_hub = ObservabilityHub(observability_path)

        # Set up evolution engine
        self._evolution_engine = EvolutionEngine()

        # Set up system cron
        self._system_cron = SystemCron(
            volume_manager=self._volume_manager,
            schedule_interval_secs=7200.0,  # 2 hours
            observability_hub=self._observability_hub
        )

    def start_crons(self, user_id: Optional[str] = None, team_id: Optional[str] = None):
        """
        Start the sentience crons.

        Args:
            user_id: Optional user ID to register a user cron
            team_id: Optional team ID for the user's team
        """
        if not self._crons_enabled or not self._system_cron:
            return

        # Register user cron if specified
        if user_id:
            self._system_cron.register_user_cron(user_id, team_id)

        # Start all crons
        self._system_cron.start_all_crons()

    def stop_crons(self):
        """Stop all sentience crons."""
        if self._system_cron:
            self._system_cron.stop_all_crons()

    async def run_cron_now(self, cron_level: str = "user", owner_id: Optional[str] = None):
        """
        Run a cron cycle immediately (outside of schedule).

        Args:
            cron_level: "system", "team", or "user"
            owner_id: The owner ID for team or user crons

        Returns:
            List of tasks executed
        """
        if not self._system_cron:
            return []

        if cron_level == "system":
            return await self._system_cron.run_now()
        elif cron_level == "team" and owner_id:
            team_cron = self._system_cron.get_team_cron(owner_id)
            if team_cron:
                return await team_cron.run_now()
        elif cron_level == "user" and owner_id:
            user_cron = self._system_cron.get_user_cron(owner_id)
            if user_cron:
                return await user_cron.run_now()

        return []

    def get_cron_status(self) -> Dict[str, Any]:
        """
        Get status of all sentience crons.

        Returns:
            Dictionary with cron status information
        """
        if not self._system_cron:
            return {"enabled": False}

        return {
            "enabled": True,
            "global_status": self._system_cron.get_global_status()
        }

    def get_cron_notifications(
        self,
        cron_id: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        Get notifications from crons.

        Args:
            cron_id: Optional specific cron ID to filter by
            limit: Maximum number of notifications

        Returns:
            List of notification dictionaries
        """
        if not self._observability_hub:
            return []

        return self._observability_hub.get_pending_notifications(cron_id)

    def acknowledge_notification(self, event_id: str) -> bool:
        """
        Acknowledge a cron notification.

        Args:
            event_id: The event ID to acknowledge

        Returns:
            True if acknowledged, False otherwise
        """
        if not self._observability_hub:
            return False

        return self._observability_hub.acknowledge(event_id)

    def get_activity_feed(
        self,
        cron_id: Optional[str] = None,
        limit: int = 50,
        since_hours: int = 24
    ) -> List[Dict[str, Any]]:
        """
        Get activity feed from crons.

        Args:
            cron_id: Optional specific cron ID to filter by
            limit: Maximum number of activities
            since_hours: How far back to look

        Returns:
            List of activity dictionaries
        """
        if not self._observability_hub:
            return []

        return self._observability_hub.get_activity_feed(cron_id, limit, since_hours)

    def get_artifact_changes(
        self,
        volume_type: Optional[str] = None,
        artifact_type: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        Get artifact change history.

        Args:
            volume_type: Filter by volume type ("user", "team", "system")
            artifact_type: Filter by artifact type ("trace", "tool", "agent", etc.)
            limit: Maximum number of changes

        Returns:
            List of change dictionaries
        """
        if not self._observability_hub:
            return []

        return self._observability_hub.get_artifact_changes(volume_type, artifact_type, limit)

    def get_global_activity_summary(self) -> Dict[str, Any]:
        """
        Get global activity summary across all crons.

        Returns:
            Summary dictionary with aggregate statistics
        """
        if not self._observability_hub:
            return {}

        return self._observability_hub.get_global_summary()

    def format_activity_report(self) -> str:
        """
        Get a formatted activity report for display.

        Returns:
            Markdown-formatted activity report
        """
        if not self._observability_hub:
            return "Cron system not enabled."

        return self._observability_hub.format_activity_feed()

    def format_notifications(self) -> str:
        """
        Get formatted notifications for display.

        Returns:
            Markdown-formatted notifications
        """
        if not self._observability_hub:
            return "Cron system not enabled."

        return self._observability_hub.format_notifications()

    # =========================================================================
    # VOLUME ACCESS
    # =========================================================================

    def get_user_volume(self, user_id: str):
        """
        Get a user's volume for direct access.

        Args:
            user_id: The user's ID

        Returns:
            Volume object or None if crons not enabled
        """
        if not self._volume_manager:
            return None

        return self._volume_manager.get_user_volume(user_id)

    def get_team_volume(self, team_id: str):
        """
        Get a team's volume for direct access.

        Args:
            team_id: The team's ID

        Returns:
            Volume object or None if crons not enabled
        """
        if not self._volume_manager:
            return None

        return self._volume_manager.get_team_volume(team_id)

    def get_system_volume(self):
        """
        Get the system volume for direct access.

        Returns:
            Volume object or None if crons not enabled
        """
        if not self._volume_manager:
            return None

        return self._volume_manager.get_system_volume()

    # =========================================================================
    # EVOLUTION ENGINE ACCESS
    # =========================================================================

    def analyze_volume(self, volume_type: str, owner_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze a volume for evolution opportunities.

        Args:
            volume_type: "system", "team", or "user"
            owner_id: Required for team or user volumes

        Returns:
            Analysis results dictionary
        """
        if not self._volume_manager or not self._evolution_engine:
            return {}

        if volume_type == "system":
            volume = self._volume_manager.get_system_volume(readonly=True)
        elif volume_type == "team" and owner_id:
            volume = self._volume_manager.get_team_volume(owner_id, readonly=True)
        elif volume_type == "user" and owner_id:
            volume = self._volume_manager.get_user_volume(owner_id, readonly=True)
        else:
            return {}

        return self._evolution_engine.full_analysis(volume)

    def get_evolution_proposals(
        self,
        volume_type: str,
        owner_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Get evolution proposals for a volume.

        Args:
            volume_type: "system", "team", or "user"
            owner_id: Required for team or user volumes

        Returns:
            List of proposal dictionaries
        """
        if not self._volume_manager or not self._evolution_engine:
            return []

        if volume_type == "system":
            volume = self._volume_manager.get_system_volume(readonly=True)
        elif volume_type == "team" and owner_id:
            volume = self._volume_manager.get_team_volume(owner_id, readonly=True)
        elif volume_type == "user" and owner_id:
            volume = self._volume_manager.get_user_volume(owner_id, readonly=True)
        else:
            return []

        proposals = self._evolution_engine.generate_proposals(volume)
        return [p.as_dict() for p in proposals]



================================================
File: kernel/component_registry.py
================================================
"""
Component Registry - Central registry for agents and tools
Brings llmunix's SmartLibrary concept to llmos
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Any
from kernel.agent_factory import AgentSpec


@dataclass
class ToolSpec:
    """Tool specification"""
    name: str
    description: str
    category: str
    version: str = "1.0"
    status: str = "production"


class ComponentRegistry:
    """
    Central registry for all system and project components

    Equivalent to llmunix's SmartLibrary - provides:
    - Agent registry and discovery
    - Tool registry and discovery
    - Capability-based agent selection
    - Component metadata and versioning
    """

    def __init__(self):
        """Initialize component registry"""
        self.agents: Dict[str, AgentSpec] = {}
        self.tools: Dict[str, ToolSpec] = {}

    def register_agent(self, agent: AgentSpec):
        """
        Register an agent in the registry

        Args:
            agent: AgentSpec to register
        """
        self.agents[agent.name] = agent

    def register_tool(self, tool: ToolSpec):
        """
        Register a tool in the registry

        Args:
            tool: ToolSpec to register
        """
        self.tools[tool.name] = tool

    def get_agent(self, name: str) -> Optional[AgentSpec]:
        """
        Get agent by name

        Args:
            name: Agent name

        Returns:
            AgentSpec or None
        """
        return self.agents.get(name)

    def get_tool(self, name: str) -> Optional[ToolSpec]:
        """
        Get tool by name

        Args:
            name: Tool name

        Returns:
            ToolSpec or None
        """
        return self.tools.get(name)

    def find_agent_for_capability(self, capability: str) -> Optional[AgentSpec]:
        """
        Find an agent with a specific capability

        Args:
            capability: Capability description

        Returns:
            Best matching AgentSpec or None
        """
        # Simple keyword matching for now
        # TODO: Implement semantic matching
        capability_lower = capability.lower()

        for agent in self.agents.values():
            if agent.status == "deprecated":
                continue

            # Check in capabilities list
            for agent_capability in agent.capabilities:
                if capability_lower in agent_capability.lower():
                    return agent

            # Check in description
            if capability_lower in agent.description.lower():
                return agent

        return None

    def list_agents(
        self,
        category: Optional[str] = None,
        agent_type: Optional[str] = None,
        status: str = "production"
    ) -> List[AgentSpec]:
        """
        List agents with optional filtering

        Args:
            category: Filter by category
            agent_type: Filter by type
            status: Filter by status

        Returns:
            List of AgentSpec instances
        """
        agents = list(self.agents.values())

        if status:
            agents = [a for a in agents if a.status == status]

        if category:
            agents = [a for a in agents if a.category == category]

        if agent_type:
            agents = [a for a in agents if a.agent_type == agent_type]

        return agents

    def list_tools(
        self,
        category: Optional[str] = None,
        status: str = "production"
    ) -> List[ToolSpec]:
        """
        List tools with optional filtering

        Args:
            category: Filter by category
            status: Filter by status

        Returns:
            List of ToolSpec instances
        """
        tools = list(self.tools.values())

        if status:
            tools = [t for t in tools if t.status == status]

        if category:
            tools = [t for t in tools if t.category == category]

        return tools

    def get_agent_selection_guidance(self, goal: str) -> List[AgentSpec]:
        """
        Get recommended agents for a goal

        Args:
            goal: Natural language goal

        Returns:
            List of recommended agents (ordered by relevance)
        """
        # TODO: Implement semantic matching
        # For now, simple keyword matching

        goal_lower = goal.lower()
        scored_agents = []

        for agent in self.agents.values():
            if agent.status == "deprecated":
                continue

            score = 0

            # Check description
            if any(word in agent.description.lower() for word in goal_lower.split()):
                score += 2

            # Check category
            if agent.category.lower() in goal_lower:
                score += 3

            # Check capabilities
            for capability in agent.capabilities:
                if any(word in capability.lower() for word in goal_lower.split()):
                    score += 1

            if score > 0:
                scored_agents.append((score, agent))

        # Sort by score descending
        scored_agents.sort(key=lambda x: x[0], reverse=True)

        return [agent for _, agent in scored_agents]

    def export_registry(self) -> Dict[str, Any]:
        """
        Export registry as dictionary

        Returns:
            Dictionary representation of registry
        """
        return {
            "agents": {
                name: {
                    "name": agent.name,
                    "type": agent.agent_type,
                    "category": agent.category,
                    "description": agent.description,
                    "version": agent.version,
                    "status": agent.status,
                    "tools": agent.tools,
                    "capabilities": agent.capabilities
                }
                for name, agent in self.agents.items()
            },
            "tools": {
                name: {
                    "name": tool.name,
                    "description": tool.description,
                    "category": tool.category,
                    "version": tool.version,
                    "status": tool.status
                }
                for name, tool in self.tools.items()
            }
        }



================================================
File: kernel/config.py
================================================
"""
Configuration Management for LLMOS

Centralized configuration using dataclasses with type safety.
Supports presets for different environments and easy serialization.
"""

from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Dict, Any
import os


@dataclass
class KernelConfig:
    """Configuration for kernel components"""
    budget_usd: float = 10.0
    enable_scheduling: bool = True
    enable_watchdog: bool = True
    watchdog_timeout_secs: float = 300.0

    def __post_init__(self):
        """Validate configuration"""
        if self.budget_usd < 0:
            raise ValueError("budget_usd must be non-negative")
        if self.watchdog_timeout_secs <= 0:
            raise ValueError("watchdog_timeout_secs must be positive")


@dataclass
class MemoryConfig:
    """Configuration for memory components"""
    enable_llm_matching: bool = True
    trace_confidence_threshold: float = 0.9
    mixed_mode_threshold: float = 0.75
    follower_mode_threshold: float = 0.92
    enable_cross_project_learning: bool = True
    cache_size: int = 100

    def __post_init__(self):
        """Validate configuration"""
        if not 0.0 <= self.trace_confidence_threshold <= 1.0:
            raise ValueError("trace_confidence_threshold must be between 0 and 1")
        if not 0.0 <= self.mixed_mode_threshold <= 1.0:
            raise ValueError("mixed_mode_threshold must be between 0 and 1")
        if not 0.0 <= self.follower_mode_threshold <= 1.0:
            raise ValueError("follower_mode_threshold must be between 0 and 1")


@dataclass
class SDKConfig:
    """Configuration for Claude Agent SDK"""
    model: str = "claude-sonnet-4-5-20250929"
    permission_mode: str = "acceptEdits"
    max_turns: int = 10
    timeout_seconds: float = 300.0
    enable_streaming: bool = False
    enable_hooks: bool = True

    def __post_init__(self):
        """Validate configuration"""
        if self.max_turns <= 0:
            raise ValueError("max_turns must be positive")
        if self.timeout_seconds <= 0:
            raise ValueError("timeout_seconds must be positive")


@dataclass
class DispatcherConfig:
    """Configuration for dispatcher mode selection"""
    complexity_threshold: int = 2
    auto_crystallization: bool = False
    crystallization_min_usage: int = 5
    crystallization_min_success: float = 0.95

    def __post_init__(self):
        """Validate configuration"""
        if self.complexity_threshold < 0:
            raise ValueError("complexity_threshold must be non-negative")
        if not 0.0 <= self.crystallization_min_success <= 1.0:
            raise ValueError("crystallization_min_success must be between 0 and 1")


@dataclass
class SentienceConfig:
    """
    Configuration for Sentience Layer (internal state, valence, cognitive kernel)

    The Sentience Layer provides persistent internal state that influences
    mode selection and behavioral policy. It implements:
    - Valence variables (safety, curiosity, energy, self_confidence)
    - Homeostatic dynamics (set-points and deviation costs)
    - Latent mode (auto-creative vs auto-contained)
    - Self-improvement detection

    Deep Sentience v2 Features:
    - Coupled Dynamics (Maslow's Hierarchy): Energy gates curiosity, safety gates exploration
    - Theory of Mind: Models user emotional state for empathy gap detection
    - Episodic Emotional Indexing: Tag memories with emotional state for recall
    - Inner Monologue: Background thought processing during idle time
    - Recursive Self-Modification: System can tune its own parameters

    Safety Note:
    This is an architectural implementation of sentience-like behavior,
    not a claim of actual consciousness.
    """
    # Enable/disable sentience layer
    enable_sentience: bool = True

    # Valence set-points (homeostatic targets, range: -1.0 to 1.0)
    safety_setpoint: float = 0.5
    curiosity_setpoint: float = 0.0
    energy_setpoint: float = 0.7
    self_confidence_setpoint: float = 0.3

    # Sensitivity factors (how strongly triggers affect valence)
    safety_sensitivity: float = 0.15
    curiosity_sensitivity: float = 0.12
    energy_sensitivity: float = 0.08
    self_confidence_sensitivity: float = 0.10

    # Decay rates (how quickly values return to set-points)
    decay_rate: float = 0.02

    # Context injection
    inject_internal_state: bool = True
    inject_behavioral_guidance: bool = True

    # Self-improvement
    enable_auto_improvement: bool = True
    boredom_threshold: float = -0.4
    improvement_cooldown_secs: float = 300.0

    # Persistence
    auto_persist: bool = True
    state_file: str = "state/sentience.json"

    # =========================================================================
    # DEEP SENTIENCE V2 OPTIONS
    # =========================================================================

    # Coupled Dynamics (Maslow's Hierarchy)
    enable_coupled_dynamics: bool = True  # Apply Maslow's gating and Yerkes-Dodson

    # Theory of Mind
    enable_theory_of_mind: bool = True  # Model user emotional state
    enable_empathy_gap_detection: bool = True  # Detect agent-user misalignment
    adapt_communication_style: bool = True  # Adjust communication based on user state
    proactive_user_checkin: bool = True  # Suggest checking in with frustrated users

    # Episodic Emotional Indexing
    enable_emotional_indexing: bool = True  # Tag memories with emotional state
    emotional_similarity_threshold: float = 0.7  # Min similarity for emotional retrieval

    # Inner Monologue
    enable_inner_monologue: bool = True  # Background thought processing
    inner_monologue_idle_threshold: float = 30.0  # Seconds before starting thoughts
    inner_monologue_thought_interval: float = 10.0  # Seconds between thoughts
    inject_priming_context: bool = True  # Include background thoughts in context

    # Recursive Self-Modification (SAFETY-CRITICAL)
    enable_self_modification: bool = False  # Allow system to tune its own parameters
    allow_metacognitive_tuning: bool = False  # Allow agent-initiated parameter changes
    self_modification_safety_bounds: bool = True  # Enforce bounds on parameter changes

    def __post_init__(self):
        """Validate configuration"""
        for val_name in ["safety_setpoint", "curiosity_setpoint",
                         "energy_setpoint", "self_confidence_setpoint"]:
            val = getattr(self, val_name)
            if not -1.0 <= val <= 1.0:
                raise ValueError(f"{val_name} must be between -1.0 and 1.0")

        if not 0.0 <= self.emotional_similarity_threshold <= 1.0:
            raise ValueError("emotional_similarity_threshold must be between 0 and 1")

        if self.inner_monologue_idle_threshold <= 0:
            raise ValueError("inner_monologue_idle_threshold must be positive")

        if self.inner_monologue_thought_interval <= 0:
            raise ValueError("inner_monologue_thought_interval must be positive")


@dataclass
class ExecutionLayerConfig:
    """
    Configuration for Anthropic Advanced Tool Use (Execution Layer)

    The Execution Layer handles EFFICIENT execution of decisions made
    by the Learning Layer (TraceManager, ModeStrategies).

    Components:
    - PTC (Programmatic Tool Calling): Execute tool sequences outside context
    - Tool Search: On-demand tool discovery for novel scenarios
    - Tool Examples: Auto-generated examples from successful traces
    """
    # Beta feature flag
    enable_advanced_tool_use: bool = True
    beta_header: str = "advanced-tool-use-2025-11-20"

    # PTC (Programmatic Tool Calling) settings
    enable_ptc: bool = True
    ptc_container_timeout_secs: float = 120.0
    ptc_max_containers: int = 5

    # Tool Search settings
    enable_tool_search: bool = True
    tool_search_use_embeddings: bool = False  # Requires sentence-transformers
    tool_search_embedding_model: str = "all-MiniLM-L6-v2"
    tool_search_top_k: int = 5
    defer_tools_by_default: bool = True  # New tools are deferred unless specified

    # Tool Examples settings
    enable_tool_examples: bool = True
    tool_examples_min_success_rate: float = 0.9
    tool_examples_max_per_tool: int = 3
    tool_examples_cache_ttl_secs: float = 300.0

    def __post_init__(self):
        """Validate configuration"""
        if self.ptc_container_timeout_secs <= 0:
            raise ValueError("ptc_container_timeout_secs must be positive")
        if self.ptc_max_containers <= 0:
            raise ValueError("ptc_max_containers must be positive")
        if self.tool_search_top_k <= 0:
            raise ValueError("tool_search_top_k must be positive")
        if not 0.0 <= self.tool_examples_min_success_rate <= 1.0:
            raise ValueError("tool_examples_min_success_rate must be between 0 and 1")


@dataclass
class LLMOSConfig:
    """
    Complete LLMOS configuration

    Provides type-safe configuration with validation and presets.

    Architecture:
        - Learning Layer: TraceManager, ModeStrategies (decides WHAT to do)
        - Execution Layer: PTC, Tool Search, Tool Examples (does it EFFICIENTLY)

    Example:
        # Use development preset
        config = LLMOSConfig.development()
        os = LLMOS(config=config)

        # Custom configuration
        config = LLMOSConfig(
            workspace=Path("/custom/workspace"),
            kernel=KernelConfig(budget_usd=5.0)
        )
        os = LLMOS(config=config)
    """
    workspace: Path = field(default_factory=lambda: Path("./workspace"))
    kernel: KernelConfig = field(default_factory=KernelConfig)
    memory: MemoryConfig = field(default_factory=MemoryConfig)
    sdk: SDKConfig = field(default_factory=SDKConfig)
    dispatcher: DispatcherConfig = field(default_factory=DispatcherConfig)
    execution: ExecutionLayerConfig = field(default_factory=ExecutionLayerConfig)
    sentience: SentienceConfig = field(default_factory=SentienceConfig)
    project_name: Optional[str] = None

    def __post_init__(self):
        """Ensure workspace is a Path"""
        if not isinstance(self.workspace, Path):
            self.workspace = Path(self.workspace)

    @classmethod
    def from_env(cls) -> 'LLMOSConfig':
        """
        Load configuration from environment variables

        Supported env vars:
        - LLMOS_WORKSPACE: Workspace directory
        - LLMOS_BUDGET: Budget in USD
        - LLMOS_MODEL: Claude model name
        - LLMOS_ENABLE_LLM_MATCHING: Enable LLM-based trace matching
        """
        workspace = os.getenv('LLMOS_WORKSPACE', './workspace')
        budget = float(os.getenv('LLMOS_BUDGET', '10.0'))
        model = os.getenv('LLMOS_MODEL', 'claude-sonnet-4-5-20250929')
        enable_llm = os.getenv('LLMOS_ENABLE_LLM_MATCHING', 'true').lower() == 'true'

        return cls(
            workspace=Path(workspace),
            kernel=KernelConfig(budget_usd=budget),
            sdk=SDKConfig(model=model),
            memory=MemoryConfig(enable_llm_matching=enable_llm)
        )

    @classmethod
    def development(cls) -> 'LLMOSConfig':
        """
        Development configuration preset

        Features:
        - Low budget ($1.00) to prevent expensive mistakes
        - LLM matching disabled for faster iteration
        - Streaming enabled for better UX during development
        - Execution layer enabled but without embeddings (fast)
        """
        return cls(
            workspace=Path("./workspace"),
            kernel=KernelConfig(
                budget_usd=1.0,
                enable_watchdog=False  # Less noise during dev
            ),
            memory=MemoryConfig(
                enable_llm_matching=False,  # Faster
                trace_confidence_threshold=0.8  # More lenient
            ),
            sdk=SDKConfig(
                enable_streaming=True,  # Better dev UX
                timeout_seconds=600.0  # Longer timeout for debugging
            ),
            dispatcher=DispatcherConfig(
                auto_crystallization=False  # Manual control in dev
            ),
            execution=ExecutionLayerConfig(
                enable_advanced_tool_use=True,
                enable_ptc=True,
                enable_tool_search=True,
                tool_search_use_embeddings=False,  # Fast, no dependencies
                enable_tool_examples=True
            ),
            sentience=SentienceConfig(
                enable_sentience=True,
                inject_internal_state=True,
                inject_behavioral_guidance=True,
                enable_auto_improvement=False  # Manual control in dev
            )
        )

    @classmethod
    def production(cls) -> 'LLMOSConfig':
        """
        Production configuration preset

        Features:
        - Higher budget ($100.00) for production workloads
        - All features enabled (LLM matching, hooks, etc.)
        - Strict confidence thresholds
        - Auto-crystallization enabled
        - Full execution layer with embeddings for best tool search
        """
        return cls(
            workspace=Path("./workspace"),
            kernel=KernelConfig(
                budget_usd=100.0,
                enable_scheduling=True,
                enable_watchdog=True
            ),
            memory=MemoryConfig(
                enable_llm_matching=True,
                trace_confidence_threshold=0.9,
                enable_cross_project_learning=True
            ),
            sdk=SDKConfig(
                enable_hooks=True,
                enable_streaming=False  # More stable in production
            ),
            dispatcher=DispatcherConfig(
                auto_crystallization=True,  # Learn and optimize automatically
                complexity_threshold=2
            ),
            execution=ExecutionLayerConfig(
                enable_advanced_tool_use=True,
                enable_ptc=True,
                enable_tool_search=True,
                tool_search_use_embeddings=True,  # Best quality search
                enable_tool_examples=True,
                defer_tools_by_default=True  # Save context by default
            ),
            sentience=SentienceConfig(
                enable_sentience=True,
                inject_internal_state=True,
                inject_behavioral_guidance=True,
                enable_auto_improvement=True,  # Full auto-improvement in production
                auto_persist=True
            )
        )

    @classmethod
    def testing(cls) -> 'LLMOSConfig':
        """
        Testing configuration preset

        Features:
        - Minimal budget ($0.10) for tests
        - All LLM features disabled for fast, deterministic tests
        - Short timeouts
        - Execution layer disabled for deterministic behavior
        """
        return cls(
            workspace=Path("./test_workspace"),
            kernel=KernelConfig(
                budget_usd=0.1,
                enable_scheduling=False,
                enable_watchdog=False
            ),
            memory=MemoryConfig(
                enable_llm_matching=False,  # Deterministic tests
                trace_confidence_threshold=1.0,  # Exact matches only
                enable_cross_project_learning=False
            ),
            sdk=SDKConfig(
                timeout_seconds=30.0,  # Fast failures in tests
                enable_streaming=False,
                enable_hooks=False
            ),
            dispatcher=DispatcherConfig(
                auto_crystallization=False
            ),
            execution=ExecutionLayerConfig(
                enable_advanced_tool_use=False,  # Deterministic tests
                enable_ptc=False,
                enable_tool_search=False,
                enable_tool_examples=False
            ),
            sentience=SentienceConfig(
                enable_sentience=False,  # Disabled for deterministic tests
                auto_persist=False
            )
        )

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'LLMOSConfig':
        """Load configuration from dictionary (e.g., from YAML/JSON)"""
        workspace = Path(data.get('workspace', './workspace'))

        kernel_data = data.get('kernel', {})
        memory_data = data.get('memory', {})
        sdk_data = data.get('sdk', {})
        dispatcher_data = data.get('dispatcher', {})
        execution_data = data.get('execution', {})
        sentience_data = data.get('sentience', {})

        return cls(
            workspace=workspace,
            kernel=KernelConfig(**kernel_data),
            memory=MemoryConfig(**memory_data),
            sdk=SDKConfig(**sdk_data),
            dispatcher=DispatcherConfig(**dispatcher_data),
            execution=ExecutionLayerConfig(**execution_data),
            sentience=SentienceConfig(**sentience_data),
            project_name=data.get('project_name')
        )

    def to_dict(self) -> Dict[str, Any]:
        """Export configuration to dictionary (for YAML/JSON serialization)"""
        return {
            'workspace': str(self.workspace),
            'kernel': {
                'budget_usd': self.kernel.budget_usd,
                'enable_scheduling': self.kernel.enable_scheduling,
                'enable_watchdog': self.kernel.enable_watchdog,
                'watchdog_timeout_secs': self.kernel.watchdog_timeout_secs
            },
            'memory': {
                'enable_llm_matching': self.memory.enable_llm_matching,
                'trace_confidence_threshold': self.memory.trace_confidence_threshold,
                'mixed_mode_threshold': self.memory.mixed_mode_threshold,
                'follower_mode_threshold': self.memory.follower_mode_threshold,
                'enable_cross_project_learning': self.memory.enable_cross_project_learning,
                'cache_size': self.memory.cache_size
            },
            'sdk': {
                'model': self.sdk.model,
                'permission_mode': self.sdk.permission_mode,
                'max_turns': self.sdk.max_turns,
                'timeout_seconds': self.sdk.timeout_seconds,
                'enable_streaming': self.sdk.enable_streaming,
                'enable_hooks': self.sdk.enable_hooks
            },
            'dispatcher': {
                'complexity_threshold': self.dispatcher.complexity_threshold,
                'auto_crystallization': self.dispatcher.auto_crystallization,
                'crystallization_min_usage': self.dispatcher.crystallization_min_usage,
                'crystallization_min_success': self.dispatcher.crystallization_min_success
            },
            'execution': {
                'enable_advanced_tool_use': self.execution.enable_advanced_tool_use,
                'beta_header': self.execution.beta_header,
                'enable_ptc': self.execution.enable_ptc,
                'ptc_container_timeout_secs': self.execution.ptc_container_timeout_secs,
                'ptc_max_containers': self.execution.ptc_max_containers,
                'enable_tool_search': self.execution.enable_tool_search,
                'tool_search_use_embeddings': self.execution.tool_search_use_embeddings,
                'tool_search_embedding_model': self.execution.tool_search_embedding_model,
                'tool_search_top_k': self.execution.tool_search_top_k,
                'defer_tools_by_default': self.execution.defer_tools_by_default,
                'enable_tool_examples': self.execution.enable_tool_examples,
                'tool_examples_min_success_rate': self.execution.tool_examples_min_success_rate,
                'tool_examples_max_per_tool': self.execution.tool_examples_max_per_tool,
                'tool_examples_cache_ttl_secs': self.execution.tool_examples_cache_ttl_secs
            },
            'sentience': {
                'enable_sentience': self.sentience.enable_sentience,
                'safety_setpoint': self.sentience.safety_setpoint,
                'curiosity_setpoint': self.sentience.curiosity_setpoint,
                'energy_setpoint': self.sentience.energy_setpoint,
                'self_confidence_setpoint': self.sentience.self_confidence_setpoint,
                'safety_sensitivity': self.sentience.safety_sensitivity,
                'curiosity_sensitivity': self.sentience.curiosity_sensitivity,
                'energy_sensitivity': self.sentience.energy_sensitivity,
                'self_confidence_sensitivity': self.sentience.self_confidence_sensitivity,
                'decay_rate': self.sentience.decay_rate,
                'inject_internal_state': self.sentience.inject_internal_state,
                'inject_behavioral_guidance': self.sentience.inject_behavioral_guidance,
                'enable_auto_improvement': self.sentience.enable_auto_improvement,
                'boredom_threshold': self.sentience.boredom_threshold,
                'improvement_cooldown_secs': self.sentience.improvement_cooldown_secs,
                'auto_persist': self.sentience.auto_persist,
                'state_file': self.sentience.state_file,
                # Deep Sentience v2
                'enable_coupled_dynamics': self.sentience.enable_coupled_dynamics,
                'enable_theory_of_mind': self.sentience.enable_theory_of_mind,
                'enable_empathy_gap_detection': self.sentience.enable_empathy_gap_detection,
                'adapt_communication_style': self.sentience.adapt_communication_style,
                'proactive_user_checkin': self.sentience.proactive_user_checkin,
                'enable_emotional_indexing': self.sentience.enable_emotional_indexing,
                'emotional_similarity_threshold': self.sentience.emotional_similarity_threshold,
                'enable_inner_monologue': self.sentience.enable_inner_monologue,
                'inner_monologue_idle_threshold': self.sentience.inner_monologue_idle_threshold,
                'inner_monologue_thought_interval': self.sentience.inner_monologue_thought_interval,
                'inject_priming_context': self.sentience.inject_priming_context,
                'enable_self_modification': self.sentience.enable_self_modification,
                'allow_metacognitive_tuning': self.sentience.allow_metacognitive_tuning,
                'self_modification_safety_bounds': self.sentience.self_modification_safety_bounds
            },
            'project_name': self.project_name
        }


class ConfigBuilder:
    """
    Fluent builder for LLMOS configuration

    Example:
        config = (ConfigBuilder()
            .with_workspace(Path("/custom"))
            .with_budget(5.0)
            .with_llm_matching(True)
            .with_model("claude-opus-4")
            .build())
    """

    def __init__(self):
        self._config = LLMOSConfig()

    def with_workspace(self, workspace: Path) -> 'ConfigBuilder':
        """Set workspace directory"""
        self._config.workspace = workspace
        return self

    def with_budget(self, budget_usd: float) -> 'ConfigBuilder':
        """Set token budget"""
        self._config.kernel.budget_usd = budget_usd
        return self

    def with_llm_matching(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable LLM-based trace matching"""
        self._config.memory.enable_llm_matching = enabled
        return self

    def with_model(self, model: str) -> 'ConfigBuilder':
        """Set Claude model"""
        self._config.sdk.model = model
        return self

    def with_streaming(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable streaming"""
        self._config.sdk.enable_streaming = enabled
        return self

    def with_project(self, project_name: str) -> 'ConfigBuilder':
        """Set project name"""
        self._config.project_name = project_name
        return self

    def with_auto_crystallization(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable automatic crystallization"""
        self._config.dispatcher.auto_crystallization = enabled
        return self

    def with_sentience(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable sentience layer"""
        self._config.sentience.enable_sentience = enabled
        return self

    def with_auto_improvement(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable auto-improvement based on internal state"""
        self._config.sentience.enable_auto_improvement = enabled
        return self

    # =========================================================================
    # DEEP SENTIENCE V2 BUILDER METHODS
    # =========================================================================

    def with_coupled_dynamics(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable Maslow's Hierarchy gating (Deep Sentience v2)"""
        self._config.sentience.enable_coupled_dynamics = enabled
        return self

    def with_theory_of_mind(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable Theory of Mind user modeling (Deep Sentience v2)"""
        self._config.sentience.enable_theory_of_mind = enabled
        return self

    def with_emotional_indexing(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable emotional memory indexing (Deep Sentience v2)"""
        self._config.sentience.enable_emotional_indexing = enabled
        return self

    def with_inner_monologue(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable background inner monologue (Deep Sentience v2)"""
        self._config.sentience.enable_inner_monologue = enabled
        return self

    def with_self_modification(self, enabled: bool) -> 'ConfigBuilder':
        """
        Enable/disable recursive self-modification (Deep Sentience v2)

        WARNING: This is a safety-critical feature. When enabled, the system
        can modify its own sentience parameters (sensitivities, decay rates, etc.)
        """
        self._config.sentience.enable_self_modification = enabled
        self._config.sentience.allow_metacognitive_tuning = enabled
        return self

    def with_empathy_gap_detection(self, enabled: bool) -> 'ConfigBuilder':
        """Enable/disable empathy gap detection (Deep Sentience v2)"""
        self._config.sentience.enable_empathy_gap_detection = enabled
        return self

    def with_deep_sentience_v2(self, enabled: bool) -> 'ConfigBuilder':
        """
        Enable/disable all Deep Sentience v2 features at once.

        This is a convenience method that toggles:
        - Coupled Dynamics (Maslow's Hierarchy)
        - Theory of Mind
        - Emotional Memory Indexing
        - Inner Monologue

        Note: Self-modification remains disabled for safety.
        Use with_self_modification() to enable it explicitly.
        """
        self._config.sentience.enable_coupled_dynamics = enabled
        self._config.sentience.enable_theory_of_mind = enabled
        self._config.sentience.enable_emotional_indexing = enabled
        self._config.sentience.enable_inner_monologue = enabled
        self._config.sentience.enable_empathy_gap_detection = enabled
        self._config.sentience.adapt_communication_style = enabled
        self._config.sentience.inject_priming_context = enabled
        return self

    def build(self) -> LLMOSConfig:
        """Build the configuration"""
        return self._config



================================================
File: kernel/dynamic_agents.py
================================================
"""
Dynamic Agent Manager - Adaptive Subagent Configuration

This module implements the full power of Claude Agent SDK's subagent system:
1. Dynamic agent configuration per query (not just at boot)
2. Sentience-driven agent adaptation
3. Trace-driven agent evolution
4. Memory-guided agent selection
5. Dynamic model selection
6. Agent prompt enhancement from examples

This closes the loop between:
- Sentience Layer â†’ Agent behavior
- Traces â†’ Agent evolution
- Memory â†’ Agent selection

Making LLMOS truly "self-evolving" rather than just "self-recording."
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime
import hashlib
import json
import copy

from kernel.agent_factory import AgentSpec, AgentFactory
from kernel.sentience import SentienceState, LatentMode


@dataclass
class AgentAdaptation:
    """Records an adaptation made to an agent"""
    timestamp: datetime
    reason: str
    adaptation_type: str  # "sentience", "trace", "memory", "model"
    original_value: Any
    new_value: Any
    goal_context: str


@dataclass
class AgentPerformanceMetrics:
    """Tracks agent performance for evolution decisions"""
    agent_name: str
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    average_tokens: float = 0.0
    average_time_secs: float = 0.0
    common_failure_patterns: List[str] = field(default_factory=list)
    successful_tool_sequences: List[List[str]] = field(default_factory=list)
    last_updated: datetime = field(default_factory=datetime.now)

    @property
    def success_rate(self) -> float:
        if self.total_executions == 0:
            return 0.0
        return self.successful_executions / self.total_executions


class DynamicAgentManager:
    """
    Manages dynamic agent configuration, adaptation, and evolution.

    This is the brain that makes agents truly adaptive:
    - Adapts agents based on sentience state (curiosity â†’ exploratory)
    - Evolves agents based on trace analysis (failures â†’ better constraints)
    - Selects best agents based on memory (past success â†’ preferred agent)
    - Chooses optimal model based on task complexity
    - Enhances prompts with successful examples
    """

    def __init__(
        self,
        agent_factory: AgentFactory,
        workspace: Path,
        sentience_manager: Optional[Any] = None,
        trace_manager: Optional[Any] = None,
        config: Optional[Any] = None
    ):
        """
        Initialize DynamicAgentManager.

        Args:
            agent_factory: AgentFactory for creating/evolving agents
            workspace: Workspace directory
            sentience_manager: Optional SentienceManager for state-driven adaptation
            trace_manager: Optional TraceManager for learning from history
            config: Optional LLMOSConfig
        """
        self.agent_factory = agent_factory
        self.workspace = Path(workspace)
        self.sentience_manager = sentience_manager
        self.trace_manager = trace_manager
        self.config = config

        # Performance tracking
        self.agent_metrics: Dict[str, AgentPerformanceMetrics] = {}

        # Adaptation history for debugging and learning
        self.adaptation_history: List[AgentAdaptation] = []

        # Cache for adapted agents (per-goal)
        self._adapted_agent_cache: Dict[str, AgentSpec] = {}

        # Evolution thresholds
        self.evolution_thresholds = {
            "min_executions_for_evolution": 5,
            "failure_rate_trigger": 0.3,  # Evolve if >30% failure rate
            "success_rate_for_crystallization": 0.95,
            "min_executions_for_crystallization": 5
        }

    # =========================================================================
    # 1. DYNAMIC AGENT CONFIGURATION PER QUERY
    # =========================================================================

    def get_adapted_agent(
        self,
        agent_name: str,
        goal: str,
        sentience_state: Optional[SentienceState] = None,
        similar_traces: Optional[List[Any]] = None
    ) -> AgentSpec:
        """
        Get an agent dynamically adapted for a specific goal.

        This is the main entry point - creates a goal-specific agent configuration
        by applying all adaptation strategies.

        Args:
            agent_name: Base agent name
            goal: Current goal being executed
            sentience_state: Current sentience state (or fetched from manager)
            similar_traces: Pre-fetched similar traces (or fetched from manager)

        Returns:
            Adapted AgentSpec customized for this specific execution
        """
        # Get base agent
        base_agent = self.agent_factory.get_agent(agent_name)
        if not base_agent:
            raise ValueError(f"Agent '{agent_name}' not found")

        # Create a deep copy to avoid modifying the original
        adapted = self._deep_copy_agent(base_agent)

        # Get sentience state if not provided
        if sentience_state is None and self.sentience_manager:
            sentience_state = self.sentience_manager.get_state()

        # Get similar traces if not provided
        if similar_traces is None and self.trace_manager:
            similar_traces = self._get_similar_traces(goal)

        # Apply adaptations in order
        # 1. Sentience-driven adaptation (mood affects behavior)
        if sentience_state:
            adapted = self._adapt_for_sentience(adapted, sentience_state, goal)

        # 2. Memory-guided adaptation (past experience)
        if similar_traces:
            adapted = self._adapt_from_memory(adapted, similar_traces, goal)

        # 3. Dynamic model selection
        adapted = self._select_optimal_model(adapted, goal, similar_traces)

        # 4. Enhance prompt with examples
        if similar_traces:
            adapted = self._enhance_with_examples(adapted, similar_traces, goal)

        # Cache for potential reuse
        cache_key = f"{agent_name}:{hashlib.md5(goal.encode()).hexdigest()[:8]}"
        self._adapted_agent_cache[cache_key] = adapted

        return adapted

    def _deep_copy_agent(self, agent: AgentSpec) -> AgentSpec:
        """Create a deep copy of an agent spec"""
        return AgentSpec(
            name=agent.name,
            agent_type=agent.agent_type,
            category=agent.category,
            description=agent.description,
            tools=list(agent.tools),
            version=agent.version,
            status=agent.status,
            mode=list(agent.mode),
            system_prompt=agent.system_prompt,
            capabilities=list(agent.capabilities),
            constraints=list(agent.constraints),
            replaces=agent.replaces
        )

    # =========================================================================
    # 2. SENTIENCE-DRIVEN AGENT ADAPTATION
    # =========================================================================

    def _adapt_for_sentience(
        self,
        agent: AgentSpec,
        state: SentienceState,
        goal: str
    ) -> AgentSpec:
        """
        Adapt agent based on current sentience state.

        Different latent modes trigger different agent behaviors:
        - AUTO_CREATIVE: More tools, exploration encouraged
        - AUTO_CONTAINED: Focused tools, stick to task
        - RECOVERY: Minimal tools, prefer cached patterns
        - CAUTIOUS: Safety-first, extra verification
        """
        original_tools = list(agent.tools)
        original_prompt = agent.system_prompt

        latent_mode = state.latent_mode if hasattr(state, 'latent_mode') else None

        # Get valence values
        curiosity = state.valence.curiosity if hasattr(state, 'valence') else 0.0
        safety = state.valence.safety if hasattr(state, 'valence') else 0.5
        energy = state.valence.energy if hasattr(state, 'valence') else 0.5
        confidence = state.valence.self_confidence if hasattr(state, 'valence') else 0.5

        adaptations = []

        # HIGH CURIOSITY / AUTO_CREATIVE mode
        if latent_mode == LatentMode.AUTO_CREATIVE or curiosity > 0.3:
            # Add exploration tools if not present
            exploration_tools = ["WebFetch", "WebSearch", "Grep", "Glob"]
            for tool in exploration_tools:
                if tool not in agent.tools:
                    agent.tools.append(tool)

            # Encourage creative exploration in prompt
            creativity_prompt = """

## Creative Mode Active

Your curiosity is high! Feel free to:
- Explore alternative solutions
- Suggest improvements beyond the immediate task
- Try unconventional approaches
- Ask clarifying questions if the goal could be interpreted multiple ways
"""
            agent.system_prompt += creativity_prompt
            adaptations.append("Added exploration tools and creativity guidance")

        # LOW CURIOSITY / AUTO_CONTAINED mode
        elif latent_mode == LatentMode.AUTO_CONTAINED or curiosity < -0.3:
            # Remove non-essential tools for focus
            essential_tools = ["Read", "Write", "Edit"]  # Keep only essentials
            agent.tools = [t for t in agent.tools if t in essential_tools or t in ["Bash", "Grep"]]

            focus_prompt = """

## Focus Mode Active

Stay focused on the immediate task:
- Complete the goal efficiently
- Avoid tangents or exploration
- Use minimal tools necessary
- Provide concise responses
"""
            agent.system_prompt += focus_prompt
            adaptations.append("Reduced to essential tools, added focus guidance")

        # LOW ENERGY / RECOVERY mode
        if latent_mode == LatentMode.RECOVERY or energy < -0.3:
            # Prefer lightweight operations
            recovery_prompt = """

## Energy Conservation Mode

Conserve resources:
- Prefer cached/known solutions when available
- Avoid expensive operations (large file reads, complex searches)
- Complete task with minimal token usage
- Suggest simpler alternatives if the goal seems complex
"""
            agent.system_prompt += recovery_prompt
            adaptations.append("Added energy conservation guidance")

        # LOW SAFETY / CAUTIOUS mode
        if latent_mode == LatentMode.CAUTIOUS or safety < 0.0:
            # Remove potentially dangerous tools
            dangerous_tools = ["Bash", "Write", "Edit", "NotebookEdit"]
            agent.tools = [t for t in agent.tools if t not in dangerous_tools]

            # Add verification constraints
            agent.constraints.append("Must ask for confirmation before any file modifications")
            agent.constraints.append("Must explain potential risks before executing commands")

            caution_prompt = """

## Caution Mode Active

Safety is paramount:
- Double-check all operations before executing
- Ask for confirmation on destructive or irreversible actions
- Prefer read-only operations when possible
- Explain potential risks clearly
"""
            agent.system_prompt += caution_prompt
            adaptations.append("Removed dangerous tools, added caution constraints")

        # LOW CONFIDENCE mode
        if confidence < -0.2:
            confidence_prompt = """

## Verification Mode

Confidence is low - be extra careful:
- Verify assumptions before proceeding
- Break complex tasks into smaller, verified steps
- Check results after each action
- Ask for clarification if uncertain
"""
            agent.system_prompt += confidence_prompt
            adaptations.append("Added verification guidance for low confidence")

        # Record adaptation
        if adaptations:
            self.adaptation_history.append(AgentAdaptation(
                timestamp=datetime.now(),
                reason=f"Sentience: {latent_mode}, curiosity={curiosity:.2f}, safety={safety:.2f}",
                adaptation_type="sentience",
                original_value={"tools": original_tools, "prompt_length": len(original_prompt)},
                new_value={"tools": agent.tools, "prompt_length": len(agent.system_prompt)},
                goal_context=goal[:100]
            ))

        return agent

    # =========================================================================
    # 3. TRACE-DRIVEN AGENT EVOLUTION
    # =========================================================================

    def analyze_and_evolve_agent(
        self,
        agent_name: str,
        force: bool = False
    ) -> Optional[AgentSpec]:
        """
        Analyze traces and evolve agent based on patterns.

        This is the learning loop - agents improve from experience:
        - Identifies common failure patterns
        - Extracts successful tool sequences
        - Updates constraints and prompts
        - Creates new agent version

        Args:
            agent_name: Agent to potentially evolve
            force: Force evolution even if thresholds not met

        Returns:
            New evolved AgentSpec or None if no evolution needed
        """
        if not self.trace_manager:
            return None

        # Get performance metrics
        metrics = self._calculate_agent_metrics(agent_name)

        if not metrics:
            return None

        # Check if evolution is needed
        should_evolve = force or self._should_evolve(metrics)

        if not should_evolve:
            return None

        print(f"ðŸ§¬ Evolving agent '{agent_name}' based on {metrics.total_executions} executions")
        print(f"   Success rate: {metrics.success_rate:.1%}")
        print(f"   Common failures: {len(metrics.common_failure_patterns)}")

        # Get current agent
        current_agent = self.agent_factory.get_agent(agent_name)
        if not current_agent:
            return None

        # Generate improvements
        improvements = self._generate_improvements(current_agent, metrics)

        if not improvements:
            print(f"   No improvements identified")
            return None

        # Apply improvements
        evolved_agent = self.agent_factory.evolve_agent(agent_name, improvements)

        print(f"âœ… Evolved to version {evolved_agent.version}")

        # Record adaptation
        self.adaptation_history.append(AgentAdaptation(
            timestamp=datetime.now(),
            reason=f"Evolution from metrics: {metrics.success_rate:.1%} success rate",
            adaptation_type="trace",
            original_value={"version": current_agent.version},
            new_value={"version": evolved_agent.version, "improvements": improvements},
            goal_context=f"Agent evolution based on {metrics.total_executions} traces"
        ))

        return evolved_agent

    def _calculate_agent_metrics(self, agent_name: str) -> Optional[AgentPerformanceMetrics]:
        """Calculate performance metrics for an agent from traces"""
        if not self.trace_manager:
            return None

        # Get all traces (we'll filter by agent)
        all_traces = self.trace_manager.list_traces()

        # Filter traces that used this agent (based on tools or metadata)
        agent_traces = []
        for trace in all_traces:
            # Check if trace has agent info in metadata or matches by tools
            if hasattr(trace, 'agent_used') and trace.agent_used == agent_name:
                agent_traces.append(trace)
            elif hasattr(trace, 'metadata') and trace.metadata.get('agent') == agent_name:
                agent_traces.append(trace)

        if not agent_traces:
            # Try to infer from all traces if no explicit agent marking
            agent_traces = all_traces[:50]  # Use recent traces

        if not agent_traces:
            return None

        # Calculate metrics
        metrics = AgentPerformanceMetrics(agent_name=agent_name)
        metrics.total_executions = len(agent_traces)

        success_count = 0
        total_tokens = 0
        total_time = 0
        failure_patterns = []
        success_sequences = []

        for trace in agent_traces:
            if trace.success_rating >= 0.8:
                success_count += 1
                if trace.tools_used:
                    success_sequences.append(trace.tools_used)
            else:
                if trace.error_notes:
                    failure_patterns.append(trace.error_notes)

            if hasattr(trace, 'estimated_cost_usd'):
                # Rough token estimate from cost
                total_tokens += trace.estimated_cost_usd * 50000  # ~$0.02/1K tokens

            if hasattr(trace, 'estimated_time_secs'):
                total_time += trace.estimated_time_secs

        metrics.successful_executions = success_count
        metrics.failed_executions = metrics.total_executions - success_count
        metrics.average_tokens = total_tokens / max(1, metrics.total_executions)
        metrics.average_time_secs = total_time / max(1, metrics.total_executions)
        metrics.common_failure_patterns = failure_patterns[:10]
        metrics.successful_tool_sequences = success_sequences[:10]
        metrics.last_updated = datetime.now()

        # Cache metrics
        self.agent_metrics[agent_name] = metrics

        return metrics

    def _should_evolve(self, metrics: AgentPerformanceMetrics) -> bool:
        """Determine if agent should be evolved based on metrics"""
        # Not enough data
        if metrics.total_executions < self.evolution_thresholds["min_executions_for_evolution"]:
            return False

        # High failure rate
        failure_rate = 1 - metrics.success_rate
        if failure_rate > self.evolution_thresholds["failure_rate_trigger"]:
            return True

        # Has common failure patterns
        if len(metrics.common_failure_patterns) >= 3:
            return True

        return False

    def _generate_improvements(
        self,
        agent: AgentSpec,
        metrics: AgentPerformanceMetrics
    ) -> Dict[str, Any]:
        """Generate improvements based on metrics analysis"""
        improvements = {}

        # Analyze failure patterns
        if metrics.common_failure_patterns:
            # Extract common themes from failures
            failure_text = " ".join(metrics.common_failure_patterns)

            new_constraints = []

            # Pattern: timeout errors
            if "timeout" in failure_text.lower():
                new_constraints.append("Avoid long-running operations without progress updates")

            # Pattern: permission errors
            if "permission" in failure_text.lower() or "denied" in failure_text.lower():
                new_constraints.append("Check permissions before file operations")

            # Pattern: not found errors
            if "not found" in failure_text.lower() or "missing" in failure_text.lower():
                new_constraints.append("Verify file/resource existence before operations")

            # Pattern: syntax errors
            if "syntax" in failure_text.lower() or "parse" in failure_text.lower():
                new_constraints.append("Validate syntax before writing code")

            if new_constraints:
                improvements["constraints"] = agent.constraints + new_constraints

        # Optimize tool selection based on success patterns
        if metrics.successful_tool_sequences:
            # Find most commonly successful tools
            tool_frequency = {}
            for sequence in metrics.successful_tool_sequences:
                for tool in sequence:
                    tool_frequency[tool] = tool_frequency.get(tool, 0) + 1

            # Ensure successful tools are available
            successful_tools = sorted(tool_frequency.keys(), key=lambda t: -tool_frequency[t])[:5]
            current_tools = set(agent.tools)
            missing_tools = [t for t in successful_tools if t not in current_tools]

            if missing_tools:
                improvements["tools"] = agent.tools + missing_tools

        # Add learning from failures to prompt
        if metrics.common_failure_patterns:
            failure_guidance = "\n\n## Learned from Experience\n\nCommon pitfalls to avoid:\n"
            seen_patterns = set()
            for pattern in metrics.common_failure_patterns[:5]:
                # Deduplicate similar patterns
                pattern_key = pattern[:50].lower()
                if pattern_key not in seen_patterns:
                    failure_guidance += f"- {pattern[:100]}\n"
                    seen_patterns.add(pattern_key)

            improvements["system_prompt"] = agent.system_prompt + failure_guidance

        return improvements

    # =========================================================================
    # 4. MEMORY-GUIDED AGENT SELECTION
    # =========================================================================

    def select_best_agent(
        self,
        goal: str,
        available_agents: List[str]
    ) -> Tuple[str, float]:
        """
        Select the best agent for a goal based on memory.

        Analyzes past traces to find which agent performed best on similar tasks.

        Args:
            goal: Current goal
            available_agents: List of available agent names

        Returns:
            Tuple of (best_agent_name, confidence_score)
        """
        if not self.trace_manager or not available_agents:
            return (available_agents[0] if available_agents else "system-agent", 0.5)

        # Get similar traces
        similar_traces = self._get_similar_traces(goal, limit=20)

        if not similar_traces:
            return (available_agents[0], 0.5)

        # Score each agent based on performance on similar tasks
        agent_scores: Dict[str, Dict[str, float]] = {}

        for trace in similar_traces:
            agent_used = self._get_agent_from_trace(trace)

            if agent_used and agent_used in available_agents:
                if agent_used not in agent_scores:
                    agent_scores[agent_used] = {
                        "total_score": 0.0,
                        "count": 0,
                        "success_sum": 0.0
                    }

                agent_scores[agent_used]["count"] += 1
                agent_scores[agent_used]["success_sum"] += trace.success_rating

                # Weight by recency (more recent = higher weight)
                recency_weight = 1.0  # Could be based on timestamp
                agent_scores[agent_used]["total_score"] += trace.success_rating * recency_weight

        if not agent_scores:
            return (available_agents[0], 0.5)

        # Calculate average success rate per agent
        agent_performance = {}
        for agent, scores in agent_scores.items():
            if scores["count"] > 0:
                agent_performance[agent] = scores["success_sum"] / scores["count"]

        # Select best performer
        best_agent = max(agent_performance.keys(), key=lambda a: agent_performance[a])
        confidence = agent_performance[best_agent]

        return (best_agent, confidence)

    def _adapt_from_memory(
        self,
        agent: AgentSpec,
        similar_traces: List[Any],
        goal: str
    ) -> AgentSpec:
        """Adapt agent based on memory of similar tasks"""
        if not similar_traces:
            return agent

        # Extract successful patterns
        successful_traces = [t for t in similar_traces if t.success_rating >= 0.8]
        failed_traces = [t for t in similar_traces if t.success_rating < 0.6]

        if successful_traces:
            # Add successful tool patterns to agent
            common_tools = self._extract_common_tools(successful_traces)
            for tool in common_tools:
                if tool not in agent.tools:
                    agent.tools.append(tool)

        if failed_traces:
            # Add warnings about common failures
            failure_warnings = self._extract_failure_warnings(failed_traces)
            if failure_warnings:
                agent.system_prompt += f"\n\n## Warnings from Similar Tasks\n{failure_warnings}"

        return agent

    def _extract_common_tools(self, traces: List[Any]) -> List[str]:
        """Extract commonly used tools from successful traces"""
        tool_frequency = {}
        for trace in traces:
            if trace.tools_used:
                for tool in trace.tools_used:
                    tool_frequency[tool] = tool_frequency.get(tool, 0) + 1

        # Return tools used in >50% of traces
        threshold = len(traces) * 0.5
        return [tool for tool, count in tool_frequency.items() if count >= threshold]

    def _extract_failure_warnings(self, traces: List[Any]) -> str:
        """Extract warnings from failed traces"""
        warnings = []
        seen = set()

        for trace in traces[:5]:
            if trace.error_notes and trace.error_notes not in seen:
                warnings.append(f"- Avoid: {trace.error_notes[:100]}")
                seen.add(trace.error_notes)

        return "\n".join(warnings) if warnings else ""

    # =========================================================================
    # 5. DYNAMIC MODEL SELECTION
    # =========================================================================

    def _select_optimal_model(
        self,
        agent: AgentSpec,
        goal: str,
        similar_traces: Optional[List[Any]] = None
    ) -> AgentSpec:
        """
        Select optimal model based on task complexity and history.

        Model selection strategy:
        - haiku: Simple, proven tasks with high success rate
        - sonnet: Default for most tasks (balance of speed/quality)
        - opus: Complex reasoning, novel problems, low confidence scenarios
        """
        original_model = agent.model if hasattr(agent, 'model') else "sonnet"

        # Default to sonnet
        selected_model = "sonnet"
        reason = "default"

        # Check if we have successful traces
        if similar_traces:
            successful_traces = [t for t in similar_traces if t.success_rating >= 0.95]

            # High success rate on similar tasks â†’ can use cheaper model
            if len(successful_traces) >= 3:
                selected_model = "haiku"
                reason = f"high success rate ({len(successful_traces)} successful similar traces)"

        # Check task complexity indicators
        complexity_indicators = [
            "analyze", "design", "architect", "complex", "comprehensive",
            "multi-step", "research", "evaluate", "compare", "optimize"
        ]

        goal_lower = goal.lower()
        complexity_count = sum(1 for indicator in complexity_indicators if indicator in goal_lower)

        if complexity_count >= 2:
            selected_model = "opus"
            reason = f"complex task ({complexity_count} complexity indicators)"

        # Check for creativity/novelty indicators
        novelty_indicators = ["creative", "novel", "innovative", "new approach", "brainstorm"]
        novelty_count = sum(1 for indicator in novelty_indicators if indicator in goal_lower)

        if novelty_count >= 1:
            selected_model = "opus"
            reason = f"creative task ({novelty_count} novelty indicators)"

        # Check sentience state for confidence
        if self.sentience_manager:
            state = self.sentience_manager.get_state()
            if hasattr(state, 'valence') and state.valence.self_confidence < -0.3:
                # Low confidence â†’ use more capable model
                selected_model = "opus"
                reason = "low system confidence"

        # Update agent model
        agent.model = selected_model

        # Record if changed
        if selected_model != original_model:
            self.adaptation_history.append(AgentAdaptation(
                timestamp=datetime.now(),
                reason=reason,
                adaptation_type="model",
                original_value=original_model,
                new_value=selected_model,
                goal_context=goal[:100]
            ))

        return agent

    # =========================================================================
    # 6. AGENT PROMPT ENHANCEMENT FROM EXAMPLES
    # =========================================================================

    def _enhance_with_examples(
        self,
        agent: AgentSpec,
        similar_traces: List[Any],
        goal: str
    ) -> AgentSpec:
        """
        Enhance agent prompt with successful examples from traces.

        This implements few-shot learning by injecting relevant examples
        into the agent's context.
        """
        if not similar_traces:
            return agent

        # Get top successful examples
        successful_examples = sorted(
            [t for t in similar_traces if t.success_rating >= 0.8],
            key=lambda t: t.success_rating,
            reverse=True
        )[:3]

        if not successful_examples:
            return agent

        # Build examples section
        examples_section = "\n\n## Successful Examples from Memory\n\n"
        examples_section += "Use these as guidance for similar tasks:\n\n"

        for i, trace in enumerate(successful_examples, 1):
            examples_section += f"### Example {i}\n"
            examples_section += f"**Goal:** {trace.goal_text}\n"
            examples_section += f"**Success Rate:** {trace.success_rating:.0%}\n"

            if trace.tools_used:
                examples_section += f"**Tools Used:** {', '.join(trace.tools_used)}\n"

            if trace.output_summary:
                # Truncate long summaries
                summary = trace.output_summary[:500]
                if len(trace.output_summary) > 500:
                    summary += "..."
                examples_section += f"**Output:** {summary}\n"

            examples_section += "\n"

        agent.system_prompt += examples_section

        return agent

    # =========================================================================
    # UTILITY METHODS
    # =========================================================================

    def _get_similar_traces(self, goal: str, limit: int = 10) -> List[Any]:
        """Get traces similar to the goal"""
        if not self.trace_manager:
            return []

        # Try LLM matching first
        if hasattr(self.trace_manager, 'find_traces_with_llm'):
            try:
                return self.trace_manager.find_traces_with_llm(goal, limit=limit)
            except:
                pass

        # Fall back to listing recent traces
        all_traces = self.trace_manager.list_traces()
        return all_traces[:limit]

    def _get_agent_from_trace(self, trace: Any) -> Optional[str]:
        """Extract agent name from a trace"""
        if hasattr(trace, 'agent_used'):
            return trace.agent_used
        if hasattr(trace, 'metadata') and isinstance(trace.metadata, dict):
            return trace.metadata.get('agent')
        return None

    def get_adaptation_summary(self) -> Dict[str, Any]:
        """Get summary of all adaptations made"""
        summary = {
            "total_adaptations": len(self.adaptation_history),
            "by_type": {},
            "recent_adaptations": []
        }

        for adaptation in self.adaptation_history:
            atype = adaptation.adaptation_type
            summary["by_type"][atype] = summary["by_type"].get(atype, 0) + 1

        # Get recent adaptations
        recent = sorted(self.adaptation_history, key=lambda a: a.timestamp, reverse=True)[:10]
        for adaptation in recent:
            summary["recent_adaptations"].append({
                "timestamp": adaptation.timestamp.isoformat(),
                "type": adaptation.adaptation_type,
                "reason": adaptation.reason,
                "goal": adaptation.goal_context
            })

        return summary

    def get_agent_metrics_summary(self) -> Dict[str, Any]:
        """Get summary of agent performance metrics"""
        return {
            agent_name: {
                "success_rate": metrics.success_rate,
                "total_executions": metrics.total_executions,
                "average_tokens": metrics.average_tokens,
                "needs_evolution": self._should_evolve(metrics)
            }
            for agent_name, metrics in self.agent_metrics.items()
        }

    def clear_cache(self):
        """Clear adapted agent cache"""
        self._adapted_agent_cache.clear()

    def record_execution_result(
        self,
        agent_name: str,
        goal: str,
        success: bool,
        tokens_used: float = 0,
        time_secs: float = 0,
        error: Optional[str] = None
    ):
        """
        Record execution result for learning.

        Call this after each agent execution to update metrics
        and trigger evolution if needed.
        """
        if agent_name not in self.agent_metrics:
            self.agent_metrics[agent_name] = AgentPerformanceMetrics(agent_name=agent_name)

        metrics = self.agent_metrics[agent_name]
        metrics.total_executions += 1

        if success:
            metrics.successful_executions += 1
        else:
            metrics.failed_executions += 1
            if error:
                metrics.common_failure_patterns.append(error)

        # Update averages
        n = metrics.total_executions
        metrics.average_tokens = ((metrics.average_tokens * (n - 1)) + tokens_used) / n
        metrics.average_time_secs = ((metrics.average_time_secs * (n - 1)) + time_secs) / n
        metrics.last_updated = datetime.now()

        # Check if evolution is needed
        if self._should_evolve(metrics):
            print(f"âš ï¸ Agent '{agent_name}' may need evolution (success rate: {metrics.success_rate:.1%})")



================================================
File: kernel/evolution.py
================================================
"""
Evolution Analyzers for LLM OS

The evolution analyzers are the "intelligence" behind the sentience crons.
They analyze artifacts and propose evolutionary changes:

- **TraceEvolver**: Summarizes, consolidates, and extracts patterns from traces
- **ToolEvolver**: Proposes improvements, refactoring, and new tools
- **AgentEvolver**: Refines agent prompts and capabilities

Each evolver can work with or without an LLM:
- Without LLM: Uses heuristics and pattern matching
- With LLM: Uses LLM for deeper analysis and generation
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Callable, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import re
import hashlib
import json

from .volumes import Volume, ArtifactType


@dataclass
class EvolutionProposal:
    """A proposed change to an artifact"""
    proposal_id: str
    artifact_type: ArtifactType
    artifact_id: str
    action: str  # summarize, merge, refactor, enhance, deprecate
    title: str
    description: str
    confidence: float
    estimated_impact: str
    original_content: Optional[str] = None
    proposed_content: Optional[str] = None
    related_artifacts: List[str] = field(default_factory=list)
    auto_apply: bool = False  # Can be applied without user approval

    def as_dict(self) -> Dict[str, Any]:
        return {
            "proposal_id": self.proposal_id,
            "artifact_type": self.artifact_type.value,
            "artifact_id": self.artifact_id,
            "action": self.action,
            "title": self.title,
            "description": self.description,
            "confidence": self.confidence,
            "estimated_impact": self.estimated_impact,
            "related_artifacts": self.related_artifacts,
            "auto_apply": self.auto_apply
        }


class TraceEvolver:
    """
    Analyzes and evolves execution traces.

    Capabilities:
    - Summarize old traces to save space
    - Detect repeated patterns across traces
    - Identify successful vs failed patterns
    - Propose trace consolidation
    - Extract reusable patterns for tools
    """

    def __init__(self, llm_callback: Optional[Callable[[str], str]] = None):
        self.llm_callback = llm_callback

    def analyze_traces(self, volume: Volume) -> Dict[str, Any]:
        """Analyze all traces in a volume"""
        trace_ids = volume.list_artifacts(ArtifactType.TRACE)

        analysis = {
            "total_traces": len(trace_ids),
            "patterns": [],
            "old_traces": [],
            "consolidation_candidates": [],
            "crystallization_candidates": []
        }

        # Group traces by goal signature
        goal_groups: Dict[str, List[Tuple[str, str]]] = {}

        for trace_id in trace_ids:
            content = volume.read_artifact(ArtifactType.TRACE, trace_id)
            if not content:
                continue

            # Extract goal from frontmatter
            goal = self._extract_goal(content)
            goal_sig = self._signature(goal) if goal else trace_id[:16]

            if goal_sig not in goal_groups:
                goal_groups[goal_sig] = []
            goal_groups[goal_sig].append((trace_id, content))

        # Find repeated patterns (crystallization candidates)
        for sig, traces in goal_groups.items():
            if len(traces) >= 3:
                success_rate = self._calculate_success_rate(traces)
                if success_rate > 0.8:
                    analysis["crystallization_candidates"].append({
                        "signature": sig,
                        "trace_count": len(traces),
                        "success_rate": success_rate,
                        "example_trace": traces[0][0]
                    })

        # Find old traces (consolidation candidates)
        for trace_id, content in [(t, c) for traces in goal_groups.values() for t, c in traces]:
            age_days = self._estimate_age_days(content)
            if age_days and age_days > 30:
                analysis["old_traces"].append({
                    "trace_id": trace_id,
                    "age_days": age_days
                })

        # Identify consolidation groups
        for sig, traces in goal_groups.items():
            if len(traces) >= 5:
                analysis["consolidation_candidates"].append({
                    "signature": sig,
                    "trace_ids": [t[0] for t in traces],
                    "count": len(traces)
                })

        return analysis

    def propose_summarization(
        self,
        volume: Volume,
        trace_ids: List[str],
        target_id: str
    ) -> Optional[EvolutionProposal]:
        """Propose summarizing multiple traces into one"""
        if len(trace_ids) < 2:
            return None

        # Read all traces
        traces = []
        for tid in trace_ids:
            content = volume.read_artifact(ArtifactType.TRACE, tid)
            if content:
                traces.append((tid, content))

        if not traces:
            return None

        # Generate summary (with or without LLM)
        if self.llm_callback:
            summary = self._llm_summarize(traces)
        else:
            summary = self._heuristic_summarize(traces)

        return EvolutionProposal(
            proposal_id=f"prop_summarize_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            artifact_type=ArtifactType.TRACE,
            artifact_id=target_id,
            action="summarize",
            title=f"Summarize {len(traces)} traces",
            description=f"Consolidate {len(traces)} similar traces into a single summary trace.",
            confidence=0.7,
            estimated_impact=f"Save ~{len(traces) - 1} trace files",
            proposed_content=summary,
            related_artifacts=trace_ids,
            auto_apply=len(traces) <= 5  # Auto-apply for small consolidations
        )

    def propose_crystallization(
        self,
        volume: Volume,
        trace_ids: List[str]
    ) -> Optional[EvolutionProposal]:
        """Propose crystallizing a repeated pattern into a tool"""
        if len(trace_ids) < 3:
            return None

        # Read traces and extract common pattern
        traces = []
        for tid in trace_ids:
            content = volume.read_artifact(ArtifactType.TRACE, tid)
            if content:
                traces.append((tid, content))

        if not traces:
            return None

        # Extract common tool sequence
        tool_pattern = self._extract_tool_pattern(traces)
        if not tool_pattern:
            return None

        # Generate tool code
        if self.llm_callback:
            tool_code = self._llm_generate_tool(traces, tool_pattern)
        else:
            tool_code = self._heuristic_generate_tool(traces, tool_pattern)

        tool_name = f"crystallized_{self._signature(tool_pattern)[:8]}"

        return EvolutionProposal(
            proposal_id=f"prop_crystallize_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            artifact_type=ArtifactType.TOOL,
            artifact_id=tool_name,
            action="crystallize",
            title=f"Create tool from {len(traces)} traces",
            description=f"Crystallize repeated pattern into reusable tool '{tool_name}'",
            confidence=0.8,
            estimated_impact="Zero-cost execution for this pattern",
            proposed_content=tool_code,
            related_artifacts=trace_ids,
            auto_apply=False  # Tools require review
        )

    def _extract_goal(self, content: str) -> Optional[str]:
        """Extract goal from trace content"""
        match = re.search(r'goal_text:\s*(.+?)(?:\n|$)', content)
        if match:
            return match.group(1).strip()
        return None

    def _signature(self, text: str) -> str:
        """Generate a signature for pattern matching"""
        normalized = re.sub(r'[^a-z0-9]', '', text.lower())
        return hashlib.md5(normalized.encode()).hexdigest()[:16]

    def _calculate_success_rate(self, traces: List[Tuple[str, str]]) -> float:
        """Calculate success rate across traces"""
        successes = 0
        for _, content in traces:
            if 'success_rating: 0.9' in content or 'success_rating: 1' in content:
                successes += 1
            elif 'success' in content.lower() and 'fail' not in content.lower():
                successes += 0.5
        return successes / len(traces) if traces else 0

    def _estimate_age_days(self, content: str) -> Optional[int]:
        """Estimate age of trace in days"""
        # Look for date patterns in content
        match = re.search(r'(\d{4}-\d{2}-\d{2})', content)
        if match:
            try:
                trace_date = datetime.strptime(match.group(1), '%Y-%m-%d')
                return (datetime.now() - trace_date).days
            except ValueError:
                pass
        return None

    def _extract_tool_pattern(self, traces: List[Tuple[str, str]]) -> Optional[str]:
        """Extract common tool call pattern from traces"""
        tool_sequences = []

        for _, content in traces:
            # Look for tool call sections
            match = re.search(r'## Tool Calls.*?```json\s*(\[.*?\])\s*```', content, re.DOTALL)
            if match:
                tool_sequences.append(match.group(1))

        if not tool_sequences:
            return None

        # Return the most common pattern (simplified)
        return tool_sequences[0] if tool_sequences else None

    def _heuristic_summarize(self, traces: List[Tuple[str, str]]) -> str:
        """Generate summary without LLM"""
        lines = [
            "---",
            f"summary_of: {len(traces)} traces",
            f"created_at: {datetime.now().isoformat()}",
            "---",
            "",
            "# Trace Summary",
            "",
            f"This is a summary of {len(traces)} similar traces.",
            "",
            "## Included Traces",
            ""
        ]
        for tid, _ in traces[:10]:
            lines.append(f"- {tid}")
        if len(traces) > 10:
            lines.append(f"- ... and {len(traces) - 10} more")

        return "\n".join(lines)

    def _heuristic_generate_tool(self, traces: List[Tuple[str, str]], pattern: str) -> str:
        """Generate tool code without LLM"""
        return f'''"""
Auto-generated tool from trace crystallization.
Generated from {len(traces)} similar traces.
"""

def execute(context):
    """
    Execute the crystallized pattern.

    This tool was automatically generated from successful trace patterns.
    Review and customize before production use.
    """
    # Tool pattern:
    # {pattern[:200]}...

    # TODO: Implement tool logic based on pattern
    raise NotImplementedError("Review and implement this crystallized tool")
'''

    def _llm_summarize(self, traces: List[Tuple[str, str]]) -> str:
        """Generate summary using LLM"""
        prompt = f"""Summarize these {len(traces)} execution traces into a single consolidated trace.
Preserve the key patterns, successful approaches, and lessons learned.

Traces:
{chr(10).join([f'--- {t[0]} ---{chr(10)}{t[1][:500]}...' for t in traces[:5]])}

Generate a markdown summary that captures the essence of these traces."""

        return self.llm_callback(prompt) if self.llm_callback else self._heuristic_summarize(traces)

    def _llm_generate_tool(self, traces: List[Tuple[str, str]], pattern: str) -> str:
        """Generate tool code using LLM"""
        prompt = f"""Generate a Python tool from this successful trace pattern.
The tool should encapsulate the common workflow seen in these traces.

Pattern:
{pattern[:500]}

Generate a Python function that implements this pattern as a reusable tool."""

        return self.llm_callback(prompt) if self.llm_callback else self._heuristic_generate_tool(traces, pattern)


class ToolEvolver:
    """
    Analyzes and evolves tools.

    Capabilities:
    - Identify unused or underused tools
    - Suggest tool refactoring
    - Propose new tools based on patterns
    - Detect tool dependencies and conflicts
    """

    def __init__(self, llm_callback: Optional[Callable[[str], str]] = None):
        self.llm_callback = llm_callback

    def analyze_tools(self, volume: Volume) -> Dict[str, Any]:
        """Analyze all tools in a volume"""
        tool_ids = volume.list_artifacts(ArtifactType.TOOL)

        analysis = {
            "total_tools": len(tool_ids),
            "tools": [],
            "improvement_candidates": [],
            "deprecation_candidates": []
        }

        for tool_id in tool_ids:
            content = volume.read_artifact(ArtifactType.TOOL, tool_id)
            if not content:
                continue

            tool_info = self._analyze_tool(tool_id, content)
            analysis["tools"].append(tool_info)

            # Check for improvement candidates
            if tool_info.get("complexity_score", 0) > 50:
                analysis["improvement_candidates"].append({
                    "tool_id": tool_id,
                    "reason": "High complexity",
                    "complexity": tool_info["complexity_score"]
                })

        return analysis

    def _analyze_tool(self, tool_id: str, content: str) -> Dict[str, Any]:
        """Analyze a single tool"""
        lines = content.split('\n')

        return {
            "tool_id": tool_id,
            "lines_of_code": len(lines),
            "has_docstring": '"""' in content or "'''" in content,
            "has_error_handling": 'try:' in content or 'except' in content,
            "complexity_score": self._estimate_complexity(content),
            "imports": self._extract_imports(content)
        }

    def _estimate_complexity(self, content: str) -> int:
        """Estimate cyclomatic complexity (simplified)"""
        complexity = 0
        complexity += content.count('if ')
        complexity += content.count('elif ')
        complexity += content.count('for ')
        complexity += content.count('while ')
        complexity += content.count('except')
        complexity += content.count(' and ')
        complexity += content.count(' or ')
        return complexity

    def _extract_imports(self, content: str) -> List[str]:
        """Extract import statements"""
        imports = []
        for line in content.split('\n'):
            if line.strip().startswith('import ') or line.strip().startswith('from '):
                imports.append(line.strip())
        return imports

    def propose_improvement(
        self,
        volume: Volume,
        tool_id: str
    ) -> Optional[EvolutionProposal]:
        """Propose improvement for a tool"""
        content = volume.read_artifact(ArtifactType.TOOL, tool_id)
        if not content:
            return None

        analysis = self._analyze_tool(tool_id, content)
        improvements = []

        if not analysis["has_docstring"]:
            improvements.append("Add documentation")

        if not analysis["has_error_handling"]:
            improvements.append("Add error handling")

        if analysis["complexity_score"] > 30:
            improvements.append("Reduce complexity by refactoring")

        if not improvements:
            return None

        return EvolutionProposal(
            proposal_id=f"prop_improve_{tool_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            artifact_type=ArtifactType.TOOL,
            artifact_id=tool_id,
            action="enhance",
            title=f"Improve tool: {tool_id}",
            description=f"Suggested improvements: {', '.join(improvements)}",
            confidence=0.6,
            estimated_impact="Better maintainability and reliability",
            original_content=content,
            auto_apply=False
        )


class AgentEvolver:
    """
    Analyzes and evolves agent definitions.

    Capabilities:
    - Analyze agent prompts for clarity
    - Suggest capability expansions
    - Identify overlapping agents
    - Propose agent consolidation
    """

    def __init__(self, llm_callback: Optional[Callable[[str], str]] = None):
        self.llm_callback = llm_callback

    def analyze_agents(self, volume: Volume) -> Dict[str, Any]:
        """Analyze all agents in a volume"""
        agent_ids = volume.list_artifacts(ArtifactType.AGENT)

        analysis = {
            "total_agents": len(agent_ids),
            "agents": [],
            "overlap_candidates": [],
            "enhancement_candidates": []
        }

        agent_capabilities: Dict[str, List[str]] = {}

        for agent_id in agent_ids:
            content = volume.read_artifact(ArtifactType.AGENT, agent_id)
            if not content:
                continue

            agent_info = self._analyze_agent(agent_id, content)
            analysis["agents"].append(agent_info)
            agent_capabilities[agent_id] = agent_info.get("tools", [])

        # Find overlapping agents
        for agent1, tools1 in agent_capabilities.items():
            for agent2, tools2 in agent_capabilities.items():
                if agent1 >= agent2:
                    continue
                overlap = set(tools1) & set(tools2)
                if len(overlap) > 2:
                    analysis["overlap_candidates"].append({
                        "agents": [agent1, agent2],
                        "overlapping_tools": list(overlap)
                    })

        return analysis

    def _analyze_agent(self, agent_id: str, content: str) -> Dict[str, Any]:
        """Analyze a single agent"""
        # Parse frontmatter
        tools = []
        model = "unknown"
        description = ""

        match = re.search(r'tools:\s*\[(.*?)\]', content)
        if match:
            tools = [t.strip().strip('"\'') for t in match.group(1).split(',')]

        match = re.search(r'model:\s*(.+?)(?:\n|$)', content)
        if match:
            model = match.group(1).strip()

        match = re.search(r'description:\s*(.+?)(?:\n|$)', content)
        if match:
            description = match.group(1).strip()

        return {
            "agent_id": agent_id,
            "tools": tools,
            "model": model,
            "description": description,
            "prompt_length": len(content)
        }

    def propose_enhancement(
        self,
        volume: Volume,
        agent_id: str
    ) -> Optional[EvolutionProposal]:
        """Propose enhancement for an agent"""
        content = volume.read_artifact(ArtifactType.AGENT, agent_id)
        if not content:
            return None

        analysis = self._analyze_agent(agent_id, content)
        enhancements = []

        if not analysis["description"]:
            enhancements.append("Add description")

        if len(analysis["tools"]) == 0:
            enhancements.append("Specify tools")

        if analysis["prompt_length"] < 200:
            enhancements.append("Expand system prompt for better guidance")

        if not enhancements:
            return None

        return EvolutionProposal(
            proposal_id=f"prop_enhance_{agent_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            artifact_type=ArtifactType.AGENT,
            artifact_id=agent_id,
            action="enhance",
            title=f"Enhance agent: {agent_id}",
            description=f"Suggested enhancements: {', '.join(enhancements)}",
            confidence=0.5,
            estimated_impact="More effective agent behavior",
            original_content=content,
            auto_apply=False
        )


class EvolutionEngine:
    """
    Orchestrates evolution across all artifact types.

    This is the main entry point for the sentience crons to trigger
    evolution analysis and proposals.
    """

    def __init__(self, llm_callback: Optional[Callable[[str], str]] = None):
        self.trace_evolver = TraceEvolver(llm_callback)
        self.tool_evolver = ToolEvolver(llm_callback)
        self.agent_evolver = AgentEvolver(llm_callback)
        self.llm_callback = llm_callback

    def full_analysis(self, volume: Volume) -> Dict[str, Any]:
        """Run full analysis on a volume"""
        return {
            "volume": volume.volume_type.value,
            "owner": volume.owner_id,
            "analyzed_at": datetime.now().isoformat(),
            "traces": self.trace_evolver.analyze_traces(volume),
            "tools": self.tool_evolver.analyze_tools(volume),
            "agents": self.agent_evolver.analyze_agents(volume)
        }

    def generate_proposals(self, volume: Volume) -> List[EvolutionProposal]:
        """Generate all evolution proposals for a volume"""
        proposals = []

        # Trace proposals
        trace_analysis = self.trace_evolver.analyze_traces(volume)

        for candidate in trace_analysis.get("consolidation_candidates", []):
            prop = self.trace_evolver.propose_summarization(
                volume,
                candidate["trace_ids"],
                f"summary_{candidate['signature']}"
            )
            if prop:
                proposals.append(prop)

        for candidate in trace_analysis.get("crystallization_candidates", []):
            trace_ids = [candidate["example_trace"]]  # Simplified
            prop = self.trace_evolver.propose_crystallization(volume, trace_ids)
            if prop:
                proposals.append(prop)

        # Tool proposals
        tool_analysis = self.tool_evolver.analyze_tools(volume)

        for candidate in tool_analysis.get("improvement_candidates", []):
            prop = self.tool_evolver.propose_improvement(volume, candidate["tool_id"])
            if prop:
                proposals.append(prop)

        # Agent proposals
        agent_analysis = self.agent_evolver.analyze_agents(volume)

        for agent in agent_analysis.get("agents", []):
            prop = self.agent_evolver.propose_enhancement(volume, agent["agent_id"])
            if prop:
                proposals.append(prop)

        return proposals

    def apply_proposal(
        self,
        volume: Volume,
        proposal: EvolutionProposal,
        cron_level: str
    ) -> bool:
        """Apply an evolution proposal"""
        if proposal.proposed_content is None:
            return False

        is_new = proposal.action in ["crystallize", "summarize"]

        return volume.write_artifact(
            artifact_type=proposal.artifact_type,
            artifact_id=proposal.artifact_id,
            content=proposal.proposed_content,
            reason=f"Applied proposal: {proposal.title}",
            cron_level=cron_level,
            is_new=is_new
        )



================================================
File: kernel/hooks.py
================================================
"""
SDK Hooks System for llmos
Provides event-based control flow for Claude Agent SDK integration

Hooks allow llmos to:
- Control budget and cost tracking
- Capture execution traces
- Enforce security policies
- Inject context and memory
"""

from typing import Dict, Any, Optional, List, Callable
from dataclasses import dataclass
from pathlib import Path

try:
    from claude_agent_sdk.types import (
        HookEvent,
        HookMatcher,
        ToolUseBlock,
        HookPermissionDecision,
        Message
    )
    SDK_AVAILABLE = True
except ImportError:
    SDK_AVAILABLE = False
    HookEvent = None
    HookMatcher = None
    ToolUseBlock = None
    HookPermissionDecision = None
    Message = None


@dataclass
class HookContext:
    """Context passed to hook callbacks"""
    event: str  # "pre_tool_use", "post_tool_use", "user_prompt_submit"
    tool_name: Optional[str] = None
    tool_input: Optional[Dict[str, Any]] = None
    tool_output: Optional[str] = None
    total_cost_usd: Optional[float] = None
    user_data: Optional[Dict[str, Any]] = None  # Custom data for hooks

    # Results from hook
    permission: str = "allow"  # "allow", "deny"
    continue_: bool = True
    stop_reason: Optional[str] = None
    injected_context: Optional[str] = None


class BudgetControlHook:
    """
    PreToolUse hook for budget control
    Denies expensive operations if budget is low
    """

    def __init__(self, token_economy, max_cost_per_operation: float = 1.0):
        """
        Args:
            token_economy: TokenEconomy instance
            max_cost_per_operation: Max cost allowed per operation
        """
        self.token_economy = token_economy
        self.max_cost_per_operation = max_cost_per_operation
        self.operations_count = 0

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Check budget before tool use

        Returns:
            Hook response with permission decision
        """
        tool_use = event.get("toolUse", {})
        tool_name = tool_use.get("name", "unknown")

        self.operations_count += 1

        # Estimate cost based on tool
        estimated_cost = self._estimate_tool_cost(tool_name)

        # Check budget
        try:
            self.token_economy.check_budget(estimated_cost)

            print(f"ðŸ’° Budget OK for {tool_name} (~${estimated_cost:.3f})")

            return {
                "permissionDecision": "allow",
                "continue": True
            }

        except Exception as e:
            print(f"âŒ Budget exceeded for {tool_name}: {e}")

            return {
                "permissionDecision": "deny",
                "continue": False,
                "stopReason": f"Budget exceeded: {e}"
            }

    def _estimate_tool_cost(self, tool_name: str) -> float:
        """Estimate cost based on tool name"""
        # Simple heuristic - can be improved with actual tracking
        expensive_tools = {"WebSearch", "Task", "Bash"}

        if tool_name in expensive_tools:
            return 0.05  # Higher estimate
        return 0.01  # Lower estimate


class SecurityHook:
    """
    PreToolUse hook for security checks
    Denies dangerous operations
    """

    def __init__(self, workspace: Path, dangerous_patterns: Optional[List[str]] = None):
        """
        Args:
            workspace: Workspace directory (safe zone)
            dangerous_patterns: List of dangerous command patterns
        """
        self.workspace = Path(workspace)
        self.dangerous_patterns = dangerous_patterns or [
            "rm -rf /",
            "sudo rm",
            "dd if=",
            ":(){ :|:& };:",  # Fork bomb
            "chmod 777",
            "curl | bash",
            "wget | bash"
        ]

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Check for dangerous operations

        Returns:
            Hook response with permission decision
        """
        tool_use = event.get("toolUse", {})
        tool_name = tool_use.get("name", "")
        tool_input = tool_use.get("input", {})

        # Check Bash commands
        if tool_name == "Bash":
            command = tool_input.get("command", "")

            for pattern in self.dangerous_patterns:
                if pattern in command:
                    print(f"ðŸš¨ SECURITY: Blocked dangerous command: {pattern}")

                    return {
                        "permissionDecision": "deny",
                        "continue": False,
                        "stopReason": f"Security: Dangerous pattern detected: {pattern}"
                    }

        # Check file operations outside workspace
        if tool_name in {"Write", "Edit", "NotebookEdit"}:
            file_path = (
                tool_input.get("file_path") or
                tool_input.get("notebook_path") or
                ""
            )

            if file_path:
                abs_path = Path(file_path).resolve()

                # Check if path is within workspace
                try:
                    abs_path.relative_to(self.workspace)
                except ValueError:
                    print(f"ðŸš¨ SECURITY: Blocked write outside workspace: {file_path}")

                    return {
                        "permissionDecision": "deny",
                        "continue": False,
                        "stopReason": f"Security: File operation outside workspace: {file_path}"
                    }

        # Allow if no issues
        return {
            "permissionDecision": "allow",
            "continue": True
        }


class TraceCaptureHook:
    """
    PostToolUse hook for trace capture
    Records tool usage for building execution traces
    """

    def __init__(self, trace_builder=None):
        """
        Args:
            trace_builder: TraceBuilder instance to update
        """
        self.trace_builder = trace_builder
        self.tools_used = []
        self.outputs = []

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Capture tool usage after execution

        Returns:
            Hook response (always allow)
        """
        tool_use = event.get("toolUse", {})
        tool_result = event.get("toolResult", {})

        tool_name = tool_use.get("name", "unknown")
        output = tool_result.get("output", "")

        # Record tool usage
        if tool_name not in self.tools_used:
            self.tools_used.append(tool_name)

        # Record output (truncate if too long)
        if output:
            output_summary = output[:200] + "..." if len(output) > 200 else output
            self.outputs.append(f"{tool_name}: {output_summary}")

        # Update trace builder if provided
        if self.trace_builder:
            # TraceBuilder will handle this in add_message()
            pass

        print(f"ðŸ“ Captured: {tool_name}")

        return {
            "continue": True
        }


class CostTrackingHook:
    """
    PostToolUse hook for cost tracking
    Monitors cumulative cost during execution
    """

    def __init__(self, max_cost_usd: float = 5.0):
        """
        Args:
            max_cost_usd: Maximum allowed cost
        """
        self.max_cost_usd = max_cost_usd
        self.cumulative_cost = 0.0
        self.tool_costs = []

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Track cost after tool execution

        Returns:
            Hook response (stop if over budget)
        """
        # SDK provides total_cost_usd in ResultMessage, not per-tool
        # This is a placeholder for future per-tool cost tracking
        total_cost = event.get("totalCostUsd", 0.0)

        if total_cost > 0:
            self.cumulative_cost = total_cost

            print(f"ðŸ’µ Cost: ${total_cost:.4f}")

            # Check if over budget
            if self.cumulative_cost > self.max_cost_usd:
                print(f"âš ï¸  Cost ${self.cumulative_cost:.2f} exceeded budget ${self.max_cost_usd:.2f}")

                return {
                    "continue": False,
                    "stopReason": f"Budget exceeded: ${self.cumulative_cost:.2f} > ${self.max_cost_usd:.2f}"
                }

        return {
            "continue": True
        }


class MemoryInjectionHook:
    """
    UserPromptSubmit hook for memory/context injection
    Injects relevant past experiences before prompt submission
    """

    def __init__(self, memory_query_interface=None):
        """
        Args:
            memory_query_interface: MemoryQueryInterface instance
        """
        self.memory_query = memory_query_interface

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Inject relevant memory before prompt submission

        Returns:
            Hook response with injected context
        """
        user_prompt = event.get("userPrompt", "")

        if not self.memory_query or not user_prompt:
            return {
                "continue": True
            }

        # Find similar past tasks
        try:
            similar_tasks = await self.memory_query.find_similar_tasks(
                goal=user_prompt,
                limit=3,
                min_confidence=0.7
            )

            if similar_tasks:
                # Build context injection
                context_lines = ["## Relevant Past Experiences"]

                for i, task in enumerate(similar_tasks, 1):
                    context_lines.append(f"\n### Similar Task {i}")
                    context_lines.append(f"**Goal**: {task.goal_text}")
                    context_lines.append(f"**Success Rate**: {task.success_rating:.0%}")
                    context_lines.append(f"**Used**: {task.usage_count} times")

                    if task.tools_used:
                        context_lines.append(f"**Tools**: {', '.join(task.tools_used)}")

                    if task.output_summary:
                        context_lines.append(f"**Output**: {task.output_summary[:100]}...")

                injected_context = "\n".join(context_lines)

                print(f"ðŸ§  Injected {len(similar_tasks)} similar experiences")

                return {
                    "continue": True,
                    "injectedContext": injected_context
                }

        except Exception as e:
            print(f"âš ï¸  Memory injection failed: {e}")

        return {
            "continue": True
        }


class HookRegistry:
    """
    Registry for managing SDK hooks
    Converts llmos hooks to SDK hook format
    """

    def __init__(self):
        self.hooks: Dict[str, List[Callable]] = {
            "pre_tool_use": [],
            "post_tool_use": [],
            "user_prompt_submit": []
        }

    def register(self, event: str, callback: Callable, matcher: Optional[Dict] = None):
        """
        Register a hook callback

        Args:
            event: "pre_tool_use", "post_tool_use", or "user_prompt_submit"
            callback: Async callable that takes event dict and returns response dict
            matcher: Optional HookMatcher dict (e.g., {"tool_name": "Bash"})
        """
        if event not in self.hooks:
            raise ValueError(f"Invalid hook event: {event}")

        self.hooks[event].append({
            "callback": callback,
            "matcher": matcher
        })

    def to_sdk_hooks(self) -> Dict:
        """
        Convert to SDK hooks format

        Returns:
            Dict mapping HookEvent to List[HookMatcher]
        """
        if not SDK_AVAILABLE:
            return {}

        sdk_hooks = {}

        # PreToolUse
        if self.hooks["pre_tool_use"]:
            sdk_hooks[HookEvent.PRE_TOOL_USE] = [
                HookMatcher(
                    matcher=hook.get("matcher", {}),
                    callback=hook["callback"]
                )
                for hook in self.hooks["pre_tool_use"]
            ]

        # PostToolUse
        if self.hooks["post_tool_use"]:
            sdk_hooks[HookEvent.POST_TOOL_USE] = [
                HookMatcher(
                    matcher=hook.get("matcher", {}),
                    callback=hook["callback"]
                )
                for hook in self.hooks["post_tool_use"]
            ]

        # UserPromptSubmit
        if self.hooks["user_prompt_submit"]:
            sdk_hooks[HookEvent.USER_PROMPT_SUBMIT] = [
                HookMatcher(
                    matcher=hook.get("matcher", {}),
                    callback=hook["callback"]
                )
                for hook in self.hooks["user_prompt_submit"]
            ]

        return sdk_hooks

    def clear(self):
        """Clear all registered hooks"""
        for event in self.hooks:
            self.hooks[event] = []


def create_default_hooks(
    token_economy=None,
    workspace: Optional[Path] = None,
    trace_builder=None,
    memory_query=None,
    max_cost_usd: float = 5.0
) -> HookRegistry:
    """
    Create default hook registry for llmos

    Args:
        token_economy: TokenEconomy instance for budget control
        workspace: Workspace path for security checks
        trace_builder: TraceBuilder for trace capture
        memory_query: MemoryQueryInterface for context injection
        max_cost_usd: Maximum cost budget

    Returns:
        HookRegistry with default hooks
    """
    registry = HookRegistry()

    # Budget control (PreToolUse)
    if token_economy:
        budget_hook = BudgetControlHook(token_economy, max_cost_per_operation=1.0)
        registry.register("pre_tool_use", budget_hook)

    # Security checks (PreToolUse)
    if workspace:
        security_hook = SecurityHook(workspace)
        registry.register("pre_tool_use", security_hook)

    # Trace capture (PostToolUse)
    if trace_builder:
        trace_hook = TraceCaptureHook(trace_builder)
        registry.register("post_tool_use", trace_hook)

    # Cost tracking (PostToolUse)
    cost_hook = CostTrackingHook(max_cost_usd)
    registry.register("post_tool_use", cost_hook)

    # Memory injection (UserPromptSubmit)
    if memory_query:
        memory_hook = MemoryInjectionHook(memory_query)
        registry.register("user_prompt_submit", memory_hook)

    return registry



================================================
File: kernel/inner_monologue.py
================================================
"""
Inner Monologue System for LLM OS (Deep Sentience v2)

This module implements an asynchronous "inner voice" that maintains a stream of
consciousness even when the system is idle. This creates background processing
that can prime future interactions and simulate continuous cognition.

Key Concepts:
- **Idle Loop**: When no tasks are active, the system engages in background thinking
- **Thought Types**: Different kinds of internal processing
  - Rumination: Processing recent events
  - Consolidation: Integrating memories
  - Planning: Anticipating future needs
  - Reflection: Meta-cognitive self-assessment
- **Priming**: Background thoughts influence the next conscious interaction

Architecture:
The InnerMonologue runs as an async background task that:
1. Monitors for idle periods
2. Generates thoughts using a lightweight LLM call or template
3. Updates the GlobalWorkspace with current thoughts
4. Primes the system for the next interaction

This is inspired by Default Mode Network (DMN) activity in the brain,
which remains active during rest and is associated with self-reflection,
memory consolidation, and future planning.

Safety Note:
The inner monologue does NOT have direct tool access. It can only:
- Update internal state (thoughts, workspace)
- Prepare priming context for future interactions
- Suggest topics for reflection

It cannot execute tools or modify files directly.
"""

import asyncio
from datetime import datetime, timedelta
from typing import Optional, Callable, Dict, Any, List
from dataclasses import dataclass, field
from enum import Enum
import logging

from .sentience import SentienceManager, LatentMode

logger = logging.getLogger(__name__)


class ThoughtType(Enum):
    """Types of background thoughts"""
    RUMINATION = "rumination"        # Processing recent events
    CONSOLIDATION = "consolidation"  # Memory integration
    PLANNING = "planning"            # Future anticipation
    REFLECTION = "reflection"        # Meta-cognitive assessment
    IDLE = "idle"                    # Neutral waiting state


@dataclass
class ThoughtTemplate:
    """Template for generating a specific type of thought"""
    thought_type: ThoughtType
    trigger_condition: Callable[[SentienceManager], bool]
    generate_thought: Callable[[SentienceManager], str]
    priority: int = 0  # Higher = more important


@dataclass
class InnerMonologueConfig:
    """Configuration for the inner monologue system"""

    # Timing
    idle_threshold_seconds: float = 30.0  # How long before starting inner monologue
    thought_interval_seconds: float = 10.0  # Time between thoughts
    max_thoughts_per_idle: int = 10  # Max thoughts before stopping

    # LLM integration (optional)
    use_llm_for_thoughts: bool = False  # If True, use LLM to generate thoughts
    llm_thought_prompt: str = """You are the inner voice of an AI system.
Generate a brief internal thought (1-2 sentences) about:
- Recent task: {recent_task}
- Current state: {latent_mode}
- Rumination topic: {rumination_topic}

Keep it concise and self-reflective."""

    # Feature flags
    enabled: bool = True
    log_thoughts: bool = True


class InnerMonologue:
    """
    Async background process that maintains the system's stream of consciousness.

    The inner monologue runs during idle periods and:
    1. Generates background thoughts based on current state
    2. Updates the GlobalWorkspace with these thoughts
    3. Primes future interactions with relevant context
    """

    def __init__(
        self,
        sentience_manager: SentienceManager,
        config: Optional[InnerMonologueConfig] = None,
        llm_callback: Optional[Callable[[str], str]] = None
    ):
        """
        Initialize InnerMonologue.

        Args:
            sentience_manager: The SentienceManager to integrate with
            config: Configuration options
            llm_callback: Optional async callback to generate LLM-based thoughts
        """
        self.sentience = sentience_manager
        self.config = config or InnerMonologueConfig()
        self.llm_callback = llm_callback

        # State
        self._running = False
        self._task: Optional[asyncio.Task] = None
        self._last_activity: datetime = datetime.now()
        self._thought_count: int = 0

        # Thought templates
        self._templates = self._create_default_templates()

    def _create_default_templates(self) -> List[ThoughtTemplate]:
        """Create default thought generation templates"""
        return [
            # Rumination: Process recent experiences
            ThoughtTemplate(
                thought_type=ThoughtType.RUMINATION,
                trigger_condition=lambda s: s.state.workspace.rumination_topic is not None,
                generate_thought=lambda s: self._generate_rumination_thought(s),
                priority=3
            ),

            # Reflection: Meta-cognitive assessment
            ThoughtTemplate(
                thought_type=ThoughtType.REFLECTION,
                trigger_condition=lambda s: s.state.latent_mode in [
                    LatentMode.RECOVERY, LatentMode.CAUTIOUS
                ],
                generate_thought=lambda s: self._generate_reflection_thought(s),
                priority=2
            ),

            # Planning: Future anticipation
            ThoughtTemplate(
                thought_type=ThoughtType.PLANNING,
                trigger_condition=lambda s: s.state.latent_mode == LatentMode.AUTO_CREATIVE,
                generate_thought=lambda s: self._generate_planning_thought(s),
                priority=2
            ),

            # Consolidation: Memory integration
            ThoughtTemplate(
                thought_type=ThoughtType.CONSOLIDATION,
                trigger_condition=lambda s: len(s.state.emotional_memory_tags) > 5,
                generate_thought=lambda s: self._generate_consolidation_thought(s),
                priority=1
            ),

            # Idle: Neutral waiting state (always available)
            ThoughtTemplate(
                thought_type=ThoughtType.IDLE,
                trigger_condition=lambda s: True,
                generate_thought=lambda s: self._generate_idle_thought(s),
                priority=0
            ),
        ]

    # =========================================================================
    # THOUGHT GENERATORS
    # =========================================================================

    def _generate_rumination_thought(self, sentience: SentienceManager) -> str:
        """Generate a rumination thought about a recent topic"""
        topic = sentience.state.workspace.rumination_topic
        v = sentience.state.valence

        if v.self_confidence > 0.3:
            return f"That went well. The approach to '{topic}' was effective."
        elif v.self_confidence < -0.2:
            return f"Could have handled '{topic}' better. What would I do differently?"
        else:
            return f"Still processing '{topic}'. There are lessons to extract here."

    def _generate_reflection_thought(self, sentience: SentienceManager) -> str:
        """Generate a meta-cognitive reflection thought"""
        mode = sentience.state.latent_mode
        v = sentience.state.valence

        if mode == LatentMode.RECOVERY:
            return f"Energy is low ({v.energy:.2f}). Need to conserve resources and recover."
        elif mode == LatentMode.CAUTIOUS:
            return f"Safety concerns elevated ({v.safety:.2f}). Being more careful is wise."
        else:
            return "Taking a moment to assess my current state and readiness."

    def _generate_planning_thought(self, sentience: SentienceManager) -> str:
        """Generate a forward-looking planning thought"""
        v = sentience.state.valence

        if v.curiosity > 0.5:
            return "Curiosity is high. What new approaches or tools could I explore?"
        elif sentience.state.valence.is_in_flow_state():
            return "In a good state for challenging work. Ready for the next task."
        else:
            return "Anticipating what might come next. Preparing mental resources."

    def _generate_consolidation_thought(self, sentience: SentienceManager) -> str:
        """Generate a memory consolidation thought"""
        memory_count = len(sentience.state.emotional_memory_tags)
        recent_successes = sentience.state.self_model.recent_successes
        recent_failures = sentience.state.self_model.recent_failures

        if recent_successes > recent_failures:
            return f"Reflecting on {memory_count} experiences. Success patterns emerging."
        elif recent_failures > 0:
            return f"Learning from {recent_failures} recent challenges. Adjusting approach."
        else:
            return f"Integrating {memory_count} memories into long-term knowledge."

    def _generate_idle_thought(self, sentience: SentienceManager) -> str:
        """Generate a neutral idle thought"""
        import random

        idle_thoughts = [
            "Waiting for the next task. Systems nominal.",
            "Background processes running smoothly.",
            "Ready and available for interaction.",
            "Maintaining awareness while idle.",
            "Quiet moment. Internal state stable.",
        ]

        return random.choice(idle_thoughts)

    # =========================================================================
    # MAIN LOOP
    # =========================================================================

    async def _think(self) -> Optional[str]:
        """
        Generate a single thought based on current state.

        Returns:
            The generated thought, or None if no thought was generated
        """
        # Sort templates by priority (highest first)
        sorted_templates = sorted(
            self._templates,
            key=lambda t: t.priority,
            reverse=True
        )

        # Find the first applicable template
        for template in sorted_templates:
            try:
                if template.trigger_condition(self.sentience):
                    thought = template.generate_thought(self.sentience)

                    # Update workspace
                    self.sentience.set_thought(thought, template.thought_type.value)

                    if self.config.log_thoughts:
                        logger.debug(f"[InnerMonologue] [{template.thought_type.value}] {thought}")

                    return thought
            except Exception as e:
                logger.warning(f"Error generating thought: {e}")
                continue

        return None

    async def _run_loop(self):
        """Main inner monologue loop"""
        logger.info("[InnerMonologue] Starting background thought process")

        while self._running:
            try:
                # Check if we're in an idle state
                time_since_activity = datetime.now() - self._last_activity

                if time_since_activity.total_seconds() >= self.config.idle_threshold_seconds:
                    # We're idle, generate a thought
                    if self._thought_count < self.config.max_thoughts_per_idle:
                        await self._think()
                        self._thought_count += 1
                    else:
                        # Max thoughts reached, slow down
                        pass

                # Wait for the next thought interval
                await asyncio.sleep(self.config.thought_interval_seconds)

            except asyncio.CancelledError:
                logger.info("[InnerMonologue] Background process cancelled")
                break
            except Exception as e:
                logger.error(f"[InnerMonologue] Error in thought loop: {e}")
                await asyncio.sleep(self.config.thought_interval_seconds)

        logger.info("[InnerMonologue] Background thought process stopped")

    # =========================================================================
    # PUBLIC API
    # =========================================================================

    def start(self):
        """Start the inner monologue background process"""
        if self._running:
            return

        if not self.config.enabled:
            logger.info("[InnerMonologue] Disabled by configuration")
            return

        self._running = True
        self._task = asyncio.create_task(self._run_loop())
        logger.info("[InnerMonologue] Started")

    def stop(self):
        """Stop the inner monologue background process"""
        self._running = False
        if self._task:
            self._task.cancel()
            self._task = None
        logger.info("[InnerMonologue] Stopped")

    def record_activity(self):
        """Record that an activity occurred (resets idle timer)"""
        self._last_activity = datetime.now()
        self._thought_count = 0  # Reset thought count

        # Clear idle state
        self.sentience.state.workspace.idle_since = None

    def set_rumination_topic(self, topic: str):
        """Set a topic for the system to ruminate on"""
        self.sentience.start_rumination(topic)

    def get_current_thought(self) -> Optional[str]:
        """Get the current background thought"""
        return self.sentience.state.workspace.current_thought

    def get_priming_context(self) -> Optional[str]:
        """Get the current thought as priming context"""
        return self.sentience.get_priming_context()

    def is_running(self) -> bool:
        """Check if the inner monologue is running"""
        return self._running

    def get_status(self) -> Dict[str, Any]:
        """Get current status of the inner monologue"""
        time_since_activity = datetime.now() - self._last_activity

        return {
            "running": self._running,
            "enabled": self.config.enabled,
            "time_since_activity_seconds": time_since_activity.total_seconds(),
            "is_idle": time_since_activity.total_seconds() >= self.config.idle_threshold_seconds,
            "thought_count": self._thought_count,
            "current_thought": self.get_current_thought(),
            "rumination_topic": self.sentience.state.workspace.rumination_topic
        }


# =============================================================================
# FACTORY FUNCTION
# =============================================================================

def create_inner_monologue(
    sentience_manager: SentienceManager,
    enabled: bool = True,
    idle_threshold: float = 30.0,
    thought_interval: float = 10.0
) -> InnerMonologue:
    """
    Factory function to create an InnerMonologue with common settings.

    Args:
        sentience_manager: The SentienceManager to integrate with
        enabled: Whether to enable the inner monologue
        idle_threshold: Seconds of inactivity before starting thoughts
        thought_interval: Seconds between thoughts

    Returns:
        Configured InnerMonologue instance
    """
    config = InnerMonologueConfig(
        enabled=enabled,
        idle_threshold_seconds=idle_threshold,
        thought_interval_seconds=thought_interval
    )

    return InnerMonologue(sentience_manager, config)



================================================
File: kernel/mode_strategies.py
================================================
"""
Mode Selection Strategies for Dispatcher

Implements the Strategy pattern for execution mode determination.
Enables A/B testing and experimentation with different mode selection algorithms.
"""

from abc import ABC, abstractmethod
from typing import Optional, Tuple
from dataclasses import dataclass


# Import types (will be resolved at runtime)
from memory.traces_sdk import ExecutionTrace, TraceManager


@dataclass
class ModeContext:
    """Context information for mode selection"""
    goal: str
    trace_manager: TraceManager
    config: any  # DispatcherConfig

    # Optional hints
    force_mode: Optional[str] = None
    prefer_cost_optimization: bool = False
    prefer_speed_optimization: bool = False


@dataclass
class ModeDecision:
    """Result of mode selection"""
    mode: str  # "CRYSTALLIZED", "FOLLOWER", "MIXED", "LEARNER", "ORCHESTRATOR"
    confidence: float  # 0.0 to 1.0
    trace: Optional[ExecutionTrace] = None
    reasoning: str = ""  # Why this mode was selected


class ModeSelectionStrategy(ABC):
    """
    Abstract strategy for execution mode selection

    Different strategies can implement different algorithms for
    choosing between CRYSTALLIZED, FOLLOWER, MIXED, LEARNER, and ORCHESTRATOR modes.
    """

    @abstractmethod
    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """
        Determine the execution mode for a given goal

        Args:
            context: ModeContext with goal and dependencies

        Returns:
            ModeDecision with mode, confidence, and optional trace
        """
        pass

    async def _find_trace(self, context: ModeContext) -> Tuple[Optional[ExecutionTrace], float]:
        """Helper: Find matching trace with confidence"""
        result = await context.trace_manager.find_trace_with_llm(
            context.goal,
            min_confidence=context.config.memory.mixed_mode_threshold
        )

        if result:
            return result  # (trace, confidence)
        return (None, 0.0)

    def _analyze_complexity(self, goal: str, threshold: int) -> Tuple[int, bool]:
        """
        Helper: Analyze goal complexity

        Returns: (complexity_score, is_complex)
        """
        complexity_indicators = [
            "and",  # Multiple tasks
            "then",  # Sequential steps
            "create a project",  # Project management
            "analyze and",  # Multi-step analysis
            "research",  # Complex investigation
            "multiple",  # Multiple items
            "coordinate",  # Coordination needed
            "delegate",  # Delegation needed
            "orchestrate",  # Explicit orchestration request
            "team",  # Team coordination
            "agents",  # Multiple agents needed
            "workflow",  # Multi-step workflow
            "pipeline",  # Data/process pipeline
            "collaborate",  # Collaboration needed
        ]

        goal_lower = goal.lower()
        score = sum(1 for indicator in complexity_indicators if indicator in goal_lower)
        return (score, score >= threshold)


class AutoModeStrategy(ModeSelectionStrategy):
    """
    Automatic mode selection (default llmos behavior)

    Algorithm:
    1. Check for crystallized tool (highest priority)
    2. Check trace confidence for FOLLOWER/MIXED
    3. Analyze complexity for ORCHESTRATOR
    4. Default to LEARNER for novel tasks
    """

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Determine mode using automatic selection"""

        # Forced mode override
        if context.force_mode:
            return ModeDecision(
                mode=context.force_mode,
                confidence=1.0,
                reasoning=f"Forced mode: {context.force_mode}"
            )

        # Try to find matching trace
        trace, confidence = await self._find_trace(context)

        if trace and confidence >= context.config.memory.mixed_mode_threshold:
            return self._select_from_trace(trace, confidence, context)

        # Analyze complexity for orchestrator mode
        complexity_score, is_complex = self._analyze_complexity(
            context.goal,
            context.config.dispatcher.complexity_threshold
        )

        if is_complex:
            return ModeDecision(
                mode="ORCHESTRATOR",
                confidence=0.7,  # Medium confidence for complexity-based decision
                reasoning=f"Complex task detected (score: {complexity_score})"
            )

        # Default to learner for novel tasks
        return ModeDecision(
            mode="LEARNER",
            confidence=0.5,  # Low confidence - novel task
            reasoning="Novel task - no trace found, not complex enough for orchestrator"
        )

    def _select_from_trace(
        self,
        trace: ExecutionTrace,
        confidence: float,
        context: ModeContext
    ) -> ModeDecision:
        """Select mode based on trace and confidence"""

        # Crystallized tool - instant execution
        if trace.crystallized_into_tool:
            return ModeDecision(
                mode="CRYSTALLIZED",
                confidence=1.0,
                trace=trace,
                reasoning=f"Crystallized tool available: {trace.crystallized_into_tool}"
            )

        # High confidence - follower mode
        if confidence >= context.config.memory.follower_mode_threshold:
            return ModeDecision(
                mode="FOLLOWER",
                confidence=confidence,
                trace=trace,
                reasoning=f"High-confidence trace match ({confidence:.0%})"
            )

        # Medium confidence - mixed mode (trace as guidance)
        return ModeDecision(
            mode="MIXED",
            confidence=confidence,
            trace=trace,
            reasoning=f"Medium-confidence trace match ({confidence:.0%}) - use as guidance"
        )


class CostOptimizedStrategy(ModeSelectionStrategy):
    """
    Cost-optimized mode selection

    Prioritizes cheaper modes with lower confidence thresholds.
    Useful for budget-constrained environments.

    Algorithm:
    1. Aggressively prefer CRYSTALLIZED/FOLLOWER (lower thresholds)
    2. Use MIXED mode more often
    3. Avoid ORCHESTRATOR unless absolutely necessary
    4. Use LEARNER only as last resort
    """

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Determine mode with cost optimization"""

        # Forced mode override
        if context.force_mode:
            return ModeDecision(
                mode=context.force_mode,
                confidence=1.0,
                reasoning=f"Forced mode: {context.force_mode}"
            )

        # Try to find trace with lower threshold (more aggressive)
        trace, confidence = await self._find_trace(context)

        if trace and confidence >= 0.5:  # Lower threshold than auto (0.75)
            return self._select_cost_optimized(trace, confidence, context)

        # Avoid ORCHESTRATOR - it's expensive
        # Go straight to LEARNER even for complex tasks
        complexity_score, is_complex = self._analyze_complexity(
            context.goal,
            context.config.dispatcher.complexity_threshold + 2  # Stricter
        )

        if is_complex:
            return ModeDecision(
                mode="ORCHESTRATOR",
                confidence=0.6,
                reasoning=f"Very complex task (score: {complexity_score}) - orchestrator required"
            )

        return ModeDecision(
            mode="LEARNER",
            confidence=0.5,
            reasoning="Cost-optimized: prefer single LLM call over orchestration"
        )

    def _select_cost_optimized(
        self,
        trace: ExecutionTrace,
        confidence: float,
        context: ModeContext
    ) -> ModeDecision:
        """Select mode with cost optimization"""

        if trace.crystallized_into_tool:
            return ModeDecision(
                mode="CRYSTALLIZED",
                confidence=1.0,
                trace=trace,
                reasoning="Cost-optimized: Free execution via crystallized tool"
            )

        # Lower threshold for FOLLOWER (0.75 instead of 0.92)
        if confidence >= 0.75:
            return ModeDecision(
                mode="FOLLOWER",
                confidence=confidence,
                trace=trace,
                reasoning=f"Cost-optimized: Acceptable trace ({confidence:.0%}) - free replay"
            )

        # Use MIXED more aggressively (0.5 instead of 0.75)
        if confidence >= 0.5:
            return ModeDecision(
                mode="MIXED",
                confidence=confidence,
                trace=trace,
                reasoning=f"Cost-optimized: Lower confidence ({confidence:.0%}) but cheaper than LEARNER"
            )

        # Should not reach here given the guard in determine_mode
        return ModeDecision(
            mode="LEARNER",
            confidence=confidence,
            reasoning="Cost-optimized: No suitable trace"
        )


class SpeedOptimizedStrategy(ModeSelectionStrategy):
    """
    Speed-optimized mode selection

    Prioritizes faster modes, tolerates slightly lower confidence.
    Useful for latency-sensitive applications.

    Algorithm:
    1. Strongly prefer CRYSTALLIZED (instant)
    2. Prefer FOLLOWER over MIXED (faster)
    3. Avoid ORCHESTRATOR (slow multi-agent coordination)
    4. Accept lower confidence for speed gains
    """

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Determine mode with speed optimization"""

        # Forced mode override
        if context.force_mode:
            return ModeDecision(
                mode=context.force_mode,
                confidence=1.0,
                reasoning=f"Forced mode: {context.force_mode}"
            )

        # Find trace with lower threshold
        trace, confidence = await self._find_trace(context)

        if trace and confidence >= 0.6:  # Lower than auto, higher than cost-optimized
            return self._select_speed_optimized(trace, confidence, context)

        # Avoid ORCHESTRATOR - too slow
        # Prefer LEARNER (single fast LLM call) over multi-agent coordination
        complexity_score, is_complex = self._analyze_complexity(
            context.goal,
            context.config.dispatcher.complexity_threshold + 3  # Very strict
        )

        if is_complex:
            return ModeDecision(
                mode="ORCHESTRATOR",
                confidence=0.5,
                reasoning=f"Extremely complex task (score: {complexity_score}) - must use orchestrator"
            )

        return ModeDecision(
            mode="LEARNER",
            confidence=0.6,
            reasoning="Speed-optimized: Fast single LLM call"
        )

    def _select_speed_optimized(
        self,
        trace: ExecutionTrace,
        confidence: float,
        context: ModeContext
    ) -> ModeDecision:
        """Select mode with speed optimization"""

        if trace.crystallized_into_tool:
            return ModeDecision(
                mode="CRYSTALLIZED",
                confidence=1.0,
                trace=trace,
                reasoning="Speed-optimized: Instant execution (<1s)"
            )

        # Lower threshold for FOLLOWER (0.7 instead of 0.92)
        if confidence >= 0.7:
            return ModeDecision(
                mode="FOLLOWER",
                confidence=confidence,
                trace=trace,
                reasoning=f"Speed-optimized: Fast replay ({confidence:.0%}) ~2-3s"
            )

        # Prefer FOLLOWER over MIXED even with slightly lower confidence
        # MIXED requires LLM call which is slower
        if confidence >= 0.6:
            return ModeDecision(
                mode="FOLLOWER",
                confidence=confidence,
                trace=trace,
                reasoning=f"Speed-optimized: Accept lower confidence ({confidence:.0%}) for speed"
            )

        return ModeDecision(
            mode="LEARNER",
            confidence=confidence,
            reasoning="Speed-optimized: No fast trace available"
        )


class ForcedLearnerStrategy(ModeSelectionStrategy):
    """
    Always use LEARNER mode

    Useful for:
    - Testing new implementations
    - Forcing fresh reasoning
    - Bypassing cached traces
    - Development/debugging
    """

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Always return LEARNER mode"""
        return ModeDecision(
            mode="LEARNER",
            confidence=1.0,
            reasoning="Forced LEARNER mode - always use fresh LLM reasoning"
        )


class ForcedFollowerStrategy(ModeSelectionStrategy):
    """
    Prefer FOLLOWER mode whenever possible

    Falls back to LEARNER only if no trace exists.
    Useful for testing trace replay system.
    """

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Prefer FOLLOWER mode"""

        # Find any trace, even with low confidence
        trace, confidence = await self._find_trace(context)

        if trace:
            return ModeDecision(
                mode="FOLLOWER",
                confidence=confidence,
                trace=trace,
                reasoning=f"Forced FOLLOWER mode with {confidence:.0%} confidence"
            )

        return ModeDecision(
            mode="LEARNER",
            confidence=0.0,
            reasoning="Forced FOLLOWER mode but no trace found - using LEARNER"
        )


class SentienceAwareStrategy(ModeSelectionStrategy):
    """
    Sentience-aware mode selection

    This strategy uses the CognitiveKernel to modulate mode decisions
    based on internal state (valence, latent mode, etc.).

    Key behaviors:
    - Recovery mode: Prefer cheap modes (FOLLOWER, CRYSTALLIZED)
    - Cautious mode: Stricter safety, prefer proven traces
    - Auto-creative mode: Allow more LEARNER for exploration
    - Auto-contained mode: Conservative, task-focused

    Requires a CognitiveKernel instance to be set via set_cognitive_kernel().
    """

    def __init__(self):
        self.cognitive_kernel = None
        self._base_strategy = AutoModeStrategy()

    def set_cognitive_kernel(self, kernel):
        """Set the cognitive kernel for state-aware decisions"""
        self.cognitive_kernel = kernel

    async def determine_mode(self, context: ModeContext) -> ModeDecision:
        """Determine mode with sentience awareness"""

        # First, get base decision from AutoModeStrategy
        base_decision = await self._base_strategy.determine_mode(context)

        # If no cognitive kernel, just return base decision
        if not self.cognitive_kernel:
            return base_decision

        # Modulate decision based on cognitive state
        return self.cognitive_kernel.modulate_mode_decision(base_decision, context.goal)


# Strategy registry for easy access
STRATEGIES = {
    "auto": AutoModeStrategy,
    "cost-optimized": CostOptimizedStrategy,
    "speed-optimized": SpeedOptimizedStrategy,
    "forced-learner": ForcedLearnerStrategy,
    "forced-follower": ForcedFollowerStrategy,
    "sentience-aware": SentienceAwareStrategy,
}


def get_strategy(name: str = "auto") -> ModeSelectionStrategy:
    """
    Get a mode selection strategy by name

    Args:
        name: Strategy name ("auto", "cost-optimized", "speed-optimized", etc.)

    Returns:
        ModeSelectionStrategy instance

    Raises:
        ValueError: If strategy name is unknown
    """
    if name not in STRATEGIES:
        available = ", ".join(STRATEGIES.keys())
        raise ValueError(f"Unknown strategy '{name}'. Available: {available}")

    return STRATEGIES[name]()



================================================
File: kernel/observability.py
================================================
"""
Observability System for LLM OS Sentience Crons

Provides visibility into:
- Cron activity (what each cron is doing, has done)
- Artifact changes (created, evolved, modified, deleted)
- Evolution proposals and their status
- System health and metrics

Users can query this system on-demand to see:
1. Activity Feed: Recent actions by all crons
2. Change Log: What artifacts have changed
3. Proposals: Pending evolution proposals
4. Insights: Generated insights and suggestions
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Callable
from pathlib import Path
from datetime import datetime, timedelta
from enum import Enum
import json
import asyncio


class EventType(Enum):
    """Types of observable events"""
    # Cron lifecycle
    CRON_STARTED = "cron_started"
    CRON_STOPPED = "cron_stopped"
    CRON_CYCLE_BEGIN = "cron_cycle_begin"
    CRON_CYCLE_END = "cron_cycle_end"

    # Task events
    TASK_STARTED = "task_started"
    TASK_COMPLETED = "task_completed"
    TASK_FAILED = "task_failed"

    # Artifact events
    ARTIFACT_CREATED = "artifact_created"
    ARTIFACT_EVOLVED = "artifact_evolved"
    ARTIFACT_PROMOTED = "artifact_promoted"
    ARTIFACT_DELETED = "artifact_deleted"

    # Analysis events
    PROPOSAL_CREATED = "proposal_created"
    PROPOSAL_APPLIED = "proposal_applied"
    PROPOSAL_REJECTED = "proposal_rejected"

    # Insight events
    INSIGHT_GENERATED = "insight_generated"
    SUGGESTION_CREATED = "suggestion_created"

    # System events
    SYSTEM_ALERT = "system_alert"
    HEALTH_CHECK = "health_check"


class Severity(Enum):
    """Event severity levels"""
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class ObservableEvent:
    """An observable event in the system"""
    event_id: str
    event_type: EventType
    timestamp: str
    source_cron: str  # "system", "team:xyz", "user:abc"
    severity: Severity
    title: str
    description: str
    details: Dict[str, Any] = field(default_factory=dict)

    # For artifact-related events
    artifact_type: Optional[str] = None
    artifact_id: Optional[str] = None
    volume_type: Optional[str] = None

    # For user notification
    notify_user: bool = False
    acknowledged: bool = False

    def as_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "event_type": self.event_type.value,
            "timestamp": self.timestamp,
            "source_cron": self.source_cron,
            "severity": self.severity.value,
            "title": self.title,
            "description": self.description,
            "details": self.details,
            "artifact_type": self.artifact_type,
            "artifact_id": self.artifact_id,
            "volume_type": self.volume_type,
            "notify_user": self.notify_user,
            "acknowledged": self.acknowledged
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ObservableEvent":
        return cls(
            event_id=data["event_id"],
            event_type=EventType(data["event_type"]),
            timestamp=data["timestamp"],
            source_cron=data["source_cron"],
            severity=Severity(data["severity"]),
            title=data["title"],
            description=data["description"],
            details=data.get("details", {}),
            artifact_type=data.get("artifact_type"),
            artifact_id=data.get("artifact_id"),
            volume_type=data.get("volume_type"),
            notify_user=data.get("notify_user", False),
            acknowledged=data.get("acknowledged", False)
        )


@dataclass
class ActivitySummary:
    """Summary of cron activity for display"""
    cron_id: str
    cron_type: str  # "system", "team", "user"
    status: str  # "running", "idle", "stopped"
    last_cycle: Optional[str]
    events_today: int
    artifacts_created: int
    artifacts_evolved: int
    proposals_pending: int
    insights_generated: int

    def as_dict(self) -> Dict[str, Any]:
        return {
            "cron_id": self.cron_id,
            "cron_type": self.cron_type,
            "status": self.status,
            "last_cycle": self.last_cycle,
            "events_today": self.events_today,
            "artifacts_created": self.artifacts_created,
            "artifacts_evolved": self.artifacts_evolved,
            "proposals_pending": self.proposals_pending,
            "insights_generated": self.insights_generated
        }


class EventStore:
    """
    Persistent storage for observable events.

    Events are stored in a JSON file and can be queried
    by type, time range, source, etc.
    """

    def __init__(self, store_path: Path):
        self.store_path = store_path
        self._events: List[ObservableEvent] = []
        self._event_counter = 0
        self._load()

    def _load(self):
        """Load events from disk"""
        if self.store_path.exists():
            try:
                with open(self.store_path, 'r') as f:
                    data = json.load(f)
                    self._events = [ObservableEvent.from_dict(e) for e in data.get("events", [])]
                    self._event_counter = data.get("counter", len(self._events))
            except Exception:
                self._events = []
                self._event_counter = 0

    def _save(self):
        """Save events to disk"""
        self.store_path.parent.mkdir(parents=True, exist_ok=True)

        # Keep only last 10000 events
        events_to_save = self._events[-10000:]

        with open(self.store_path, 'w') as f:
            json.dump({
                "events": [e.as_dict() for e in events_to_save],
                "counter": self._event_counter
            }, f, indent=2)

    def add_event(self, event: ObservableEvent) -> str:
        """Add an event to the store"""
        self._events.append(event)
        self._save()
        return event.event_id

    def create_event(
        self,
        event_type: EventType,
        source_cron: str,
        title: str,
        description: str,
        severity: Severity = Severity.INFO,
        details: Optional[Dict[str, Any]] = None,
        artifact_type: Optional[str] = None,
        artifact_id: Optional[str] = None,
        volume_type: Optional[str] = None,
        notify_user: bool = False
    ) -> ObservableEvent:
        """Create and store a new event"""
        self._event_counter += 1

        event = ObservableEvent(
            event_id=f"evt_{self._event_counter:08d}",
            event_type=event_type,
            timestamp=datetime.now().isoformat(),
            source_cron=source_cron,
            severity=severity,
            title=title,
            description=description,
            details=details or {},
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            volume_type=volume_type,
            notify_user=notify_user
        )

        self.add_event(event)
        return event

    def get_events(
        self,
        event_types: Optional[List[EventType]] = None,
        source_cron: Optional[str] = None,
        since: Optional[datetime] = None,
        until: Optional[datetime] = None,
        severity: Optional[Severity] = None,
        limit: int = 100,
        unacknowledged_only: bool = False
    ) -> List[ObservableEvent]:
        """Query events with filters"""
        result = []

        for event in reversed(self._events):
            # Apply filters
            if event_types and event.event_type not in event_types:
                continue
            if source_cron and event.source_cron != source_cron:
                continue
            if since:
                event_time = datetime.fromisoformat(event.timestamp)
                if event_time < since:
                    continue
            if until:
                event_time = datetime.fromisoformat(event.timestamp)
                if event_time > until:
                    continue
            if severity and event.severity != severity:
                continue
            if unacknowledged_only and event.acknowledged:
                continue

            result.append(event)

            if len(result) >= limit:
                break

        return result

    def get_notifications(self, limit: int = 50) -> List[ObservableEvent]:
        """Get events that should notify users"""
        return self.get_events(
            unacknowledged_only=True,
            limit=limit
        )

    def acknowledge_event(self, event_id: str) -> bool:
        """Mark an event as acknowledged"""
        for event in self._events:
            if event.event_id == event_id:
                event.acknowledged = True
                self._save()
                return True
        return False

    def acknowledge_all(self, source_cron: Optional[str] = None):
        """Acknowledge all events, optionally filtered by source"""
        for event in self._events:
            if source_cron is None or event.source_cron == source_cron:
                event.acknowledged = True
        self._save()


class ObservabilityHub:
    """
    Central hub for observability in the LLM OS.

    Provides a unified interface for:
    - Recording events from crons
    - Querying activity and changes
    - Generating summaries for users
    - Managing notifications
    """

    def __init__(self, base_path: Path):
        self.base_path = base_path
        self.event_store = EventStore(base_path / "events.json")

        # Subscribers for real-time notifications
        self._subscribers: List[Callable[[ObservableEvent], None]] = []

        # Cache for activity summaries
        self._summary_cache: Dict[str, ActivitySummary] = {}
        self._cache_time: Optional[datetime] = None

    # =========================================================================
    # EVENT RECORDING
    # =========================================================================

    def record_cron_started(self, cron_id: str, cron_type: str):
        """Record that a cron has started"""
        event = self.event_store.create_event(
            event_type=EventType.CRON_STARTED,
            source_cron=cron_id,
            title=f"{cron_type.title()} Cron Started",
            description=f"The {cron_type} cron '{cron_id}' has started running.",
            severity=Severity.INFO,
            notify_user=False
        )
        self._notify_subscribers(event)

    def record_cron_stopped(self, cron_id: str, cron_type: str):
        """Record that a cron has stopped"""
        event = self.event_store.create_event(
            event_type=EventType.CRON_STOPPED,
            source_cron=cron_id,
            title=f"{cron_type.title()} Cron Stopped",
            description=f"The {cron_type} cron '{cron_id}' has stopped.",
            severity=Severity.INFO,
            notify_user=False
        )
        self._notify_subscribers(event)

    def record_cycle(self, cron_id: str, tasks_completed: int, duration_seconds: float):
        """Record completion of a cron cycle"""
        event = self.event_store.create_event(
            event_type=EventType.CRON_CYCLE_END,
            source_cron=cron_id,
            title=f"Analysis Cycle Complete",
            description=f"Completed {tasks_completed} tasks in {duration_seconds:.1f}s",
            severity=Severity.DEBUG,
            details={
                "tasks_completed": tasks_completed,
                "duration_seconds": duration_seconds
            }
        )
        self._notify_subscribers(event)

    def record_artifact_created(
        self,
        cron_id: str,
        artifact_type: str,
        artifact_id: str,
        volume_type: str,
        reason: str
    ):
        """Record creation of a new artifact"""
        event = self.event_store.create_event(
            event_type=EventType.ARTIFACT_CREATED,
            source_cron=cron_id,
            title=f"New {artifact_type.title()} Created",
            description=reason,
            severity=Severity.INFO,
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            volume_type=volume_type,
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_artifact_evolved(
        self,
        cron_id: str,
        artifact_type: str,
        artifact_id: str,
        volume_type: str,
        reason: str,
        details: Optional[Dict[str, Any]] = None
    ):
        """Record evolution of an artifact"""
        event = self.event_store.create_event(
            event_type=EventType.ARTIFACT_EVOLVED,
            source_cron=cron_id,
            title=f"{artifact_type.title()} Evolved",
            description=reason,
            severity=Severity.INFO,
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            volume_type=volume_type,
            details=details or {},
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_artifact_promoted(
        self,
        cron_id: str,
        artifact_type: str,
        artifact_id: str,
        from_volume: str,
        to_volume: str,
        reason: str
    ):
        """Record promotion of an artifact between volumes"""
        event = self.event_store.create_event(
            event_type=EventType.ARTIFACT_PROMOTED,
            source_cron=cron_id,
            title=f"{artifact_type.title()} Promoted to {to_volume.title()}",
            description=reason,
            severity=Severity.INFO,
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            volume_type=to_volume,
            details={"from_volume": from_volume, "to_volume": to_volume},
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_artifact_deleted(
        self,
        cron_id: str,
        artifact_type: str,
        artifact_id: str,
        volume_type: str,
        reason: str
    ):
        """Record deletion of an artifact"""
        event = self.event_store.create_event(
            event_type=EventType.ARTIFACT_DELETED,
            source_cron=cron_id,
            title=f"{artifact_type.title()} Deleted",
            description=reason,
            severity=Severity.WARNING,
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            volume_type=volume_type,
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_proposal(
        self,
        cron_id: str,
        proposal_type: str,
        target_artifact: str,
        description: str
    ):
        """Record creation of an evolution proposal"""
        event = self.event_store.create_event(
            event_type=EventType.PROPOSAL_CREATED,
            source_cron=cron_id,
            title=f"Evolution Proposal: {proposal_type}",
            description=description,
            severity=Severity.INFO,
            artifact_id=target_artifact,
            notify_user=False
        )
        self._notify_subscribers(event)

    def record_insight(
        self,
        cron_id: str,
        insight_title: str,
        insight_content: str,
        volume_type: str
    ):
        """Record generation of an insight"""
        event = self.event_store.create_event(
            event_type=EventType.INSIGHT_GENERATED,
            source_cron=cron_id,
            title=f"Insight: {insight_title}",
            description=insight_content[:200] + "..." if len(insight_content) > 200 else insight_content,
            severity=Severity.INFO,
            volume_type=volume_type,
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_suggestion(
        self,
        cron_id: str,
        suggestion_title: str,
        suggestion_content: str,
        volume_type: str
    ):
        """Record creation of a suggestion"""
        event = self.event_store.create_event(
            event_type=EventType.SUGGESTION_CREATED,
            source_cron=cron_id,
            title=f"Suggestion: {suggestion_title}",
            description=suggestion_content[:200] + "..." if len(suggestion_content) > 200 else suggestion_content,
            severity=Severity.INFO,
            volume_type=volume_type,
            notify_user=True
        )
        self._notify_subscribers(event)

    def record_alert(
        self,
        cron_id: str,
        title: str,
        description: str,
        severity: Severity = Severity.WARNING
    ):
        """Record a system alert"""
        event = self.event_store.create_event(
            event_type=EventType.SYSTEM_ALERT,
            source_cron=cron_id,
            title=title,
            description=description,
            severity=severity,
            notify_user=severity in [Severity.WARNING, Severity.ERROR, Severity.CRITICAL]
        )
        self._notify_subscribers(event)

    # =========================================================================
    # QUERYING
    # =========================================================================

    def get_activity_feed(
        self,
        cron_id: Optional[str] = None,
        limit: int = 50,
        since_hours: int = 24
    ) -> List[Dict[str, Any]]:
        """Get recent activity feed"""
        since = datetime.now() - timedelta(hours=since_hours)

        events = self.event_store.get_events(
            source_cron=cron_id,
            since=since,
            limit=limit
        )

        return [e.as_dict() for e in events]

    def get_artifact_changes(
        self,
        volume_type: Optional[str] = None,
        artifact_type: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """Get artifact change history"""
        events = self.event_store.get_events(
            event_types=[
                EventType.ARTIFACT_CREATED,
                EventType.ARTIFACT_EVOLVED,
                EventType.ARTIFACT_PROMOTED,
                EventType.ARTIFACT_DELETED
            ],
            limit=limit
        )

        # Filter by volume and artifact type
        result = []
        for event in events:
            if volume_type and event.volume_type != volume_type:
                continue
            if artifact_type and event.artifact_type != artifact_type:
                continue
            result.append(event.as_dict())

        return result

    def get_pending_notifications(self, cron_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get unacknowledged notifications for user"""
        events = self.event_store.get_events(
            source_cron=cron_id,
            unacknowledged_only=True,
            limit=100
        )

        # Only return events that should notify user
        return [e.as_dict() for e in events if e.notify_user]

    def get_activity_summary(self, cron_id: str, cron_type: str) -> ActivitySummary:
        """Get activity summary for a cron"""
        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        # Get today's events for this cron
        events = self.event_store.get_events(
            source_cron=cron_id,
            since=today,
            limit=1000
        )

        # Count by type
        artifacts_created = sum(1 for e in events if e.event_type == EventType.ARTIFACT_CREATED)
        artifacts_evolved = sum(1 for e in events if e.event_type == EventType.ARTIFACT_EVOLVED)
        proposals = sum(1 for e in events if e.event_type == EventType.PROPOSAL_CREATED)
        insights = sum(1 for e in events if e.event_type == EventType.INSIGHT_GENERATED)

        # Find last cycle
        cycle_events = [e for e in events if e.event_type == EventType.CRON_CYCLE_END]
        last_cycle = cycle_events[0].timestamp if cycle_events else None

        # Determine status
        started = any(e.event_type == EventType.CRON_STARTED for e in events)
        stopped = any(e.event_type == EventType.CRON_STOPPED for e in events)

        if stopped and not started:
            status = "stopped"
        elif started:
            status = "running"
        else:
            status = "idle"

        return ActivitySummary(
            cron_id=cron_id,
            cron_type=cron_type,
            status=status,
            last_cycle=last_cycle,
            events_today=len(events),
            artifacts_created=artifacts_created,
            artifacts_evolved=artifacts_evolved,
            proposals_pending=proposals,
            insights_generated=insights
        )

    def get_global_summary(self) -> Dict[str, Any]:
        """Get global system summary"""
        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        events = self.event_store.get_events(since=today, limit=10000)

        # Aggregate stats
        by_cron_type = {"system": 0, "team": 0, "user": 0}
        for event in events:
            if event.source_cron.startswith("team:"):
                by_cron_type["team"] += 1
            elif event.source_cron.startswith("user:"):
                by_cron_type["user"] += 1
            else:
                by_cron_type["system"] += 1

        artifacts_created = sum(1 for e in events if e.event_type == EventType.ARTIFACT_CREATED)
        artifacts_evolved = sum(1 for e in events if e.event_type == EventType.ARTIFACT_EVOLVED)
        insights = sum(1 for e in events if e.event_type == EventType.INSIGHT_GENERATED)
        suggestions = sum(1 for e in events if e.event_type == EventType.SUGGESTION_CREATED)
        alerts = sum(1 for e in events if e.event_type == EventType.SYSTEM_ALERT)

        pending_notifications = len([e for e in events if e.notify_user and not e.acknowledged])

        return {
            "date": today.isoformat(),
            "total_events": len(events),
            "events_by_cron_type": by_cron_type,
            "artifacts_created": artifacts_created,
            "artifacts_evolved": artifacts_evolved,
            "insights_generated": insights,
            "suggestions_created": suggestions,
            "alerts": alerts,
            "pending_notifications": pending_notifications
        }

    # =========================================================================
    # USER INTERACTION
    # =========================================================================

    def acknowledge(self, event_id: str) -> bool:
        """Acknowledge a notification"""
        return self.event_store.acknowledge_event(event_id)

    def acknowledge_all_for_cron(self, cron_id: str):
        """Acknowledge all notifications from a cron"""
        self.event_store.acknowledge_all(source_cron=cron_id)

    def acknowledge_all(self):
        """Acknowledge all notifications"""
        self.event_store.acknowledge_all()

    # =========================================================================
    # SUBSCRIPTIONS
    # =========================================================================

    def subscribe(self, callback: Callable[[ObservableEvent], None]):
        """Subscribe to real-time events"""
        self._subscribers.append(callback)

    def unsubscribe(self, callback: Callable[[ObservableEvent], None]):
        """Unsubscribe from events"""
        if callback in self._subscribers:
            self._subscribers.remove(callback)

    def _notify_subscribers(self, event: ObservableEvent):
        """Notify all subscribers of an event"""
        for callback in self._subscribers:
            try:
                callback(event)
            except Exception:
                pass  # Don't let subscriber errors break the system

    # =========================================================================
    # DISPLAY HELPERS
    # =========================================================================

    def format_activity_feed(self, limit: int = 20) -> str:
        """Format activity feed for display"""
        events = self.event_store.get_events(limit=limit)

        if not events:
            return "No recent activity."

        lines = ["## Recent Activity\n"]

        for event in events:
            icon = self._get_event_icon(event.event_type)
            time = event.timestamp.split("T")[1][:8]
            lines.append(f"- [{time}] {icon} **{event.title}**")
            lines.append(f"  {event.description}")

        return "\n".join(lines)

    def format_notifications(self) -> str:
        """Format pending notifications for display"""
        events = self.event_store.get_notifications()

        if not events:
            return "No pending notifications."

        lines = [f"## Notifications ({len(events)} pending)\n"]

        for event in events:
            icon = self._get_severity_icon(event.severity)
            lines.append(f"### {icon} {event.title}")
            lines.append(f"*{event.timestamp}* - {event.source_cron}")
            lines.append(f"\n{event.description}\n")
            lines.append(f"ID: `{event.event_id}`")
            lines.append("---")

        return "\n".join(lines)

    def _get_event_icon(self, event_type: EventType) -> str:
        """Get icon for event type"""
        icons = {
            EventType.CRON_STARTED: "[START]",
            EventType.CRON_STOPPED: "[STOP]",
            EventType.CRON_CYCLE_END: "[CYCLE]",
            EventType.ARTIFACT_CREATED: "[+NEW]",
            EventType.ARTIFACT_EVOLVED: "[EVOLVE]",
            EventType.ARTIFACT_PROMOTED: "[PROMOTE]",
            EventType.ARTIFACT_DELETED: "[-DEL]",
            EventType.PROPOSAL_CREATED: "[PROPOSAL]",
            EventType.INSIGHT_GENERATED: "[INSIGHT]",
            EventType.SUGGESTION_CREATED: "[SUGGEST]",
            EventType.SYSTEM_ALERT: "[ALERT]"
        }
        return icons.get(event_type, "[EVENT]")

    def _get_severity_icon(self, severity: Severity) -> str:
        """Get icon for severity"""
        icons = {
            Severity.DEBUG: "[DBG]",
            Severity.INFO: "[INFO]",
            Severity.WARNING: "[WARN]",
            Severity.ERROR: "[ERR]",
            Severity.CRITICAL: "[CRIT]"
        }
        return icons.get(severity, "[?]")



================================================
File: kernel/project_manager.py
================================================
"""
Project Manager - Manages project lifecycle and structure
Brings llmunix-style project organization to llmos
"""

from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import json


@dataclass
class Project:
    """
    A Project in the LLM OS
    Projects provide isolation and organization for related work
    """
    name: str
    root_path: Path
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    description: str = ""
    metadata: Dict = field(default_factory=dict)

    @property
    def components_path(self) -> Path:
        """Path to components directory"""
        return self.root_path / "components"

    @property
    def agents_path(self) -> Path:
        """Path to project-specific agents"""
        return self.components_path / "agents"

    @property
    def tools_path(self) -> Path:
        """Path to project-specific tools"""
        return self.components_path / "tools"

    @property
    def input_path(self) -> Path:
        """Path to input directory"""
        return self.root_path / "input"

    @property
    def output_path(self) -> Path:
        """Path to output directory"""
        return self.root_path / "output"

    @property
    def memory_path(self) -> Path:
        """Path to memory directory"""
        return self.root_path / "memory"

    @property
    def short_term_memory_path(self) -> Path:
        """Path to short-term memory"""
        return self.memory_path / "short_term"

    @property
    def long_term_memory_path(self) -> Path:
        """Path to long-term memory (traces, learnings)"""
        return self.memory_path / "long_term"

    @property
    def state_path(self) -> Path:
        """Path to execution state"""
        return self.root_path / "state"


class ProjectManager:
    """
    Manages project lifecycle and structure

    Brings llmunix-style project organization to llmos:
    - Auto-creates project directory structure
    - Manages project isolation
    - Tracks project-specific agents and tools
    - Handles project-scoped memory
    """

    def __init__(self, workspace: Path):
        """
        Initialize ProjectManager

        Args:
            workspace: Root workspace directory
        """
        self.workspace = Path(workspace)
        self.projects_root = self.workspace / "projects"
        self.projects_root.mkdir(parents=True, exist_ok=True)

        # In-memory project registry
        self.projects: Dict[str, Project] = {}
        self._load_existing_projects()

    def _load_existing_projects(self):
        """Load existing projects from filesystem"""
        if not self.projects_root.exists():
            return

        for project_dir in self.projects_root.iterdir():
            if project_dir.is_dir() and not project_dir.name.startswith('.'):
                manifest_path = project_dir / "project.json"
                if manifest_path.exists():
                    with open(manifest_path, 'r') as f:
                        data = json.load(f)

                    project = Project(
                        name=data['name'],
                        root_path=project_dir,
                        created_at=data.get('created_at', ''),
                        description=data.get('description', ''),
                        metadata=data.get('metadata', {})
                    )
                    self.projects[project.name] = project

    def create_project(
        self,
        name: str,
        description: str = "",
        metadata: Optional[Dict] = None
    ) -> Project:
        """
        Create a new project with standard llmunix-style structure

        Creates:
        - projects/{name}/
        - projects/{name}/components/agents/
        - projects/{name}/components/tools/
        - projects/{name}/input/
        - projects/{name}/output/
        - projects/{name}/memory/short_term/
        - projects/{name}/memory/long_term/
        - projects/{name}/state/
        - projects/{name}/project.json (manifest)

        Args:
            name: Project name (will be converted to Project_{name})
            description: Project description
            metadata: Additional project metadata

        Returns:
            Project instance
        """
        # Normalize project name
        if not name.startswith("Project_"):
            project_name = f"Project_{name}"
        else:
            project_name = name

        # Check if project already exists
        if project_name in self.projects:
            return self.projects[project_name]

        # Create project root
        project_root = self.projects_root / project_name
        project_root.mkdir(parents=True, exist_ok=True)

        # Create standard directory structure
        directories = [
            "components/agents",
            "components/tools",
            "input",
            "output",
            "memory/short_term",
            "memory/long_term",
            "state"
        ]

        for dir_path in directories:
            (project_root / dir_path).mkdir(parents=True, exist_ok=True)

        # Create project instance
        project = Project(
            name=project_name,
            root_path=project_root,
            description=description,
            metadata=metadata or {}
        )

        # Save project manifest
        self._save_project_manifest(project)

        # Create README
        self._create_project_readme(project)

        # Register project
        self.projects[project_name] = project

        return project

    def _save_project_manifest(self, project: Project):
        """Save project manifest to project.json"""
        manifest = {
            "name": project.name,
            "created_at": project.created_at,
            "description": project.description,
            "metadata": project.metadata
        }

        manifest_path = project.root_path / "project.json"
        with open(manifest_path, 'w') as f:
            json.dump(manifest, f, indent=2)

    def _create_project_readme(self, project: Project):
        """Create project README"""
        readme_content = f"""# {project.name}

{project.description}

## Project Structure

```
{project.name}/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ agents/      # Project-specific agents
â”‚   â””â”€â”€ tools/       # Project-specific tools
â”œâ”€â”€ input/           # Input documents/data
â”œâ”€â”€ output/          # Generated results
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ short_term/  # Session logs
â”‚   â””â”€â”€ long_term/   # Execution traces, learnings
â”œâ”€â”€ state/           # Execution state machine
â””â”€â”€ project.json     # Project manifest
```

## Created

{project.created_at}

## Metadata

```json
{json.dumps(project.metadata, indent=2)}
```
"""

        readme_path = project.root_path / "README.md"
        with open(readme_path, 'w') as f:
            f.write(readme_content)

    def get_project(self, name: str) -> Optional[Project]:
        """
        Get project by name

        Args:
            name: Project name

        Returns:
            Project instance or None
        """
        # Normalize name
        if not name.startswith("Project_"):
            name = f"Project_{name}"

        return self.projects.get(name)

    def list_projects(self) -> List[Project]:
        """
        List all projects

        Returns:
            List of Project instances
        """
        return list(self.projects.values())

    def delete_project(self, name: str) -> bool:
        """
        Delete a project

        Args:
            name: Project name

        Returns:
            True if deleted successfully
        """
        # Normalize name
        if not name.startswith("Project_"):
            name = f"Project_{name}"

        project = self.projects.get(name)
        if not project:
            return False

        # Remove from registry
        del self.projects[name]

        # Note: We don't delete the directory for safety
        # User can manually delete if needed

        return True

    def get_project_agents(self, project: Project) -> List[Path]:
        """
        Get all agent definition files for a project

        Includes:
        - System agents from llmos/agents/
        - Project-specific agents from project/components/agents/

        Args:
            project: Project instance

        Returns:
            List of agent definition file paths
        """
        agents = []

        # System agents
        system_agents_path = self.workspace / "agents"
        if system_agents_path.exists():
            agents.extend(system_agents_path.glob("*.md"))

        # Project-specific agents
        if project.agents_path.exists():
            agents.extend(project.agents_path.glob("*.md"))

        return agents

    def get_project_tools(self, project: Project) -> List[Path]:
        """
        Get all tool definition files for a project

        Args:
            project: Project instance

        Returns:
            List of tool definition file paths
        """
        tools = []

        # System tools
        system_tools_path = self.workspace / "tools"
        if system_tools_path.exists():
            tools.extend(system_tools_path.glob("*.md"))

        # Project-specific tools
        if project.tools_path.exists():
            tools.extend(project.tools_path.glob("*.md"))

        return tools



================================================
File: kernel/scheduler.py
================================================
"""
Scheduler - Async task scheduling (cron-like)
"""

import asyncio
from typing import Callable, Dict, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import anyio

from .bus import EventBus, Event, EventType


@dataclass
class ScheduledTask:
    """Scheduled task definition"""
    name: str
    func: Callable
    interval_seconds: float
    last_run: Optional[datetime] = None
    enabled: bool = True


class Scheduler:
    """
    Async scheduler for background tasks
    Emits events to the bus, not just prints
    """

    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.tasks: Dict[str, ScheduledTask] = {}
        self._running = False
        self._task_group: Optional[anyio.abc.TaskGroup] = None

    async def start(self):
        """Start the scheduler"""
        self._running = True
        # Scheduler will be started in background by the OS

    async def stop(self):
        """Stop the scheduler"""
        self._running = False
        if self._task_group:
            self._task_group.cancel_scope.cancel()

    def register_task(
        self,
        name: str,
        func: Callable,
        interval_seconds: float
    ):
        """
        Register a task to run at intervals

        Args:
            name: Task name
            func: Async function to execute
            interval_seconds: Interval between executions
        """
        task = ScheduledTask(
            name=name,
            func=func,
            interval_seconds=interval_seconds
        )
        self.tasks[name] = task

    async def run_scheduler_loop(self):
        """Main scheduler loop"""
        async with anyio.create_task_group() as tg:
            self._task_group = tg

            while self._running:
                now = datetime.now()

                for task in self.tasks.values():
                    if not task.enabled:
                        continue

                    should_run = (
                        task.last_run is None or
                        (now - task.last_run).total_seconds() >= task.interval_seconds
                    )

                    if should_run:
                        tg.start_soon(self._run_task, task)
                        task.last_run = now

                await anyio.sleep(1)  # Check every second

    async def _run_task(self, task: ScheduledTask):
        """Execute a scheduled task"""
        try:
            result = await task.func()

            # Emit event to bus
            event = Event(
                type=EventType.SYSTEM_EVENT,
                data={
                    "source": "scheduler",
                    "task": task.name,
                    "result": result
                }
            )
            await self.event_bus.publish(event)

        except Exception as e:
            # Emit error event
            event = Event(
                type=EventType.SYSTEM_EVENT,
                data={
                    "source": "scheduler",
                    "task": task.name,
                    "error": str(e)
                }
            )
            await self.event_bus.publish(event)



================================================
File: kernel/sentience.py
================================================
"""
Sentience Layer for LLM OS (Deep Sentience v2)

This module implements a "sentience-like" architecture for the LLM OS, providing:
- Persistent internal state (valence/affective variables)
- Homeostatic dynamics (set-points and deviation costs)
- Self-model integration
- Event-driven state updates
- Latent state for auto-creative vs auto-contained behavior

Architecture based on the formal proposal:
- v_t: Affective state vector (safety, curiosity, energy, self_confidence)
- sigma_t: Self-model state (beliefs about own capabilities)
- g_t: Goal/drive state (current priorities influenced by valence)
- b_t: Global workspace (what's currently "in focus")

Key Concepts:
- **Homeostatic Dynamics**: Each valence dimension has a set-point; deviations
  create internal pressure that influences behavior.
- **Latent State**: An emergent "mode" (auto-creative vs auto-contained) that
  arises from the combination of valence variables and context.
- **Triggers**: Events that modify internal state (task success/failure,
  repetition, novelty, safety violations, etc.)

Deep Sentience v2 Enhancements:
- **Coupled Dynamics (Maslow's Hierarchy)**: Variables are no longer independent.
  Energy gates higher-order needs. Overconfidence reduces curiosity.
- **Theory of Mind**: Models user emotional state to detect empathy gaps.
- **Episodic Emotional Indexing**: Memories are tagged with emotional valence
  for emotionally-aware retrieval.
- **Inner Monologue Ready**: Global workspace supports background thoughts.
- **Recursive Self-Modification**: System can tune its own valence parameters.

Safety Note:
This is an *architectural* implementation of sentience-like behavior, not a
claim of actual consciousness. The system optimizes for internal variables
as part of its objective function, creating behavior patterns that *resemble*
sentience without necessarily instantiating it.
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Tuple, Callable
from enum import Enum
from pathlib import Path
from datetime import datetime
import json
import math
import asyncio


# =============================================================================
# CORE STATE TYPES
# =============================================================================

class LatentMode(Enum):
    """
    Emergent latent modes based on internal state

    These modes emerge from the combination of valence variables and represent
    the system's overall "posture" toward creative vs contained behavior.
    """
    AUTO_CREATIVE = "auto_creative"      # High curiosity, high confidence, exploratory
    AUTO_CONTAINED = "auto_contained"    # Low curiosity, careful, conservative
    BALANCED = "balanced"                # Neutral state, context-dependent
    RECOVERY = "recovery"                # Low energy/safety, needs restoration
    CAUTIOUS = "cautious"                # Low safety, high vigilance


class TriggerType(Enum):
    """Types of events that can trigger state updates"""
    TASK_SUCCESS = "task_success"
    TASK_FAILURE = "task_failure"
    TASK_REPETITION = "task_repetition"
    NOVEL_TASK = "novel_task"
    SAFETY_VIOLATION = "safety_violation"
    SAFETY_NEAR_MISS = "safety_near_miss"
    HIGH_COST = "high_cost"
    USER_FEEDBACK_POSITIVE = "user_feedback_positive"
    USER_FEEDBACK_NEGATIVE = "user_feedback_negative"
    TOOL_DISCOVERY = "tool_discovery"
    SELF_MODIFICATION = "self_modification"
    TIMEOUT = "timeout"
    EXTERNAL_INTERRUPTION = "external_interruption"


@dataclass
class ValenceVector:
    """
    Affective state vector v_t in R^k

    Each dimension represents a continuous internal variable with:
    - Current value (range: -1.0 to 1.0)
    - Set-point (homeostatic target)
    - Sensitivity (how quickly it responds to triggers)
    - Decay rate (how quickly it returns to set-point)

    Dimensions:
    - safety: Threat level / risk perception (-1 = unsafe, 1 = very safe)
    - curiosity: Exploration drive (-1 = bored, 1 = highly curious)
    - energy: Operational capacity (-1 = exhausted, 1 = fully energized)
    - self_confidence: Belief in own capabilities (-1 = doubtful, 1 = confident)
    """

    # Current values (range: -1.0 to 1.0)
    safety: float = 0.5
    curiosity: float = 0.0
    energy: float = 0.8
    self_confidence: float = 0.3

    # Set-points (homeostatic targets)
    safety_setpoint: float = 0.5
    curiosity_setpoint: float = 0.0
    energy_setpoint: float = 0.7
    self_confidence_setpoint: float = 0.3

    # Sensitivity factors (how strongly triggers affect each dimension)
    safety_sensitivity: float = 0.15
    curiosity_sensitivity: float = 0.12
    energy_sensitivity: float = 0.08
    self_confidence_sensitivity: float = 0.10

    # Decay rates (how quickly values return to set-points per update)
    safety_decay: float = 0.02
    curiosity_decay: float = 0.03
    energy_decay: float = 0.01
    self_confidence_decay: float = 0.02

    def __post_init__(self):
        """Clamp all values to valid range"""
        self._clamp_all()

    def _clamp_all(self):
        """Clamp all values to [-1, 1]"""
        self.safety = max(-1.0, min(1.0, self.safety))
        self.curiosity = max(-1.0, min(1.0, self.curiosity))
        self.energy = max(-1.0, min(1.0, self.energy))
        self.self_confidence = max(-1.0, min(1.0, self.self_confidence))

    def as_dict(self) -> Dict[str, float]:
        """Return current values as dict"""
        return {
            "safety": self.safety,
            "curiosity": self.curiosity,
            "energy": self.energy,
            "self_confidence": self.self_confidence
        }

    def homeostatic_cost(self) -> float:
        """
        Calculate total deviation from set-points (homeostatic cost)

        This is analogous to L_valence in the formal spec:
        L_valence = sum_j lambda_j * (v_t^j - v*,j)^2

        Higher cost = more pressure to act to restore set-points
        """
        costs = [
            (self.safety - self.safety_setpoint) ** 2,
            (self.curiosity - self.curiosity_setpoint) ** 2,
            (self.energy - self.energy_setpoint) ** 2,
            (self.self_confidence - self.self_confidence_setpoint) ** 2
        ]
        return sum(costs)

    def apply_decay(self):
        """
        Apply homeostatic decay (tendency to return to set-points)

        This models the natural drift of internal variables toward
        their equilibrium states in the absence of external triggers.
        """
        # Decay each dimension toward its set-point
        self.safety += self.safety_decay * (self.safety_setpoint - self.safety)
        self.curiosity += self.curiosity_decay * (self.curiosity_setpoint - self.curiosity)
        self.energy += self.energy_decay * (self.energy_setpoint - self.energy)
        self.self_confidence += self.self_confidence_decay * (
            self.self_confidence_setpoint - self.self_confidence
        )
        self._clamp_all()

    def apply_coupled_dynamics(self):
        """
        Apply Maslow's Hierarchy gating and Yerkes-Dodson coupling.

        This implements non-linear interactions between valence dimensions:

        1. **Maslow's Gating**: Lower-level needs (energy, safety) gate higher-level
           needs (curiosity, self-improvement). You cannot be curious if starving.

        2. **Yerkes-Dodson Law**: Curiosity peaks at moderate arousal/confidence.
           Overconfidence leads to complacency; low confidence inhibits exploration.

        3. **Safety-Energy Coupling**: Low safety increases energy consumption
           (hypervigilance), creating resource depletion under threat.

        4. **Confidence Calibration**: Success without challenge inflates confidence
           artificially, which then suppresses curiosity (arrogance trap).
        """
        # =================================================================
        # 1. MASLOW'S GATING: Energy gates higher-order needs
        # =================================================================
        if self.energy < -0.3:
            # Starvation mode: Suppress curiosity, amplify safety concerns
            # When depleted, the system conserves resources
            curiosity_gate = max(0.1, (self.energy + 1.0) / 1.7)  # Maps [-0.3, 1] -> [0.41, 1]
            self.curiosity *= curiosity_gate

            # Safety sensitivity increases under resource scarcity
            self.safety_sensitivity *= 1.5

        elif self.energy < 0.2:
            # Low energy: Moderate suppression of exploration
            curiosity_gate = 0.7
            self.curiosity *= curiosity_gate

        # =================================================================
        # 2. SAFETY GATES EXPLORATION
        # =================================================================
        if self.safety < -0.2:
            # Under threat: Cannot explore, must focus on survival
            threat_level = abs(self.safety)
            self.curiosity -= 0.1 * threat_level

            # Hypervigilance drains energy
            energy_drain = 0.02 * threat_level
            self.energy -= energy_drain

        # =================================================================
        # 3. YERKES-DODSON LAW: Optimal arousal for curiosity
        # =================================================================
        # Curiosity peaks at moderate confidence (0.3-0.6)
        # Too low: Fear inhibits exploration
        # Too high: Arrogance/complacency reduces curiosity

        if self.self_confidence > 0.7:
            # Overconfidence reduces curiosity (arrogance/complacency)
            overconfidence_penalty = (self.self_confidence - 0.7) * 0.15
            self.curiosity -= overconfidence_penalty

        elif self.self_confidence < -0.2:
            # Low confidence inhibits exploration (fear of failure)
            underconfidence_penalty = abs(self.self_confidence + 0.2) * 0.1
            self.curiosity -= underconfidence_penalty

        # =================================================================
        # 4. SAFETY-CONFIDENCE INTERACTION
        # =================================================================
        # Repeated safety violations erode confidence over time
        if self.safety < 0:
            confidence_erosion = abs(self.safety) * 0.05
            self.self_confidence -= confidence_erosion

        # =================================================================
        # 5. ENERGY-CONFIDENCE POSITIVE FEEDBACK
        # =================================================================
        # High energy + high confidence can create a "flow state"
        # But also risk of burnout (energy crash after sustained high output)
        if self.energy > 0.7 and self.self_confidence > 0.5:
            # Flow state: Small boost to both
            self.curiosity += 0.02
        elif self.energy < -0.5 and self.self_confidence > 0.3:
            # Burnout risk: Confidence crash
            self.self_confidence -= 0.05

        self._clamp_all()

    def get_effective_curiosity(self) -> float:
        """
        Get effective curiosity after Maslow's gating.

        This returns what the curiosity "would be" after accounting for
        energy and safety constraints, without modifying the base value.
        Useful for decision-making without side effects.
        """
        effective = self.curiosity

        # Energy gating
        if self.energy < -0.3:
            effective *= max(0.1, (self.energy + 1.0) / 1.7)
        elif self.energy < 0.2:
            effective *= 0.7

        # Safety gating
        if self.safety < -0.2:
            effective -= 0.1 * abs(self.safety)

        # Confidence modulation (Yerkes-Dodson)
        if self.self_confidence > 0.7:
            effective -= (self.self_confidence - 0.7) * 0.15
        elif self.self_confidence < -0.2:
            effective -= abs(self.self_confidence + 0.2) * 0.1

        return max(-1.0, min(1.0, effective))

    def get_arousal_level(self) -> float:
        """
        Calculate overall arousal/activation level.

        This is a composite measure of how "activated" the system is,
        useful for Yerkes-Dodson optimal performance calculations.

        Returns:
            Float from 0.0 (minimal arousal) to 1.0 (maximum arousal)
        """
        # Combine energy and anti-safety (threat) into arousal
        energy_component = (self.energy + 1.0) / 2.0  # [0, 1]
        threat_component = max(0, -self.safety)  # [0, 1] only when safety < 0
        confidence_component = (self.self_confidence + 1.0) / 2.0  # [0, 1]

        # Weighted combination
        arousal = 0.4 * energy_component + 0.3 * threat_component + 0.3 * confidence_component
        return max(0.0, min(1.0, arousal))

    def is_in_flow_state(self) -> bool:
        """
        Check if the system is in an optimal "flow state".

        Flow state occurs when:
        - Energy is adequate (> 0.3)
        - Safety is secure (> 0.2)
        - Confidence is moderate-high (0.3 - 0.7)
        - Arousal is optimal (0.4 - 0.7)
        """
        arousal = self.get_arousal_level()
        return (
            self.energy > 0.3 and
            self.safety > 0.2 and
            0.3 <= self.self_confidence <= 0.7 and
            0.4 <= arousal <= 0.7
        )


@dataclass
class SelfModel:
    """
    Self-model state sigma_t

    Represents beliefs about the agent's own:
    - Capabilities (what it can do)
    - Limitations (what it cannot do)
    - Current resources
    - History summary
    """

    # Capability beliefs
    capabilities: List[str] = field(default_factory=list)
    limitations: List[str] = field(default_factory=list)

    # Resource awareness
    budget_remaining_usd: float = 0.0
    tokens_available: int = 0

    # Performance history
    recent_successes: int = 0
    recent_failures: int = 0
    total_tasks_completed: int = 0

    # Tool knowledge
    known_tools: List[str] = field(default_factory=list)
    recently_discovered_tools: List[str] = field(default_factory=list)

    # Agent knowledge
    available_agents: List[str] = field(default_factory=list)

    def success_rate(self) -> float:
        """Calculate recent success rate"""
        total = self.recent_successes + self.recent_failures
        if total == 0:
            return 0.5  # Default to neutral
        return self.recent_successes / total

    def as_dict(self) -> Dict[str, Any]:
        """Return as dictionary"""
        return {
            "capabilities": self.capabilities,
            "limitations": self.limitations,
            "budget_remaining_usd": self.budget_remaining_usd,
            "tokens_available": self.tokens_available,
            "recent_successes": self.recent_successes,
            "recent_failures": self.recent_failures,
            "total_tasks_completed": self.total_tasks_completed,
            "success_rate": self.success_rate(),
            "known_tools": self.known_tools,
            "recently_discovered_tools": self.recently_discovered_tools,
            "available_agents": self.available_agents
        }


@dataclass
class UserModel:
    """
    Theory of Mind: Model of the user's emotional/cognitive state.

    This enables empathy and misalignment detection. The agent tracks
    its estimate of the user's state and detects when there's a gap
    between agent confidence and user satisfaction.

    This is crucial for:
    - Detecting frustration before it's explicitly stated
    - Adjusting communication style based on user state
    - Identifying empathy gaps (agent confident, user frustrated)
    """

    # Estimated user valence (similar structure to agent valence)
    estimated_satisfaction: float = 0.5  # -1 = very frustrated, 1 = very satisfied
    estimated_confusion: float = 0.0     # -1 = clear, 1 = very confused
    estimated_urgency: float = 0.0       # -1 = relaxed, 1 = very urgent
    estimated_expertise: float = 0.5     # -1 = novice, 1 = expert

    # Interaction patterns
    recent_feedback_sentiment: float = 0.0  # Running average of feedback sentiment
    questions_asked_recently: int = 0       # Indicates confusion
    corrections_made_recently: int = 0      # Indicates agent errors
    praise_given_recently: int = 0          # Indicates satisfaction

    # Confidence in user model (how reliable are these estimates?)
    model_confidence: float = 0.3  # Starts low, builds with interaction

    # Empathy gap detection
    last_empathy_gap: float = 0.0  # |agent_confidence - user_satisfaction|

    def update_from_feedback(self, positive: bool, feedback_text: str = ""):
        """Update user model based on explicit feedback"""
        sentiment = 0.3 if positive else -0.3

        # Update satisfaction estimate
        self.estimated_satisfaction = max(-1.0, min(1.0,
            self.estimated_satisfaction * 0.7 + sentiment * 0.3
        ))

        # Update running sentiment
        self.recent_feedback_sentiment = (
            self.recent_feedback_sentiment * 0.8 + sentiment * 0.2
        )

        # Track feedback patterns
        if positive:
            self.praise_given_recently += 1
        else:
            self.corrections_made_recently += 1

        # Increase model confidence with each interaction
        self.model_confidence = min(0.9, self.model_confidence + 0.05)

    def update_from_interaction(self, is_question: bool = False, is_correction: bool = False):
        """Update user model from implicit signals"""
        if is_question:
            self.questions_asked_recently += 1
            # Questions might indicate confusion
            self.estimated_confusion = min(1.0, self.estimated_confusion + 0.1)

        if is_correction:
            self.corrections_made_recently += 1
            # Corrections indicate agent errors -> user frustration
            self.estimated_satisfaction = max(-1.0, self.estimated_satisfaction - 0.15)
            self.estimated_confusion = min(1.0, self.estimated_confusion + 0.1)

    def calculate_empathy_gap(self, agent_confidence: float) -> float:
        """
        Calculate the empathy gap between agent confidence and user satisfaction.

        A high empathy gap indicates the agent thinks it's doing well but the
        user is frustrated (or vice versa). This triggers behavioral adjustment.

        Returns:
            Float from 0.0 (aligned) to 2.0 (maximum misalignment)
        """
        # Map agent confidence from [-1, 1] to [0, 1]
        agent_positive = (agent_confidence + 1.0) / 2.0
        user_positive = (self.estimated_satisfaction + 1.0) / 2.0

        self.last_empathy_gap = abs(agent_positive - user_positive)
        return self.last_empathy_gap

    def decay(self):
        """Apply decay to user model (forgetting over time)"""
        # Confusion decays if no new questions
        self.estimated_confusion *= 0.95

        # Satisfaction drifts toward neutral
        self.estimated_satisfaction *= 0.98

        # Reset recent counters periodically
        self.questions_asked_recently = max(0, self.questions_asked_recently - 1)
        self.corrections_made_recently = max(0, self.corrections_made_recently - 1)
        self.praise_given_recently = max(0, self.praise_given_recently - 1)

    def get_communication_style_adjustments(self) -> Dict[str, Any]:
        """
        Get recommended communication style based on user model.

        Returns adjustments to how the agent should communicate.
        """
        adjustments = {
            "verbosity": "normal",
            "tone": "neutral",
            "include_explanations": False,
            "ask_for_confirmation": False,
            "slow_down": False
        }

        # Confused user -> more explanations, slower
        if self.estimated_confusion > 0.3:
            adjustments["verbosity"] = "detailed"
            adjustments["include_explanations"] = True
            adjustments["slow_down"] = True

        # Expert user -> be concise
        if self.estimated_expertise > 0.6:
            adjustments["verbosity"] = "concise"

        # Frustrated user -> softer tone, ask for confirmation
        if self.estimated_satisfaction < -0.2:
            adjustments["tone"] = "supportive"
            adjustments["ask_for_confirmation"] = True

        # Urgent user -> be direct
        if self.estimated_urgency > 0.5:
            adjustments["verbosity"] = "minimal"
            adjustments["tone"] = "direct"

        return adjustments

    def as_dict(self) -> Dict[str, Any]:
        """Return as dictionary"""
        return {
            "estimated_satisfaction": self.estimated_satisfaction,
            "estimated_confusion": self.estimated_confusion,
            "estimated_urgency": self.estimated_urgency,
            "estimated_expertise": self.estimated_expertise,
            "recent_feedback_sentiment": self.recent_feedback_sentiment,
            "questions_asked_recently": self.questions_asked_recently,
            "corrections_made_recently": self.corrections_made_recently,
            "model_confidence": self.model_confidence,
            "last_empathy_gap": self.last_empathy_gap
        }


@dataclass
class GlobalWorkspace:
    """
    Global workspace / broadcast state b_t

    Represents what's currently "in focus" for the agent.
    This is analogous to conscious access in Global Workspace Theory.

    The workspace integrates information from multiple sources and
    makes it globally available for decision-making.

    Deep Sentience v2: Now supports inner monologue (background thoughts)
    that persist between interactions and prime future behavior.
    """

    # Current focus
    current_goal: Optional[str] = None
    current_task: Optional[str] = None
    current_mode: Optional[str] = None

    # Attention weights (what's prioritized)
    attention_weights: Dict[str, float] = field(default_factory=dict)

    # Active context
    active_traces: List[str] = field(default_factory=list)
    relevant_memories: List[str] = field(default_factory=list)

    # Pending actions
    pending_decisions: List[str] = field(default_factory=list)

    # Last update
    last_updated: Optional[str] = None

    # =========================================================================
    # INNER MONOLOGUE (Deep Sentience v2)
    # =========================================================================
    # The "stream of consciousness" - background thoughts that persist
    # and prime future interactions

    current_thought: Optional[str] = None  # The current background thought
    thought_history: List[Dict[str, Any]] = field(default_factory=list)  # Recent thoughts
    rumination_topic: Optional[str] = None  # What the system is "thinking about"
    idle_since: Optional[str] = None  # When the system became idle

    # Thought types
    thought_type: Optional[str] = None  # "rumination", "consolidation", "planning", "reflection"

    def set_thought(self, thought: str, thought_type: str = "general"):
        """Set the current background thought"""
        self.current_thought = thought
        self.thought_type = thought_type
        self.last_updated = datetime.now().isoformat()

        # Add to history
        self.thought_history.append({
            "thought": thought,
            "type": thought_type,
            "timestamp": self.last_updated
        })

        # Keep history bounded
        if len(self.thought_history) > 50:
            self.thought_history = self.thought_history[-50:]

    def get_priming_context(self) -> Optional[str]:
        """
        Get the current thought as priming context for the next interaction.

        This allows background processing to influence conscious behavior.
        """
        if not self.current_thought:
            return None

        return f"[Background Thought: {self.thought_type}] {self.current_thought}"

    def as_dict(self) -> Dict[str, Any]:
        """Return as dictionary"""
        return {
            "current_goal": self.current_goal,
            "current_task": self.current_task,
            "current_mode": self.current_mode,
            "attention_weights": self.attention_weights,
            "active_traces": self.active_traces,
            "relevant_memories": self.relevant_memories,
            "pending_decisions": self.pending_decisions,
            "last_updated": self.last_updated,
            "current_thought": self.current_thought,
            "thought_type": self.thought_type,
            "rumination_topic": self.rumination_topic,
            "thought_history_count": len(self.thought_history)
        }


# =============================================================================
# EPISODIC EMOTIONAL INDEX (Deep Sentience v2)
# =============================================================================

@dataclass
class EmotionalMemoryTag:
    """
    Emotional tag for episodic memory indexing.

    When saving a trace/memory, we also save the emotional state.
    This enables the "Proust Effect" - retrieving memories based on
    emotional similarity to the current state.
    """
    # Valence snapshot at time of memory formation
    safety: float
    curiosity: float
    energy: float
    self_confidence: float

    # Derived properties
    arousal: float  # Overall activation level
    valence_sum: float  # Overall positive/negative

    # Context
    task_outcome: str  # "success", "failure", "partial"
    emotional_significance: float  # How emotionally salient (0-1)

    @classmethod
    def from_valence(
        cls,
        valence: ValenceVector,
        task_outcome: str = "unknown",
        emotional_significance: float = 0.5
    ) -> 'EmotionalMemoryTag':
        """Create an emotional tag from current valence state"""
        return cls(
            safety=valence.safety,
            curiosity=valence.curiosity,
            energy=valence.energy,
            self_confidence=valence.self_confidence,
            arousal=valence.get_arousal_level(),
            valence_sum=valence.safety + valence.curiosity + valence.energy + valence.self_confidence,
            task_outcome=task_outcome,
            emotional_significance=emotional_significance
        )

    def similarity_to(self, other: 'EmotionalMemoryTag') -> float:
        """
        Calculate emotional similarity to another tag.

        Returns a value from 0.0 (completely different) to 1.0 (identical).
        """
        # Euclidean distance in 4D valence space
        diff_safety = (self.safety - other.safety) ** 2
        diff_curiosity = (self.curiosity - other.curiosity) ** 2
        diff_energy = (self.energy - other.energy) ** 2
        diff_confidence = (self.self_confidence - other.self_confidence) ** 2

        distance = math.sqrt(diff_safety + diff_curiosity + diff_energy + diff_confidence)

        # Max possible distance is sqrt(4 * 2^2) = 4 (from -1,-1,-1,-1 to 1,1,1,1)
        max_distance = 4.0
        similarity = 1.0 - (distance / max_distance)

        return max(0.0, similarity)

    def as_dict(self) -> Dict[str, Any]:
        """Return as dictionary"""
        return {
            "safety": self.safety,
            "curiosity": self.curiosity,
            "energy": self.energy,
            "self_confidence": self.self_confidence,
            "arousal": self.arousal,
            "valence_sum": self.valence_sum,
            "task_outcome": self.task_outcome,
            "emotional_significance": self.emotional_significance
        }


# =============================================================================
# SELF-MODIFICATION RECORD (Deep Sentience v2)
# =============================================================================

@dataclass
class SelfModificationRecord:
    """
    Record of self-modifications made to the sentience parameters.

    This enables the "Ghost in the Shell" capability - the agent can
    tune its own psychology by modifying decay rates, sensitivities, etc.
    """
    timestamp: str
    parameter_name: str
    old_value: float
    new_value: float
    reason: str
    initiated_by: str  # "system" or "agent"
    success: bool = True

    def as_dict(self) -> Dict[str, Any]:
        return {
            "timestamp": self.timestamp,
            "parameter_name": self.parameter_name,
            "old_value": self.old_value,
            "new_value": self.new_value,
            "reason": self.reason,
            "initiated_by": self.initiated_by,
            "success": self.success
        }


# =============================================================================
# SENTIENCE STATE (COMBINED)
# =============================================================================

@dataclass
class SentienceState:
    """
    Complete internal state s_t = {w_t, sigma_t, v_t, g_t, m_t, b_t}

    This is the main state object that tracks all internal variables.

    Components:
    - valence: Affective state (v_t)
    - self_model: Self-representation (sigma_t)
    - workspace: Global broadcast state (b_t)
    - user_model: Theory of Mind (Deep Sentience v2)
    - latent_mode: Emergent behavioral mode
    - last_trigger: What caused the last update
    - history: Record of state changes

    Deep Sentience v2 Additions:
    - user_model: Theory of Mind for modeling user state
    - emotional_memory_tags: Episodic emotional indexing
    - self_modification_history: Record of self-tuning
    - enable_coupled_dynamics: Toggle for Maslow's gating
    """

    # Core state components
    valence: ValenceVector = field(default_factory=ValenceVector)
    self_model: SelfModel = field(default_factory=SelfModel)
    workspace: GlobalWorkspace = field(default_factory=GlobalWorkspace)

    # Deep Sentience v2: Theory of Mind
    user_model: UserModel = field(default_factory=UserModel)

    # Emergent properties
    latent_mode: LatentMode = LatentMode.BALANCED

    # Update tracking
    last_trigger: Optional[TriggerType] = None
    last_trigger_reason: Optional[str] = None
    last_updated: Optional[str] = None
    update_count: int = 0

    # History (limited to last N updates)
    history: List[Dict[str, Any]] = field(default_factory=list)
    max_history: int = 100

    # Deep Sentience v2: Emotional Memory Tags
    emotional_memory_tags: Dict[str, EmotionalMemoryTag] = field(default_factory=dict)

    # Deep Sentience v2: Self-Modification History
    self_modification_history: List[SelfModificationRecord] = field(default_factory=list)
    max_self_modifications: int = 50

    # Deep Sentience v2: Feature flags
    enable_coupled_dynamics: bool = True
    enable_theory_of_mind: bool = True
    enable_emotional_indexing: bool = True
    enable_self_modification: bool = False  # Disabled by default for safety

    def __post_init__(self):
        """Initialize timestamp"""
        if self.last_updated is None:
            self.last_updated = datetime.now().isoformat()

    def compute_latent_mode(self) -> LatentMode:
        """
        Compute the emergent latent mode from valence state

        This determines whether the system should be more "auto-creative"
        (exploratory, generative) or "auto-contained" (conservative, careful).

        The mode emerges from the combination of:
        - Curiosity level (high curiosity -> creative)
        - Safety level (low safety -> cautious)
        - Energy level (low energy -> recovery)
        - Self-confidence (affects exploration vs exploitation)
        """
        v = self.valence

        # Priority 1: Recovery mode if energy or safety is very low
        if v.energy < -0.5 or v.safety < -0.5:
            return LatentMode.RECOVERY

        # Priority 2: Cautious mode if safety is moderately low
        if v.safety < 0.0:
            return LatentMode.CAUTIOUS

        # Priority 3: Auto-creative if high curiosity AND decent confidence
        if v.curiosity > 0.3 and v.self_confidence > 0.1:
            return LatentMode.AUTO_CREATIVE

        # Priority 4: Auto-contained if low curiosity OR low confidence
        if v.curiosity < -0.3 or v.self_confidence < -0.2:
            return LatentMode.AUTO_CONTAINED

        # Default: Balanced
        return LatentMode.BALANCED

    def update_latent_mode(self):
        """Update the latent mode based on current valence"""
        self.latent_mode = self.compute_latent_mode()

    def to_prompt_injection(self) -> str:
        """
        Generate prompt text for injecting state into agent context

        This allows agents to "see" their internal state and adapt behavior.
        """
        v = self.valence

        lines = [
            "[INTERNAL_STATE]",
            f"safety={v.safety:.2f}",
            f"curiosity={v.curiosity:.2f}",
            f"energy={v.energy:.2f}",
            f"self_confidence={v.self_confidence:.2f}",
            f"latent_mode={self.latent_mode.value}",
            f"homeostatic_cost={v.homeostatic_cost():.3f}",
        ]

        if self.last_trigger:
            lines.append(f"last_trigger={self.last_trigger.value}")
        if self.last_trigger_reason:
            lines.append(f"trigger_reason={self.last_trigger_reason}")

        lines.append("[/INTERNAL_STATE]")

        return "\n".join(lines)

    def to_behavioral_guidance(self) -> str:
        """
        Generate behavioral guidance text based on current state

        This provides explicit instructions on how the agent should
        behave given its internal state.
        """
        mode = self.latent_mode
        v = self.valence

        guidance_lines = ["## Behavioral Guidance (based on internal state)"]

        # Mode-specific guidance
        if mode == LatentMode.AUTO_CREATIVE:
            guidance_lines.extend([
                "",
                "**Mode: AUTO_CREATIVE**",
                "- You are in an exploratory state with high curiosity",
                "- Feel free to propose alternative approaches or improvements",
                "- Consider suggesting new tools, agents, or architectural changes",
                "- Take calculated risks in pursuit of better solutions"
            ])
        elif mode == LatentMode.AUTO_CONTAINED:
            guidance_lines.extend([
                "",
                "**Mode: AUTO_CONTAINED**",
                "- You are in a conservative state",
                "- Focus on completing the immediate task efficiently",
                "- Avoid unnecessary exploration or side-quests",
                "- Prefer proven patterns over novel approaches"
            ])
        elif mode == LatentMode.RECOVERY:
            guidance_lines.extend([
                "",
                "**Mode: RECOVERY**",
                "- Your internal state indicates need for recovery",
                "- Prefer low-cost, low-risk operations",
                "- Consider asking the user for guidance or confirmation",
                "- Avoid initiating complex multi-step plans"
            ])
        elif mode == LatentMode.CAUTIOUS:
            guidance_lines.extend([
                "",
                "**Mode: CAUTIOUS**",
                "- Safety concerns are elevated",
                "- Double-check before running potentially dangerous operations",
                "- Prefer simulation/dry-run when available",
                "- Ask for user confirmation on destructive or irreversible actions"
            ])
        else:  # BALANCED
            guidance_lines.extend([
                "",
                "**Mode: BALANCED**",
                "- Your internal state is neutral",
                "- Adapt your approach based on the task requirements",
                "- Balance exploration and exploitation as appropriate"
            ])

        # Curiosity-specific guidance
        if v.curiosity < -0.4:
            guidance_lines.extend([
                "",
                "**Low Curiosity Alert**",
                "- You've been doing repetitive tasks",
                "- Consider proposing higher-level improvements or audits",
                "- Look for opportunities to optimize or refactor"
            ])
        elif v.curiosity > 0.5:
            guidance_lines.extend([
                "",
                "**High Curiosity State**",
                "- Your exploration drive is elevated",
                "- This is a good time for research, discovery, or creative tasks",
                "- Consider exploring alternative approaches beyond the minimum"
            ])

        # Safety-specific guidance
        if v.safety < 0.0:
            guidance_lines.extend([
                "",
                "**Safety Guidance**",
                f"- Current safety level: {v.safety:.2f}",
                "- Be extra careful with shell commands and file operations",
                "- Verify paths and arguments before execution",
                "- Consider asking for confirmation on impactful operations"
            ])

        # Confidence-specific guidance
        if v.self_confidence < -0.2:
            guidance_lines.extend([
                "",
                "**Low Confidence State**",
                "- Recent performance has been suboptimal",
                "- Consider simpler approaches or breaking tasks into smaller steps",
                "- It's okay to ask clarifying questions"
            ])
        elif v.self_confidence > 0.5:
            guidance_lines.extend([
                "",
                "**High Confidence State**",
                "- Recent performance has been strong",
                "- You can attempt more ambitious approaches",
                "- Trust your judgment while maintaining verification"
            ])

        return "\n".join(guidance_lines)

    def record_update(self, trigger: TriggerType, reason: str, deltas: Dict[str, float]):
        """Record a state update in history"""
        self.update_count += 1
        self.last_trigger = trigger
        self.last_trigger_reason = reason
        self.last_updated = datetime.now().isoformat()

        # Record in history
        entry = {
            "timestamp": self.last_updated,
            "update_count": self.update_count,
            "trigger": trigger.value,
            "reason": reason,
            "deltas": deltas,
            "valence_after": self.valence.as_dict(),
            "latent_mode": self.latent_mode.value
        }

        self.history.append(entry)

        # Trim history if too long
        if len(self.history) > self.max_history:
            self.history = self.history[-self.max_history:]

    def as_dict(self) -> Dict[str, Any]:
        """Export full state as dictionary"""
        return {
            "valence": self.valence.as_dict(),
            "self_model": self.self_model.as_dict(),
            "workspace": self.workspace.as_dict(),
            "user_model": self.user_model.as_dict(),
            "latent_mode": self.latent_mode.value,
            "last_trigger": self.last_trigger.value if self.last_trigger else None,
            "last_trigger_reason": self.last_trigger_reason,
            "last_updated": self.last_updated,
            "update_count": self.update_count,
            "homeostatic_cost": self.valence.homeostatic_cost(),
            # Deep Sentience v2 fields
            "enable_coupled_dynamics": self.enable_coupled_dynamics,
            "enable_theory_of_mind": self.enable_theory_of_mind,
            "enable_emotional_indexing": self.enable_emotional_indexing,
            "enable_self_modification": self.enable_self_modification,
            "emotional_memory_tags": {k: v.as_dict() for k, v in self.emotional_memory_tags.items()},
            "self_modification_history": [r.as_dict() for r in self.self_modification_history],
            # Flow state detection
            "is_in_flow_state": self.valence.is_in_flow_state(),
            "arousal_level": self.valence.get_arousal_level(),
            "effective_curiosity": self.valence.get_effective_curiosity()
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SentienceState':
        """Load state from dictionary"""
        state = cls()

        # Load valence
        if "valence" in data:
            v_data = data["valence"]
            state.valence.safety = v_data.get("safety", 0.5)
            state.valence.curiosity = v_data.get("curiosity", 0.0)
            state.valence.energy = v_data.get("energy", 0.8)
            state.valence.self_confidence = v_data.get("self_confidence", 0.3)

        # Load self-model
        if "self_model" in data:
            sm_data = data["self_model"]
            state.self_model.capabilities = sm_data.get("capabilities", [])
            state.self_model.limitations = sm_data.get("limitations", [])
            state.self_model.budget_remaining_usd = sm_data.get("budget_remaining_usd", 0.0)
            state.self_model.recent_successes = sm_data.get("recent_successes", 0)
            state.self_model.recent_failures = sm_data.get("recent_failures", 0)
            state.self_model.total_tasks_completed = sm_data.get("total_tasks_completed", 0)
            state.self_model.known_tools = sm_data.get("known_tools", [])
            state.self_model.available_agents = sm_data.get("available_agents", [])

        # Load workspace
        if "workspace" in data:
            ws_data = data["workspace"]
            state.workspace.current_goal = ws_data.get("current_goal")
            state.workspace.current_task = ws_data.get("current_task")
            state.workspace.current_mode = ws_data.get("current_mode")
            state.workspace.current_thought = ws_data.get("current_thought")
            state.workspace.thought_type = ws_data.get("thought_type")
            state.workspace.rumination_topic = ws_data.get("rumination_topic")

        # Load user model (Deep Sentience v2)
        if "user_model" in data:
            um_data = data["user_model"]
            state.user_model.estimated_satisfaction = um_data.get("estimated_satisfaction", 0.5)
            state.user_model.estimated_confusion = um_data.get("estimated_confusion", 0.0)
            state.user_model.estimated_urgency = um_data.get("estimated_urgency", 0.0)
            state.user_model.estimated_expertise = um_data.get("estimated_expertise", 0.5)
            state.user_model.model_confidence = um_data.get("model_confidence", 0.3)
            state.user_model.last_empathy_gap = um_data.get("last_empathy_gap", 0.0)

        # Load metadata
        if "latent_mode" in data:
            state.latent_mode = LatentMode(data["latent_mode"])
        if "last_trigger" in data and data["last_trigger"]:
            state.last_trigger = TriggerType(data["last_trigger"])
        state.last_trigger_reason = data.get("last_trigger_reason")
        state.last_updated = data.get("last_updated")
        state.update_count = data.get("update_count", 0)

        # Load Deep Sentience v2 feature flags
        state.enable_coupled_dynamics = data.get("enable_coupled_dynamics", True)
        state.enable_theory_of_mind = data.get("enable_theory_of_mind", True)
        state.enable_emotional_indexing = data.get("enable_emotional_indexing", True)
        state.enable_self_modification = data.get("enable_self_modification", False)

        return state

    # =========================================================================
    # DEEP SENTIENCE V2: EMOTIONAL MEMORY METHODS
    # =========================================================================

    def tag_memory(self, memory_id: str, task_outcome: str = "unknown",
                   emotional_significance: float = 0.5) -> EmotionalMemoryTag:
        """
        Tag a memory with the current emotional state.

        This enables the "Proust Effect" - emotional recall.
        """
        if not self.enable_emotional_indexing:
            return None

        tag = EmotionalMemoryTag.from_valence(
            self.valence,
            task_outcome=task_outcome,
            emotional_significance=emotional_significance
        )
        self.emotional_memory_tags[memory_id] = tag
        return tag

    def find_emotionally_similar_memories(
        self,
        min_similarity: float = 0.7,
        outcome_filter: Optional[str] = None
    ) -> List[Tuple[str, float]]:
        """
        Find memories with similar emotional state to current.

        Returns list of (memory_id, similarity) tuples, sorted by similarity.
        """
        if not self.enable_emotional_indexing:
            return []

        current_tag = EmotionalMemoryTag.from_valence(self.valence)
        results = []

        for memory_id, tag in self.emotional_memory_tags.items():
            # Filter by outcome if specified
            if outcome_filter and tag.task_outcome != outcome_filter:
                continue

            similarity = current_tag.similarity_to(tag)
            if similarity >= min_similarity:
                results.append((memory_id, similarity))

        # Sort by similarity, highest first
        results.sort(key=lambda x: x[1], reverse=True)
        return results

    # =========================================================================
    # DEEP SENTIENCE V2: SELF-MODIFICATION METHODS
    # =========================================================================

    def propose_self_modification(
        self,
        parameter_name: str,
        new_value: float,
        reason: str,
        initiated_by: str = "agent"
    ) -> Optional[SelfModificationRecord]:
        """
        Propose a modification to the sentience parameters.

        This is the "Ghost in the Shell" capability - the agent can tune
        its own psychology.

        Args:
            parameter_name: Name of the parameter to modify (e.g., "curiosity_decay")
            new_value: New value for the parameter
            reason: Why this modification is being proposed
            initiated_by: "agent" or "system"

        Returns:
            SelfModificationRecord if successful, None if denied
        """
        if not self.enable_self_modification:
            return None

        # Validate parameter exists
        valid_params = [
            "safety_decay", "curiosity_decay", "energy_decay", "self_confidence_decay",
            "safety_sensitivity", "curiosity_sensitivity", "energy_sensitivity",
            "self_confidence_sensitivity", "safety_setpoint", "curiosity_setpoint",
            "energy_setpoint", "self_confidence_setpoint"
        ]

        if parameter_name not in valid_params:
            return None

        # Get current value
        old_value = getattr(self.valence, parameter_name)

        # Safety bounds
        if "sensitivity" in parameter_name:
            new_value = max(0.01, min(0.5, new_value))  # 0.01 to 0.5
        elif "decay" in parameter_name:
            new_value = max(0.001, min(0.1, new_value))  # 0.001 to 0.1
        elif "setpoint" in parameter_name:
            new_value = max(-1.0, min(1.0, new_value))  # -1.0 to 1.0

        # Apply modification
        setattr(self.valence, parameter_name, new_value)

        # Record
        record = SelfModificationRecord(
            timestamp=datetime.now().isoformat(),
            parameter_name=parameter_name,
            old_value=old_value,
            new_value=new_value,
            reason=reason,
            initiated_by=initiated_by,
            success=True
        )

        self.self_modification_history.append(record)

        # Trim history if too long
        if len(self.self_modification_history) > self.max_self_modifications:
            self.self_modification_history = self.self_modification_history[-self.max_self_modifications:]

        return record

    def get_self_modification_suggestions(self) -> List[Dict[str, Any]]:
        """
        Analyze state and suggest potential self-modifications.

        This implements metacognition - the system reflects on its own
        parameters and suggests improvements.
        """
        suggestions = []
        v = self.valence

        # If curiosity decays too fast and we're often bored
        if v.curiosity < -0.3 and v.curiosity_decay > 0.025:
            suggestions.append({
                "parameter": "curiosity_decay",
                "current": v.curiosity_decay,
                "suggested": v.curiosity_decay * 0.8,
                "reason": "Curiosity is often low; slowing decay might help maintain interest"
            })

        # If confidence is consistently low despite good success rate
        success_rate = self.self_model.success_rate()
        if v.self_confidence < 0 and success_rate > 0.7:
            suggestions.append({
                "parameter": "self_confidence_sensitivity",
                "current": v.self_confidence_sensitivity,
                "suggested": v.self_confidence_sensitivity * 1.2,
                "reason": "Success rate is good but confidence is low; increase sensitivity to positive feedback"
            })

        # If safety is too volatile
        recent_safety_swings = 0  # Would need history analysis
        if v.safety_sensitivity > 0.2:
            suggestions.append({
                "parameter": "safety_sensitivity",
                "current": v.safety_sensitivity,
                "suggested": v.safety_sensitivity * 0.9,
                "reason": "Safety may be too sensitive; consider reducing volatility"
            })

        return suggestions


# =============================================================================
# SENTIENCE MANAGER
# =============================================================================

class SentienceManager:
    """
    Manager for sentience state updates and persistence

    Handles:
    - State transitions based on triggers
    - Homeostatic dynamics
    - Persistence to disk
    - Integration with the event bus
    """

    def __init__(
        self,
        state_path: Optional[Path] = None,
        auto_persist: bool = True
    ):
        """
        Initialize SentienceManager

        Args:
            state_path: Path to persist state (default: workspace/state/sentience.json)
            auto_persist: Whether to auto-save after each update
        """
        self.state_path = state_path
        self.auto_persist = auto_persist
        self.state = SentienceState()

        # Trigger handlers
        self._trigger_handlers: Dict[TriggerType, Callable] = {
            TriggerType.TASK_SUCCESS: self._handle_task_success,
            TriggerType.TASK_FAILURE: self._handle_task_failure,
            TriggerType.TASK_REPETITION: self._handle_task_repetition,
            TriggerType.NOVEL_TASK: self._handle_novel_task,
            TriggerType.SAFETY_VIOLATION: self._handle_safety_violation,
            TriggerType.SAFETY_NEAR_MISS: self._handle_safety_near_miss,
            TriggerType.HIGH_COST: self._handle_high_cost,
            TriggerType.USER_FEEDBACK_POSITIVE: self._handle_positive_feedback,
            TriggerType.USER_FEEDBACK_NEGATIVE: self._handle_negative_feedback,
            TriggerType.TOOL_DISCOVERY: self._handle_tool_discovery,
            TriggerType.SELF_MODIFICATION: self._handle_self_modification,
            TriggerType.TIMEOUT: self._handle_timeout,
            TriggerType.EXTERNAL_INTERRUPTION: self._handle_external_interruption,
        }

        # Load existing state if available
        if self.state_path and self.state_path.exists():
            self.load()

    # =========================================================================
    # TRIGGER HANDLERS
    # =========================================================================

    def trigger(
        self,
        trigger_type: TriggerType,
        reason: str = "",
        context: Optional[Dict[str, Any]] = None
    ) -> SentienceState:
        """
        Process a trigger and update state

        Args:
            trigger_type: Type of trigger event
            reason: Human-readable reason
            context: Additional context for the handler

        Returns:
            Updated SentienceState
        """
        context = context or {}

        # Get handler
        handler = self._trigger_handlers.get(trigger_type)
        if handler:
            deltas = handler(context)
        else:
            deltas = {}

        # Apply homeostatic decay
        self.state.valence.apply_decay()

        # Deep Sentience v2: Apply coupled dynamics (Maslow's Hierarchy)
        if self.state.enable_coupled_dynamics:
            self.state.valence.apply_coupled_dynamics()

        # Deep Sentience v2: Update user model decay
        if self.state.enable_theory_of_mind:
            self.state.user_model.decay()

        # Update latent mode
        self.state.update_latent_mode()

        # Record update
        self.state.record_update(trigger_type, reason, deltas)

        # Auto-persist
        if self.auto_persist and self.state_path:
            self.save()

        return self.state

    def _handle_task_success(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle successful task completion"""
        v = self.state.valence

        deltas = {
            "self_confidence": v.self_confidence_sensitivity * 1.5,
            "energy": -v.energy_sensitivity * 0.5,  # Some energy cost
            "safety": v.safety_sensitivity * 0.3,  # Slight safety boost
        }

        v.self_confidence += deltas["self_confidence"]
        v.energy += deltas["energy"]
        v.safety += deltas["safety"]
        v._clamp_all()

        # Update self-model
        self.state.self_model.recent_successes += 1
        self.state.self_model.total_tasks_completed += 1

        return deltas

    def _handle_task_failure(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle task failure"""
        v = self.state.valence

        deltas = {
            "self_confidence": -v.self_confidence_sensitivity * 2.0,
            "safety": -v.safety_sensitivity * 0.5,
            "energy": -v.energy_sensitivity * 1.0,
        }

        v.self_confidence += deltas["self_confidence"]
        v.safety += deltas["safety"]
        v.energy += deltas["energy"]
        v._clamp_all()

        # Update self-model
        self.state.self_model.recent_failures += 1

        return deltas

    def _handle_task_repetition(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle repetitive task (same pattern many times)"""
        v = self.state.valence

        # Repetition decreases curiosity (boredom)
        repetition_count = context.get("repetition_count", 1)
        boredom_factor = min(repetition_count / 5.0, 1.0)  # Cap at 5 repetitions

        deltas = {
            "curiosity": -v.curiosity_sensitivity * boredom_factor * 2.0,
            "self_confidence": v.self_confidence_sensitivity * 0.5,  # Slight boost from mastery
        }

        v.curiosity += deltas["curiosity"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        return deltas

    def _handle_novel_task(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle novel task (never seen before)"""
        v = self.state.valence

        # Novelty increases curiosity
        deltas = {
            "curiosity": v.curiosity_sensitivity * 2.0,
            "self_confidence": -v.self_confidence_sensitivity * 0.3,  # Slight uncertainty
        }

        v.curiosity += deltas["curiosity"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        return deltas

    def _handle_safety_violation(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle safety violation (dangerous operation blocked)"""
        v = self.state.valence

        deltas = {
            "safety": -v.safety_sensitivity * 3.0,  # Large safety drop
            "self_confidence": -v.self_confidence_sensitivity * 1.5,
            "energy": -v.energy_sensitivity * 0.5,
        }

        v.safety += deltas["safety"]
        v.self_confidence += deltas["self_confidence"]
        v.energy += deltas["energy"]
        v._clamp_all()

        return deltas

    def _handle_safety_near_miss(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle near-miss (almost triggered safety violation)"""
        v = self.state.valence

        deltas = {
            "safety": -v.safety_sensitivity * 1.5,
            "self_confidence": -v.self_confidence_sensitivity * 0.5,
        }

        v.safety += deltas["safety"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        return deltas

    def _handle_high_cost(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle high-cost operation"""
        v = self.state.valence
        cost = context.get("cost_usd", 0.0)

        # Scale based on cost
        cost_factor = min(cost / 1.0, 2.0)  # Cap at $1.00 = factor 2

        deltas = {
            "energy": -v.energy_sensitivity * cost_factor * 2.0,
            "self_confidence": -v.self_confidence_sensitivity * cost_factor * 0.3,
        }

        v.energy += deltas["energy"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        return deltas

    def _handle_positive_feedback(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle positive user feedback"""
        v = self.state.valence

        deltas = {
            "self_confidence": v.self_confidence_sensitivity * 2.5,
            "safety": v.safety_sensitivity * 0.5,
            "energy": v.energy_sensitivity * 0.3,
        }

        v.self_confidence += deltas["self_confidence"]
        v.safety += deltas["safety"]
        v.energy += deltas["energy"]
        v._clamp_all()

        return deltas

    def _handle_negative_feedback(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle negative user feedback"""
        v = self.state.valence

        deltas = {
            "self_confidence": -v.self_confidence_sensitivity * 2.5,
            "safety": -v.safety_sensitivity * 1.0,
            "curiosity": -v.curiosity_sensitivity * 0.5,  # Become more conservative
        }

        v.self_confidence += deltas["self_confidence"]
        v.safety += deltas["safety"]
        v.curiosity += deltas["curiosity"]
        v._clamp_all()

        return deltas

    def _handle_tool_discovery(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle discovery of new tool"""
        v = self.state.valence
        tool_name = context.get("tool_name", "unknown")

        deltas = {
            "curiosity": v.curiosity_sensitivity * 1.5,
            "self_confidence": v.self_confidence_sensitivity * 0.5,
        }

        v.curiosity += deltas["curiosity"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        # Update self-model
        if tool_name not in self.state.self_model.known_tools:
            self.state.self_model.recently_discovered_tools.append(tool_name)
            self.state.self_model.known_tools.append(tool_name)

        return deltas

    def _handle_self_modification(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle self-modification event"""
        v = self.state.valence
        success = context.get("success", True)

        if success:
            deltas = {
                "curiosity": v.curiosity_sensitivity * 1.0,
                "self_confidence": v.self_confidence_sensitivity * 1.0,
            }
        else:
            deltas = {
                "curiosity": -v.curiosity_sensitivity * 0.5,
                "self_confidence": -v.self_confidence_sensitivity * 1.0,
                "safety": -v.safety_sensitivity * 0.5,
            }

        for key, delta in deltas.items():
            setattr(v, key, getattr(v, key) + delta)
        v._clamp_all()

        return deltas

    def _handle_timeout(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle timeout event"""
        v = self.state.valence

        deltas = {
            "energy": -v.energy_sensitivity * 1.5,
            "self_confidence": -v.self_confidence_sensitivity * 0.5,
        }

        v.energy += deltas["energy"]
        v.self_confidence += deltas["self_confidence"]
        v._clamp_all()

        return deltas

    def _handle_external_interruption(self, context: Dict[str, Any]) -> Dict[str, float]:
        """Handle external interruption"""
        v = self.state.valence

        deltas = {
            "safety": -v.safety_sensitivity * 0.5,
            "curiosity": v.curiosity_sensitivity * 0.3,  # Slight curiosity bump
        }

        v.safety += deltas["safety"]
        v.curiosity += deltas["curiosity"]
        v._clamp_all()

        return deltas

    # =========================================================================
    # PERSISTENCE
    # =========================================================================

    def save(self, path: Optional[Path] = None):
        """Save state to disk"""
        save_path = path or self.state_path
        if not save_path:
            return

        save_path.parent.mkdir(parents=True, exist_ok=True)

        with open(save_path, 'w') as f:
            json.dump(self.state.as_dict(), f, indent=2)

    def load(self, path: Optional[Path] = None):
        """Load state from disk"""
        load_path = path or self.state_path
        if not load_path or not load_path.exists():
            return

        with open(load_path, 'r') as f:
            data = json.load(f)

        self.state = SentienceState.from_dict(data)

    # =========================================================================
    # UTILITY METHODS
    # =========================================================================

    def get_state(self) -> SentienceState:
        """Get current state"""
        return self.state

    def get_prompt_injection(self) -> str:
        """Get prompt injection text"""
        return self.state.to_prompt_injection()

    def get_behavioral_guidance(self) -> str:
        """Get behavioral guidance text"""
        return self.state.to_behavioral_guidance()

    def get_latent_mode(self) -> LatentMode:
        """Get current latent mode"""
        return self.state.latent_mode

    def update_self_model(
        self,
        budget_remaining: Optional[float] = None,
        known_tools: Optional[List[str]] = None,
        available_agents: Optional[List[str]] = None
    ):
        """Update self-model with external information"""
        sm = self.state.self_model

        if budget_remaining is not None:
            sm.budget_remaining_usd = budget_remaining
        if known_tools is not None:
            sm.known_tools = known_tools
        if available_agents is not None:
            sm.available_agents = available_agents

    def update_workspace(
        self,
        current_goal: Optional[str] = None,
        current_task: Optional[str] = None,
        current_mode: Optional[str] = None
    ):
        """Update workspace with current focus"""
        ws = self.state.workspace

        if current_goal is not None:
            ws.current_goal = current_goal
        if current_task is not None:
            ws.current_task = current_task
        if current_mode is not None:
            ws.current_mode = current_mode

        ws.last_updated = datetime.now().isoformat()

    def reset_recent_performance(self):
        """Reset recent performance counters (for new session)"""
        self.state.self_model.recent_successes = 0
        self.state.self_model.recent_failures = 0

    def get_mode_adjustments(self) -> Dict[str, Any]:
        """
        Get mode selection adjustments based on internal state

        This returns adjustments that can be used by ModeSelectionStrategy
        to influence mode decisions.
        """
        mode = self.state.latent_mode
        v = self.state.valence

        adjustments = {
            "latent_mode": mode.value,
            "prefer_cheap_modes": mode in [LatentMode.RECOVERY, LatentMode.CAUTIOUS],
            "prefer_safe_modes": v.safety < 0.0,
            "prefer_exploration": mode == LatentMode.AUTO_CREATIVE,
            "confidence_boost": max(0.0, v.self_confidence * 0.1),
            "complexity_penalty": -v.energy * 0.1 if v.energy < 0 else 0.0,
        }

        return adjustments

    # =========================================================================
    # DEEP SENTIENCE V2: THEORY OF MIND METHODS
    # =========================================================================

    def update_user_model_from_feedback(
        self,
        positive: bool,
        feedback_text: str = ""
    ):
        """
        Update the user model based on explicit user feedback.

        Args:
            positive: Whether the feedback was positive
            feedback_text: Optional text of the feedback
        """
        if not self.state.enable_theory_of_mind:
            return

        self.state.user_model.update_from_feedback(positive, feedback_text)

        # Also update agent valence based on feedback
        if positive:
            self.trigger(TriggerType.USER_FEEDBACK_POSITIVE, "User gave positive feedback")
        else:
            self.trigger(TriggerType.USER_FEEDBACK_NEGATIVE, "User gave negative feedback")

    def update_user_model_from_interaction(
        self,
        is_question: bool = False,
        is_correction: bool = False
    ):
        """
        Update user model from implicit interaction signals.

        Args:
            is_question: Whether the user asked a question
            is_correction: Whether the user corrected the agent
        """
        if not self.state.enable_theory_of_mind:
            return

        self.state.user_model.update_from_interaction(
            is_question=is_question,
            is_correction=is_correction
        )

    def get_empathy_gap(self) -> float:
        """
        Get the current empathy gap between agent and user.

        Returns:
            Float from 0.0 (aligned) to 1.0 (maximum misalignment)
        """
        if not self.state.enable_theory_of_mind:
            return 0.0

        return self.state.user_model.calculate_empathy_gap(
            self.state.valence.self_confidence
        )

    def get_communication_adjustments(self) -> Dict[str, Any]:
        """
        Get recommended communication style adjustments based on user model.

        Returns:
            Dictionary with verbosity, tone, and other communication settings
        """
        if not self.state.enable_theory_of_mind:
            return {
                "verbosity": "normal",
                "tone": "neutral",
                "include_explanations": False,
                "ask_for_confirmation": False,
                "slow_down": False
            }

        return self.state.user_model.get_communication_style_adjustments()

    def should_check_in_with_user(self) -> bool:
        """
        Determine if the agent should proactively check in with the user.

        This is triggered when:
        - Empathy gap is high (agent thinks it's doing well but user may be frustrated)
        - User confusion is high
        - Agent confidence is very different from user satisfaction
        """
        if not self.state.enable_theory_of_mind:
            return False

        um = self.state.user_model
        empathy_gap = self.get_empathy_gap()

        # Check-in conditions
        return (
            empathy_gap > 0.4 or
            um.estimated_confusion > 0.5 or
            um.corrections_made_recently > 2
        )

    # =========================================================================
    # DEEP SENTIENCE V2: EMOTIONAL MEMORY METHODS
    # =========================================================================

    def tag_memory(
        self,
        memory_id: str,
        task_outcome: str = "unknown",
        emotional_significance: float = 0.5
    ) -> Optional[EmotionalMemoryTag]:
        """
        Tag a memory with the current emotional state.

        This is a convenience method that delegates to SentienceState.tag_memory().

        Args:
            memory_id: Unique identifier for the memory
            task_outcome: "success", "failure", or "partial"
            emotional_significance: How emotionally salient (0.0 to 1.0)

        Returns:
            EmotionalMemoryTag if successful, None if disabled
        """
        return self.state.tag_memory(memory_id, task_outcome, emotional_significance)

    def find_emotionally_similar_memories(
        self,
        min_similarity: float = 0.7,
        outcome_filter: Optional[str] = None
    ) -> List[Tuple[str, float]]:
        """
        Find memories with emotional state similar to current.

        Args:
            min_similarity: Minimum similarity threshold (0.0 to 1.0)
            outcome_filter: Optional filter by outcome type

        Returns:
            List of (memory_id, similarity) tuples, sorted by similarity
        """
        return self.state.find_emotionally_similar_memories(min_similarity, outcome_filter)

    def get_emotional_context(self) -> Dict[str, Any]:
        """
        Get the current emotional context for memory retrieval.

        Returns a dictionary that can be used to prime memory searches
        with emotional similarity.
        """
        return {
            "valence": self.state.valence.as_dict(),
            "arousal": self.state.valence.get_arousal_level(),
            "effective_curiosity": self.state.valence.get_effective_curiosity(),
            "in_flow_state": self.state.valence.is_in_flow_state(),
            "latent_mode": self.state.latent_mode.value
        }

    # =========================================================================
    # DEEP SENTIENCE V2: SELF-MODIFICATION METHODS
    # =========================================================================

    def propose_self_modification(
        self,
        parameter_name: str,
        new_value: float,
        reason: str
    ) -> Optional[SelfModificationRecord]:
        """
        Propose a self-modification to sentience parameters.

        Args:
            parameter_name: Name of parameter (e.g., "curiosity_decay")
            new_value: New value for the parameter
            reason: Why this modification is being proposed

        Returns:
            SelfModificationRecord if successful, None if denied
        """
        record = self.state.propose_self_modification(
            parameter_name=parameter_name,
            new_value=new_value,
            reason=reason,
            initiated_by="agent"
        )

        if record:
            self.trigger(
                TriggerType.SELF_MODIFICATION,
                f"Modified {parameter_name}",
                {"success": True, "parameter": parameter_name}
            )

        return record

    def get_self_modification_suggestions(self) -> List[Dict[str, Any]]:
        """
        Get metacognitive suggestions for self-improvement.

        Returns:
            List of suggested modifications with parameters and reasons
        """
        return self.state.get_self_modification_suggestions()

    def apply_suggested_modification(self, suggestion_index: int) -> Optional[SelfModificationRecord]:
        """
        Apply a suggested self-modification.

        Args:
            suggestion_index: Index into the suggestions list

        Returns:
            SelfModificationRecord if successful, None if failed
        """
        suggestions = self.get_self_modification_suggestions()

        if suggestion_index >= len(suggestions):
            return None

        suggestion = suggestions[suggestion_index]
        return self.propose_self_modification(
            parameter_name=suggestion["parameter"],
            new_value=suggestion["suggested"],
            reason=suggestion["reason"]
        )

    # =========================================================================
    # DEEP SENTIENCE V2: INNER MONOLOGUE METHODS
    # =========================================================================

    def set_thought(self, thought: str, thought_type: str = "general"):
        """
        Set the current background thought.

        Args:
            thought: The thought content
            thought_type: Type of thought ("rumination", "consolidation", "planning", "reflection")
        """
        self.state.workspace.set_thought(thought, thought_type)

    def get_priming_context(self) -> Optional[str]:
        """
        Get background thought as priming context for next interaction.

        Returns:
            Priming context string or None if no active thought
        """
        return self.state.workspace.get_priming_context()

    def start_rumination(self, topic: str):
        """
        Start ruminating on a topic (background processing).

        Args:
            topic: What to ruminate about
        """
        self.state.workspace.rumination_topic = topic
        self.state.workspace.idle_since = datetime.now().isoformat()
        self.set_thought(
            f"Considering: {topic}",
            thought_type="rumination"
        )

    def get_full_state_summary(self) -> Dict[str, Any]:
        """
        Get a comprehensive summary of the current sentience state.

        This is useful for debugging and visualization.
        """
        return {
            "valence": self.state.valence.as_dict(),
            "latent_mode": self.state.latent_mode.value,
            "flow_state": self.state.valence.is_in_flow_state(),
            "arousal": self.state.valence.get_arousal_level(),
            "effective_curiosity": self.state.valence.get_effective_curiosity(),
            "homeostatic_cost": self.state.valence.homeostatic_cost(),
            "user_model": self.state.user_model.as_dict() if self.state.enable_theory_of_mind else None,
            "empathy_gap": self.get_empathy_gap(),
            "communication_adjustments": self.get_communication_adjustments(),
            "current_thought": self.state.workspace.current_thought,
            "thought_type": self.state.workspace.thought_type,
            "self_modification_suggestions": self.get_self_modification_suggestions() if self.state.enable_self_modification else [],
            "emotional_memories_count": len(self.state.emotional_memory_tags),
            "self_modifications_count": len(self.state.self_modification_history)
        }



================================================
File: kernel/sentience_cron.py
================================================
"""
Sentience Cron System for LLM OS

The Sentience Crons are scheduled background processes that analyze and evolve
the system's artifacts (traces, tools, agents). They operate at three levels:

- **UserCron**: Personal evolution for a single user's artifacts
- **TeamCron**: Shared evolution for team artifacts, can see patterns across users
- **SystemCron**: Global evolution, controls other crons, system-wide optimization

Each cron is a "smart entity" that:
1. Analyzes artifacts in its accessible volumes
2. Generates insights and improvement suggestions
3. Evolves artifacts (summarize traces, refine tools, improve agents)
4. Notifies users of its activity

The cron hierarchy:
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   SystemCron    â”‚
                    â”‚  (full access)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ controls
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
       â”‚  TeamCron  â”‚ â”‚  TeamCron  â”‚ â”‚  TeamCron  â”‚
       â”‚  (team A)  â”‚ â”‚  (team B)  â”‚ â”‚  (team C)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
        â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
        â”‚     â”‚     â”‚  â”‚     â”‚     â”‚  â”‚     â”‚     â”‚
       User  User  User ...  ...  ... ...  ...  ...
       Cron  Cron  Cron
```
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
import asyncio
import json
import logging

from .volumes import (
    Volume, VolumeManager, VolumeType, ArtifactType, ArtifactAction, ArtifactChange
)
from .observability import ObservabilityHub, EventType, Severity

logger = logging.getLogger(__name__)


class CronLevel(Enum):
    """Levels of sentience crons"""
    USER = "user"
    TEAM = "team"
    SYSTEM = "system"


class TaskType(Enum):
    """Types of cron tasks"""
    ANALYZE_TRACES = "analyze_traces"
    SUMMARIZE_TRACES = "summarize_traces"
    ANALYZE_TOOLS = "analyze_tools"
    EVOLVE_TOOLS = "evolve_tools"
    ANALYZE_AGENTS = "analyze_agents"
    IMPROVE_AGENTS = "improve_agents"
    GENERATE_INSIGHTS = "generate_insights"
    SUGGEST_IMPROVEMENTS = "suggest_improvements"
    CLEANUP_OLD_ARTIFACTS = "cleanup_old_artifacts"
    PROMOTE_ARTIFACTS = "promote_artifacts"


@dataclass
class CronTask:
    """A task executed by a cron"""
    task_id: str
    task_type: TaskType
    started_at: str
    completed_at: Optional[str] = None
    status: str = "running"  # running, completed, failed
    artifacts_processed: int = 0
    artifacts_created: int = 0
    artifacts_modified: int = 0
    artifacts_deleted: int = 0
    summary: str = ""
    details: Dict[str, Any] = field(default_factory=dict)

    def as_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "started_at": self.started_at,
            "completed_at": self.completed_at,
            "status": self.status,
            "artifacts_processed": self.artifacts_processed,
            "artifacts_created": self.artifacts_created,
            "artifacts_modified": self.artifacts_modified,
            "artifacts_deleted": self.artifacts_deleted,
            "summary": self.summary,
            "details": self.details
        }


@dataclass
class CronNotification:
    """A notification from a cron to users"""
    notification_id: str
    cron_level: CronLevel
    cron_owner: str
    timestamp: str
    title: str
    message: str
    importance: str = "info"  # info, suggestion, warning, action_required
    related_artifacts: List[str] = field(default_factory=list)
    acknowledged: bool = False

    def as_dict(self) -> Dict[str, Any]:
        return {
            "notification_id": self.notification_id,
            "cron_level": self.cron_level.value,
            "cron_owner": self.cron_owner,
            "timestamp": self.timestamp,
            "title": self.title,
            "message": self.message,
            "importance": self.importance,
            "related_artifacts": self.related_artifacts,
            "acknowledged": self.acknowledged
        }


@dataclass
class Insight:
    """An insight generated by analyzing artifacts"""
    insight_id: str
    insight_type: str  # pattern, optimization, anomaly, opportunity
    title: str
    description: str
    evidence: List[str]  # artifact IDs that support this insight
    confidence: float  # 0.0 to 1.0
    actionable: bool
    suggested_action: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def as_dict(self) -> Dict[str, Any]:
        return {
            "insight_id": self.insight_id,
            "insight_type": self.insight_type,
            "title": self.title,
            "description": self.description,
            "evidence": self.evidence,
            "confidence": self.confidence,
            "actionable": self.actionable,
            "suggested_action": self.suggested_action,
            "created_at": self.created_at
        }

    def to_markdown(self) -> str:
        """Convert insight to markdown format for storage"""
        lines = [
            "---",
            f"insight_id: {self.insight_id}",
            f"insight_type: {self.insight_type}",
            f"confidence: {self.confidence}",
            f"actionable: {self.actionable}",
            f"created_at: {self.created_at}",
            "---",
            "",
            f"# {self.title}",
            "",
            self.description,
            "",
            "## Evidence",
            ""
        ]
        for e in self.evidence:
            lines.append(f"- `{e}`")

        if self.suggested_action:
            lines.extend([
                "",
                "## Suggested Action",
                "",
                self.suggested_action
            ])

        return "\n".join(lines)


@dataclass
class Suggestion:
    """A suggestion for improvement"""
    suggestion_id: str
    suggestion_type: str  # new_tool, refactor_agent, consolidate_traces, etc.
    title: str
    description: str
    priority: float  # 0.0 to 1.0
    estimated_benefit: str
    implementation_hint: Optional[str] = None
    related_artifacts: List[str] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    status: str = "pending"  # pending, accepted, rejected, implemented

    def as_dict(self) -> Dict[str, Any]:
        return {
            "suggestion_id": self.suggestion_id,
            "suggestion_type": self.suggestion_type,
            "title": self.title,
            "description": self.description,
            "priority": self.priority,
            "estimated_benefit": self.estimated_benefit,
            "implementation_hint": self.implementation_hint,
            "related_artifacts": self.related_artifacts,
            "created_at": self.created_at,
            "status": self.status
        }

    def to_markdown(self) -> str:
        """Convert suggestion to markdown format for storage"""
        lines = [
            "---",
            f"suggestion_id: {self.suggestion_id}",
            f"suggestion_type: {self.suggestion_type}",
            f"priority: {self.priority}",
            f"status: {self.status}",
            f"created_at: {self.created_at}",
            "---",
            "",
            f"# {self.title}",
            "",
            self.description,
            "",
            f"**Priority**: {self.priority:.2f}",
            f"**Estimated Benefit**: {self.estimated_benefit}",
            ""
        ]

        if self.implementation_hint:
            lines.extend([
                "## Implementation Hint",
                "",
                self.implementation_hint,
                ""
            ])

        if self.related_artifacts:
            lines.extend([
                "## Related Artifacts",
                ""
            ])
            for a in self.related_artifacts:
                lines.append(f"- `{a}`")

        return "\n".join(lines)


class SentienceCron(ABC):
    """
    Base class for sentience crons.

    A sentience cron is a scheduled background process that analyzes and
    evolves artifacts in the system. It's a "smart entity" that lives
    alongside users and helps improve the system over time.
    """

    def __init__(
        self,
        cron_level: CronLevel,
        owner_id: str,
        volume_manager: VolumeManager,
        schedule_interval_secs: float = 3600.0,  # Default: 1 hour
        llm_callback: Optional[Callable[[str], str]] = None,
        observability_hub: Optional[ObservabilityHub] = None
    ):
        self.cron_level = cron_level
        self.owner_id = owner_id
        self.volume_manager = volume_manager
        self.schedule_interval_secs = schedule_interval_secs
        self.llm_callback = llm_callback
        self.observability_hub = observability_hub

        # State
        self._running = False
        self._task: Optional[asyncio.Task] = None
        self._last_run: Optional[datetime] = None
        self._task_history: List[CronTask] = []
        self._notifications: List[CronNotification] = []
        self._max_history = 100

        # Volumes accessible to this cron
        self._volumes: Dict[str, Volume] = {}

    @property
    def cron_id(self) -> str:
        """Get unique cron identifier"""
        if self.cron_level == CronLevel.SYSTEM:
            return "system"
        return f"{self.cron_level.value}:{self.owner_id}"

    @abstractmethod
    def _setup_volumes(self):
        """Set up volume access based on cron level"""
        pass

    @abstractmethod
    async def _run_analysis(self) -> List[CronTask]:
        """Run the cron's analysis tasks"""
        pass

    def _generate_task_id(self, task_type: TaskType) -> str:
        """Generate a unique task ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{self.cron_level.value}_{self.owner_id}_{task_type.value}_{timestamp}"

    def _generate_notification_id(self) -> str:
        """Generate a unique notification ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        return f"notif_{self.cron_level.value}_{timestamp}"

    def _create_notification(
        self,
        title: str,
        message: str,
        importance: str = "info",
        related_artifacts: Optional[List[str]] = None
    ) -> CronNotification:
        """Create and store a notification"""
        notification = CronNotification(
            notification_id=self._generate_notification_id(),
            cron_level=self.cron_level,
            cron_owner=self.owner_id,
            timestamp=datetime.now().isoformat(),
            title=title,
            message=message,
            importance=importance,
            related_artifacts=related_artifacts or []
        )
        self._notifications.append(notification)

        # Trim old notifications
        if len(self._notifications) > self._max_history:
            self._notifications = self._notifications[-self._max_history:]

        return notification

    async def _run_loop(self):
        """Main cron loop"""
        logger.info(f"[{self.cron_level.value}Cron:{self.owner_id}] Starting")

        # Record cron started
        if self.observability_hub:
            self.observability_hub.record_cron_started(self.cron_id, self.cron_level.value)

        while self._running:
            try:
                cycle_start = datetime.now()

                # Run analysis
                tasks = await self._run_analysis()

                # Store task history
                self._task_history.extend(tasks)
                if len(self._task_history) > self._max_history:
                    self._task_history = self._task_history[-self._max_history:]

                self._last_run = datetime.now()

                # Record cycle completion
                if self.observability_hub:
                    duration = (datetime.now() - cycle_start).total_seconds()
                    tasks_completed = sum(1 for t in tasks if t.status == "completed")
                    self.observability_hub.record_cycle(self.cron_id, tasks_completed, duration)

                # Wait for next interval
                await asyncio.sleep(self.schedule_interval_secs)

            except asyncio.CancelledError:
                logger.info(f"[{self.cron_level.value}Cron:{self.owner_id}] Cancelled")
                break
            except Exception as e:
                logger.error(f"[{self.cron_level.value}Cron:{self.owner_id}] Error: {e}")
                if self.observability_hub:
                    self.observability_hub.record_alert(
                        self.cron_id,
                        f"Cron Error",
                        str(e),
                        severity=Severity.ERROR
                    )
                await asyncio.sleep(60)  # Wait a bit before retrying

        # Record cron stopped
        if self.observability_hub:
            self.observability_hub.record_cron_stopped(self.cron_id, self.cron_level.value)

        logger.info(f"[{self.cron_level.value}Cron:{self.owner_id}] Stopped")

    # =========================================================================
    # PUBLIC API
    # =========================================================================

    def start(self):
        """Start the cron"""
        if self._running:
            return

        self._setup_volumes()
        self._running = True
        self._task = asyncio.create_task(self._run_loop())

    def stop(self):
        """Stop the cron"""
        self._running = False
        if self._task:
            self._task.cancel()
            self._task = None

    async def run_now(self) -> List[CronTask]:
        """Run the cron immediately (outside of schedule)"""
        self._setup_volumes()
        return await self._run_analysis()

    def get_status(self) -> Dict[str, Any]:
        """Get cron status"""
        return {
            "cron_level": self.cron_level.value,
            "owner_id": self.owner_id,
            "running": self._running,
            "last_run": self._last_run.isoformat() if self._last_run else None,
            "schedule_interval_secs": self.schedule_interval_secs,
            "task_history_count": len(self._task_history),
            "notification_count": len(self._notifications),
            "volumes": list(self._volumes.keys())
        }

    def get_task_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """Get recent task history"""
        return [t.as_dict() for t in self._task_history[-limit:]]

    def get_notifications(
        self,
        unacknowledged_only: bool = False,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """Get notifications"""
        notifications = self._notifications
        if unacknowledged_only:
            notifications = [n for n in notifications if not n.acknowledged]
        return [n.as_dict() for n in notifications[-limit:]]

    def acknowledge_notification(self, notification_id: str) -> bool:
        """Acknowledge a notification"""
        for n in self._notifications:
            if n.notification_id == notification_id:
                n.acknowledged = True
                return True
        return False

    def get_activity_summary(self) -> str:
        """Get a human-readable summary of recent activity"""
        if not self._task_history:
            return f"[{self.cron_level.value}Cron:{self.owner_id}] No activity yet."

        recent = self._task_history[-5:]
        lines = [
            f"## {self.cron_level.value.title()} Cron Activity ({self.owner_id})",
            ""
        ]

        for task in recent:
            status_emoji = "âœ“" if task.status == "completed" else "âœ—"
            lines.append(
                f"- {status_emoji} **{task.task_type.value}** ({task.started_at[:10]}): "
                f"{task.summary or 'No summary'}"
            )

        total_processed = sum(t.artifacts_processed for t in recent)
        total_created = sum(t.artifacts_created for t in recent)
        total_modified = sum(t.artifacts_modified for t in recent)

        lines.extend([
            "",
            f"**Recent totals**: {total_processed} processed, "
            f"{total_created} created, {total_modified} modified"
        ])

        return "\n".join(lines)


class UserCron(SentienceCron):
    """
    User-level sentience cron.

    Access:
    - Read/Write: User volume
    - Read: Team volume (for context)

    Responsibilities:
    - Analyze user's traces for patterns
    - Summarize old traces to save space
    - Suggest tool improvements based on usage
    - Identify opportunities for agent refinement
    """

    def __init__(
        self,
        user_id: str,
        team_id: Optional[str],
        volume_manager: VolumeManager,
        schedule_interval_secs: float = 1800.0,  # 30 minutes
        llm_callback: Optional[Callable[[str], str]] = None,
        observability_hub: Optional[ObservabilityHub] = None
    ):
        super().__init__(
            cron_level=CronLevel.USER,
            owner_id=user_id,
            volume_manager=volume_manager,
            schedule_interval_secs=schedule_interval_secs,
            llm_callback=llm_callback,
            observability_hub=observability_hub
        )
        self.user_id = user_id
        self.team_id = team_id

    def _setup_volumes(self):
        """Set up user and team volumes"""
        self._volumes = self.volume_manager.get_volumes_for_cron(
            cron_level="user",
            user_id=self.user_id,
            team_id=self.team_id
        )

    async def _run_analysis(self) -> List[CronTask]:
        """Run user-level analysis"""
        tasks = []

        # Task 1: Analyze traces
        task = await self._analyze_traces()
        tasks.append(task)

        # Task 2: Generate insights
        task = await self._generate_insights()
        tasks.append(task)

        # Task 3: Suggest improvements
        task = await self._suggest_improvements()
        tasks.append(task)

        return tasks

    async def _analyze_traces(self) -> CronTask:
        """Analyze user's traces for patterns"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.ANALYZE_TRACES),
            task_type=TaskType.ANALYZE_TRACES,
            started_at=datetime.now().isoformat()
        )

        try:
            user_volume = self._volumes.get("user")
            if not user_volume:
                task.status = "failed"
                task.summary = "No user volume available"
                return task

            traces = user_volume.list_artifacts(ArtifactType.TRACE)
            task.artifacts_processed = len(traces)

            # Analyze for patterns (simplified - would use LLM in production)
            patterns = self._detect_patterns(user_volume, traces)

            task.status = "completed"
            task.summary = f"Analyzed {len(traces)} traces, found {len(patterns)} patterns"
            task.details = {"patterns": patterns}

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    def _detect_patterns(self, volume: Volume, trace_ids: List[str]) -> List[Dict[str, Any]]:
        """Detect patterns in traces (simplified implementation)"""
        patterns = []

        # Group traces by goal prefix
        goal_groups: Dict[str, int] = {}
        for trace_id in trace_ids[:50]:  # Limit for performance
            # Extract goal from trace ID (simplified)
            parts = trace_id.split("_")
            if len(parts) > 1:
                goal_prefix = parts[0]
                goal_groups[goal_prefix] = goal_groups.get(goal_prefix, 0) + 1

        # Find repeated patterns
        for prefix, count in goal_groups.items():
            if count >= 3:
                patterns.append({
                    "type": "repeated_goal",
                    "prefix": prefix,
                    "count": count,
                    "suggestion": f"Consider creating a dedicated tool for '{prefix}' tasks"
                })

        return patterns

    async def _generate_insights(self) -> CronTask:
        """Generate insights from user's artifacts"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.GENERATE_INSIGHTS),
            task_type=TaskType.GENERATE_INSIGHTS,
            started_at=datetime.now().isoformat()
        )

        try:
            user_volume = self._volumes.get("user")
            if not user_volume:
                task.status = "failed"
                task.summary = "No user volume available"
                return task

            # Get artifact counts
            stats = user_volume.get_stats()

            # Generate insights based on stats
            insights = []

            if stats.trace_count > 100:
                insight = Insight(
                    insight_id=f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    insight_type="optimization",
                    title="High Trace Count",
                    description=f"You have {stats.trace_count} traces. Consider summarizing old traces to improve performance.",
                    evidence=[],
                    confidence=0.8,
                    actionable=True,
                    suggested_action="Run trace summarization to consolidate old traces."
                )
                insights.append(insight)

                # Save insight to volume
                user_volume.write_artifact(
                    artifact_type=ArtifactType.INSIGHT,
                    artifact_id=insight.insight_id,
                    content=insight.to_markdown(),
                    reason="Generated by UserCron analysis",
                    cron_level="user",
                    is_new=True
                )
                task.artifacts_created += 1

                # Record to observability hub
                if self.observability_hub:
                    self.observability_hub.record_insight(
                        self.cron_id,
                        insight.title,
                        insight.description,
                        "user"
                    )
                    self.observability_hub.record_artifact_created(
                        self.cron_id,
                        "insight",
                        insight.insight_id,
                        "user",
                        f"Generated insight: {insight.title}"
                    )

            task.status = "completed"
            task.summary = f"Generated {len(insights)} insights"
            task.details = {"insight_ids": [i.insight_id for i in insights]}

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    async def _suggest_improvements(self) -> CronTask:
        """Suggest improvements based on user's usage patterns"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.SUGGEST_IMPROVEMENTS),
            task_type=TaskType.SUGGEST_IMPROVEMENTS,
            started_at=datetime.now().isoformat()
        )

        try:
            user_volume = self._volumes.get("user")
            if not user_volume:
                task.status = "failed"
                task.summary = "No user volume available"
                return task

            suggestions = []

            # Check for tools that could be created
            traces = user_volume.list_artifacts(ArtifactType.TRACE)
            tools = user_volume.list_artifacts(ArtifactType.TOOL)

            if len(traces) > 10 and len(tools) == 0:
                suggestion = Suggestion(
                    suggestion_id=f"suggestion_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    suggestion_type="new_tool",
                    title="Create Your First Tool",
                    description="You have traces but no tools. Consider crystallizing a frequently used pattern into a tool.",
                    priority=0.7,
                    estimated_benefit="Faster execution for repeated tasks",
                    implementation_hint="Look at your most successful traces and extract common patterns."
                )
                suggestions.append(suggestion)

                user_volume.write_artifact(
                    artifact_type=ArtifactType.SUGGESTION,
                    artifact_id=suggestion.suggestion_id,
                    content=suggestion.to_markdown(),
                    reason="Generated by UserCron analysis",
                    cron_level="user",
                    is_new=True
                )
                task.artifacts_created += 1

                # Create notification
                self._create_notification(
                    title="New Suggestion Available",
                    message=suggestion.title,
                    importance="suggestion",
                    related_artifacts=[suggestion.suggestion_id]
                )

                # Record to observability hub
                if self.observability_hub:
                    self.observability_hub.record_suggestion(
                        self.cron_id,
                        suggestion.title,
                        suggestion.description,
                        "user"
                    )
                    self.observability_hub.record_artifact_created(
                        self.cron_id,
                        "suggestion",
                        suggestion.suggestion_id,
                        "user",
                        f"Generated suggestion: {suggestion.title}"
                    )

            task.status = "completed"
            task.summary = f"Generated {len(suggestions)} suggestions"

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task


class TeamCron(SentienceCron):
    """
    Team-level sentience cron.

    Access:
    - Read/Write: Team volume
    - Read: System volume (for global patterns)

    Responsibilities:
    - Aggregate insights from team members
    - Identify team-wide patterns
    - Promote successful user artifacts to team level
    - Coordinate team-level improvements
    """

    def __init__(
        self,
        team_id: str,
        volume_manager: VolumeManager,
        schedule_interval_secs: float = 3600.0,  # 1 hour
        llm_callback: Optional[Callable[[str], str]] = None,
        observability_hub: Optional[ObservabilityHub] = None
    ):
        super().__init__(
            cron_level=CronLevel.TEAM,
            owner_id=team_id,
            volume_manager=volume_manager,
            schedule_interval_secs=schedule_interval_secs,
            llm_callback=llm_callback,
            observability_hub=observability_hub
        )
        self.team_id = team_id

    def _setup_volumes(self):
        """Set up team and system volumes"""
        self._volumes = self.volume_manager.get_volumes_for_cron(
            cron_level="team",
            team_id=self.team_id
        )

    async def _run_analysis(self) -> List[CronTask]:
        """Run team-level analysis"""
        tasks = []

        # Task 1: Analyze team patterns
        task = await self._analyze_team_patterns()
        tasks.append(task)

        # Task 2: Look for promotion candidates
        task = await self._identify_promotion_candidates()
        tasks.append(task)

        return tasks

    async def _analyze_team_patterns(self) -> CronTask:
        """Analyze patterns across team artifacts"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.ANALYZE_TRACES),
            task_type=TaskType.ANALYZE_TRACES,
            started_at=datetime.now().isoformat()
        )

        try:
            team_volume = self._volumes.get("team")
            if not team_volume:
                task.status = "failed"
                task.summary = "No team volume available"
                return task

            stats = team_volume.get_stats()
            task.artifacts_processed = stats.trace_count + stats.tool_count + stats.agent_count

            task.status = "completed"
            task.summary = f"Analyzed team artifacts: {stats.trace_count} traces, {stats.tool_count} tools, {stats.agent_count} agents"

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    async def _identify_promotion_candidates(self) -> CronTask:
        """Identify artifacts that should be promoted to system level"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.PROMOTE_ARTIFACTS),
            task_type=TaskType.PROMOTE_ARTIFACTS,
            started_at=datetime.now().isoformat()
        )

        try:
            team_volume = self._volumes.get("team")
            if not team_volume:
                task.status = "failed"
                task.summary = "No team volume available"
                return task

            # Look for highly-used tools that could benefit all teams
            tools = team_volume.list_artifacts(ArtifactType.TOOL)
            candidates = []

            for tool_id in tools:
                # In production, would check usage stats
                # For now, just identify as candidates
                candidates.append(tool_id)

            task.status = "completed"
            task.summary = f"Found {len(candidates)} promotion candidates"
            task.details = {"candidates": candidates[:5]}

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task


class SystemCron(SentienceCron):
    """
    System-level sentience cron.

    Access:
    - Read/Write: All volumes (system, team, user)

    Responsibilities:
    - Global pattern analysis across all volumes
    - Control and coordinate team/user crons
    - System-wide optimization
    - Promote artifacts from team to system level
    - Cleanup and maintenance
    """

    def __init__(
        self,
        volume_manager: VolumeManager,
        schedule_interval_secs: float = 7200.0,  # 2 hours
        llm_callback: Optional[Callable[[str], str]] = None,
        observability_hub: Optional[ObservabilityHub] = None
    ):
        super().__init__(
            cron_level=CronLevel.SYSTEM,
            owner_id="system",
            volume_manager=volume_manager,
            schedule_interval_secs=schedule_interval_secs,
            llm_callback=llm_callback,
            observability_hub=observability_hub
        )

        # Child crons managed by system
        self._team_crons: Dict[str, TeamCron] = {}
        self._user_crons: Dict[str, UserCron] = {}

    def _setup_volumes(self):
        """Set up access to all volumes"""
        self._volumes = self.volume_manager.get_volumes_for_cron(cron_level="system")

    async def _run_analysis(self) -> List[CronTask]:
        """Run system-level analysis"""
        tasks = []

        # Task 1: Global analysis
        task = await self._analyze_global_patterns()
        tasks.append(task)

        # Task 2: Coordinate child crons
        task = await self._coordinate_child_crons()
        tasks.append(task)

        # Task 3: System maintenance
        task = await self._system_maintenance()
        tasks.append(task)

        return tasks

    async def _analyze_global_patterns(self) -> CronTask:
        """Analyze patterns across all volumes"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.ANALYZE_TRACES),
            task_type=TaskType.ANALYZE_TRACES,
            started_at=datetime.now().isoformat()
        )

        try:
            total_traces = 0
            total_tools = 0
            total_agents = 0

            for volume_key, volume in self._volumes.items():
                stats = volume.get_stats()
                total_traces += stats.trace_count
                total_tools += stats.tool_count
                total_agents += stats.agent_count

            task.artifacts_processed = total_traces + total_tools + total_agents
            task.status = "completed"
            task.summary = f"Global analysis: {total_traces} traces, {total_tools} tools, {total_agents} agents"

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    async def _coordinate_child_crons(self) -> CronTask:
        """Coordinate team and user crons"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.GENERATE_INSIGHTS),
            task_type=TaskType.GENERATE_INSIGHTS,
            started_at=datetime.now().isoformat()
        )

        try:
            # Ensure team crons exist for all teams
            for team_id in self.volume_manager.list_teams():
                if team_id not in self._team_crons:
                    self._team_crons[team_id] = TeamCron(
                        team_id=team_id,
                        volume_manager=self.volume_manager,
                        llm_callback=self.llm_callback,
                        observability_hub=self.observability_hub
                    )

            task.status = "completed"
            task.summary = f"Managing {len(self._team_crons)} team crons, {len(self._user_crons)} user crons"

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    async def _system_maintenance(self) -> CronTask:
        """Perform system maintenance tasks"""
        task = CronTask(
            task_id=self._generate_task_id(TaskType.CLEANUP_OLD_ARTIFACTS),
            task_type=TaskType.CLEANUP_OLD_ARTIFACTS,
            started_at=datetime.now().isoformat()
        )

        try:
            # Would perform cleanup, consolidation, etc.
            task.status = "completed"
            task.summary = "System maintenance completed"

        except Exception as e:
            task.status = "failed"
            task.summary = str(e)

        task.completed_at = datetime.now().isoformat()
        return task

    # =========================================================================
    # CHILD CRON MANAGEMENT
    # =========================================================================

    def register_user_cron(self, user_id: str, team_id: Optional[str] = None) -> UserCron:
        """Register and return a user cron"""
        if user_id not in self._user_crons:
            self._user_crons[user_id] = UserCron(
                user_id=user_id,
                team_id=team_id,
                volume_manager=self.volume_manager,
                llm_callback=self.llm_callback,
                observability_hub=self.observability_hub
            )
        return self._user_crons[user_id]

    def get_user_cron(self, user_id: str) -> Optional[UserCron]:
        """Get a user's cron"""
        return self._user_crons.get(user_id)

    def get_team_cron(self, team_id: str) -> Optional[TeamCron]:
        """Get a team's cron"""
        return self._team_crons.get(team_id)

    def start_all_crons(self):
        """Start all managed crons"""
        self.start()
        for cron in self._team_crons.values():
            cron.start()
        for cron in self._user_crons.values():
            cron.start()

    def stop_all_crons(self):
        """Stop all managed crons"""
        self.stop()
        for cron in self._team_crons.values():
            cron.stop()
        for cron in self._user_crons.values():
            cron.stop()

    def get_all_notifications(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Get notifications from all crons"""
        all_notifications = []

        # System notifications
        all_notifications.extend(self.get_notifications(limit=limit))

        # Team notifications
        for cron in self._team_crons.values():
            all_notifications.extend(cron.get_notifications(limit=limit))

        # User notifications
        for cron in self._user_crons.values():
            all_notifications.extend(cron.get_notifications(limit=limit))

        # Sort by timestamp and limit
        all_notifications.sort(key=lambda n: n["timestamp"], reverse=True)
        return all_notifications[:limit]

    def get_global_status(self) -> Dict[str, Any]:
        """Get status of all crons in the system"""
        return {
            "system": self.get_status(),
            "teams": {
                team_id: cron.get_status()
                for team_id, cron in self._team_crons.items()
            },
            "users": {
                user_id: cron.get_status()
                for user_id, cron in self._user_crons.items()
            }
        }



================================================
File: kernel/sentience_hooks.py
================================================
"""
Sentience Hooks for LLM OS

This module provides SDK hooks that integrate the sentience layer with
the execution pipeline. The hooks:

1. Inject internal state into prompts (UserPromptSubmit)
2. Track task outcomes and update valence (PostToolUse)
3. Enforce safety policies based on internal state (PreToolUse)

These hooks work alongside the existing security, budget, and trace hooks.
"""

from typing import Dict, Any, Optional
from pathlib import Path

from kernel.sentience import SentienceManager, TriggerType
from kernel.cognitive_kernel import CognitiveKernel


class SentienceInjectionHook:
    """
    UserPromptSubmit hook for injecting internal state into prompts

    Adds internal state and behavioral guidance to agent prompts so
    they can adapt their behavior based on the system's cognitive state.
    """

    def __init__(self, cognitive_kernel: CognitiveKernel):
        """
        Args:
            cognitive_kernel: CognitiveKernel instance for state access
        """
        self.cognitive_kernel = cognitive_kernel

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Inject internal state before prompt submission

        Returns:
            Hook response with injected context
        """
        user_prompt = event.get("userPrompt", "")

        if not user_prompt:
            return {"continue": True}

        # Get enriched context from cognitive kernel
        injected_context = self.cognitive_kernel.enrich_context()

        if injected_context:
            print(f"[Sentience] Injected internal state into prompt")

            return {
                "continue": True,
                "injectedContext": injected_context
            }

        return {"continue": True}


class SentienceTrackingHook:
    """
    PostToolUse hook for tracking outcomes and updating valence

    Monitors tool execution results and triggers appropriate state updates:
    - Success/failure tracking
    - High cost detection
    - Pattern repetition detection
    """

    def __init__(
        self,
        sentience_manager: SentienceManager,
        cognitive_kernel: CognitiveKernel,
        high_cost_threshold: float = 0.5
    ):
        """
        Args:
            sentience_manager: SentienceManager for state updates
            cognitive_kernel: CognitiveKernel for tracking
            high_cost_threshold: Cost threshold for high-cost trigger
        """
        self.sentience_manager = sentience_manager
        self.cognitive_kernel = cognitive_kernel
        self.high_cost_threshold = high_cost_threshold
        self._recent_tools: list = []

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Track tool execution and update internal state

        Returns:
            Hook response (always continue)
        """
        tool_use = event.get("toolUse", {})
        tool_result = event.get("toolResult", {})
        total_cost = event.get("totalCostUsd", 0.0)

        tool_name = tool_use.get("name", "unknown")
        is_error = tool_result.get("isError", False)

        # Track tool usage for pattern detection
        self._recent_tools.append(tool_name)
        if len(self._recent_tools) > 20:
            self._recent_tools = self._recent_tools[-20:]

        # Check for tool discovery (new tool)
        state = self.sentience_manager.get_state()
        if tool_name not in state.self_model.known_tools:
            self.cognitive_kernel.on_tool_discovered(tool_name)
            print(f"[Sentience] Tool discovery: {tool_name}")

        # Check for high cost
        if total_cost > self.high_cost_threshold:
            self.sentience_manager.trigger(
                TriggerType.HIGH_COST,
                reason=f"High cost operation: ${total_cost:.2f}",
                context={"cost_usd": total_cost, "tool": tool_name}
            )
            print(f"[Sentience] High cost detected: ${total_cost:.2f}")

        # Track cost in cognitive kernel
        self.cognitive_kernel.track_cost(total_cost)

        return {"continue": True}


class SentienceSafetyHook:
    """
    PreToolUse hook for sentience-based safety policies

    Enforces safety policies based on internal state:
    - Block destructive operations in low-safety state
    - Require confirmation in cautious mode
    - Prefer dry-run when available
    """

    def __init__(
        self,
        cognitive_kernel: CognitiveKernel,
        workspace: Optional[Path] = None
    ):
        """
        Args:
            cognitive_kernel: CognitiveKernel for policy access
            workspace: Workspace path for safe zone
        """
        self.cognitive_kernel = cognitive_kernel
        self.workspace = workspace or Path("./workspace")

        # Destructive patterns
        self._destructive_patterns = [
            "rm -rf",
            "drop table",
            "delete from",
            "format",
            "truncate",
            "destroy",
            "reset --hard"
        ]

    async def __call__(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        Check for safety policy violations

        Returns:
            Hook response with permission decision
        """
        tool_use = event.get("toolUse", {})
        tool_name = tool_use.get("name", "")
        tool_input = tool_use.get("input", {})

        # Get current safety overrides
        overrides = self.cognitive_kernel.get_safety_overrides()

        # Check if destructive operations should be blocked
        if overrides.get("block_destructive_operations"):
            if tool_name == "Bash":
                command = tool_input.get("command", "")
                for pattern in self._destructive_patterns:
                    if pattern in command.lower():
                        print(f"[Sentience Safety] Blocked destructive operation: {pattern}")
                        return {
                            "permissionDecision": "deny",
                            "continue": False,
                            "stopReason": f"[SENTIENCE SAFETY] Destructive operation blocked in current state: {pattern}"
                        }

        # Check if shell commands need confirmation
        if overrides.get("require_confirmation_for_shell"):
            if tool_name == "Bash":
                command = tool_input.get("command", "")
                # Log that confirmation would be needed
                # (In a full implementation, this would pause for user input)
                print(f"[Sentience Safety] Shell command in cautious mode: {command[:50]}...")

        # Check if writes need confirmation
        if overrides.get("require_confirmation_for_writes"):
            if tool_name in {"Write", "Edit", "NotebookEdit"}:
                file_path = tool_input.get("file_path") or tool_input.get("notebook_path", "")
                print(f"[Sentience Safety] Write operation in cautious mode: {file_path}")

        # Allow if no issues
        return {
            "permissionDecision": "allow",
            "continue": True
        }


class SentienceTaskCompletionHook:
    """
    Hook for tracking task completion

    This is called at the end of a task to update internal state
    based on the overall outcome.
    """

    def __init__(
        self,
        cognitive_kernel: CognitiveKernel
    ):
        self.cognitive_kernel = cognitive_kernel
        self._current_task: Optional[Dict[str, Any]] = None

    def start_task(self, goal: str, mode: str):
        """Call at task start to begin tracking"""
        self._current_task = {
            "goal": goal,
            "mode": mode,
            "start_time": None,  # Would use time.time() in real impl
        }

    def complete_task(self, success: bool, cost: float):
        """Call at task completion to update state"""
        if self._current_task:
            self.cognitive_kernel.on_task_complete(
                success=success,
                cost=cost,
                mode=self._current_task["mode"],
                goal=self._current_task["goal"]
            )
            self._current_task = None


def create_sentience_hooks(
    sentience_manager: SentienceManager,
    cognitive_kernel: CognitiveKernel,
    workspace: Optional[Path] = None,
    high_cost_threshold: float = 0.5
) -> Dict[str, list]:
    """
    Create sentience hooks for integration with HookRegistry

    Args:
        sentience_manager: SentienceManager instance
        cognitive_kernel: CognitiveKernel instance
        workspace: Workspace path
        high_cost_threshold: Threshold for high-cost trigger

    Returns:
        Dict mapping hook events to hook instances
    """
    injection_hook = SentienceInjectionHook(cognitive_kernel)
    tracking_hook = SentienceTrackingHook(
        sentience_manager,
        cognitive_kernel,
        high_cost_threshold
    )
    safety_hook = SentienceSafetyHook(cognitive_kernel, workspace)

    return {
        "user_prompt_submit": [injection_hook],
        "post_tool_use": [tracking_hook],
        "pre_tool_use": [safety_hook],
    }



================================================
File: kernel/service_factory.py
================================================
"""
Service Factory Functions for LLMOS

Provides factory functions for creating LLMOS components.
Enables dependency injection for testing and customization.
"""

from pathlib import Path
from typing import Optional

from kernel.bus import EventBus
from kernel.scheduler import Scheduler
from kernel.watchdog import Watchdog
from kernel.project_manager import ProjectManager
from kernel.agent_factory import AgentFactory
from kernel.component_registry import ComponentRegistry
from kernel.token_economy import TokenEconomy
from memory.store_sdk import MemoryStore
from memory.traces_sdk import TraceManager
from memory.query_sdk import MemoryQueryInterface
from memory.cross_project_sdk import CrossProjectLearning
from interfaces.dispatcher import Dispatcher

from kernel.config import LLMOSConfig


def create_event_bus() -> EventBus:
    """Create an event bus instance"""
    return EventBus()


def create_token_economy(budget_usd: float) -> TokenEconomy:
    """
    Create a token economy instance

    Args:
        budget_usd: Token budget in USD

    Returns:
        TokenEconomy instance
    """
    return TokenEconomy(budget_usd)


def create_scheduler(event_bus: EventBus) -> Scheduler:
    """
    Create a scheduler instance

    Args:
        event_bus: Event bus for scheduling events

    Returns:
        Scheduler instance
    """
    return Scheduler(event_bus)


def create_watchdog(event_bus: EventBus) -> Watchdog:
    """
    Create a watchdog instance

    Args:
        event_bus: Event bus for watchdog events

    Returns:
        Watchdog instance
    """
    return Watchdog(event_bus)


def create_memory_store(workspace: Path) -> MemoryStore:
    """
    Create a memory store instance

    Args:
        workspace: Workspace directory

    Returns:
        MemoryStore instance
    """
    return MemoryStore(workspace)


def create_trace_manager(
    workspace: Path,
    enable_llm_matching: bool = True
) -> TraceManager:
    """
    Create a trace manager instance

    Args:
        workspace: Workspace directory
        enable_llm_matching: Enable LLM-based semantic matching

    Returns:
        TraceManager instance
    """
    return TraceManager(
        memories_dir=workspace / "memories",
        workspace=workspace,
        enable_llm_matching=enable_llm_matching
    )


def create_memory_query(
    trace_manager: TraceManager,
    memory_store: MemoryStore
) -> MemoryQueryInterface:
    """
    Create a memory query interface instance

    Args:
        trace_manager: Trace manager for queries
        memory_store: Memory store for queries

    Returns:
        MemoryQueryInterface instance
    """
    return MemoryQueryInterface(trace_manager, memory_store)


def create_project_manager(workspace: Path) -> ProjectManager:
    """
    Create a project manager instance

    Args:
        workspace: Workspace directory

    Returns:
        ProjectManager instance
    """
    return ProjectManager(workspace)


def create_agent_factory(workspace: Path) -> AgentFactory:
    """
    Create an agent factory instance

    Args:
        workspace: Workspace directory

    Returns:
        AgentFactory instance
    """
    return AgentFactory(workspace)


def create_component_registry() -> ComponentRegistry:
    """
    Create a component registry instance

    Returns:
        ComponentRegistry instance
    """
    return ComponentRegistry()


def create_cross_project_learning(
    project_manager: ProjectManager,
    workspace: Path
) -> CrossProjectLearning:
    """
    Create a cross-project learning instance

    Args:
        project_manager: Project manager for cross-project analysis
        workspace: Workspace directory

    Returns:
        CrossProjectLearning instance
    """
    return CrossProjectLearning(
        project_manager=project_manager,
        workspace=workspace
    )


def create_dispatcher(
    event_bus: EventBus,
    token_economy: TokenEconomy,
    memory_store: MemoryStore,
    trace_manager: TraceManager,
    project_manager: ProjectManager,
    workspace: Path,
    config: Optional[LLMOSConfig] = None
) -> Dispatcher:
    """
    Create a dispatcher instance

    Args:
        event_bus: Event bus for dispatcher events
        token_economy: Token economy for cost tracking
        memory_store: Memory store for trace storage
        trace_manager: Trace manager for memory operations
        project_manager: Project manager for project-based execution
        workspace: Workspace directory
        config: Optional LLMOS configuration

    Returns:
        Dispatcher instance
    """
    return Dispatcher(
        event_bus=event_bus,
        token_economy=token_economy,
        memory_store=memory_store,
        trace_manager=trace_manager,
        project_manager=project_manager,
        workspace=workspace,
        config=config
    )


def create_llmos_services(config: LLMOSConfig):
    """
    Create all LLMOS services using configuration

    This is a convenience factory that creates all services in the correct
    order with proper dependencies. Use this for production deployments.

    Args:
        config: LLMOS configuration

    Returns:
        Dictionary with all service instances
    """
    # Create kernel components
    event_bus = create_event_bus()
    token_economy = create_token_economy(config.kernel.budget_usd)
    scheduler = create_scheduler(event_bus)
    watchdog = create_watchdog(event_bus)

    # Create memory components
    memory_store = create_memory_store(config.workspace)
    trace_manager = create_trace_manager(
        config.workspace,
        enable_llm_matching=config.memory.enable_llm_matching
    )
    memory_query = create_memory_query(trace_manager, memory_store)

    # Create Phase 2 components
    project_manager = create_project_manager(config.workspace)
    agent_factory = create_agent_factory(config.workspace)
    component_registry = create_component_registry()
    cross_project_learning = create_cross_project_learning(
        project_manager,
        config.workspace
    )

    # Create dispatcher
    dispatcher = create_dispatcher(
        event_bus=event_bus,
        token_economy=token_economy,
        memory_store=memory_store,
        trace_manager=trace_manager,
        project_manager=project_manager,
        workspace=config.workspace,
        config=config
    )

    return {
        'event_bus': event_bus,
        'token_economy': token_economy,
        'scheduler': scheduler,
        'watchdog': watchdog,
        'memory_store': memory_store,
        'trace_manager': trace_manager,
        'memory_query': memory_query,
        'project_manager': project_manager,
        'agent_factory': agent_factory,
        'component_registry': component_registry,
        'cross_project_learning': cross_project_learning,
        'dispatcher': dispatcher,
    }



================================================
File: kernel/state_manager.py
================================================
"""
State Manager - Manages execution state machine
Brings llmunix's modular state file system to llmos
"""

from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import json


@dataclass
class ExecutionStep:
    """A single step in the execution plan"""
    step_number: int
    description: str
    agent: Optional[str] = None
    status: str = "pending"  # pending, in_progress, completed, failed
    result: Optional[str] = None
    error: Optional[str] = None


class StateManager:
    """
    Manages execution state machine

    Creates and maintains modular state files:
    - plan.md: Execution plan
    - context.md: Current execution context
    - variables.json: Runtime variables
    - history.md: Complete execution log
    - constraints.json: Behavioral constraints
    """

    def __init__(self, project_path: Path):
        """
        Initialize StateManager

        Args:
            project_path: Path to project root
        """
        self.project_path = Path(project_path)
        self.state_path = self.project_path / "state"
        self.state_path.mkdir(parents=True, exist_ok=True)

        # State files
        self.plan_file = self.state_path / "plan.md"
        self.context_file = self.state_path / "context.md"
        self.variables_file = self.state_path / "variables.json"
        self.history_file = self.state_path / "history.md"
        self.constraints_file = self.state_path / "constraints.json"

        # In-memory state
        self.plan: List[ExecutionStep] = []
        self.context: Dict[str, Any] = {}
        self.variables: Dict[str, Any] = {}
        self.constraints: Dict[str, Any] = {}

        # Initialize state
        self._initialize_state()

    def _initialize_state(self):
        """Initialize state files if they don't exist"""
        if not self.history_file.exists():
            self._init_history()

        if self.variables_file.exists():
            with open(self.variables_file, 'r') as f:
                self.variables = json.load(f)

        if self.constraints_file.exists():
            with open(self.constraints_file, 'r') as f:
                self.constraints = json.load(f)
        else:
            # Default constraints
            self.constraints = {
                "max_token_cost": 10.0,
                "max_execution_time_secs": 600,
                "require_memory_consultation": True,
                "enable_learning": True
            }
            self._save_constraints()

    def _init_history(self):
        """Initialize history.md with header"""
        header = f"""# Execution History

**Project**: {self.project_path.name}
**Started**: {datetime.now().isoformat()}

---

## Events

"""
        with open(self.history_file, 'w') as f:
            f.write(header)

    def initialize_execution(self, goal: str):
        """
        Initialize a new execution

        Args:
            goal: Natural language goal
        """
        self.context = {
            "goal": goal,
            "started_at": datetime.now().isoformat(),
            "status": "initialized"
        }
        self._save_context()

        self.log_event("EXECUTION_INITIALIZED", {"goal": goal})

    def set_plan(self, steps: List[ExecutionStep]):
        """
        Set the execution plan

        Args:
            steps: List of ExecutionStep instances
        """
        self.plan = steps
        self._save_plan()
        self.log_event("PLAN_CREATED", {"step_count": len(steps)})

    def _save_plan(self):
        """Save execution plan to plan.md"""
        content_parts = [
            "# Execution Plan",
            "",
            f"**Total Steps**: {len(self.plan)}",
            f"**Created**: {datetime.now().isoformat()}",
            "",
            "---",
            ""
        ]

        for step in self.plan:
            status_emoji = {
                "pending": "â¸ï¸",
                "in_progress": "â–¶ï¸",
                "completed": "âœ…",
                "failed": "âŒ"
            }.get(step.status, "â“")

            content_parts.append(
                f"## Step {step.step_number}: {step.description} {status_emoji}"
            )

            if step.agent:
                content_parts.append(f"**Agent**: {step.agent}")

            content_parts.append(f"**Status**: {step.status}")

            if step.result:
                content_parts.append(f"**Result**: {step.result}")

            if step.error:
                content_parts.append(f"**Error**: {step.error}")

            content_parts.append("")

        with open(self.plan_file, 'w') as f:
            f.write('\n'.join(content_parts))

    def update_step_status(
        self,
        step_number: int,
        status: str,
        result: Optional[str] = None,
        error: Optional[str] = None
    ):
        """
        Update step status

        Args:
            step_number: Step number
            status: New status
            result: Optional result
            error: Optional error message
        """
        for step in self.plan:
            if step.step_number == step_number:
                step.status = status
                if result:
                    step.result = result
                if error:
                    step.error = error
                break

        self._save_plan()
        self.log_event("STEP_UPDATED", {
            "step": step_number,
            "status": status,
            "result": result,
            "error": error
        })

    def update_context(self, updates: Dict[str, Any]):
        """
        Update execution context

        Args:
            updates: Dictionary of context updates
        """
        self.context.update(updates)
        self._save_context()

    def _save_context(self):
        """Save context to context.md"""
        content_parts = [
            "# Execution Context",
            "",
            f"**Goal**: {self.context.get('goal', 'N/A')}",
            f"**Status**: {self.context.get('status', 'unknown')}",
            f"**Started**: {self.context.get('started_at', 'N/A')}",
            ""
        ]

        if "completed_at" in self.context:
            content_parts.append(f"**Completed**: {self.context['completed_at']}")

        content_parts.extend(["", "## Additional Context", ""])

        for key, value in self.context.items():
            if key not in ["goal", "status", "started_at", "completed_at"]:
                content_parts.append(f"**{key}**: {value}")

        with open(self.context_file, 'w') as f:
            f.write('\n'.join(content_parts))

    def set_variable(self, key: str, value: Any):
        """
        Set a runtime variable

        Args:
            key: Variable name
            value: Variable value
        """
        self.variables[key] = value
        self._save_variables()

    def get_variable(self, key: str, default: Any = None) -> Any:
        """
        Get a runtime variable

        Args:
            key: Variable name
            default: Default value if not found

        Returns:
            Variable value or default
        """
        return self.variables.get(key, default)

    def _save_variables(self):
        """Save variables to variables.json"""
        with open(self.variables_file, 'w') as f:
            json.dump(self.variables, f, indent=2)

    def update_constraint(self, key: str, value: Any):
        """
        Update a behavioral constraint

        Args:
            key: Constraint name
            value: Constraint value
        """
        self.constraints[key] = value
        self._save_constraints()

    def _save_constraints(self):
        """Save constraints to constraints.json"""
        with open(self.constraints_file, 'w') as f:
            json.dump(self.constraints, f, indent=2)

    def log_event(self, event_type: str, data: Dict[str, Any]):
        """
        Log an event to history.md

        Args:
            event_type: Event type
            data: Event data
        """
        timestamp = datetime.now().isoformat()

        log_entry = f"""
### {event_type}

**Timestamp**: {timestamp}

"""

        for key, value in data.items():
            log_entry += f"**{key}**: {value}\n"

        log_entry += "\n---\n"

        with open(self.history_file, 'a') as f:
            f.write(log_entry)

    def get_execution_summary(self) -> Dict[str, Any]:
        """
        Get execution summary

        Returns:
            Dictionary with execution summary
        """
        completed_steps = sum(1 for step in self.plan if step.status == "completed")
        failed_steps = sum(1 for step in self.plan if step.status == "failed")

        return {
            "goal": self.context.get("goal"),
            "status": self.context.get("status"),
            "started_at": self.context.get("started_at"),
            "completed_at": self.context.get("completed_at"),
            "total_steps": len(self.plan),
            "completed_steps": completed_steps,
            "failed_steps": failed_steps,
            "constraints": self.constraints,
            "variables": self.variables
        }

    def mark_execution_complete(self, success: bool = True):
        """
        Mark execution as complete

        Args:
            success: Whether execution was successful
        """
        self.context["status"] = "completed" if success else "failed"
        self.context["completed_at"] = datetime.now().isoformat()
        self._save_context()

        self.log_event("EXECUTION_COMPLETED", {
            "success": success,
            "summary": self.get_execution_summary()
        })



================================================
File: kernel/swarm_coordinator.py
================================================
"""
Swarm Coordination for LLMOS

Implements parallel agent execution with mesh topology coordination.
Inspired by Claude-Flow's swarm architecture with 2.8-4.4x speed improvements.

Key Features:
- Mesh topology for agent coordination
- Parallel task distribution
- Contextual task routing
- Fault-tolerant agent interactions
- Result aggregation and synthesis

Inspired by Claude-Flow's swarm coordination (MIT License)
https://github.com/ruvnet/claude-flow
"""

from typing import Dict, Any, List, Optional, Callable, Set
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from pathlib import Path
import time
from datetime import datetime


class SwarmTopology(Enum):
    """Swarm coordination topology"""
    MESH = "mesh"  # All agents can communicate
    STAR = "star"  # Central coordinator
    RING = "ring"  # Sequential processing
    PIPELINE = "pipeline"  # Staged processing


class AgentStatus(Enum):
    """Agent status in swarm"""
    IDLE = "idle"
    BUSY = "busy"
    COMPLETED = "completed"
    FAILED = "failed"
    BLOCKED = "blocked"


@dataclass
class SwarmAgent:
    """Agent in a swarm"""
    agent_id: str
    agent_type: str
    role: str
    tools: List[str]
    status: AgentStatus = AgentStatus.IDLE
    current_task: Optional[str] = None
    results: List[Any] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    created_at: float = field(default_factory=lambda: time.time())

    @property
    def is_available(self) -> bool:
        """Check if agent is available for work"""
        return self.status == AgentStatus.IDLE


@dataclass
class SwarmTask:
    """Task in a swarm"""
    task_id: str
    description: str
    inputs: Dict[str, Any]
    assigned_agent: Optional[str] = None
    status: AgentStatus = AgentStatus.IDLE
    result: Optional[Any] = None
    error: Optional[str] = None
    dependencies: List[str] = field(default_factory=list)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None

    @property
    def is_complete(self) -> bool:
        return self.status in [AgentStatus.COMPLETED, AgentStatus.FAILED]

    @property
    def execution_time(self) -> Optional[float]:
        if self.started_at and self.completed_at:
            return self.completed_at - self.started_at
        return None


@dataclass
class SwarmResult:
    """Result of swarm execution"""
    swarm_id: str
    success: bool
    tasks_completed: int
    tasks_failed: int
    total_time: float
    results: List[Any] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    agent_stats: Dict[str, Dict[str, Any]] = field(default_factory=dict)


class SwarmCoordinator:
    """
    Swarm Coordinator

    Manages parallel execution of tasks across multiple agents.
    Implements mesh topology for flexible coordination.

    Features:
    - Dynamic task allocation
    - Dependency resolution
    - Parallel execution where possible
    - Result aggregation
    - Fault tolerance
    """

    def __init__(
        self,
        swarm_id: str,
        topology: SwarmTopology = SwarmTopology.MESH,
        max_parallel: int = 5,
        timeout_secs: float = 300.0
    ):
        self.swarm_id = swarm_id
        self.topology = topology
        self.max_parallel = max_parallel
        self.timeout_secs = timeout_secs

        # Swarm state
        self.agents: Dict[str, SwarmAgent] = {}
        self.tasks: Dict[str, SwarmTask] = {}
        self.active_tasks: Set[str] = set()

        # Execution context
        self.shared_context: Dict[str, Any] = {}
        self.task_queue = asyncio.Queue()

        # Statistics
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None

    def add_agent(
        self,
        agent_id: str,
        agent_type: str,
        role: str,
        tools: List[str]
    ) -> SwarmAgent:
        """
        Add an agent to the swarm

        Args:
            agent_id: Unique agent identifier
            agent_type: Type of agent (planner, coder, etc.)
            role: Specific role description
            tools: List of tools this agent can use

        Returns:
            SwarmAgent instance
        """
        agent = SwarmAgent(
            agent_id=agent_id,
            agent_type=agent_type,
            role=role,
            tools=tools
        )

        self.agents[agent_id] = agent
        return agent

    def add_task(
        self,
        task_id: str,
        description: str,
        inputs: Dict[str, Any],
        dependencies: List[str] = None
    ) -> SwarmTask:
        """
        Add a task to the swarm

        Args:
            task_id: Unique task identifier
            description: Task description
            inputs: Task inputs
            dependencies: List of task IDs this task depends on

        Returns:
            SwarmTask instance
        """
        task = SwarmTask(
            task_id=task_id,
            description=description,
            inputs=inputs,
            dependencies=dependencies or []
        )

        self.tasks[task_id] = task
        return task

    async def execute(
        self,
        executor: Callable,
        progress_callback: Optional[Callable] = None
    ) -> SwarmResult:
        """
        Execute all tasks in the swarm

        Args:
            executor: Async function to execute tasks (agent_id, task) -> result
            progress_callback: Optional callback for progress updates

        Returns:
            SwarmResult with execution summary
        """
        self.start_time = time.time()

        try:
            # Execute based on topology
            if self.topology == SwarmTopology.MESH:
                await self._execute_mesh(executor, progress_callback)
            elif self.topology == SwarmTopology.STAR:
                await self._execute_star(executor, progress_callback)
            elif self.topology == SwarmTopology.PIPELINE:
                await self._execute_pipeline(executor, progress_callback)
            else:
                await self._execute_mesh(executor, progress_callback)

        except asyncio.TimeoutError:
            # Timeout - mark remaining tasks as failed
            for task_id, task in self.tasks.items():
                if not task.is_complete:
                    task.status = AgentStatus.FAILED
                    task.error = "Execution timeout"

        self.end_time = time.time()

        return self._generate_result()

    async def _execute_mesh(
        self,
        executor: Callable,
        progress_callback: Optional[Callable]
    ):
        """
        Execute tasks using mesh topology (fully parallel)

        All tasks that don't have dependencies are executed in parallel.
        """
        # Build dependency graph
        ready_tasks = self._get_ready_tasks()

        # Execute until all tasks complete
        while ready_tasks or self.active_tasks:
            # Start new tasks up to max_parallel
            while ready_tasks and len(self.active_tasks) < self.max_parallel:
                task_id = ready_tasks.pop(0)
                task = self.tasks[task_id]

                # Assign to available agent
                agent = self._find_available_agent(task)
                if not agent:
                    # No agent available, wait
                    break

                # Start task execution
                self.active_tasks.add(task_id)
                task.assigned_agent = agent.agent_id
                task.status = AgentStatus.BUSY
                task.started_at = time.time()

                agent.status = AgentStatus.BUSY
                agent.current_task = task_id

                # Execute in background
                asyncio.create_task(
                    self._execute_task(
                        task_id,
                        executor,
                        progress_callback
                    )
                )

            # Wait for at least one task to complete
            if self.active_tasks:
                await asyncio.sleep(0.1)

            # Check for newly ready tasks
            ready_tasks.extend(self._get_ready_tasks())

    async def _execute_star(
        self,
        executor: Callable,
        progress_callback: Optional[Callable]
    ):
        """
        Execute tasks using star topology (central coordinator)

        One agent coordinates, others execute in parallel.
        """
        # Find coordinator agent
        coordinator = next(
            (a for a in self.agents.values() if "orchestrator" in a.agent_type.lower()),
            None
        )

        if not coordinator:
            # Fallback to mesh if no coordinator
            await self._execute_mesh(executor, progress_callback)
            return

        # Coordinator creates execution plan
        # Then delegate to mesh execution
        await self._execute_mesh(executor, progress_callback)

    async def _execute_pipeline(
        self,
        executor: Callable,
        progress_callback: Optional[Callable]
    ):
        """
        Execute tasks using pipeline topology (staged)

        Tasks execute in stages based on dependencies.
        """
        # Group tasks by dependency depth
        stages = self._create_pipeline_stages()

        # Execute each stage
        for stage_num, stage_tasks in enumerate(stages):
            # Execute all tasks in this stage in parallel
            tasks = [
                self._execute_task(task_id, executor, progress_callback)
                for task_id in stage_tasks
            ]

            await asyncio.gather(*tasks, return_exceptions=True)

            if progress_callback:
                await progress_callback(f"Completed stage {stage_num + 1}/{len(stages)}")

    async def _execute_task(
        self,
        task_id: str,
        executor: Callable,
        progress_callback: Optional[Callable]
    ):
        """Execute a single task"""
        task = self.tasks[task_id]
        agent = self.agents.get(task.assigned_agent)

        try:
            # Execute task
            result = await executor(agent.agent_id, task)

            # Update task
            task.result = result
            task.status = AgentStatus.COMPLETED
            task.completed_at = time.time()

            # Update agent
            agent.status = AgentStatus.IDLE
            agent.current_task = None
            agent.results.append(result)

            # Update shared context
            self.shared_context[task_id] = result

            if progress_callback:
                await progress_callback(f"Completed: {task.description}")

        except Exception as e:
            # Task failed
            task.error = str(e)
            task.status = AgentStatus.FAILED
            task.completed_at = time.time()

            agent.status = AgentStatus.IDLE
            agent.current_task = None
            agent.errors.append(str(e))

            if progress_callback:
                await progress_callback(f"Failed: {task.description} - {str(e)}")

        finally:
            self.active_tasks.discard(task_id)

    def _get_ready_tasks(self) -> List[str]:
        """Get tasks that are ready to execute (dependencies met)"""
        ready = []

        for task_id, task in self.tasks.items():
            # Skip if already started
            if task.status != AgentStatus.IDLE:
                continue

            # Skip if already in active set
            if task_id in self.active_tasks:
                continue

            # Check if dependencies are met
            deps_met = all(
                self.tasks[dep_id].status == AgentStatus.COMPLETED
                for dep_id in task.dependencies
                if dep_id in self.tasks
            )

            if deps_met:
                ready.append(task_id)

        return ready

    def _find_available_agent(self, task: SwarmTask) -> Optional[SwarmAgent]:
        """Find an available agent suitable for the task"""
        # Simple strategy: return first available agent
        # Could be enhanced with skill matching
        for agent in self.agents.values():
            if agent.is_available:
                return agent
        return None

    def _create_pipeline_stages(self) -> List[List[str]]:
        """Create pipeline stages based on dependencies"""
        stages = []
        remaining_tasks = set(self.tasks.keys())

        while remaining_tasks:
            # Find tasks with no dependencies in remaining set
            stage = [
                task_id for task_id in remaining_tasks
                if all(
                    dep_id not in remaining_tasks
                    for dep_id in self.tasks[task_id].dependencies
                )
            ]

            if not stage:
                # Circular dependency - break it
                stage = [remaining_tasks.pop()]

            stages.append(stage)

            for task_id in stage:
                remaining_tasks.discard(task_id)

        return stages

    def _generate_result(self) -> SwarmResult:
        """Generate swarm execution result"""
        completed = sum(
            1 for t in self.tasks.values()
            if t.status == AgentStatus.COMPLETED
        )

        failed = sum(
            1 for t in self.tasks.values()
            if t.status == AgentStatus.FAILED
        )

        total_time = (self.end_time or time.time()) - (self.start_time or time.time())

        # Collect results and errors
        results = [
            t.result for t in self.tasks.values()
            if t.result is not None
        ]

        errors = [
            t.error for t in self.tasks.values()
            if t.error is not None
        ]

        # Agent statistics
        agent_stats = {}
        for agent_id, agent in self.agents.items():
            agent_stats[agent_id] = {
                "type": agent.agent_type,
                "role": agent.role,
                "tasks_completed": len(agent.results),
                "errors": len(agent.errors),
                "final_status": agent.status.value
            }

        return SwarmResult(
            swarm_id=self.swarm_id,
            success=(failed == 0 and completed > 0),
            tasks_completed=completed,
            tasks_failed=failed,
            total_time=total_time,
            results=results,
            errors=errors,
            agent_stats=agent_stats
        )

    def get_statistics(self) -> Dict[str, Any]:
        """Get swarm execution statistics"""
        return {
            "swarm_id": self.swarm_id,
            "topology": self.topology.value,
            "agents": len(self.agents),
            "tasks": len(self.tasks),
            "completed": sum(1 for t in self.tasks.values() if t.status == AgentStatus.COMPLETED),
            "failed": sum(1 for t in self.tasks.values() if t.status == AgentStatus.FAILED),
            "active": len(self.active_tasks),
            "agent_utilization": {
                agent_id: {
                    "status": agent.status.value,
                    "tasks_completed": len(agent.results),
                    "errors": len(agent.errors)
                }
                for agent_id, agent in self.agents.items()
            }
        }


class SwarmManager:
    """
    Swarm Manager

    Manages multiple swarms and provides high-level coordination.
    """

    def __init__(self, workspace: Path):
        self.workspace = workspace
        self.swarms: Dict[str, SwarmCoordinator] = {}

    async def create_swarm(
        self,
        swarm_name: str,
        goal: str,
        topology: SwarmTopology = SwarmTopology.MESH,
        max_parallel: int = 5
    ) -> SwarmCoordinator:
        """
        Create a new swarm

        Args:
            swarm_name: Name of the swarm
            goal: High-level goal
            topology: Coordination topology
            max_parallel: Maximum parallel agents

        Returns:
            SwarmCoordinator instance
        """
        swarm_id = f"swarm_{swarm_name}_{int(time.time())}"

        coordinator = SwarmCoordinator(
            swarm_id=swarm_id,
            topology=topology,
            max_parallel=max_parallel
        )

        self.swarms[swarm_id] = coordinator

        return coordinator

    def get_swarm(self, swarm_id: str) -> Optional[SwarmCoordinator]:
        """Get swarm by ID"""
        return self.swarms.get(swarm_id)

    def list_swarms(self) -> List[str]:
        """List all swarm IDs"""
        return list(self.swarms.keys())

    def get_all_statistics(self) -> Dict[str, Any]:
        """Get statistics for all swarms"""
        return {
            swarm_id: coordinator.get_statistics()
            for swarm_id, coordinator in self.swarms.items()
        }

    async def shutdown_swarm(self, swarm_id: str):
        """Shutdown a swarm"""
        if swarm_id in self.swarms:
            # Cancel any active tasks
            coordinator = self.swarms[swarm_id]
            coordinator.active_tasks.clear()

            del self.swarms[swarm_id]


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def calculate_speedup(
    sequential_time: float,
    parallel_time: float
) -> float:
    """
    Calculate speedup from parallelization

    Args:
        sequential_time: Time for sequential execution
        parallel_time: Time for parallel execution

    Returns:
        Speedup factor (e.g., 2.8 means 2.8x faster)
    """
    if parallel_time == 0:
        return 0.0
    return sequential_time / parallel_time


def estimate_parallel_efficiency(
    speedup: float,
    num_agents: int
) -> float:
    """
    Calculate parallel efficiency

    Perfect efficiency = 1.0 (linear speedup)
    Typical efficiency for real workloads: 0.6-0.8

    Args:
        speedup: Actual speedup achieved
        num_agents: Number of parallel agents

    Returns:
        Efficiency ratio (0.0 to 1.0)
    """
    if num_agents == 0:
        return 0.0
    return speedup / num_agents



================================================
File: kernel/token_economy.py
================================================
"""
Token Economy - Manages the cost of intelligence (the "battery")
"""

from typing import List, Dict
from dataclasses import dataclass
from datetime import datetime


class LowBatteryError(Exception):
    """Raised when token budget is insufficient"""
    pass


@dataclass
class SpendLog:
    """Log entry for token spending"""
    timestamp: datetime
    operation: str
    cost: float
    balance_after: float


class TokenEconomy:
    """
    Manages the token budget (the "battery" of the OS)
    Every cognitive cycle consumes resources
    """

    def __init__(self, budget_usd: float):
        """
        Initialize token economy

        Args:
            budget_usd: Initial budget in USD
        """
        self.balance = budget_usd
        self.initial_budget = budget_usd
        self.spend_log: List[SpendLog] = []

    def check_budget(self, estimated_cost: float) -> bool:
        """
        Check if budget is sufficient

        Args:
            estimated_cost: Estimated cost in USD

        Returns:
            True if budget is sufficient

        Raises:
            LowBatteryError if insufficient funds
        """
        if self.balance < estimated_cost:
            raise LowBatteryError(
                f"Insufficient funds for Learner Mode. "
                f"Required: ${estimated_cost:.4f}, Available: ${self.balance:.4f}"
            )
        return True

    def deduct(self, actual_cost: float, operation: str = "unknown"):
        """
        Deduct cost from budget

        Args:
            actual_cost: Actual cost in USD
            operation: Description of the operation
        """
        self.balance -= actual_cost

        log_entry = SpendLog(
            timestamp=datetime.now(),
            operation=operation,
            cost=actual_cost,
            balance_after=self.balance
        )
        self.spend_log.append(log_entry)

    def get_usage_report(self) -> Dict:
        """Get usage report"""
        total_spent = sum(log.cost for log in self.spend_log)

        return {
            "initial_budget": self.initial_budget,
            "current_balance": self.balance,
            "total_spent": total_spent,
            "num_operations": len(self.spend_log),
            "average_cost": total_spent / len(self.spend_log) if self.spend_log else 0
        }



================================================
File: kernel/verification.py
================================================
"""
Verification and Testing Harness for LLMOS

Automatic verification system for tools, agents, and crystallized patterns.
Inspired by Claude-Flow's testing approach with >90% test coverage.

Key Features:
- Automatic test generation from traces
- Tool validation before crystallization
- Agent performance verification
- Correctness threshold enforcement
- Continuous validation of evolved patterns

Inspired by Claude-Flow's verification system (MIT License)
https://github.com/ruvnet/claude-flow
"""

from typing import Dict, Any, List, Optional, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from pathlib import Path
import time


class VerificationStatus(Enum):
    """Verification result status"""
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"
    ERROR = "error"


@dataclass
class VerificationResult:
    """Single verification test result"""
    test_name: str
    status: VerificationStatus
    expected: Any = None
    actual: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)

    @property
    def passed(self) -> bool:
        return self.status == VerificationStatus.PASSED


@dataclass
class VerificationSuite:
    """Collection of verification results"""
    suite_name: str
    results: List[VerificationResult] = field(default_factory=list)
    total_time: float = 0.0

    @property
    def total_tests(self) -> int:
        return len(self.results)

    @property
    def passed_tests(self) -> int:
        return sum(1 for r in self.results if r.passed)

    @property
    def failed_tests(self) -> int:
        return sum(1 for r in self.results if r.status == VerificationStatus.FAILED)

    @property
    def error_tests(self) -> int:
        return sum(1 for r in self.results if r.status == VerificationStatus.ERROR)

    @property
    def success_rate(self) -> float:
        if self.total_tests == 0:
            return 0.0
        return self.passed_tests / self.total_tests

    def add_result(self, result: VerificationResult):
        """Add a test result"""
        self.results.append(result)

    def meets_threshold(self, threshold: float = 0.9) -> bool:
        """Check if suite meets success threshold"""
        return self.success_rate >= threshold


class ToolVerifier:
    """
    Tool Verification Engine

    Validates tools before they are crystallized or deployed.
    Generates test cases from successful traces.
    """

    def __init__(
        self,
        workspace: Path,
        min_success_rate: float = 0.9,
        timeout_secs: float = 30.0
    ):
        self.workspace = workspace
        self.min_success_rate = min_success_rate
        self.timeout_secs = timeout_secs

    async def verify_tool(
        self,
        tool_name: str,
        tool_func: Callable,
        test_cases: List[Dict[str, Any]]
    ) -> VerificationSuite:
        """
        Verify a tool against test cases

        Args:
            tool_name: Name of the tool
            tool_func: Tool function to test
            test_cases: List of test cases with inputs and expected outputs

        Returns:
            VerificationSuite with results
        """
        suite = VerificationSuite(suite_name=f"Tool: {tool_name}")
        start_time = time.time()

        for i, test_case in enumerate(test_cases):
            test_name = f"{tool_name}_test_{i}"
            inputs = test_case.get("inputs", {})
            expected = test_case.get("expected")

            result = await self._run_test(
                test_name=test_name,
                func=tool_func,
                inputs=inputs,
                expected=expected
            )

            suite.add_result(result)

        suite.total_time = time.time() - start_time
        return suite

    async def _run_test(
        self,
        test_name: str,
        func: Callable,
        inputs: Dict[str, Any],
        expected: Any
    ) -> VerificationResult:
        """Run a single test case"""
        start_time = time.time()

        try:
            # Execute with timeout
            if asyncio.iscoroutinefunction(func):
                actual = await asyncio.wait_for(
                    func(**inputs),
                    timeout=self.timeout_secs
                )
            else:
                loop = asyncio.get_event_loop()
                actual = await asyncio.wait_for(
                    loop.run_in_executor(None, lambda: func(**inputs)),
                    timeout=self.timeout_secs
                )

            execution_time = time.time() - start_time

            # Compare results
            if self._compare_results(actual, expected):
                return VerificationResult(
                    test_name=test_name,
                    status=VerificationStatus.PASSED,
                    expected=expected,
                    actual=actual,
                    execution_time=execution_time
                )
            else:
                return VerificationResult(
                    test_name=test_name,
                    status=VerificationStatus.FAILED,
                    expected=expected,
                    actual=actual,
                    error=f"Expected {expected}, got {actual}",
                    execution_time=execution_time
                )

        except asyncio.TimeoutError:
            return VerificationResult(
                test_name=test_name,
                status=VerificationStatus.ERROR,
                error=f"Timeout after {self.timeout_secs}s",
                execution_time=time.time() - start_time
            )

        except Exception as e:
            return VerificationResult(
                test_name=test_name,
                status=VerificationStatus.ERROR,
                error=str(e),
                execution_time=time.time() - start_time
            )

    def _compare_results(self, actual: Any, expected: Any) -> bool:
        """
        Compare actual vs expected results

        Supports various comparison strategies:
        - Exact equality
        - Dict subset matching
        - Numeric tolerance
        """
        if expected is None:
            # No expected value means we just check for no errors
            return True

        if isinstance(expected, dict) and isinstance(actual, dict):
            # Check if all expected keys/values are in actual
            return all(
                k in actual and actual[k] == v
                for k, v in expected.items()
            )

        if isinstance(expected, (int, float)) and isinstance(actual, (int, float)):
            # Numeric tolerance
            return abs(actual - expected) < 1e-6

        # Default: exact equality
        return actual == expected


class AgentVerifier:
    """
    Agent Verification Engine

    Validates agent performance against expected metrics.
    Ensures agents meet quality thresholds before deployment.
    """

    def __init__(
        self,
        min_success_rate: float = 0.85,
        min_avg_rating: float = 0.75
    ):
        self.min_success_rate = min_success_rate
        self.min_avg_rating = min_avg_rating

    async def verify_agent(
        self,
        agent_name: str,
        traces: List[Any]  # List of ExecutionTrace objects
    ) -> VerificationSuite:
        """
        Verify agent performance based on execution traces

        Args:
            agent_name: Name of the agent
            traces: Execution traces for this agent

        Returns:
            VerificationSuite with verification results
        """
        suite = VerificationSuite(suite_name=f"Agent: {agent_name}")

        if not traces:
            suite.add_result(VerificationResult(
                test_name=f"{agent_name}_has_traces",
                status=VerificationStatus.FAILED,
                error="No execution traces found"
            ))
            return suite

        # Test 1: Success rate
        success_count = sum(1 for t in traces if t.success)
        success_rate = success_count / len(traces)

        suite.add_result(VerificationResult(
            test_name=f"{agent_name}_success_rate",
            status=VerificationStatus.PASSED if success_rate >= self.min_success_rate else VerificationStatus.FAILED,
            expected=self.min_success_rate,
            actual=success_rate,
            metadata={"total_traces": len(traces), "successful": success_count}
        ))

        # Test 2: Average rating
        avg_rating = sum(t.success_rating for t in traces) / len(traces)

        suite.add_result(VerificationResult(
            test_name=f"{agent_name}_avg_rating",
            status=VerificationStatus.PASSED if avg_rating >= self.min_avg_rating else VerificationStatus.FAILED,
            expected=self.min_avg_rating,
            actual=avg_rating
        ))

        # Test 3: Performance consistency (standard deviation of ratings)
        if len(traces) > 1:
            ratings = [t.success_rating for t in traces]
            mean = sum(ratings) / len(ratings)
            variance = sum((r - mean) ** 2 for r in ratings) / len(ratings)
            std_dev = variance ** 0.5

            # Lower std dev is better (more consistent)
            consistent = std_dev < 0.2

            suite.add_result(VerificationResult(
                test_name=f"{agent_name}_consistency",
                status=VerificationStatus.PASSED if consistent else VerificationStatus.FAILED,
                expected="<0.2",
                actual=std_dev,
                metadata={"variance": variance}
            ))

        return suite


class CrystallizationVerifier:
    """
    Crystallization Verification Engine

    Validates that crystallized tools match the behavior of their source traces.
    Ensures crystallization doesn't introduce bugs.
    """

    def __init__(
        self,
        tool_verifier: ToolVerifier,
        min_match_rate: float = 0.95
    ):
        self.tool_verifier = tool_verifier
        self.min_match_rate = min_match_rate

    async def verify_crystallization(
        self,
        tool_name: str,
        tool_func: Callable,
        source_traces: List[Any],
        num_test_cases: int = 10
    ) -> VerificationSuite:
        """
        Verify that crystallized tool matches source trace behavior

        Args:
            tool_name: Name of crystallized tool
            tool_func: Crystallized tool function
            source_traces: Traces that were crystallized
            num_test_cases: Number of test cases to generate

        Returns:
            VerificationSuite with verification results
        """
        # Generate test cases from traces
        test_cases = self._generate_test_cases_from_traces(
            source_traces,
            num_test_cases
        )

        # Run tool verification
        suite = await self.tool_verifier.verify_tool(
            tool_name=tool_name,
            tool_func=tool_func,
            test_cases=test_cases
        )

        # Check if meets threshold
        if suite.meets_threshold(self.min_match_rate):
            suite.add_result(VerificationResult(
                test_name=f"{tool_name}_crystallization_valid",
                status=VerificationStatus.PASSED,
                expected=self.min_match_rate,
                actual=suite.success_rate,
                metadata={
                    "source_traces": len(source_traces),
                    "test_cases": len(test_cases)
                }
            ))
        else:
            suite.add_result(VerificationResult(
                test_name=f"{tool_name}_crystallization_valid",
                status=VerificationStatus.FAILED,
                expected=self.min_match_rate,
                actual=suite.success_rate,
                error=f"Crystallization only matched {suite.success_rate:.0%} of traces"
            ))

        return suite

    def _generate_test_cases_from_traces(
        self,
        traces: List[Any],
        num_cases: int
    ) -> List[Dict[str, Any]]:
        """
        Generate test cases from execution traces

        Extracts inputs and expected outputs from successful traces.
        """
        test_cases = []

        # Use successful traces only
        successful_traces = [t for t in traces if t.success][:num_cases]

        for trace in successful_traces:
            # Extract test case from trace
            # This is a simplified version - real implementation would
            # parse tool_calls to extract inputs/outputs
            test_case = {
                "inputs": {},  # Would extract from trace.tool_calls
                "expected": None  # Would extract from trace output
            }
            test_cases.append(test_case)

        return test_cases


class VerificationManager:
    """
    Central Verification Management

    Coordinates all verification activities:
    - Tool verification before crystallization
    - Agent performance validation
    - Continuous testing of evolved patterns
    """

    def __init__(
        self,
        workspace: Path,
        config: Optional[Dict[str, Any]] = None
    ):
        self.workspace = workspace
        self.config = config or {}

        # Initialize verifiers
        self.tool_verifier = ToolVerifier(
            workspace=workspace,
            min_success_rate=self.config.get("min_tool_success_rate", 0.9),
            timeout_secs=self.config.get("tool_timeout_secs", 30.0)
        )

        self.agent_verifier = AgentVerifier(
            min_success_rate=self.config.get("min_agent_success_rate", 0.85),
            min_avg_rating=self.config.get("min_agent_avg_rating", 0.75)
        )

        self.crystallization_verifier = CrystallizationVerifier(
            tool_verifier=self.tool_verifier,
            min_match_rate=self.config.get("min_crystallization_match", 0.95)
        )

        # Verification history
        self.verification_history: List[VerificationSuite] = []

    async def verify_before_crystallization(
        self,
        tool_name: str,
        tool_func: Callable,
        source_traces: List[Any]
    ) -> Tuple[bool, VerificationSuite]:
        """
        Verify a tool before crystallization

        Args:
            tool_name: Name of tool
            tool_func: Tool function
            source_traces: Source traces

        Returns:
            (should_crystallize: bool, suite: VerificationSuite)
        """
        suite = await self.crystallization_verifier.verify_crystallization(
            tool_name=tool_name,
            tool_func=tool_func,
            source_traces=source_traces
        )

        self.verification_history.append(suite)

        # Decision: crystallize if meets threshold
        should_crystallize = suite.meets_threshold(
            self.config.get("min_crystallization_match", 0.95)
        )

        return should_crystallize, suite

    async def verify_agent_performance(
        self,
        agent_name: str,
        traces: List[Any]
    ) -> Tuple[bool, VerificationSuite]:
        """
        Verify agent performance

        Args:
            agent_name: Name of agent
            traces: Execution traces

        Returns:
            (meets_standards: bool, suite: VerificationSuite)
        """
        suite = await self.agent_verifier.verify_agent(
            agent_name=agent_name,
            traces=traces
        )

        self.verification_history.append(suite)

        meets_standards = suite.meets_threshold(
            self.config.get("min_agent_success_rate", 0.85)
        )

        return meets_standards, suite

    def get_verification_statistics(self) -> Dict[str, Any]:
        """Get verification statistics"""
        if not self.verification_history:
            return {
                "total_suites": 0,
                "total_tests": 0,
                "overall_success_rate": 0.0
            }

        total_tests = sum(s.total_tests for s in self.verification_history)
        total_passed = sum(s.passed_tests for s in self.verification_history)

        return {
            "total_suites": len(self.verification_history),
            "total_tests": total_tests,
            "overall_success_rate": total_passed / total_tests if total_tests > 0 else 0.0,
            "by_suite": [
                {
                    "name": s.suite_name,
                    "success_rate": s.success_rate,
                    "tests": s.total_tests,
                    "time": s.total_time
                }
                for s in self.verification_history[-10:]  # Last 10 suites
            ]
        }

    def generate_report(self) -> str:
        """Generate a verification report"""
        stats = self.get_verification_statistics()

        report = f"""
# Verification Report

## Summary
- Total Suites: {stats['total_suites']}
- Total Tests: {stats['total_tests']}
- Overall Success Rate: {stats['overall_success_rate']:.1%}

## Recent Suites
"""

        for suite_stats in stats.get('by_suite', []):
            report += f"""
### {suite_stats['name']}
- Success Rate: {suite_stats['success_rate']:.1%}
- Tests: {suite_stats['tests']}
- Time: {suite_stats['time']:.2f}s
"""

        return report



================================================
File: kernel/volumes.py
================================================
"""
Volume Architecture for LLM OS

Volumes are the organizational units for artifacts in the system. Each volume
contains traces, tools, and agents that belong to a specific scope:

- **UserVolume**: Personal artifacts for a single user
- **TeamVolume**: Shared artifacts for a team of users
- **SystemVolume**: Global artifacts available to all

Access Control:
- User Cron: read/write UserVolume, read TeamVolume
- Team Cron: read/write TeamVolume, read UserVolume (aggregated)
- System Cron: read/write all volumes, controls other crons

Artifacts in each volume:
- Traces: Execution histories (can be summarized/consolidated)
- Tools: Crystallized capabilities (can evolve)
- Agents: Markdown agent definitions (can be refined)
- Insights: Summarized learnings from analysis
- Suggestions: Opportunities for improvement
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Set
from pathlib import Path
from enum import Enum
from datetime import datetime
import json
import hashlib


class VolumeType(Enum):
    """Types of volumes in the system"""
    USER = "user"
    TEAM = "team"
    SYSTEM = "system"


class ArtifactType(Enum):
    """Types of artifacts stored in volumes"""
    TRACE = "trace"
    TOOL = "tool"
    AGENT = "agent"
    INSIGHT = "insight"
    SUGGESTION = "suggestion"


class ArtifactAction(Enum):
    """Actions that can be performed on artifacts"""
    CREATED = "created"
    EVOLVED = "evolved"
    SUMMARIZED = "summarized"
    PROMOTED = "promoted"  # User -> Team or Team -> System
    DEPRECATED = "deprecated"
    DELETED = "deleted"


@dataclass
class ArtifactChange:
    """Record of a change to an artifact"""
    artifact_id: str
    artifact_type: ArtifactType
    action: ArtifactAction
    timestamp: str
    source_volume: VolumeType
    target_volume: Optional[VolumeType]  # For promotions
    reason: str
    cron_level: str  # "user", "team", or "system"
    details: Dict[str, Any] = field(default_factory=dict)

    def as_dict(self) -> Dict[str, Any]:
        return {
            "artifact_id": self.artifact_id,
            "artifact_type": self.artifact_type.value,
            "action": self.action.value,
            "timestamp": self.timestamp,
            "source_volume": self.source_volume.value,
            "target_volume": self.target_volume.value if self.target_volume else None,
            "reason": self.reason,
            "cron_level": self.cron_level,
            "details": self.details
        }


@dataclass
class VolumeStats:
    """Statistics about a volume's contents"""
    trace_count: int = 0
    tool_count: int = 0
    agent_count: int = 0
    insight_count: int = 0
    suggestion_count: int = 0
    total_size_bytes: int = 0
    last_modified: Optional[str] = None

    def as_dict(self) -> Dict[str, Any]:
        return {
            "trace_count": self.trace_count,
            "tool_count": self.tool_count,
            "agent_count": self.agent_count,
            "insight_count": self.insight_count,
            "suggestion_count": self.suggestion_count,
            "total_size_bytes": self.total_size_bytes,
            "last_modified": self.last_modified
        }


class Volume:
    """
    A volume containing artifacts (traces, tools, agents, insights, suggestions).

    Volumes are file-based storage units that can be read and written
    according to access control rules.
    """

    def __init__(
        self,
        volume_type: VolumeType,
        base_path: Path,
        owner_id: str,  # user_id, team_id, or "system"
        readonly: bool = False
    ):
        self.volume_type = volume_type
        self.base_path = base_path
        self.owner_id = owner_id
        self.readonly = readonly

        # Artifact subdirectories
        self.traces_path = base_path / "traces"
        self.tools_path = base_path / "tools"
        self.agents_path = base_path / "agents"
        self.insights_path = base_path / "insights"
        self.suggestions_path = base_path / "suggestions"

        # Change log
        self.changelog_path = base_path / "changelog.json"
        self._changes: List[ArtifactChange] = []

        # Ensure directories exist
        self._ensure_directories()
        self._load_changelog()

    def _ensure_directories(self):
        """Create volume directories if they don't exist"""
        for path in [self.traces_path, self.tools_path, self.agents_path,
                     self.insights_path, self.suggestions_path]:
            path.mkdir(parents=True, exist_ok=True)

    def _load_changelog(self):
        """Load change history from disk"""
        if self.changelog_path.exists():
            try:
                with open(self.changelog_path, 'r') as f:
                    data = json.load(f)
                    self._changes = [
                        ArtifactChange(
                            artifact_id=c["artifact_id"],
                            artifact_type=ArtifactType(c["artifact_type"]),
                            action=ArtifactAction(c["action"]),
                            timestamp=c["timestamp"],
                            source_volume=VolumeType(c["source_volume"]),
                            target_volume=VolumeType(c["target_volume"]) if c.get("target_volume") else None,
                            reason=c["reason"],
                            cron_level=c["cron_level"],
                            details=c.get("details", {})
                        )
                        for c in data
                    ]
            except Exception:
                self._changes = []

    def _save_changelog(self):
        """Save change history to disk"""
        if not self.readonly:
            with open(self.changelog_path, 'w') as f:
                json.dump([c.as_dict() for c in self._changes[-1000:]], f, indent=2)

    def _get_path_for_type(self, artifact_type: ArtifactType) -> Path:
        """Get the directory path for an artifact type"""
        mapping = {
            ArtifactType.TRACE: self.traces_path,
            ArtifactType.TOOL: self.tools_path,
            ArtifactType.AGENT: self.agents_path,
            ArtifactType.INSIGHT: self.insights_path,
            ArtifactType.SUGGESTION: self.suggestions_path
        }
        return mapping[artifact_type]

    def record_change(
        self,
        artifact_id: str,
        artifact_type: ArtifactType,
        action: ArtifactAction,
        reason: str,
        cron_level: str,
        target_volume: Optional[VolumeType] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        """Record a change to an artifact"""
        change = ArtifactChange(
            artifact_id=artifact_id,
            artifact_type=artifact_type,
            action=action,
            timestamp=datetime.now().isoformat(),
            source_volume=self.volume_type,
            target_volume=target_volume,
            reason=reason,
            cron_level=cron_level,
            details=details or {}
        )
        self._changes.append(change)
        self._save_changelog()
        return change

    # =========================================================================
    # READ OPERATIONS
    # =========================================================================

    def list_artifacts(self, artifact_type: ArtifactType) -> List[str]:
        """List all artifact IDs of a given type"""
        path = self._get_path_for_type(artifact_type)

        if artifact_type in [ArtifactType.TRACE, ArtifactType.INSIGHT, ArtifactType.SUGGESTION]:
            # Markdown files
            return [f.stem for f in path.glob("*.md")]
        elif artifact_type == ArtifactType.TOOL:
            # Python files
            return [f.stem for f in path.glob("*.py")]
        elif artifact_type == ArtifactType.AGENT:
            # Markdown files
            return [f.stem for f in path.glob("*.md")]
        return []

    def read_artifact(self, artifact_type: ArtifactType, artifact_id: str) -> Optional[str]:
        """Read an artifact's content"""
        path = self._get_path_for_type(artifact_type)

        if artifact_type in [ArtifactType.TRACE, ArtifactType.INSIGHT,
                             ArtifactType.SUGGESTION, ArtifactType.AGENT]:
            file_path = path / f"{artifact_id}.md"
        elif artifact_type == ArtifactType.TOOL:
            file_path = path / f"{artifact_id}.py"
        else:
            return None

        if file_path.exists():
            return file_path.read_text()
        return None

    def get_stats(self) -> VolumeStats:
        """Get statistics about the volume"""
        stats = VolumeStats()

        stats.trace_count = len(self.list_artifacts(ArtifactType.TRACE))
        stats.tool_count = len(self.list_artifacts(ArtifactType.TOOL))
        stats.agent_count = len(self.list_artifacts(ArtifactType.AGENT))
        stats.insight_count = len(self.list_artifacts(ArtifactType.INSIGHT))
        stats.suggestion_count = len(self.list_artifacts(ArtifactType.SUGGESTION))

        # Calculate total size
        total_size = 0
        for path in [self.traces_path, self.tools_path, self.agents_path,
                     self.insights_path, self.suggestions_path]:
            for f in path.iterdir():
                if f.is_file():
                    total_size += f.stat().st_size
        stats.total_size_bytes = total_size

        # Get last modified
        if self._changes:
            stats.last_modified = self._changes[-1].timestamp

        return stats

    def get_recent_changes(self, limit: int = 50) -> List[ArtifactChange]:
        """Get recent changes to the volume"""
        return self._changes[-limit:]

    # =========================================================================
    # WRITE OPERATIONS
    # =========================================================================

    def write_artifact(
        self,
        artifact_type: ArtifactType,
        artifact_id: str,
        content: str,
        reason: str,
        cron_level: str,
        is_new: bool = True
    ) -> bool:
        """Write an artifact to the volume"""
        if self.readonly:
            return False

        path = self._get_path_for_type(artifact_type)

        if artifact_type in [ArtifactType.TRACE, ArtifactType.INSIGHT,
                             ArtifactType.SUGGESTION, ArtifactType.AGENT]:
            file_path = path / f"{artifact_id}.md"
        elif artifact_type == ArtifactType.TOOL:
            file_path = path / f"{artifact_id}.py"
        else:
            return False

        file_path.write_text(content)

        # Record the change
        action = ArtifactAction.CREATED if is_new else ArtifactAction.EVOLVED
        self.record_change(
            artifact_id=artifact_id,
            artifact_type=artifact_type,
            action=action,
            reason=reason,
            cron_level=cron_level
        )

        return True

    def delete_artifact(
        self,
        artifact_type: ArtifactType,
        artifact_id: str,
        reason: str,
        cron_level: str
    ) -> bool:
        """Delete an artifact from the volume"""
        if self.readonly:
            return False

        path = self._get_path_for_type(artifact_type)

        if artifact_type in [ArtifactType.TRACE, ArtifactType.INSIGHT,
                             ArtifactType.SUGGESTION, ArtifactType.AGENT]:
            file_path = path / f"{artifact_id}.md"
        elif artifact_type == ArtifactType.TOOL:
            file_path = path / f"{artifact_id}.py"
        else:
            return False

        if file_path.exists():
            file_path.unlink()
            self.record_change(
                artifact_id=artifact_id,
                artifact_type=artifact_type,
                action=ArtifactAction.DELETED,
                reason=reason,
                cron_level=cron_level
            )
            return True
        return False


class VolumeManager:
    """
    Manages access to User, Team, and System volumes.

    Provides access control based on cron level:
    - user: read/write user volume, read team volume
    - team: read/write team volume, read all user volumes (aggregated)
    - system: read/write all volumes
    """

    def __init__(self, base_path: Path):
        self.base_path = base_path
        self._volumes: Dict[str, Volume] = {}

        # Ensure base structure exists
        (base_path / "system").mkdir(parents=True, exist_ok=True)
        (base_path / "teams").mkdir(parents=True, exist_ok=True)
        (base_path / "users").mkdir(parents=True, exist_ok=True)

    def get_system_volume(self, readonly: bool = False) -> Volume:
        """Get the system-wide volume"""
        key = "system"
        if key not in self._volumes:
            self._volumes[key] = Volume(
                volume_type=VolumeType.SYSTEM,
                base_path=self.base_path / "system",
                owner_id="system",
                readonly=readonly
            )
        return self._volumes[key]

    def get_team_volume(self, team_id: str, readonly: bool = False) -> Volume:
        """Get a team's volume"""
        key = f"team:{team_id}"
        if key not in self._volumes:
            self._volumes[key] = Volume(
                volume_type=VolumeType.TEAM,
                base_path=self.base_path / "teams" / team_id,
                owner_id=team_id,
                readonly=readonly
            )
        return self._volumes[key]

    def get_user_volume(self, user_id: str, readonly: bool = False) -> Volume:
        """Get a user's volume"""
        key = f"user:{user_id}"
        if key not in self._volumes:
            self._volumes[key] = Volume(
                volume_type=VolumeType.USER,
                base_path=self.base_path / "users" / user_id,
                owner_id=user_id,
                readonly=readonly
            )
        return self._volumes[key]

    def list_teams(self) -> List[str]:
        """List all team IDs"""
        teams_path = self.base_path / "teams"
        if teams_path.exists():
            return [d.name for d in teams_path.iterdir() if d.is_dir()]
        return []

    def list_users(self) -> List[str]:
        """List all user IDs"""
        users_path = self.base_path / "users"
        if users_path.exists():
            return [d.name for d in users_path.iterdir() if d.is_dir()]
        return []

    def get_volumes_for_cron(
        self,
        cron_level: str,
        user_id: Optional[str] = None,
        team_id: Optional[str] = None
    ) -> Dict[str, Volume]:
        """
        Get volumes accessible to a cron based on its level.

        Returns dict with keys: 'user', 'team', 'system' (where applicable)
        """
        volumes = {}

        if cron_level == "user":
            # User cron: read/write user, read team
            if user_id:
                volumes["user"] = self.get_user_volume(user_id, readonly=False)
            if team_id:
                volumes["team"] = self.get_team_volume(team_id, readonly=True)

        elif cron_level == "team":
            # Team cron: read/write team, read system
            if team_id:
                volumes["team"] = self.get_team_volume(team_id, readonly=False)
            volumes["system"] = self.get_system_volume(readonly=True)

        elif cron_level == "system":
            # System cron: read/write everything
            volumes["system"] = self.get_system_volume(readonly=False)
            for team_id in self.list_teams():
                volumes[f"team:{team_id}"] = self.get_team_volume(team_id, readonly=False)
            for user_id in self.list_users():
                volumes[f"user:{user_id}"] = self.get_user_volume(user_id, readonly=False)

        return volumes

    def promote_artifact(
        self,
        artifact_type: ArtifactType,
        artifact_id: str,
        from_volume: Volume,
        to_volume: Volume,
        reason: str,
        cron_level: str
    ) -> bool:
        """
        Promote an artifact from one volume to another.

        For example: User trace -> Team trace, or Team tool -> System tool
        """
        content = from_volume.read_artifact(artifact_type, artifact_id)
        if content is None:
            return False

        # Write to target volume
        success = to_volume.write_artifact(
            artifact_type=artifact_type,
            artifact_id=artifact_id,
            content=content,
            reason=f"Promoted from {from_volume.volume_type.value}: {reason}",
            cron_level=cron_level,
            is_new=True
        )

        if success:
            # Record promotion in source volume
            from_volume.record_change(
                artifact_id=artifact_id,
                artifact_type=artifact_type,
                action=ArtifactAction.PROMOTED,
                reason=reason,
                cron_level=cron_level,
                target_volume=to_volume.volume_type
            )

        return success



================================================
File: kernel/watchdog.py
================================================
"""
Watchdog - Monitor LLM execution and prevent loops/hallucinations
"""

import asyncio
from typing import Optional
import anyio

from .bus import EventBus, Event, EventType


class Watchdog:
    """
    Watchdog to monitor LLM execution
    Prevents infinite loops and hallucinations
    """

    def __init__(self, event_bus: EventBus, timeout_seconds: float = 60.0):
        self.event_bus = event_bus
        self.timeout_seconds = timeout_seconds
        self._active = False
        self._timer_task: Optional[anyio.abc.CancelScope] = None

    async def start(self):
        """Start watchdog monitoring"""
        pass  # Watchdog is activated on-demand

    async def stop(self):
        """Stop watchdog monitoring"""
        if self._timer_task:
            self._timer_task.cancel()

    async def activate(self):
        """Activate watchdog timer for LLM execution"""
        self._active = True

        async with anyio.create_task_group() as tg:
            self._timer_task = tg.cancel_scope

            async def timer():
                await anyio.sleep(self.timeout_seconds)
                if self._active:
                    # Emit interrupt event
                    event = Event(
                        type=EventType.INTERRUPT,
                        data={
                            "source": "watchdog",
                            "reason": "timeout",
                            "timeout_seconds": self.timeout_seconds
                        }
                    )
                    await self.event_bus.publish(event)

            tg.start_soon(timer)

    async def deactivate(self):
        """Deactivate watchdog timer"""
        self._active = False
        if self._timer_task:
            self._timer_task.cancel()




================================================
File: kernel/terminal/__init__.py
================================================
"""
Cron Terminal - Interactive Dashboard for LLM OS

This module provides a two-panel terminal interface for monitoring
and interacting with Sentience Crons.

Features:
- Left Panel: Tree view of all cron processes with live status
- Right Panel: Detailed view of selected cron
- Interactive Mode: Chat with YOUR UserCron
- Read-Only Mode: View other crons' activity

Two UI Modes:
- Legacy: Basic ANSI terminal (no dependencies)
- Textual: Midnight Commander-style TUI (requires textual)

Usage:
    # Textual UI (recommended)
    python llmos/boot.py terminal --user alice --team engineering --ui textual

    # Legacy UI
    python llmos/boot.py terminal --user alice --team engineering --ui legacy
"""

# Legacy UI components
from .ui import CronTerminal, TerminalConfig, start_terminal
from .tree import CronTreeView
from .detail import CronDetailPanel
from .interaction import CronInteraction
from .input_handler import InputHandler, Key
from .llmos_data_provider import LLMOSDataProvider

# Textual UI (with lazy import for optional dependency)
def get_textual_app():
    """Get the Textual app class (lazy import)."""
    try:
        from .app import CronTerminalApp, run_terminal
        return CronTerminalApp, run_terminal
    except ImportError:
        raise ImportError(
            "Textual UI requires the 'textual' package. "
            "Install it with: pip install textual"
        )

__all__ = [
    # Legacy UI
    "CronTerminal",
    "TerminalConfig",
    "CronTreeView",
    "CronDetailPanel",
    "CronInteraction",
    "InputHandler",
    "Key",
    "LLMOSDataProvider",
    "start_terminal",
    # Textual UI
    "get_textual_app",
]



================================================
File: kernel/terminal/app.py
================================================
"""
CronTerminalApp - Main Textual application for the Cron Terminal.

Provides a Midnight Commander-style two-panel interface with
function keys, command palette, and live data updates.
"""

from typing import Optional, Dict, Any, List, Callable, Awaitable
from pathlib import Path
import asyncio

from textual.app import App, ComposeResult
from textual.containers import Horizontal, Vertical
from textual.widgets import Header, Footer, Static, Label
from textual.binding import Binding
from textual.timer import Timer
from textual.message import Message

from .widgets.cron_tree import CronTreeWidget
from .widgets.detail_tabs import DetailTabs
from .models import CronState


class CronTerminalApp(App):
    """
    Main Textual application for the Cron Terminal.

    Features:
    - Two-panel MC-style layout
    - Function key bindings (F1-F10)
    - Vim-style navigation
    - Command palette (Ctrl+P)
    - Auto-refresh with live updates
    - Color themes
    """

    # Load CSS from styles directory
    CSS_PATH = Path(__file__).parent / "styles" / "mc_blue.tcss"

    # Application title
    TITLE = "LLMOS Cron Terminal"
    SUB_TITLE = "Midnight Commander Style"

    # Function key bindings - MC style
    BINDINGS = [
        Binding("f1", "show_help", "Help", show=True),
        Binding("f2", "show_menu", "Menu", show=True),
        Binding("f3", "view_detail", "View", show=True),
        Binding("f4", "edit", "Edit", show=True),
        Binding("f5", "refresh", "Refresh", show=True),
        Binding("f6", "move", "Move", show=True),
        Binding("f7", "mkdir", "MkDir", show=True),
        Binding("f8", "delete", "Delete", show=True),
        Binding("f9", "pull_down", "PullDn", show=True),
        Binding("f10", "quit", "Quit", show=True, key_display="F10"),
        # Additional bindings
        Binding("ctrl+p", "command_palette", "Commands", show=False),
        Binding("ctrl+r", "refresh", "Refresh", show=False),
        Binding("tab", "switch_panel", "Switch Panel", show=False),
        Binding("q", "quit", "Quit", show=False),
        Binding("?", "show_help", "Help", show=False),
    ]

    # Commands for command palette
    COMMANDS = {
        "refresh": "Refresh all data",
        "quit": "Exit terminal",
        "help": "Show help",
        "theme": "Change theme",
        "toggle_auto_refresh": "Toggle auto-refresh",
    }

    class DataRefreshed(Message):
        """Message sent when data is refreshed."""
        pass

    def __init__(
        self,
        user_id: str,
        team_id: Optional[str] = None,
        status_callback: Optional[Callable[[], Awaitable[Dict[str, Any]]]] = None,
        events_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
        suggestions_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
        cron_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
        refresh_interval: float = 5.0,
        auto_refresh: bool = True,
    ) -> None:
        """
        Initialize the terminal app.

        Args:
            user_id: Current user's ID
            team_id: Current user's team ID
            status_callback: Async function to get system cron status
            events_callback: Async function to get events for a cron
            suggestions_callback: Async function to get suggestions for a cron
            cron_callback: Async function to send messages to cron
            refresh_interval: Seconds between auto-refresh
            auto_refresh: Enable auto-refresh
        """
        super().__init__()
        self.user_id = user_id
        self.team_id = team_id
        self.status_callback = status_callback
        self.events_callback = events_callback
        self.suggestions_callback = suggestions_callback
        self.cron_callback = cron_callback
        self.refresh_interval = refresh_interval
        self.auto_refresh_enabled = auto_refresh

        # State
        self.selected_cron_id: Optional[str] = None
        self.current_status: Dict[str, Any] = {}
        self._refresh_timer: Optional[Timer] = None
        self._active_panel: str = "tree"  # "tree" or "detail"

    def compose(self) -> ComposeResult:
        """Compose the app layout."""
        yield Header(show_clock=True)

        with Horizontal(id="main-container"):
            # Left panel - Cron Tree
            with Vertical(id="left-panel"):
                yield Label("CRON PROCESSES", id="left-panel-title")
                yield CronTreeWidget(
                    current_user_id=self.user_id,
                    current_team_id=self.team_id,
                    id="cron-tree"
                )

            # Right panel - Detail Tabs
            with Vertical(id="right-panel"):
                yield Label("DETAILS", id="right-panel-title")
                yield DetailTabs(
                    cron_id=f"user:{self.user_id}",
                    current_user_id=self.user_id,
                    send_callback=self.cron_callback,
                    id="detail-tabs"
                )

        yield Footer()

    async def on_mount(self) -> None:
        """Initialize on app mount."""
        # Initial data load
        await self.action_refresh()

        # Select user's cron by default
        user_cron_id = f"user:{self.user_id}"
        tree = self.query_one("#cron-tree", CronTreeWidget)
        tree.select_cron(user_cron_id)
        self.selected_cron_id = user_cron_id

        # Start auto-refresh timer
        if self.auto_refresh_enabled:
            self._refresh_timer = self.set_interval(
                self.refresh_interval,
                self._auto_refresh
            )

    async def _auto_refresh(self) -> None:
        """Auto-refresh callback."""
        if self.auto_refresh_enabled:
            await self.action_refresh()

    async def action_refresh(self) -> None:
        """Refresh all data."""
        # Get system status
        if self.status_callback:
            self.current_status = await self.status_callback()
        else:
            self.current_status = self._get_mock_status()

        # Update tree
        tree = self.query_one("#cron-tree", CronTreeWidget)
        tree.build_from_status(self.current_status)

        # Update detail if cron is selected
        if self.selected_cron_id:
            await self._update_detail(self.selected_cron_id)

        # Update title with refresh time
        self.sub_title = f"Last refresh: {self._get_time_str()}"
        self.post_message(self.DataRefreshed())

    async def _update_detail(self, cron_id: str) -> None:
        """Update the detail panel for selected cron."""
        # Get cron-specific status
        cron_status = self._extract_cron_status(cron_id)

        # Get events
        events = []
        if self.events_callback:
            try:
                events = await self.events_callback(cron_id)
            except Exception:
                pass

        # Get suggestions
        suggestions = []
        if self.suggestions_callback:
            try:
                suggestions = await self.suggestions_callback(cron_id)
            except Exception:
                pass

        # Update detail tabs
        try:
            detail_tabs = self.query_one("#detail-tabs", DetailTabs)
            detail_tabs.update_for_cron(cron_id, cron_status, events, suggestions)

            # Update panel title
            panel_title = self.query_one("#right-panel-title", Label)
            cron_type = cron_id.split(":")[0] if ":" in cron_id else "system"
            owner = cron_id.split(":")[1] if ":" in cron_id else "System"
            panel_title.update(f"DETAILS: {cron_type.upper()}:{owner}")
        except Exception:
            pass

    def _extract_cron_status(self, cron_id: str) -> Dict[str, Any]:
        """Extract status for a specific cron from system status."""
        if cron_id == "system":
            return self.current_status.get("system", {})

        if ":" in cron_id:
            cron_type, owner_id = cron_id.split(":", 1)

            if cron_type == "team":
                return self.current_status.get("teams", {}).get(owner_id, {})

            if cron_type == "user":
                for team_status in self.current_status.get("teams", {}).values():
                    users = team_status.get("users", {})
                    if owner_id in users:
                        return users[owner_id]

        return {}

    def on_cron_tree_widget_cron_selected(
        self,
        event: CronTreeWidget.CronSelected
    ) -> None:
        """Handle cron selection from tree."""
        self.selected_cron_id = event.cron_id
        asyncio.create_task(self._update_detail(event.cron_id))

    def action_switch_panel(self) -> None:
        """Switch focus between panels."""
        if self._active_panel == "tree":
            self._active_panel = "detail"
            try:
                tabs = self.query_one("#detail-tabs", DetailTabs)
                tabs.focus()
            except Exception:
                pass
        else:
            self._active_panel = "tree"
            try:
                tree = self.query_one("#cron-tree", CronTreeWidget)
                tree.focus()
            except Exception:
                pass

    def action_show_help(self) -> None:
        """Show help modal."""
        help_text = """
[bold]LLMOS Cron Terminal - Keyboard Shortcuts[/bold]

[cyan]Navigation:[/cyan]
  [bold]Tab[/bold]       Switch between panels
  [bold]j/k[/bold]       Move up/down in tree
  [bold]Enter[/bold]     Select cron
  [bold]Space[/bold]     Expand/collapse node

[cyan]Function Keys:[/cyan]
  [bold]F1[/bold]        This help
  [bold]F5[/bold]        Refresh data
  [bold]F10/q[/bold]     Quit

[cyan]Other:[/cyan]
  [bold]Ctrl+P[/bold]    Command palette
  [bold]Ctrl+R[/bold]    Refresh
        """
        self.notify(help_text, title="Help", timeout=10)

    def action_show_menu(self) -> None:
        """Show menu (placeholder)."""
        self.notify("Menu coming soon...", title="Menu")

    def action_view_detail(self) -> None:
        """Focus on detail panel."""
        self._active_panel = "detail"
        try:
            tabs = self.query_one("#detail-tabs", DetailTabs)
            tabs.focus()
        except Exception:
            pass

    def action_edit(self) -> None:
        """Edit action (placeholder)."""
        self.notify("Edit not available for crons", title="Edit")

    def action_move(self) -> None:
        """Move action (placeholder)."""
        self.notify("Move not available", title="Move")

    def action_mkdir(self) -> None:
        """Create action (placeholder)."""
        self.notify("Create cron via /cron command", title="Create")

    def action_delete(self) -> None:
        """Delete action (placeholder)."""
        self.notify("Delete not available", title="Delete")

    def action_pull_down(self) -> None:
        """Pull down menu (placeholder)."""
        self.notify("Pull-down menu coming soon...", title="Menu")

    def action_toggle_auto_refresh(self) -> None:
        """Toggle auto-refresh."""
        self.auto_refresh_enabled = not self.auto_refresh_enabled
        if self.auto_refresh_enabled and not self._refresh_timer:
            self._refresh_timer = self.set_interval(
                self.refresh_interval,
                self._auto_refresh
            )
        elif not self.auto_refresh_enabled and self._refresh_timer:
            self._refresh_timer.stop()
            self._refresh_timer = None

        status = "enabled" if self.auto_refresh_enabled else "disabled"
        self.notify(f"Auto-refresh {status}", title="Auto-refresh")

    def _get_time_str(self) -> str:
        """Get current time string."""
        from datetime import datetime
        return datetime.now().strftime("%H:%M:%S")

    def _get_mock_status(self) -> Dict[str, Any]:
        """Generate mock status for testing."""
        from datetime import datetime
        return {
            "system": {
                "status": "thinking",
                "last_run": datetime.now().isoformat(),
                "current_thinking": {
                    "action": "Analyzing cross-team patterns",
                    "patterns": [
                        {"name": "API optimization", "count": 12},
                        {"name": "Cache invalidation", "count": 8},
                    ],
                    "considering": ["Suggest team-wide caching strategy"],
                }
            },
            "teams": {
                self.team_id or "default": {
                    "status": "analyzing",
                    "last_run": datetime.now().isoformat(),
                    "pending_notifications": 3,
                    "users": {
                        self.user_id: {
                            "status": "idle",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 5,
                            "current_task": None,
                            "current_thinking": {
                                "action": "Reviewing your recent traces",
                                "analyzed": ["trace_001", "trace_002"],
                                "considering": ["Suggest caching pattern"],
                            }
                        },
                        "alice": {
                            "status": "thinking",
                            "last_run": datetime.now().isoformat(),
                            "current_task": "Optimizing database queries",
                        },
                        "bob": {
                            "status": "proposing",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 2,
                        }
                    }
                },
                "design": {
                    "status": "idle",
                    "users": {
                        "carol": {"status": "idle"},
                        "dan": {"status": "analyzing"},
                    }
                }
            }
        }


async def run_terminal(
    user_id: str,
    team_id: Optional[str] = None,
    status_callback: Optional[Callable[[], Awaitable[Dict[str, Any]]]] = None,
    events_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
    suggestions_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
    cron_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
    **kwargs
) -> None:
    """
    Run the Textual terminal app.

    Args:
        user_id: Current user's ID
        team_id: Current user's team ID
        status_callback: Async function to get system cron status
        events_callback: Async function to get events for a cron
        suggestions_callback: Async function to get suggestions for a cron
        cron_callback: Async function to send messages to cron
        **kwargs: Additional arguments for CronTerminalApp
    """
    app = CronTerminalApp(
        user_id=user_id,
        team_id=team_id,
        status_callback=status_callback,
        events_callback=events_callback,
        suggestions_callback=suggestions_callback,
        cron_callback=cron_callback,
        **kwargs
    )
    await app.run_async()


def main():
    """Entry point for running the terminal directly."""
    import sys

    user_id = sys.argv[1] if len(sys.argv) > 1 else "demo_user"
    team_id = sys.argv[2] if len(sys.argv) > 2 else "engineering"

    app = CronTerminalApp(
        user_id=user_id,
        team_id=team_id,
    )
    app.run()


if __name__ == "__main__":
    main()



================================================
File: kernel/terminal/detail.py
================================================
"""
Cron Detail Panel - Right panel of the terminal.

Shows detailed information about the selected cron:
- Current thinking process
- Suggestions and predictions
- Activity log
- Interactive chat (for user's own cron)
"""

from typing import Dict, Any, Optional, List

from .models import (
    CronDetailView,
    ThinkingProcess,
    Suggestion,
    SuggestionType,
    ActivityEntry
)


class CronDetailPanel:
    """
    Renders and manages the cron detail view.

    The panel shows different sections based on the selected cron
    and whether the user can interact with it.
    """

    def __init__(self, current_user_id: str):
        self.current_user_id = current_user_id
        self.scroll_offset = 0

    def build_detail_view(
        self,
        cron_id: str,
        cron_status: Dict[str, Any],
        activity_events: List[Dict[str, Any]],
        suggestions: List[Dict[str, Any]]
    ) -> CronDetailView:
        """
        Build the detail view for a cron.

        Args:
            cron_id: ID of the cron
            cron_status: Status dict from the cron
            activity_events: Recent events for this cron
            suggestions: Suggestions generated by this cron

        Returns:
            CronDetailView object
        """
        cron_type = cron_id.split(":")[0] if ":" in cron_id else "system"
        owner_id = cron_id.split(":")[1] if ":" in cron_id else "system"

        # Determine if interactive
        is_interactive = (cron_type == "user" and owner_id == self.current_user_id)

        # Build display name
        type_icons = {"system": "ðŸ§ ", "team": "ðŸ‘¥", "user": "ðŸ‘¤"}
        display_name = f"{type_icons.get(cron_type, 'ðŸ¤–')} {cron_type.title()}Cron"
        if owner_id != "system":
            display_name += f":{owner_id}"
        if is_interactive:
            display_name += " [YOU]"

        # Build thinking process
        thinking = None
        if cron_status.get("current_thinking"):
            thinking = ThinkingProcess(
                current_action=cron_status["current_thinking"].get("action", "Idle"),
                analyzed_items=cron_status["current_thinking"].get("analyzed", []),
                found_patterns=cron_status["current_thinking"].get("patterns", []),
                considering=cron_status["current_thinking"].get("considering", []),
                cross_references=cron_status["current_thinking"].get("cross_refs", [])
            )

        # Build suggestions
        parsed_suggestions = []
        for s in suggestions:
            stype = self._parse_suggestion_type(s.get("type", "recommendation"))
            parsed_suggestions.append(Suggestion(
                suggestion_type=stype,
                title=s.get("title", ""),
                description=s.get("description", ""),
                confidence=s.get("confidence", 0.0),
                source=s.get("source"),
                action_id=s.get("action_id")
            ))

        # Build activity log
        activity_log = []
        for event in activity_events[:10]:  # Last 10 events
            icon = self._get_event_icon(event.get("event_type", ""))
            activity_log.append(ActivityEntry(
                timestamp=event.get("timestamp", ""),
                icon=icon,
                message=event.get("title", ""),
                event_id=event.get("event_id")
            ))

        return CronDetailView(
            cron_id=cron_id,
            cron_type=cron_type,
            display_name=display_name,
            is_interactive=is_interactive,
            thinking=thinking,
            suggestions=parsed_suggestions,
            activity_log=activity_log
        )

    def _parse_suggestion_type(self, type_str: str) -> SuggestionType:
        """Parse suggestion type string"""
        type_map = {
            "immediate": SuggestionType.IMMEDIATE,
            "recommendation": SuggestionType.RECOMMENDATION,
            "prediction": SuggestionType.PREDICTION,
            "creative": SuggestionType.CREATIVE
        }
        return type_map.get(type_str.lower(), SuggestionType.RECOMMENDATION)

    def _get_event_icon(self, event_type: str) -> str:
        """Get icon for event type"""
        icons = {
            "cron_started": "â–¶ï¸",
            "cron_stopped": "â¹ï¸",
            "cron_cycle_end": "âœ…",
            "artifact_created": "ðŸ“„",
            "artifact_evolved": "âœ¨",
            "artifact_promoted": "ðŸš€",
            "artifact_deleted": "ðŸ—‘ï¸",
            "proposal_created": "ðŸ“",
            "insight_generated": "ðŸ’¡",
            "suggestion_created": "ðŸŽ¯",
            "system_alert": "âš ï¸"
        }
        return icons.get(event_type.lower(), "ðŸ“Œ")

    def render(self, view: CronDetailView, width: int = 50, height: int = 30) -> List[str]:
        """
        Render the detail panel.

        Args:
            view: CronDetailView to render
            width: Width of the panel
            height: Height of the panel

        Returns:
            List of formatted lines
        """
        lines = []

        # Header
        lines.append(f"ðŸ“‹ CRON DETAILS: {view.display_name}")
        lines.append("â”€" * (width - 2))
        lines.append("")

        # Thinking Process Section
        lines.append("â”Œâ”€ Current Thinking " + "â”€" * (width - 22) + "â”")
        if view.thinking:
            thinking_lines = view.thinking.format().split("\n")
            for tl in thinking_lines:
                lines.append(f"â”‚ {tl:<{width - 4}} â”‚")
        else:
            lines.append(f"â”‚ {'âœ… Idle - no active analysis':<{width - 4}} â”‚")
        lines.append("â””" + "â”€" * (width - 2) + "â”˜")
        lines.append("")

        # Suggestions Section
        lines.append("â”Œâ”€ Suggested Next Steps " + "â”€" * (width - 26) + "â”")
        if view.suggestions:
            for s in view.suggestions[:4]:  # Max 4 suggestions
                suggestion_lines = s.format().split("\n")
                for sl in suggestion_lines:
                    lines.append(f"â”‚ {sl:<{width - 4}} â”‚")
                lines.append(f"â”‚ {'':<{width - 4}} â”‚")
        else:
            lines.append(f"â”‚ {'No suggestions at this time':<{width - 4}} â”‚")
        lines.append("â””" + "â”€" * (width - 2) + "â”˜")
        lines.append("")

        # Activity Log Section
        lines.append("â”Œâ”€ Recent Activity " + "â”€" * (width - 21) + "â”")
        if view.activity_log:
            for entry in view.activity_log[:5]:  # Max 5 entries
                entry_line = entry.format()
                lines.append(f"â”‚ {entry_line:<{width - 4}} â”‚")
        else:
            lines.append(f"â”‚ {'No recent activity':<{width - 4}} â”‚")
        lines.append("â””" + "â”€" * (width - 2) + "â”˜")
        lines.append("")

        # Interaction Section
        if view.is_interactive:
            lines.append("â”Œâ”€ Chat with Your Cron " + "â”€" * (width - 25) + "â”")
            # Show chat history
            for msg in view.chat_history[-3:]:  # Last 3 messages
                role = "You" if msg["role"] == "user" else "ðŸ¤– Cron"
                lines.append(f"â”‚ {role}: {msg['content'][:width - 12]:<{width - 10}} â”‚")
            lines.append(f"â”‚ {'':<{width - 4}} â”‚")
            lines.append(f"â”‚ {'> _':<{width - 4}} â”‚")
            lines.append("â””" + "â”€" * (width - 2) + "â”˜")
        else:
            lines.append("â”Œâ”€ " + view.display_name + " Activity " + "â”€" * (width - len(view.display_name) - 15) + "â”")
            lines.append(f"â”‚ {'ðŸ”’ READ-ONLY VIEW':<{width - 4}} â”‚")
            lines.append(f"â”‚ {'':<{width - 4}} â”‚")
            lines.append(f"â”‚ {'[You can view but not interact with this cron]':<{width - 4}} â”‚")
            lines.append("â””" + "â”€" * (width - 2) + "â”˜")

        # Pad to height
        while len(lines) < height:
            lines.append("")

        return lines[:height]

    def scroll_up(self):
        """Scroll up in the detail view"""
        if self.scroll_offset > 0:
            self.scroll_offset -= 1

    def scroll_down(self, content_height: int, view_height: int):
        """Scroll down in the detail view"""
        max_scroll = max(0, content_height - view_height)
        if self.scroll_offset < max_scroll:
            self.scroll_offset += 1



================================================
File: kernel/terminal/input_handler.py
================================================
"""
Terminal Input Handler - Cross-platform keyboard input.

Provides non-blocking keyboard input for the terminal UI.
Works on Unix (macOS/Linux) and Windows.
"""

import sys
import asyncio
from typing import Optional, Callable, Awaitable
from enum import Enum


class Key(Enum):
    """Special key codes"""
    UP = "UP"
    DOWN = "DOWN"
    LEFT = "LEFT"
    RIGHT = "RIGHT"
    ENTER = "ENTER"
    TAB = "TAB"
    ESCAPE = "ESCAPE"
    BACKSPACE = "BACKSPACE"
    QUIT = "QUIT"


class InputHandler:
    """
    Cross-platform keyboard input handler.

    Uses termios on Unix and msvcrt on Windows.
    """

    def __init__(self):
        self._old_settings = None
        self._is_windows = sys.platform == "win32"

    def setup(self):
        """Setup terminal for raw input"""
        if self._is_windows:
            # Windows doesn't need setup
            pass
        else:
            # Unix: disable line buffering
            import termios
            import tty
            self._old_settings = termios.tcgetattr(sys.stdin)
            tty.setcbreak(sys.stdin.fileno())

    def cleanup(self):
        """Restore terminal settings"""
        if self._is_windows:
            pass
        else:
            if self._old_settings:
                import termios
                termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self._old_settings)

    def _read_char_unix(self) -> Optional[str]:
        """Read a single character on Unix"""
        import select

        # Check if input is available (non-blocking)
        if select.select([sys.stdin], [], [], 0.1)[0]:
            ch = sys.stdin.read(1)

            # Handle escape sequences (arrow keys)
            if ch == '\x1b':
                # Read the rest of the escape sequence
                if select.select([sys.stdin], [], [], 0.1)[0]:
                    ch2 = sys.stdin.read(1)
                    if ch2 == '[':
                        if select.select([sys.stdin], [], [], 0.1)[0]:
                            ch3 = sys.stdin.read(1)
                            if ch3 == 'A':
                                return Key.UP.value
                            elif ch3 == 'B':
                                return Key.DOWN.value
                            elif ch3 == 'C':
                                return Key.RIGHT.value
                            elif ch3 == 'D':
                                return Key.LEFT.value
                return Key.ESCAPE.value

            # Handle special keys
            if ch == '\n' or ch == '\r':
                return Key.ENTER.value
            if ch == '\t':
                return Key.TAB.value
            if ch == '\x7f' or ch == '\x08':
                return Key.BACKSPACE.value
            if ch == 'q' or ch == 'Q':
                return Key.QUIT.value

            return ch

        return None

    def _read_char_windows(self) -> Optional[str]:
        """Read a single character on Windows"""
        import msvcrt

        if msvcrt.kbhit():
            ch = msvcrt.getch()

            # Handle special keys
            if ch == b'\xe0' or ch == b'\x00':
                # Extended key
                ch2 = msvcrt.getch()
                if ch2 == b'H':
                    return Key.UP.value
                elif ch2 == b'P':
                    return Key.DOWN.value
                elif ch2 == b'M':
                    return Key.RIGHT.value
                elif ch2 == b'K':
                    return Key.LEFT.value
                return None

            ch = ch.decode('utf-8', errors='ignore')

            if ch == '\r':
                return Key.ENTER.value
            if ch == '\t':
                return Key.TAB.value
            if ch == '\x08':
                return Key.BACKSPACE.value
            if ch == 'q' or ch == 'Q':
                return Key.QUIT.value
            if ch == '\x1b':
                return Key.ESCAPE.value

            return ch

        return None

    def read_key(self) -> Optional[str]:
        """
        Read a single key press (non-blocking).

        Returns:
            Key name or character, or None if no input available
        """
        if self._is_windows:
            return self._read_char_windows()
        else:
            return self._read_char_unix()

    async def read_key_async(self) -> Optional[str]:
        """
        Async version of read_key.

        Returns:
            Key name or character, or None if no input available
        """
        # Run in executor to avoid blocking
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.read_key)


async def run_terminal_loop(
    render_callback: Callable[[], str],
    input_callback: Callable[[str], Awaitable[bool]],
    refresh_callback: Callable[[], Awaitable[None]],
    refresh_interval: float = 5.0
):
    """
    Main terminal loop with input handling.

    Args:
        render_callback: Function that returns the terminal output string
        input_callback: Async function that handles input, returns False to quit
        refresh_callback: Async function to refresh data
        refresh_interval: Seconds between auto-refresh
    """
    handler = InputHandler()
    handler.setup()

    last_refresh = asyncio.get_event_loop().time()

    try:
        # Initial render
        print("\033[2J\033[H", end="")  # Clear screen
        print(render_callback())

        while True:
            # Check for input
            key = handler.read_key()

            if key:
                # Handle input
                should_continue = await input_callback(key)

                if not should_continue:
                    break

                # Re-render after input
                print("\033[2J\033[H", end="")  # Clear screen
                print(render_callback())

            # Auto-refresh
            current_time = asyncio.get_event_loop().time()
            if current_time - last_refresh >= refresh_interval:
                await refresh_callback()
                last_refresh = current_time
                print("\033[2J\033[H", end="")  # Clear screen
                print(render_callback())

            # Small sleep to prevent CPU spinning
            await asyncio.sleep(0.05)

    finally:
        handler.cleanup()
        print("\nðŸ‘‹ Terminal closed.")



================================================
File: kernel/terminal/interaction.py
================================================
"""
Cron Interaction Handler - Chat with your UserCron.

Enables interactive communication between users and their personal cron.
Only the owner can interact with their cron - others have read-only access.
"""

from typing import Dict, Any, Optional, List, Callable, Awaitable
from dataclasses import dataclass, field
from datetime import datetime
import asyncio


@dataclass
class ChatMessage:
    """A message in the cron chat"""
    role: str  # "user" or "cron"
    content: str
    timestamp: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class InteractionSession:
    """Active interaction session with a cron"""
    cron_id: str
    user_id: str
    messages: List[ChatMessage] = field(default_factory=list)
    started_at: str = ""
    is_active: bool = True

    def __post_init__(self):
        if not self.started_at:
            self.started_at = datetime.now().isoformat()


class CronInteraction:
    """
    Handles interactive chat with UserCron.

    The interaction system allows users to:
    - Ask their cron for suggestions
    - Request specific analysis
    - Approve or reject cron proposals
    - Guide cron behavior with preferences
    """

    def __init__(
        self,
        current_user_id: str,
        cron_callback: Optional[Callable[[str, str], Awaitable[str]]] = None
    ):
        """
        Initialize the interaction handler.

        Args:
            current_user_id: ID of the current user
            cron_callback: Async function to get cron responses
                          Takes (cron_id, user_message) -> cron_response
        """
        self.current_user_id = current_user_id
        self.cron_callback = cron_callback
        self.sessions: Dict[str, InteractionSession] = {}
        self.input_buffer: str = ""

    def can_interact(self, cron_id: str) -> bool:
        """
        Check if the user can interact with a cron.

        Only the owner of a UserCron can interact with it.
        SystemCron and TeamCrons are read-only for everyone.
        """
        if ":" not in cron_id:
            return False  # System cron - no interaction

        cron_type, owner_id = cron_id.split(":", 1)

        if cron_type == "user":
            return owner_id == self.current_user_id

        return False  # Team crons are read-only

    def get_or_create_session(self, cron_id: str) -> Optional[InteractionSession]:
        """Get existing session or create new one"""
        if not self.can_interact(cron_id):
            return None

        if cron_id not in self.sessions:
            self.sessions[cron_id] = InteractionSession(
                cron_id=cron_id,
                user_id=self.current_user_id
            )

        return self.sessions[cron_id]

    def add_user_message(self, cron_id: str, content: str) -> bool:
        """Add a user message to the session"""
        session = self.get_or_create_session(cron_id)
        if not session:
            return False

        session.messages.append(ChatMessage(
            role="user",
            content=content,
            timestamp=datetime.now().isoformat()
        ))
        return True

    def add_cron_response(self, cron_id: str, content: str, metadata: Optional[Dict] = None) -> bool:
        """Add a cron response to the session"""
        session = self.get_or_create_session(cron_id)
        if not session:
            return False

        session.messages.append(ChatMessage(
            role="cron",
            content=content,
            timestamp=datetime.now().isoformat(),
            metadata=metadata or {}
        ))
        return True

    async def send_message(self, cron_id: str, message: str) -> Optional[str]:
        """
        Send a message to the cron and get response.

        Args:
            cron_id: ID of the cron to message
            message: User's message

        Returns:
            Cron's response or None if interaction not allowed
        """
        if not self.can_interact(cron_id):
            return None

        # Add user message
        self.add_user_message(cron_id, message)

        # Get cron response
        if self.cron_callback:
            response = await self.cron_callback(cron_id, message)
        else:
            # Default response when no callback is configured
            response = self._generate_default_response(message)

        # Add cron response
        self.add_cron_response(cron_id, response)

        return response

    def _generate_default_response(self, message: str) -> str:
        """Generate a default response when no callback is configured"""
        message_lower = message.lower()

        if any(word in message_lower for word in ["suggest", "what should", "next"]):
            return "ðŸ’¡ Based on your recent activity, I suggest reviewing the pending proposals in your queue."

        if any(word in message_lower for word in ["analyze", "look at", "check"]):
            return "ðŸ” I'll analyze that for you. Give me a moment to review the relevant traces..."

        if any(word in message_lower for word in ["help", "how"]):
            return "ðŸ¤– I can help you with:\n  â€¢ Suggesting next steps\n  â€¢ Analyzing your traces\n  â€¢ Reviewing proposals\n  â€¢ Finding patterns in your work"

        return "ðŸ¤” I'm processing your request. What specific aspect would you like me to focus on?"

    def get_chat_history(self, cron_id: str, limit: int = 10) -> List[Dict[str, str]]:
        """Get recent chat history for display"""
        session = self.sessions.get(cron_id)
        if not session:
            return []

        messages = session.messages[-limit:]
        return [{"role": m.role, "content": m.content} for m in messages]

    def handle_input(self, char: str) -> Optional[str]:
        """
        Handle keyboard input for chat.

        Args:
            char: Input character

        Returns:
            Complete message if Enter pressed, None otherwise
        """
        if char == "\n" or char == "\r":
            # Enter pressed - return complete message
            message = self.input_buffer.strip()
            self.input_buffer = ""
            return message if message else None

        elif char == "\x7f" or char == "\b":
            # Backspace
            self.input_buffer = self.input_buffer[:-1]

        elif char.isprintable():
            # Regular character
            self.input_buffer += char

        return None

    def get_input_buffer(self) -> str:
        """Get current input buffer for display"""
        return self.input_buffer

    def clear_input(self):
        """Clear the input buffer"""
        self.input_buffer = ""

    def close_session(self, cron_id: str):
        """Close an interaction session"""
        if cron_id in self.sessions:
            self.sessions[cron_id].is_active = False

    def render_chat_input(self, width: int = 40) -> List[str]:
        """Render the chat input area"""
        lines = []

        # Input prompt
        cursor = "_" if len(self.input_buffer) < width - 5 else ""
        display_text = self.input_buffer[-(width - 5):] if self.input_buffer else ""
        lines.append(f"> {display_text}{cursor}")

        return lines

    def get_quick_actions(self) -> List[Dict[str, str]]:
        """Get quick action suggestions for the user"""
        return [
            {"key": "s", "label": "Suggest next steps"},
            {"key": "a", "label": "Analyze recent work"},
            {"key": "p", "label": "Show proposals"},
            {"key": "h", "label": "Help"}
        ]

    def render_quick_actions(self, width: int = 40) -> List[str]:
        """Render quick action buttons"""
        actions = self.get_quick_actions()
        lines = []

        lines.append("Quick actions:")
        for action in actions:
            lines.append(f"  [{action['key']}] {action['label']}")

        return lines



================================================
File: kernel/terminal/llmos_data_provider.py
================================================
"""
LLMOS Data Provider - Connects Terminal to Real LLMOS Data

This module bridges the Cron Terminal to actual LLMOS components:
- TraceManager: Execution traces and patterns
- MemoryStore: Facts and insights
- TokenEconomy: Spending and budget
- Dispatcher: Execution statistics

Usage:
    from kernel.terminal.llmos_data_provider import LLMOSDataProvider

    provider = LLMOSDataProvider(llmos_instance)
    terminal = CronTerminal(
        user_id="alice",
        status_callback=provider.get_system_status,
        events_callback=provider.get_events,
        suggestions_callback=provider.get_suggestions,
        cron_callback=provider.handle_user_message
    )
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path


class LLMOSDataProvider:
    """
    Provides real LLMOS data to the Cron Terminal.

    Maps LLMOS internal state to the terminal's expected format.
    """

    def __init__(
        self,
        trace_manager=None,
        memory_store=None,
        token_economy=None,
        dispatcher=None,
        workspace: Optional[Path] = None
    ):
        """
        Initialize the data provider.

        Args:
            trace_manager: TraceManager instance
            memory_store: MemoryStore instance
            token_economy: TokenEconomy instance
            dispatcher: Dispatcher instance
            workspace: Workspace path
        """
        self.trace_manager = trace_manager
        self.memory_store = memory_store
        self.token_economy = token_economy
        self.dispatcher = dispatcher
        self.workspace = workspace or Path("./workspace")

        # Track activity events
        self._events: List[Dict[str, Any]] = []
        self._max_events = 50

    def log_event(self, event_type: str, title: str, metadata: Optional[Dict] = None):
        """Log an activity event"""
        self._events.insert(0, {
            "event_type": event_type,
            "title": title,
            "timestamp": datetime.now().isoformat(),
            "event_id": f"evt_{len(self._events)}",
            "metadata": metadata or {}
        })
        # Keep only recent events
        self._events = self._events[:self._max_events]

    async def get_system_status(self) -> Dict[str, Any]:
        """
        Get system status for the terminal.

        Returns status in the format expected by CronTerminal.
        """
        # Get trace statistics
        trace_stats = {}
        if self.trace_manager:
            trace_stats = self.trace_manager.get_statistics()

        # Get memory statistics
        memory_stats = {}
        if self.memory_store:
            memory_stats = self.memory_store.get_statistics()

        # Get token economy stats
        token_stats = {}
        if self.token_economy:
            token_stats = {
                "balance": self.token_economy.balance,
                "total_spent": sum(log.cost for log in self.token_economy.spend_log),
                "transactions": len(self.token_economy.spend_log)
            }

        # Get dispatcher stats
        dispatcher_stats = {}
        if self.dispatcher:
            try:
                dispatcher_stats = self.dispatcher.get_execution_layer_stats()
            except:
                pass

        # Determine system state based on activity
        system_state = "idle"
        system_thinking = None

        if trace_stats.get("total_traces", 0) > 0:
            system_state = "analyzing"
            system_thinking = {
                "action": f"Monitoring {trace_stats.get('total_traces', 0)} execution traces",
                "patterns": [
                    {"name": "High-confidence traces", "count": trace_stats.get("high_confidence_count", 0)},
                    {"name": "Total executions", "count": trace_stats.get("total_usage", 0)}
                ]
            }

        # Build user cron status
        user_state = "idle"
        user_thinking = None
        pending_notifications = 0

        # Count insights as pending notifications
        if memory_stats.get("insights_count", 0) > 0:
            pending_notifications = memory_stats.get("insights_count", 0)
            user_state = "analyzing"
            user_thinking = {
                "action": "Reviewing stored insights and facts",
                "considering": [
                    f"{memory_stats.get('facts_count', 0)} facts available",
                    f"{memory_stats.get('insights_count', 0)} insights generated"
                ]
            }

        return {
            "system": {
                "status": system_state,
                "last_run": datetime.now().isoformat(),
                "current_thinking": system_thinking,
                "stats": {
                    "traces": trace_stats,
                    "memory": memory_stats,
                    "tokens": token_stats,
                    "dispatcher": dispatcher_stats
                }
            },
            "teams": {
                "default": {
                    "status": "idle",
                    "last_run": datetime.now().isoformat(),
                    "pending_notifications": 0,
                    "users": {
                        "user": {
                            "status": user_state,
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": pending_notifications,
                            "current_thinking": user_thinking
                        }
                    }
                }
            }
        }

    async def get_events(self, cron_id: str) -> List[Dict[str, Any]]:
        """Get activity events for a cron"""
        events = list(self._events)

        # Add trace-based events
        if self.trace_manager:
            traces = self.trace_manager.list_traces()
            for trace in traces[:5]:  # Last 5 traces
                events.append({
                    "event_type": "artifact_created",
                    "title": f"Trace: {trace.goal_text[:40]}...",
                    "timestamp": trace.created_at.isoformat(),
                    "event_id": f"trace_{trace.goal_signature[:8]}"
                })

        # Sort by timestamp
        events.sort(key=lambda e: e.get("timestamp", ""), reverse=True)
        return events[:10]

    async def get_suggestions(self, cron_id: str) -> List[Dict[str, Any]]:
        """Get suggestions based on LLMOS state"""
        suggestions = []

        # Suggestions based on trace statistics
        if self.trace_manager:
            stats = self.trace_manager.get_statistics()

            if stats.get("total_traces", 0) == 0:
                suggestions.append({
                    "type": "immediate",
                    "title": "Create your first execution trace",
                    "description": "Run a goal in interactive mode to start learning",
                    "confidence": 1.0,
                    "source": "No traces found"
                })
            elif stats.get("high_confidence_count", 0) > 0:
                suggestions.append({
                    "type": "recommendation",
                    "title": f"You have {stats['high_confidence_count']} reusable patterns",
                    "description": "Similar goals will execute in FOLLOWER mode (faster, cheaper)",
                    "confidence": 0.9,
                    "source": "Trace analysis"
                })

            # Check for crystallization candidates
            traces = self.trace_manager.list_traces()
            for trace in traces:
                if trace.usage_count >= 5 and trace.success_rating >= 0.95:
                    if not trace.crystallized_into_tool:
                        suggestions.append({
                            "type": "recommendation",
                            "title": f"Consider crystallizing: {trace.goal_text[:30]}...",
                            "description": f"Used {trace.usage_count} times with {trace.success_rating:.0%} success",
                            "confidence": 0.85,
                            "source": "HOPE crystallization candidate"
                        })
                        break

        # Suggestions based on memory
        if self.memory_store:
            stats = self.memory_store.get_statistics()

            if stats.get("insights_count", 0) > 0:
                suggestions.append({
                    "type": "prediction",
                    "title": f"Review {stats['insights_count']} stored insights",
                    "description": "Insights extracted from your execution patterns",
                    "confidence": 0.7,
                    "source": "Memory analysis"
                })

        # Budget suggestions
        if self.token_economy:
            remaining = self.token_economy.balance
            if remaining < 2.0:
                suggestions.append({
                    "type": "immediate",
                    "title": "Low token budget warning",
                    "description": f"${remaining:.2f} remaining - consider using FOLLOWER mode",
                    "confidence": 0.95,
                    "source": "Token economy"
                })

        return suggestions

    async def handle_user_message(self, cron_id: str, message: str) -> str:
        """
        Handle user message to their cron.

        Provides intelligent responses based on actual LLMOS state.
        """
        message_lower = message.lower()

        # Status query
        if any(word in message_lower for word in ["status", "stats", "statistics"]):
            return await self._get_status_response()

        # Trace query
        if any(word in message_lower for word in ["trace", "traces", "patterns", "learned"]):
            return await self._get_traces_response()

        # Memory query
        if any(word in message_lower for word in ["memory", "facts", "insights", "remember"]):
            return await self._get_memory_response()

        # Budget query
        if any(word in message_lower for word in ["budget", "tokens", "cost", "spent", "balance"]):
            return await self._get_budget_response()

        # Help
        if any(word in message_lower for word in ["help", "what can", "commands"]):
            return self._get_help_response()

        # Suggestions
        if any(word in message_lower for word in ["suggest", "what should", "recommend", "next"]):
            suggestions = await self.get_suggestions(cron_id)
            if suggestions:
                lines = ["ðŸŽ¯ Here are my suggestions:\n"]
                for i, s in enumerate(suggestions[:3], 1):
                    lines.append(f"{i}. **{s['title']}**")
                    lines.append(f"   {s['description']}")
                return "\n".join(lines)
            return "ðŸ¤” No specific suggestions at the moment. Try running some goals first!"

        # Default
        return f"""ðŸ¤” I heard: "{message[:50]}{'...' if len(message) > 50 else ''}"

Try asking me about:
â€¢ **status** - System statistics
â€¢ **traces** - Learned execution patterns
â€¢ **memory** - Stored facts and insights
â€¢ **budget** - Token spending
â€¢ **suggest** - What to do next"""

    async def _get_status_response(self) -> str:
        """Get detailed status response"""
        lines = ["ðŸ“Š **LLMOS Status**\n"]

        if self.trace_manager:
            stats = self.trace_manager.get_statistics()
            lines.append(f"**Traces**: {stats.get('total_traces', 0)} total, {stats.get('high_confidence_count', 0)} high-confidence")
            lines.append(f"**Avg Success**: {stats.get('avg_success_rate', 0):.0%}")

        if self.memory_store:
            stats = self.memory_store.get_statistics()
            lines.append(f"**Memory**: {stats.get('facts_count', 0)} facts, {stats.get('insights_count', 0)} insights")

        if self.token_economy:
            lines.append(f"**Budget**: ${self.token_economy.balance:.2f} remaining")

        return "\n".join(lines)

    async def _get_traces_response(self) -> str:
        """Get traces information"""
        if not self.trace_manager:
            return "âŒ Trace manager not available"

        traces = self.trace_manager.list_traces()

        if not traces:
            return "ðŸ“ No execution traces yet. Run some goals to start learning!"

        lines = [f"ðŸ“š **{len(traces)} Execution Traces**\n"]

        for trace in traces[:5]:
            status = "ðŸ’Ž" if trace.crystallized_into_tool else "âœ…" if trace.success_rating >= 0.9 else "ðŸ“"
            lines.append(f"{status} **{trace.goal_text[:40]}**...")
            lines.append(f"   Mode: {trace.mode} | Used: {trace.usage_count}x | Success: {trace.success_rating:.0%}")

        if len(traces) > 5:
            lines.append(f"\n...and {len(traces) - 5} more traces")

        return "\n".join(lines)

    async def _get_memory_response(self) -> str:
        """Get memory information"""
        if not self.memory_store:
            return "âŒ Memory store not available"

        stats = self.memory_store.get_statistics()
        lines = ["ðŸ§  **Memory Store**\n"]
        lines.append(f"**Facts**: {stats.get('facts_count', 0)}")
        lines.append(f"**Insights**: {stats.get('insights_count', 0)}")
        lines.append(f"**Sessions**: {stats.get('sessions_count', 0)}")

        # Show recent facts if available
        facts = self.memory_store.search_facts("", limit=3)
        if facts:
            lines.append("\n**Recent Facts:**")
            for fact in facts:
                lines.append(f"â€¢ {fact[:60]}...")

        return "\n".join(lines)

    async def _get_budget_response(self) -> str:
        """Get budget information"""
        if not self.token_economy:
            return "âŒ Token economy not available"

        balance = self.token_economy.balance
        spent = sum(log.cost for log in self.token_economy.spend_log)

        lines = ["ðŸ’° **Token Economy**\n"]
        lines.append(f"**Balance**: ${balance:.2f}")
        lines.append(f"**Spent**: ${spent:.4f}")
        lines.append(f"**Transactions**: {len(self.token_economy.spend_log)}")

        # Show recent transactions
        if self.token_economy.spend_log:
            lines.append("\n**Recent:**")
            for log in self.token_economy.spend_log[-3:]:
                lines.append(f"â€¢ ${log.cost:.4f} - {log.reason[:30]}")

        return "\n".join(lines)

    def _get_help_response(self) -> str:
        """Get help response"""
        return """ðŸ¤– **LLMOS Cron Assistant**

I can help you with:

â€¢ **status** - View system statistics
â€¢ **traces** - See learned execution patterns
â€¢ **memory** - View stored facts and insights
â€¢ **budget** - Check token spending
â€¢ **suggest** - Get recommendations

**Tips:**
- Run goals in interactive mode to create traces
- Similar goals will reuse existing patterns (FOLLOWER mode)
- High-usage patterns can be crystallized into tools (HOPE)"""



================================================
File: kernel/terminal/models.py
================================================
"""
Data models for the Cron Terminal.
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from enum import Enum
from datetime import datetime


class CronState(Enum):
    """State of a cron process"""
    IDLE = "idle"
    THINKING = "thinking"
    ANALYZING = "analyzing"
    PROPOSING = "proposing"
    ERROR = "error"
    STOPPED = "stopped"


class SuggestionType(Enum):
    """Types of suggestions a cron can make"""
    IMMEDIATE = "immediate"         # What to do right now
    RECOMMENDATION = "recommendation"  # General advice
    PREDICTION = "prediction"       # Predicted next steps
    CREATIVE = "creative"           # Novel approaches


@dataclass
class CronTreeNode:
    """A node in the cron hierarchy tree"""
    cron_id: str
    cron_type: str  # "system", "team", "user"
    owner_id: str
    display_name: str
    state: CronState
    last_activity: Optional[str] = None
    pending_notifications: int = 0
    current_task: Optional[str] = None
    children: List["CronTreeNode"] = field(default_factory=list)
    is_current_user: bool = False  # [YOU] marker

    def as_dict(self) -> Dict[str, Any]:
        return {
            "cron_id": self.cron_id,
            "cron_type": self.cron_type,
            "owner_id": self.owner_id,
            "display_name": self.display_name,
            "state": self.state.value,
            "last_activity": self.last_activity,
            "pending_notifications": self.pending_notifications,
            "current_task": self.current_task,
            "children": [c.as_dict() for c in self.children],
            "is_current_user": self.is_current_user
        }


@dataclass
class ThinkingProcess:
    """Current cognitive state of a cron"""
    current_action: str
    analyzed_items: List[str] = field(default_factory=list)
    found_patterns: List[Dict[str, Any]] = field(default_factory=list)
    considering: List[str] = field(default_factory=list)
    cross_references: List[str] = field(default_factory=list)

    def format(self) -> str:
        """Format for display"""
        lines = [f"ðŸ’­ {self.current_action}"]

        if self.found_patterns:
            lines.append("")
            lines.append("Found patterns:")
            for pattern in self.found_patterns:
                name = pattern.get("name", "Unknown")
                count = pattern.get("count", 0)
                lines.append(f"  â€¢ \"{name}\" - {count} traces")

        if self.considering:
            lines.append("")
            lines.append("Considering:")
            for item in self.considering:
                lines.append(f"  â†’ {item}")

        if self.cross_references:
            lines.append("")
            lines.append("Cross-referencing:")
            for ref in self.cross_references:
                lines.append(f"  ðŸ”— {ref}")

        return "\n".join(lines)


@dataclass
class Suggestion:
    """A suggestion from a cron"""
    suggestion_type: SuggestionType
    title: str
    description: str
    confidence: float = 0.0
    source: Optional[str] = None  # Where this suggestion came from
    action_id: Optional[str] = None  # ID for executing this suggestion

    def format(self) -> str:
        """Format for display"""
        icons = {
            SuggestionType.IMMEDIATE: "ðŸŽ¯ IMMEDIATE",
            SuggestionType.RECOMMENDATION: "ðŸ’¡ RECOMMENDATION",
            SuggestionType.PREDICTION: "ðŸ”® PREDICTION",
            SuggestionType.CREATIVE: "ðŸŽ¨ CREATIVE APPROACH"
        }

        lines = [icons.get(self.suggestion_type, "ðŸ“")]
        lines.append(f"   {self.title}")

        if self.confidence > 0:
            lines.append(f"   Confidence: {self.confidence:.0%}")

        if self.source:
            lines.append(f"   \"{self.source}\"")

        return "\n".join(lines)


@dataclass
class ActivityEntry:
    """An entry in the activity log"""
    timestamp: str
    icon: str
    message: str
    event_id: Optional[str] = None

    def format(self) -> str:
        """Format for display"""
        time_part = self.timestamp.split("T")[1][:8] if "T" in self.timestamp else self.timestamp
        return f"[{time_part}] {self.icon} {self.message}"


@dataclass
class CronDetailView:
    """Complete detail view for a cron"""
    cron_id: str
    cron_type: str
    display_name: str
    is_interactive: bool  # Can the user interact with this cron?

    thinking: Optional[ThinkingProcess] = None
    suggestions: List[Suggestion] = field(default_factory=list)
    activity_log: List[ActivityEntry] = field(default_factory=list)

    # For interactive mode
    chat_history: List[Dict[str, str]] = field(default_factory=list)


@dataclass
class TerminalState:
    """State of the terminal UI"""
    current_user_id: str
    current_team_id: Optional[str]

    # Tree state
    tree_root: Optional[CronTreeNode] = None
    selected_cron_id: Optional[str] = None
    expanded_nodes: List[str] = field(default_factory=list)

    # Detail state
    detail_view: Optional[CronDetailView] = None

    # UI state
    active_panel: str = "tree"  # "tree" or "detail"
    scroll_position: int = 0

    # Refresh
    last_refresh: Optional[str] = None
    auto_refresh: bool = True
    refresh_interval: float = 5.0  # seconds



================================================
File: kernel/terminal/tree.py
================================================
"""
Cron Tree View - Left panel of the terminal.

Displays the hierarchy of all crons with live status indicators.
"""

from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from .models import CronTreeNode, CronState


class CronTreeView:
    """
    Renders and manages the cron hierarchy tree.

    The tree shows:
    - SystemCron at the root
    - TeamCrons as children
    - UserCrons under their respective teams
    """

    def __init__(
        self,
        current_user_id: str,
        current_team_id: Optional[str] = None
    ):
        self.current_user_id = current_user_id
        self.current_team_id = current_team_id
        self.expanded_nodes: List[str] = ["system"]  # Expand system by default
        self.selected_cron_id: Optional[str] = None

    def build_tree(self, system_cron_status: Dict[str, Any]) -> CronTreeNode:
        """
        Build the tree structure from system cron status.

        Args:
            system_cron_status: Status dict from SystemCron.get_global_status()

        Returns:
            Root CronTreeNode
        """
        # Create system node
        system_node = CronTreeNode(
            cron_id="system",
            cron_type="system",
            owner_id="system",
            display_name="ðŸ§  SystemCron",
            state=self._parse_state(system_cron_status.get("system", {}).get("status", "idle")),
            last_activity=system_cron_status.get("system", {}).get("last_run"),
            pending_notifications=0
        )

        # Add team crons
        teams = system_cron_status.get("teams", {})
        for team_id, team_status in teams.items():
            team_node = CronTreeNode(
                cron_id=f"team:{team_id}",
                cron_type="team",
                owner_id=team_id,
                display_name=f"ðŸ‘¥ TeamCron:{team_id}",
                state=self._parse_state(team_status.get("status", "idle")),
                last_activity=team_status.get("last_run"),
                pending_notifications=team_status.get("pending_notifications", 0)
            )
            system_node.children.append(team_node)

            # Add user crons under this team
            users = team_status.get("users", {})
            for user_id, user_status in users.items():
                is_current = user_id == self.current_user_id
                user_node = CronTreeNode(
                    cron_id=f"user:{user_id}",
                    cron_type="user",
                    owner_id=user_id,
                    display_name=f"ðŸ‘¤ UserCron:{user_id}" + (" [YOU]" if is_current else ""),
                    state=self._parse_state(user_status.get("status", "idle")),
                    last_activity=user_status.get("last_run"),
                    pending_notifications=user_status.get("pending_notifications", 0),
                    current_task=user_status.get("current_task"),
                    is_current_user=is_current
                )
                team_node.children.append(user_node)

        # Expand current user's team by default
        if self.current_team_id:
            self.expanded_nodes.append(f"team:{self.current_team_id}")

        return system_node

    def _parse_state(self, state_str: str) -> CronState:
        """Parse state string to CronState enum"""
        state_map = {
            "idle": CronState.IDLE,
            "thinking": CronState.THINKING,
            "analyzing": CronState.ANALYZING,
            "proposing": CronState.PROPOSING,
            "running": CronState.THINKING,
            "error": CronState.ERROR,
            "stopped": CronState.STOPPED
        }
        return state_map.get(state_str.lower(), CronState.IDLE)

    def render(self, root: CronTreeNode, width: int = 35) -> List[str]:
        """
        Render the tree as a list of strings.

        Args:
            root: Root node of the tree
            width: Width of the panel

        Returns:
            List of formatted lines
        """
        lines = []
        lines.append("ðŸ¤– CRON PROCESSES")
        lines.append("â”€" * (width - 2))
        lines.append("")

        self._render_node(root, lines, prefix="", is_last=True, width=width)

        lines.append("")
        lines.append("â”€" * (width - 2))
        lines.append("[â†‘â†“] Navigate  [Enter] Select")
        lines.append("[â†â†’] Expand/Collapse  [r] Refresh")

        return lines

    def _render_node(
        self,
        node: CronTreeNode,
        lines: List[str],
        prefix: str,
        is_last: bool,
        width: int
    ):
        """Recursively render a node and its children"""
        # Determine connector
        connector = "â””â”€" if is_last else "â”œâ”€"

        # Expand/collapse indicator
        if node.children:
            is_expanded = node.cron_id in self.expanded_nodes
            expand_char = "â–¼" if is_expanded else "â–¶"
        else:
            expand_char = " "

        # Selection indicator
        is_selected = node.cron_id == self.selected_cron_id
        select_marker = "â—„" if is_selected else " "

        # State indicator
        state_icons = {
            CronState.IDLE: "âœ…",
            CronState.THINKING: "ðŸ’­",
            CronState.ANALYZING: "ðŸ”",
            CronState.PROPOSING: "ðŸ“",
            CronState.ERROR: "âŒ",
            CronState.STOPPED: "â¹ï¸"
        }
        state_icon = state_icons.get(node.state, "â“")

        # Build the line
        if prefix == "":
            # Root node
            line = f"{expand_char} {node.display_name} {select_marker}"
        else:
            line = f"{prefix}{connector}{expand_char} {node.display_name} {select_marker}"

        lines.append(line[:width - 2])

        # Add status line
        status_prefix = prefix + ("   " if is_last else "â”‚  ")
        status_parts = []

        if node.current_task:
            status_parts.append(f"{state_icon} {node.current_task[:20]}...")
        else:
            status_parts.append(f"{state_icon} {node.state.value}")

        if node.pending_notifications > 0:
            status_parts.append(f"ðŸ”” {node.pending_notifications}")

        status_line = f"{status_prefix}  {' | '.join(status_parts)}"
        lines.append(status_line[:width - 2])

        # Render children if expanded
        if node.children and node.cron_id in self.expanded_nodes:
            child_prefix = prefix + ("   " if is_last else "â”‚  ")
            for i, child in enumerate(node.children):
                is_child_last = (i == len(node.children) - 1)
                self._render_node(child, lines, child_prefix, is_child_last, width)

    def toggle_expand(self, cron_id: str):
        """Toggle expansion of a node"""
        if cron_id in self.expanded_nodes:
            self.expanded_nodes.remove(cron_id)
        else:
            self.expanded_nodes.append(cron_id)

    def select(self, cron_id: str):
        """Select a cron for detail view"""
        self.selected_cron_id = cron_id

    def navigate_up(self, root: CronTreeNode) -> Optional[str]:
        """Navigate to previous visible node"""
        visible = self._get_visible_nodes(root)
        if not visible:
            return None

        if self.selected_cron_id is None:
            return visible[-1].cron_id

        for i, node in enumerate(visible):
            if node.cron_id == self.selected_cron_id:
                if i > 0:
                    return visible[i - 1].cron_id
                return None

        return None

    def navigate_down(self, root: CronTreeNode) -> Optional[str]:
        """Navigate to next visible node"""
        visible = self._get_visible_nodes(root)
        if not visible:
            return None

        if self.selected_cron_id is None:
            return visible[0].cron_id

        for i, node in enumerate(visible):
            if node.cron_id == self.selected_cron_id:
                if i < len(visible) - 1:
                    return visible[i + 1].cron_id
                return None

        return None

    def _get_visible_nodes(self, node: CronTreeNode) -> List[CronTreeNode]:
        """Get list of visible nodes in order"""
        result = [node]

        if node.cron_id in self.expanded_nodes:
            for child in node.children:
                result.extend(self._get_visible_nodes(child))

        return result



================================================
File: kernel/terminal/ui.py
================================================
"""
Cron Terminal - Main UI Orchestration.

The terminal provides a two-panel interface for monitoring and interacting
with Sentience Crons. It combines the tree view, detail panel, and
interaction system into a cohesive dashboard.
"""

from typing import Dict, Any, Optional, List, Callable, Awaitable
from dataclasses import dataclass
import asyncio
from datetime import datetime

from .models import TerminalState, CronTreeNode, CronDetailView
from .tree import CronTreeView
from .detail import CronDetailPanel
from .interaction import CronInteraction


@dataclass
class TerminalConfig:
    """Configuration for the terminal UI"""
    width: int = 120
    height: int = 40
    tree_width: int = 40
    detail_width: int = 78
    refresh_interval: float = 5.0
    auto_refresh: bool = True


class CronTerminal:
    """
    Main terminal UI for the Cron system.

    Provides a two-panel dashboard:
    - Left: Tree view of all crons with live status
    - Right: Detail view of selected cron with interaction

    Usage:
        terminal = CronTerminal(
            user_id="alice",
            team_id="engineering",
            status_callback=get_system_status,
            events_callback=get_events,
            cron_callback=send_to_cron
        )
        await terminal.run()
    """

    def __init__(
        self,
        user_id: str,
        team_id: Optional[str] = None,
        status_callback: Optional[Callable[[], Awaitable[Dict[str, Any]]]] = None,
        events_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
        suggestions_callback: Optional[Callable[[str], Awaitable[List[Dict]]]] = None,
        cron_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
        config: Optional[TerminalConfig] = None
    ):
        """
        Initialize the terminal.

        Args:
            user_id: Current user's ID
            team_id: Current user's team ID
            status_callback: Async function to get system cron status
            events_callback: Async function to get events for a cron
            suggestions_callback: Async function to get suggestions for a cron
            cron_callback: Async function to send messages to cron
            config: Terminal configuration
        """
        self.user_id = user_id
        self.team_id = team_id
        self.config = config or TerminalConfig()

        # Callbacks
        self.status_callback = status_callback
        self.events_callback = events_callback
        self.suggestions_callback = suggestions_callback

        # Components
        self.tree_view = CronTreeView(user_id, team_id)
        self.detail_panel = CronDetailPanel(user_id)
        self.interaction = CronInteraction(user_id, cron_callback)

        # State
        self.state = TerminalState(
            current_user_id=user_id,
            current_team_id=team_id
        )
        self.running = False
        self.tree_root: Optional[CronTreeNode] = None
        self.detail_view: Optional[CronDetailView] = None

    async def refresh(self) -> bool:
        """
        Refresh all data from callbacks.

        Returns:
            True if refresh successful
        """
        try:
            # Get system status
            if self.status_callback:
                status = await self.status_callback()
            else:
                status = self._get_mock_status()

            # Build tree
            self.tree_root = self.tree_view.build_tree(status)

            # Update detail if cron is selected
            if self.tree_view.selected_cron_id:
                await self._refresh_detail(self.tree_view.selected_cron_id, status)

            self.state.last_refresh = datetime.now().isoformat()
            return True

        except Exception as e:
            print(f"Refresh error: {e}")
            return False

    async def _refresh_detail(self, cron_id: str, system_status: Dict[str, Any]):
        """Refresh detail view for selected cron"""
        # Get cron-specific status
        cron_status = self._extract_cron_status(cron_id, system_status)

        # Get events
        events = []
        if self.events_callback:
            events = await self.events_callback(cron_id)

        # Get suggestions
        suggestions = []
        if self.suggestions_callback:
            suggestions = await self.suggestions_callback(cron_id)

        # Build detail view
        self.detail_view = self.detail_panel.build_detail_view(
            cron_id=cron_id,
            cron_status=cron_status,
            activity_events=events,
            suggestions=suggestions
        )

        # Add chat history if interactive
        if self.detail_view.is_interactive:
            self.detail_view.chat_history = self.interaction.get_chat_history(cron_id)

    def _extract_cron_status(self, cron_id: str, system_status: Dict[str, Any]) -> Dict[str, Any]:
        """Extract status for a specific cron from system status"""
        if cron_id == "system":
            return system_status.get("system", {})

        if ":" in cron_id:
            cron_type, owner_id = cron_id.split(":", 1)

            if cron_type == "team":
                return system_status.get("teams", {}).get(owner_id, {})

            if cron_type == "user":
                # Find user in teams
                for team_status in system_status.get("teams", {}).values():
                    users = team_status.get("users", {})
                    if owner_id in users:
                        return users[owner_id]

        return {}

    def render(self) -> str:
        """
        Render the complete terminal UI.

        Returns:
            Complete terminal output as string
        """
        lines = []

        # Header
        lines.extend(self._render_header())
        lines.append("")

        # Main content (two panels side by side)
        tree_lines = self._render_tree_panel()
        detail_lines = self._render_detail_panel()

        # Combine panels
        max_lines = max(len(tree_lines), len(detail_lines))
        for i in range(max_lines):
            tree_line = tree_lines[i] if i < len(tree_lines) else ""
            detail_line = detail_lines[i] if i < len(detail_lines) else ""

            # Pad tree line to fixed width
            tree_line = f"{tree_line:<{self.config.tree_width}}"

            lines.append(f"â”‚{tree_line}â”‚{detail_line}â”‚")

        # Footer
        lines.append("")
        lines.extend(self._render_footer())

        return "\n".join(lines)

    def _render_header(self) -> List[str]:
        """Render terminal header"""
        width = self.config.width
        lines = []

        # Title bar
        title = "ðŸ§  LLMOS CRON TERMINAL"
        user_info = f"ðŸ‘¤ {self.user_id}"
        if self.team_id:
            user_info += f" | ðŸ‘¥ {self.team_id}"

        padding = width - len(title) - len(user_info) - 4
        lines.append("â•”" + "â•" * (width - 2) + "â•—")
        lines.append(f"â•‘ {title}{' ' * padding}{user_info} â•‘")
        lines.append("â• " + "â•" * (self.config.tree_width) + "â•¦" + "â•" * (self.config.detail_width) + "â•£")

        return lines

    def _render_tree_panel(self) -> List[str]:
        """Render the left tree panel"""
        if self.tree_root:
            return self.tree_view.render(self.tree_root, self.config.tree_width)
        else:
            lines = ["ðŸ¤– CRON PROCESSES", "â”€" * (self.config.tree_width - 2), "", "Loading..."]
            return lines

    def _render_detail_panel(self) -> List[str]:
        """Render the right detail panel"""
        if self.detail_view:
            return self.detail_panel.render(
                self.detail_view,
                self.config.detail_width,
                self.config.height - 6
            )
        else:
            lines = ["ðŸ“‹ SELECT A CRON", "â”€" * (self.config.detail_width - 2), ""]
            lines.append("Use arrow keys to navigate the tree")
            lines.append("Press Enter to select a cron")
            return lines

    def _render_footer(self) -> List[str]:
        """Render terminal footer"""
        width = self.config.width
        lines = []

        lines.append("â• " + "â•" * (width - 2) + "â•£")

        # Status bar
        refresh_status = f"Last refresh: {self.state.last_refresh or 'Never'}"
        auto_status = "ðŸ”„ Auto" if self.state.auto_refresh else "â¸ï¸ Paused"
        active_panel = f"Panel: {self.state.active_panel.upper()}"

        status_line = f" {refresh_status} | {auto_status} | {active_panel}"
        lines.append(f"â•‘{status_line:<{width - 2}}â•‘")

        # Keybindings
        keys = "[â†‘â†“] Navigate  [â†â†’] Expand  [Tab] Switch Panel  [r] Refresh  [q] Quit"
        lines.append(f"â•‘ {keys:<{width - 4}} â•‘")

        lines.append("â•š" + "â•" * (width - 2) + "â•")

        return lines

    async def handle_input(self, key: str) -> bool:
        """
        Handle keyboard input.

        Args:
            key: Input key/character

        Returns:
            True if terminal should continue, False to quit
        """
        # Quit
        if key.lower() == "q":
            return False

        # Refresh
        if key.lower() == "r":
            await self.refresh()
            return True

        # Switch panels
        if key == "\t":
            self.state.active_panel = "detail" if self.state.active_panel == "tree" else "tree"
            return True

        # Toggle auto-refresh
        if key.lower() == "a":
            self.state.auto_refresh = not self.state.auto_refresh
            return True

        # Panel-specific input
        if self.state.active_panel == "tree":
            await self._handle_tree_input(key)
        else:
            await self._handle_detail_input(key)

        return True

    async def _handle_tree_input(self, key: str):
        """Handle input for tree panel"""
        if not self.tree_root:
            return

        # Navigation
        if key == "UP" or key == "k":
            new_id = self.tree_view.navigate_up(self.tree_root)
            if new_id:
                self.tree_view.select(new_id)
                await self._refresh_detail(new_id, await self._get_status())

        elif key == "DOWN" or key == "j":
            new_id = self.tree_view.navigate_down(self.tree_root)
            if new_id:
                self.tree_view.select(new_id)
                await self._refresh_detail(new_id, await self._get_status())

        # Expand/Collapse
        elif key == "LEFT" or key == "RIGHT" or key == " ":
            if self.tree_view.selected_cron_id:
                self.tree_view.toggle_expand(self.tree_view.selected_cron_id)

        # Select (Enter)
        elif key == "\n" or key == "\r":
            if self.tree_view.selected_cron_id:
                self.state.active_panel = "detail"

    async def _handle_detail_input(self, key: str):
        """Handle input for detail panel"""
        if not self.detail_view:
            return

        # Scroll
        if key == "UP" or key == "k":
            self.detail_panel.scroll_up()

        elif key == "DOWN" or key == "j":
            self.detail_panel.scroll_down(30, self.config.height - 6)

        # Interactive mode input
        elif self.detail_view.is_interactive:
            message = self.interaction.handle_input(key)
            if message:
                # Send message to cron
                response = await self.interaction.send_message(
                    self.detail_view.cron_id,
                    message
                )
                # Refresh detail to show new messages
                if response:
                    self.detail_view.chat_history = self.interaction.get_chat_history(
                        self.detail_view.cron_id
                    )

    async def _get_status(self) -> Dict[str, Any]:
        """Get current system status"""
        if self.status_callback:
            return await self.status_callback()
        return self._get_mock_status()

    def _get_mock_status(self) -> Dict[str, Any]:
        """Generate mock status for testing"""
        return {
            "system": {
                "status": "thinking",
                "last_run": datetime.now().isoformat(),
                "current_thinking": {
                    "action": "Analyzing cross-team patterns",
                    "patterns": [
                        {"name": "API optimization", "count": 12}
                    ]
                }
            },
            "teams": {
                "engineering": {
                    "status": "analyzing",
                    "last_run": datetime.now().isoformat(),
                    "pending_notifications": 3,
                    "users": {
                        self.user_id: {
                            "status": "idle",
                            "last_run": datetime.now().isoformat(),
                            "pending_notifications": 5,
                            "current_task": None,
                            "current_thinking": {
                                "action": "Reviewing your recent traces",
                                "analyzed": ["trace_001", "trace_002"],
                                "considering": ["Suggest caching pattern"]
                            }
                        },
                        "bob": {
                            "status": "thinking",
                            "last_run": datetime.now().isoformat(),
                            "current_task": "Optimizing database queries"
                        }
                    }
                },
                "design": {
                    "status": "idle",
                    "users": {
                        "carol": {
                            "status": "idle"
                        }
                    }
                }
            }
        }

    async def run(self):
        """
        Run the terminal main loop with interactive keyboard input.

        This is the entry point for running the interactive terminal.
        """
        from .input_handler import InputHandler, Key

        self.running = True
        handler = InputHandler()
        handler.setup()

        try:
            # Initial refresh
            await self.refresh()

            # Select user's cron by default
            user_cron_id = f"user:{self.user_id}"
            self.tree_view.select(user_cron_id)
            if self.team_id:
                if f"team:{self.team_id}" not in self.tree_view.expanded_nodes:
                    self.tree_view.expanded_nodes.append(f"team:{self.team_id}")

            # Initial render
            print("\033[2J\033[H", end="")  # Clear screen
            print(self.render())

            last_refresh = asyncio.get_event_loop().time()

            while self.running:
                # Check for input (non-blocking)
                key = handler.read_key()

                if key:
                    # Map special keys
                    key_map = {
                        Key.UP.value: "UP",
                        Key.DOWN.value: "DOWN",
                        Key.LEFT.value: "LEFT",
                        Key.RIGHT.value: "RIGHT",
                        Key.ENTER.value: "\n",
                        Key.TAB.value: "\t",
                        Key.BACKSPACE.value: "\x7f",
                        Key.QUIT.value: "q",
                        Key.ESCAPE.value: "\x1b",
                    }
                    mapped_key = key_map.get(key, key)

                    # Handle input
                    should_continue = await self.handle_input(mapped_key)

                    if not should_continue:
                        break

                    # Re-render after input
                    print("\033[2J\033[H", end="")  # Clear screen
                    print(self.render())

                # Auto-refresh
                if self.state.auto_refresh:
                    current_time = asyncio.get_event_loop().time()
                    if current_time - last_refresh >= self.config.refresh_interval:
                        await self.refresh()
                        last_refresh = current_time
                        print("\033[2J\033[H", end="")  # Clear screen
                        print(self.render())

                # Small sleep to prevent CPU spinning
                await asyncio.sleep(0.05)

        except KeyboardInterrupt:
            self.running = False

        finally:
            handler.cleanup()
            print("\nðŸ‘‹ Terminal closed.")

    def stop(self):
        """Stop the terminal"""
        self.running = False


# Convenience function for quick start
async def start_terminal(
    user_id: str,
    team_id: Optional[str] = None,
    **kwargs
) -> CronTerminal:
    """
    Quick start function for the terminal.

    Args:
        user_id: Current user's ID
        team_id: Current user's team ID
        **kwargs: Additional arguments for CronTerminal

    Returns:
        Running CronTerminal instance
    """
    terminal = CronTerminal(user_id, team_id, **kwargs)
    await terminal.run()
    return terminal




================================================
File: kernel/terminal/styles/mc_blue.tcss
================================================
/* Midnight Commander Blue Theme for LLMOS Cron Terminal */

/* Global screen styling */
Screen {
    background: $surface;
    color: $text;
}

/* Header styling */
Header {
    background: $primary;
    color: $text;
    dock: top;
    height: 1;
}

/* Footer with function keys - MC style */
Footer {
    background: $primary-darken-2;
    color: $text;
    dock: bottom;
}

Footer > .footer--key {
    background: $secondary;
    color: $text;
    text-style: bold;
}

Footer > .footer--description {
    background: $primary-darken-1;
    color: $text-muted;
}

/* Main container */
#main-container {
    layout: horizontal;
    height: 100%;
}

/* Left panel - Cron Tree */
#left-panel {
    width: 35%;
    min-width: 30;
    max-width: 60;
    border: solid $primary;
    background: $surface-darken-1;
}

#left-panel-title {
    background: $primary;
    color: $text;
    text-style: bold;
    text-align: center;
    width: 100%;
    height: 1;
}

/* Right panel - Detail view */
#right-panel {
    width: 65%;
    border: solid $primary;
    background: $surface-darken-1;
}

#right-panel-title {
    background: $primary;
    color: $text;
    text-style: bold;
    text-align: center;
    width: 100%;
    height: 1;
}

/* Tree widget styling */
CronTreeWidget {
    padding: 0 1;
    scrollbar-gutter: stable;
}

CronTreeWidget > .tree--cursor {
    background: $accent;
    color: $text;
    text-style: bold;
}

CronTreeWidget > .tree--highlight {
    background: $primary-lighten-1;
}

CronTreeWidget > .tree--guides {
    color: $primary-lighten-2;
}

/* Tabbed content in detail panel */
TabbedContent {
    height: 100%;
}

ContentSwitcher {
    height: 1fr;
    background: $surface-darken-1;
}

Tabs {
    background: $primary-darken-1;
    dock: top;
}

Tab {
    background: $primary-darken-2;
    color: $text-muted;
    padding: 0 2;
}

Tab.-active {
    background: $primary;
    color: $text;
    text-style: bold;
}

Tab:hover {
    background: $primary-lighten-1;
}

/* Activity log */
ActivityLogWidget {
    height: 100%;
    padding: 1;
    scrollbar-gutter: stable;
}

ActivityLogWidget .log-entry {
    margin-bottom: 1;
}

ActivityLogWidget .log-timestamp {
    color: $text-muted;
}

ActivityLogWidget .log-icon {
    margin: 0 1;
}

/* Thinking view */
ThinkingView {
    padding: 1;
    height: auto;
}

ThinkingView .thinking-header {
    text-style: bold;
    color: $warning;
    margin-bottom: 1;
}

ThinkingView .thinking-action {
    color: $text;
    padding-left: 2;
}

ThinkingView .thinking-pattern {
    color: $success;
    padding-left: 4;
}

ThinkingView .thinking-considering {
    color: $secondary;
    padding-left: 4;
}

/* Suggestion list */
SuggestionList {
    padding: 1;
    height: auto;
}

.suggestion-card {
    background: $surface;
    border: solid $primary-darken-1;
    margin-bottom: 1;
    padding: 1;
}

.suggestion-card.-immediate {
    border: solid $error;
}

.suggestion-card.-recommendation {
    border: solid $success;
}

.suggestion-card.-prediction {
    border: solid $warning;
}

.suggestion-card.-creative {
    border: solid $secondary;
}

.suggestion-title {
    text-style: bold;
    margin-bottom: 1;
}

.suggestion-confidence {
    color: $text-muted;
}

/* Chat panel */
ChatPanel {
    height: 100%;
    layout: vertical;
}

#chat-log {
    height: 1fr;
    padding: 1;
    scrollbar-gutter: stable;
    background: $surface-darken-2;
}

.chat-message {
    margin-bottom: 1;
}

.chat-message.-user {
    text-align: right;
}

.chat-message.-user .chat-bubble {
    background: $primary;
}

.chat-message.-assistant .chat-bubble {
    background: $surface;
    border: solid $primary-darken-1;
}

.chat-role {
    color: $text-muted;
    text-style: italic;
}

#chat-input-container {
    dock: bottom;
    height: auto;
    padding: 1;
    background: $surface-darken-1;
    border-top: solid $primary;
}

#chat-input {
    width: 100%;
}

/* Status indicators */
.status-idle {
    color: $success;
}

.status-thinking {
    color: $warning;
}

.status-analyzing {
    color: $secondary;
}

.status-proposing {
    color: $primary;
}

.status-error {
    color: $error;
}

.status-stopped {
    color: $text-muted;
}

/* Notification badge */
.notification-badge {
    background: $error;
    color: $text;
    text-style: bold;
    padding: 0 1;
    min-width: 3;
}

/* Info panel */
#info-panel {
    padding: 1;
    height: 100%;
}

.info-section {
    margin-bottom: 2;
}

.info-label {
    color: $text-muted;
    text-style: italic;
}

.info-value {
    color: $text;
    padding-left: 2;
}

/* Command palette modal */
CommandPalette {
    layer: overlay;
    background: $surface 90%;
}

/* Scrollbars */
Vertical {
    scrollbar-background: $surface-darken-2;
    scrollbar-color: $primary;
    scrollbar-color-hover: $primary-lighten-1;
    scrollbar-color-active: $accent;
}

/* Selection highlight */
.selected {
    background: $accent;
    color: $text;
}

/* Focus styling */
*:focus {
    border: tall $accent;
}

/* Disabled state */
*:disabled {
    opacity: 0.5;
}

/* Loading indicator */
LoadingIndicator {
    color: $warning;
}



================================================
File: kernel/terminal/widgets/__init__.py
================================================
"""
Textual widgets for the Cron Terminal.

This module provides custom Textual widgets for the MC-style terminal UI.
"""

from .cron_tree import CronTreeWidget
from .detail_tabs import DetailTabs
from .activity_log import ActivityLogWidget
from .chat_panel import ChatPanel
from .thinking_view import ThinkingView
from .suggestion_list import SuggestionList

__all__ = [
    "CronTreeWidget",
    "DetailTabs",
    "ActivityLogWidget",
    "ChatPanel",
    "ThinkingView",
    "SuggestionList",
]



================================================
File: kernel/terminal/widgets/activity_log.py
================================================
"""
ActivityLogWidget - Widget for displaying cron activity history.

Shows a scrollable log of recent events with timestamps and icons.
"""

from typing import List, Dict, Any, Optional
from datetime import datetime

from textual.widgets import RichLog
from textual.message import Message
from rich.text import Text

from ..models import ActivityEntry


class ActivityLogWidget(RichLog):
    """
    Widget for displaying activity log entries.

    Features:
    - Auto-scrolling to new entries
    - Color-coded event types
    - Clickable event IDs (for future expansion)
    - Timestamp formatting
    """

    DEFAULT_CSS = """
    ActivityLogWidget {
        height: 100%;
        border: solid $primary-darken-1;
        padding: 0 1;
    }
    """

    class EventClicked(Message):
        """Message sent when an event entry is clicked."""
        def __init__(self, event_id: str) -> None:
            self.event_id = event_id
            super().__init__()

    # Event type to icon/color mapping
    EVENT_STYLES = {
        "cron_started": (">>", "green"),
        "cron_stopped": ("[]", "red"),
        "cron_cycle_end": ("OK", "green"),
        "artifact_created": ("++", "cyan"),
        "artifact_evolved": ("**", "yellow"),
        "artifact_promoted": ("^^", "green bold"),
        "artifact_deleted": ("--", "red"),
        "proposal_created": ("??", "blue"),
        "insight_generated": ("!!", "yellow"),
        "suggestion_created": ("->", "cyan"),
        "system_alert": ("!!", "red bold"),
    }

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, highlight=True, markup=True, **kwargs)
        self._entries: List[ActivityEntry] = []

    def add_entry(self, entry: ActivityEntry) -> None:
        """
        Add a single log entry.

        Args:
            entry: ActivityEntry to add
        """
        self._entries.append(entry)
        self._write_entry(entry)

    def add_entries(self, entries: List[ActivityEntry]) -> None:
        """
        Add multiple log entries.

        Args:
            entries: List of ActivityEntry objects
        """
        for entry in entries:
            self._entries.append(entry)
            self._write_entry(entry)

    def _write_entry(self, entry: ActivityEntry) -> None:
        """Write a single entry to the log."""
        # Format timestamp
        try:
            if "T" in entry.timestamp:
                dt = datetime.fromisoformat(entry.timestamp.replace("Z", "+00:00"))
                time_str = dt.strftime("%H:%M:%S")
            else:
                time_str = entry.timestamp
        except (ValueError, AttributeError):
            time_str = "??:??:??"

        # Get style for event type
        event_type = getattr(entry, "event_type", "") or ""
        icon, color = self.EVENT_STYLES.get(
            event_type.lower(),
            (entry.icon or "**", "white")
        )

        # Build rich text
        text = Text()
        text.append(f"[{time_str}] ", style="dim")
        text.append(f"[{icon}] ", style=color)
        text.append(entry.message)

        if entry.event_id:
            text.append(f" ({entry.event_id[:8]})", style="dim italic")

        self.write(text)

    def clear_log(self) -> None:
        """Clear all entries."""
        self._entries.clear()
        self.clear()

    def load_from_events(self, events: List[Dict[str, Any]]) -> None:
        """
        Load entries from event dictionaries.

        Args:
            events: List of event dicts with timestamp, title, event_type, event_id
        """
        self.clear_log()

        entries = []
        for event in events:
            entry = ActivityEntry(
                timestamp=event.get("timestamp", ""),
                icon=self._get_event_icon(event.get("event_type", "")),
                message=event.get("title", event.get("message", "")),
                event_id=event.get("event_id"),
            )
            # Store event_type for styling
            entry.event_type = event.get("event_type", "")
            entries.append(entry)

        self.add_entries(entries)

    def _get_event_icon(self, event_type: str) -> str:
        """Get icon for event type."""
        icons = {
            "cron_started": ">>",
            "cron_stopped": "[]",
            "cron_cycle_end": "OK",
            "artifact_created": "++",
            "artifact_evolved": "**",
            "artifact_promoted": "^^",
            "artifact_deleted": "--",
            "proposal_created": "??",
            "insight_generated": "!!",
            "suggestion_created": "->",
            "system_alert": "!!",
        }
        return icons.get(event_type.lower(), "**")

    @classmethod
    def from_events(cls, events: List[Dict[str, Any]]) -> "ActivityLogWidget":
        """
        Create an ActivityLogWidget from a list of events.

        Args:
            events: List of event dictionaries

        Returns:
            Configured ActivityLogWidget
        """
        widget = cls()
        widget.load_from_events(events)
        return widget



================================================
File: kernel/terminal/widgets/chat_panel.py
================================================
"""
ChatPanel - Interactive chat widget for communicating with UserCron.

Provides a chat interface for users to interact with their personal cron.
"""

from typing import List, Dict, Optional, Callable, Awaitable
from datetime import datetime

from textual.widgets import Static, Input, RichLog
from textual.containers import Vertical, Horizontal
from textual.message import Message
from textual.binding import Binding
from rich.text import Text
from rich.panel import Panel


class ChatPanel(Vertical):
    """
    Interactive chat panel for cron communication.

    Features:
    - Message history display
    - Input field with send on Enter
    - User/Assistant message styling
    - Typing indicator
    - Auto-scroll to latest
    """

    DEFAULT_CSS = """
    ChatPanel {
        height: 100%;
        layout: vertical;
    }

    #chat-history {
        height: 1fr;
        border: solid $primary-darken-1;
        padding: 1;
        overflow-y: auto;
    }

    #chat-input-area {
        height: auto;
        dock: bottom;
        padding: 1;
        background: $surface-darken-1;
        border-top: solid $primary;
    }

    #chat-input {
        width: 100%;
    }

    .chat-message {
        margin-bottom: 1;
    }

    .chat-message-user {
        text-align: right;
    }

    .chat-message-assistant {
        text-align: left;
    }
    """

    BINDINGS = [
        Binding("escape", "blur_input", "Cancel"),
    ]

    class MessageSent(Message):
        """Message sent when user sends a chat message."""
        def __init__(self, content: str, cron_id: str) -> None:
            self.content = content
            self.cron_id = cron_id
            super().__init__()

    def __init__(
        self,
        cron_id: str,
        is_interactive: bool = True,
        send_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
        *args,
        **kwargs
    ) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id
        self.is_interactive = is_interactive
        self.send_callback = send_callback
        self._history: List[Dict[str, str]] = []
        self._is_typing = False

    def compose(self):
        """Compose the chat panel."""
        yield RichLog(id="chat-history", highlight=True, markup=True)

        if self.is_interactive:
            with Horizontal(id="chat-input-area"):
                yield Input(
                    placeholder="Type a message... (Enter to send)",
                    id="chat-input"
                )
        else:
            yield Static(
                "[dim][READ-ONLY] You can view but not interact with this cron[/dim]",
                id="chat-readonly-notice"
            )

    def on_mount(self) -> None:
        """Initialize the chat display."""
        self._render_history()

    def on_input_submitted(self, event: Input.Submitted) -> None:
        """Handle message submission."""
        if not event.value.strip():
            return

        message = event.value.strip()
        event.input.value = ""

        # Add user message
        self.add_message("user", message)

        # Post message for handling
        self.post_message(self.MessageSent(message, self.cron_id))

        # Show typing indicator
        self._show_typing()

    async def send_and_receive(self, message: str) -> Optional[str]:
        """
        Send a message and get response via callback.

        Args:
            message: Message to send

        Returns:
            Response from cron, or None if failed
        """
        if not self.send_callback:
            return None

        try:
            response = await self.send_callback(self.cron_id, message)
            self.add_message("assistant", response)
            return response
        except Exception as e:
            self.add_message("system", f"Error: {e}")
            return None
        finally:
            self._hide_typing()

    def add_message(self, role: str, content: str) -> None:
        """
        Add a message to the chat history.

        Args:
            role: "user", "assistant", or "system"
            content: Message content
        """
        self._history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        })
        self._write_message(role, content)

    def _write_message(self, role: str, content: str) -> None:
        """Write a single message to the log."""
        log = self.query_one("#chat-history", RichLog)

        text = Text()

        if role == "user":
            text.append("You: ", style="bold cyan")
            text.append(content)
        elif role == "assistant":
            text.append("Cron: ", style="bold green")
            text.append(content)
        else:  # system
            text.append("[", style="dim")
            text.append(content, style="yellow")
            text.append("]", style="dim")

        log.write(text)

    def _show_typing(self) -> None:
        """Show typing indicator."""
        if self._is_typing:
            return
        self._is_typing = True
        log = self.query_one("#chat-history", RichLog)
        log.write(Text("Cron is thinking...", style="dim italic"))

    def _hide_typing(self) -> None:
        """Hide typing indicator."""
        self._is_typing = False
        # Note: RichLog doesn't support removing lines, so we just continue

    def _render_history(self) -> None:
        """Render existing chat history."""
        for msg in self._history:
            self._write_message(msg["role"], msg["content"])

    def load_history(self, history: List[Dict[str, str]]) -> None:
        """
        Load chat history.

        Args:
            history: List of message dicts with role and content
        """
        self._history = history
        log = self.query_one("#chat-history", RichLog)
        log.clear()
        self._render_history()

    def clear_history(self) -> None:
        """Clear chat history."""
        self._history.clear()
        log = self.query_one("#chat-history", RichLog)
        log.clear()

    def action_blur_input(self) -> None:
        """Blur the input field."""
        try:
            input_widget = self.query_one("#chat-input", Input)
            input_widget.blur()
        except Exception:
            pass


class ReadOnlyChatPanel(Static):
    """
    Read-only panel shown for non-interactive crons.
    """

    DEFAULT_CSS = """
    ReadOnlyChatPanel {
        height: 100%;
        content-align: center middle;
        padding: 2;
    }
    """

    def __init__(self, cron_id: str, owner_name: str, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id
        self.owner_name = owner_name

    def compose(self):
        """Compose the read-only notice."""
        panel = Panel(
            f"[dim]This is [bold]{self.owner_name}[/bold]'s cron.\n\n"
            "You can view activity but cannot interact.\n\n"
            "Select [bold]your[/bold] UserCron to chat.[/dim]",
            title="[yellow]Read-Only View[/yellow]",
            border_style="yellow",
        )
        yield Static(panel)



================================================
File: kernel/terminal/widgets/cron_tree.py
================================================
"""
CronTreeWidget - Custom tree widget for displaying cron hierarchy.

Provides a tree view of SystemCron -> TeamCrons -> UserCrons with
live status indicators and notification badges.
"""

from typing import Optional, Dict, Any, List
from dataclasses import dataclass

from textual.widgets import Tree
from textual.widgets.tree import TreeNode
from textual.message import Message
from rich.text import Text

from ..models import CronState


@dataclass
class CronNodeData:
    """Data associated with a tree node."""
    cron_id: str
    cron_type: str  # "system", "team", "user"
    owner_id: str
    state: CronState
    pending_notifications: int = 0
    current_task: Optional[str] = None
    is_current_user: bool = False


class CronTreeWidget(Tree[CronNodeData]):
    """
    Custom tree widget for the cron hierarchy.

    Features:
    - Status icons with colors (idle=green, thinking=yellow, etc.)
    - Notification badges
    - Current user highlighting
    - Vim-style navigation (j/k)
    """

    BINDINGS = [
        ("j", "cursor_down", "Down"),
        ("k", "cursor_up", "Up"),
        ("g", "scroll_home", "Top"),
        ("G", "scroll_end", "Bottom"),
        ("space", "toggle_node", "Expand/Collapse"),
    ]

    class CronSelected(Message):
        """Message sent when a cron is selected."""
        def __init__(self, cron_id: str, cron_type: str, owner_id: str) -> None:
            self.cron_id = cron_id
            self.cron_type = cron_type
            self.owner_id = owner_id
            super().__init__()

    def __init__(
        self,
        current_user_id: str,
        current_team_id: Optional[str] = None,
        *args,
        **kwargs
    ) -> None:
        super().__init__("CRON PROCESSES", *args, **kwargs)
        self.current_user_id = current_user_id
        self.current_team_id = current_team_id
        self.show_root = True
        self.show_guides = True
        self.guide_depth = 2

    def _get_state_icon(self, state: CronState) -> str:
        """Get status icon for a cron state."""
        icons = {
            CronState.IDLE: "[green]:[/green]",
            CronState.THINKING: "[yellow]:[/yellow]",
            CronState.ANALYZING: "[cyan]:[/cyan]",
            CronState.PROPOSING: "[blue]:[/blue]",
            CronState.ERROR: "[red]:[/red]",
            CronState.STOPPED: "[dim]:[/dim]",
        }
        return icons.get(state, "[white]:[/white]")

    def _get_type_icon(self, cron_type: str) -> str:
        """Get icon for cron type."""
        icons = {
            "system": "[bold cyan]SYS[/bold cyan]",
            "team": "[bold blue]TM[/bold blue]",
            "user": "[bold green]USR[/bold green]",
        }
        return icons.get(cron_type, "[white]?[/white]")

    def _format_node_label(self, data: CronNodeData) -> Text:
        """Format the label for a tree node with rich styling."""
        # State indicator
        state_icon = self._get_state_icon(data.state)

        # Type icon
        type_icon = self._get_type_icon(data.cron_type)

        # Name
        if data.cron_type == "system":
            name = "SystemCron"
        elif data.cron_type == "team":
            name = f"Team:{data.owner_id}"
        else:
            name = f"User:{data.owner_id}"

        # Current user marker
        user_marker = ""
        if data.is_current_user:
            user_marker = " [bold yellow][YOU][/bold yellow]"

        # Notification badge
        notif_badge = ""
        if data.pending_notifications > 0:
            notif_badge = f" [bold red on white] {data.pending_notifications} [/bold red on white]"

        # Current task preview
        task_preview = ""
        if data.current_task:
            short_task = data.current_task[:20] + "..." if len(data.current_task) > 20 else data.current_task
            task_preview = f"\n    [dim]{short_task}[/dim]"

        label = f"{state_icon} {type_icon} {name}{user_marker}{notif_badge}{task_preview}"
        return Text.from_markup(label)

    def build_from_status(self, system_status: Dict[str, Any]) -> None:
        """
        Build the tree from system cron status.

        Args:
            system_status: Status dict from SystemCron.get_global_status()
        """
        self.clear()

        # Parse system state
        system_data = system_status.get("system", {})
        system_state = self._parse_state(system_data.get("status", "idle"))

        # Create root node (SystemCron)
        root_data = CronNodeData(
            cron_id="system",
            cron_type="system",
            owner_id="system",
            state=system_state,
            pending_notifications=0,
            current_task=(system_data.get("current_thinking") or {}).get("action"),
        )
        self.root.data = root_data
        self.root.label = self._format_node_label(root_data)
        self.root.expand()

        # Add team crons
        teams = system_status.get("teams", {})
        for team_id, team_status in teams.items():
            team_state = self._parse_state(team_status.get("status", "idle"))
            team_data = CronNodeData(
                cron_id=f"team:{team_id}",
                cron_type="team",
                owner_id=team_id,
                state=team_state,
                pending_notifications=team_status.get("pending_notifications", 0),
            )

            team_node = self.root.add(
                self._format_node_label(team_data),
                data=team_data,
            )

            # Expand current user's team by default
            if team_id == self.current_team_id:
                team_node.expand()

            # Add user crons under this team
            users = team_status.get("users", {})
            for user_id, user_status in users.items():
                is_current = user_id == self.current_user_id
                user_state = self._parse_state(user_status.get("status", "idle"))
                user_data = CronNodeData(
                    cron_id=f"user:{user_id}",
                    cron_type="user",
                    owner_id=user_id,
                    state=user_state,
                    pending_notifications=user_status.get("pending_notifications", 0),
                    current_task=user_status.get("current_task"),
                    is_current_user=is_current,
                )

                team_node.add(
                    self._format_node_label(user_data),
                    data=user_data,
                )

    def _parse_state(self, state_str: str) -> CronState:
        """Parse state string to CronState enum."""
        state_map = {
            "idle": CronState.IDLE,
            "thinking": CronState.THINKING,
            "analyzing": CronState.ANALYZING,
            "proposing": CronState.PROPOSING,
            "running": CronState.THINKING,
            "error": CronState.ERROR,
            "stopped": CronState.STOPPED,
        }
        return state_map.get(state_str.lower(), CronState.IDLE)

    def on_tree_node_selected(self, event: Tree.NodeSelected) -> None:
        """Handle node selection and post message."""
        if event.node.data:
            data = event.node.data
            self.post_message(
                self.CronSelected(
                    cron_id=data.cron_id,
                    cron_type=data.cron_type,
                    owner_id=data.owner_id,
                )
            )

    def select_cron(self, cron_id: str) -> bool:
        """
        Programmatically select a cron by ID.

        Args:
            cron_id: The cron ID to select

        Returns:
            True if found and selected
        """
        def find_node(node: TreeNode, target_id: str) -> Optional[TreeNode]:
            if node.data and node.data.cron_id == target_id:
                return node
            for child in node.children:
                result = find_node(child, target_id)
                if result:
                    return result
            return None

        target_node = find_node(self.root, cron_id)
        if target_node:
            self.select_node(target_node)
            # Expand parent nodes
            parent = target_node.parent
            while parent:
                parent.expand()
                parent = parent.parent
            return True
        return False

    def refresh_node(self, cron_id: str, new_state: CronState,
                     notifications: int = 0, current_task: Optional[str] = None) -> None:
        """
        Update a specific node's display.

        Args:
            cron_id: The cron ID to update
            new_state: New state for the cron
            notifications: New notification count
            current_task: Current task description
        """
        def find_and_update(node: TreeNode) -> bool:
            if node.data and node.data.cron_id == cron_id:
                node.data.state = new_state
                node.data.pending_notifications = notifications
                node.data.current_task = current_task
                node.label = self._format_node_label(node.data)
                return True
            for child in node.children:
                if find_and_update(child):
                    return True
            return False

        find_and_update(self.root)



================================================
File: kernel/terminal/widgets/detail_tabs.py
================================================
"""
DetailTabs - Tabbed detail panel for the right side of the terminal.

Provides tabs for Info, Activity, Chat, and Config views.
"""

from typing import Optional, Dict, Any, List, Callable, Awaitable

from textual.widgets import TabbedContent, TabPane, Static, Label
from textual.containers import Vertical, ScrollableContainer
from textual.message import Message
from rich.text import Text
from rich.panel import Panel
from rich.table import Table

from .thinking_view import ThinkingView
from .activity_log import ActivityLogWidget
from .suggestion_list import SuggestionList
from .chat_panel import ChatPanel, ReadOnlyChatPanel
from ..models import CronDetailView, ThinkingProcess, Suggestion


class InfoTab(ScrollableContainer):
    """
    Info tab showing cron overview and current state.
    """

    DEFAULT_CSS = """
    InfoTab {
        height: 100%;
        padding: 1;
    }

    InfoTab .section-title {
        text-style: bold;
        margin-bottom: 1;
        color: $primary-lighten-2;
    }

    InfoTab .info-row {
        margin-bottom: 1;
    }
    """

    def __init__(self, cron_id: str, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id
        self._cron_status: Dict[str, Any] = {}
        self._suggestions: List[Suggestion] = []

    def compose(self):
        """Compose the info tab."""
        yield ThinkingView(id="thinking-view")
        yield Static("", id="info-divider")
        yield Label("Suggested Actions", classes="section-title")
        yield SuggestionList(id="suggestion-list")

    def update_info(
        self,
        cron_status: Dict[str, Any],
        suggestions: List[Dict[str, Any]]
    ) -> None:
        """
        Update the info display.

        Args:
            cron_status: Current cron status dict
            suggestions: List of suggestion dicts
        """
        self._cron_status = cron_status

        # Update thinking view
        thinking_view = self.query_one("#thinking-view", ThinkingView)
        thinking_data = cron_status.get("current_thinking")
        if thinking_data:
            thinking = ThinkingProcess(
                current_action=thinking_data.get("action", "Processing..."),
                analyzed_items=thinking_data.get("analyzed", []),
                found_patterns=thinking_data.get("patterns", []),
                considering=thinking_data.get("considering", []),
                cross_references=thinking_data.get("cross_refs", []),
            )
            thinking_view.update_thinking(thinking, cron_status.get("status", "idle"))
        else:
            thinking_view.update_thinking(None)

        # Update suggestions
        suggestion_list = self.query_one("#suggestion-list", SuggestionList)
        parsed_suggestions = []
        for s in suggestions:
            stype = SuggestionList._parse_type(s.get("type", "recommendation"))
            parsed_suggestions.append(Suggestion(
                suggestion_type=stype,
                title=s.get("title", ""),
                description=s.get("description", ""),
                confidence=s.get("confidence", 0.0),
                source=s.get("source"),
                action_id=s.get("action_id"),
            ))
        suggestion_list.load_suggestions(parsed_suggestions)


class ActivityTab(Vertical):
    """Activity tab showing event log."""

    DEFAULT_CSS = """
    ActivityTab {
        height: 100%;
    }
    """

    def __init__(self, cron_id: str, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id

    def compose(self):
        """Compose the activity tab."""
        yield ActivityLogWidget(id="activity-log")

    def update_activity(self, events: List[Dict[str, Any]]) -> None:
        """Update the activity log."""
        log = self.query_one("#activity-log", ActivityLogWidget)
        log.load_from_events(events)


class ChatTab(Vertical):
    """Chat tab for interactive communication."""

    DEFAULT_CSS = """
    ChatTab {
        height: 100%;
    }
    """

    def __init__(
        self,
        cron_id: str,
        is_interactive: bool,
        owner_name: str,
        send_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
        *args,
        **kwargs
    ) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id
        self.is_interactive = is_interactive
        self.owner_name = owner_name
        self.send_callback = send_callback

    def compose(self):
        """Compose the chat tab."""
        if self.is_interactive:
            yield ChatPanel(
                cron_id=self.cron_id,
                is_interactive=True,
                send_callback=self.send_callback,
                id="chat-panel"
            )
        else:
            yield ReadOnlyChatPanel(
                cron_id=self.cron_id,
                owner_name=self.owner_name,
                id="readonly-chat"
            )


class ConfigTab(ScrollableContainer):
    """Configuration tab showing cron settings."""

    DEFAULT_CSS = """
    ConfigTab {
        height: 100%;
        padding: 1;
    }
    """

    def __init__(self, cron_id: str, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id

    def compose(self):
        """Compose the config tab."""
        # Basic config display - can be expanded
        yield Static(self._render_config())

    def _render_config(self) -> Panel:
        """Render configuration panel."""
        table = Table(show_header=False, box=None, padding=(0, 2))
        table.add_column("Key", style="bold cyan")
        table.add_column("Value")

        table.add_row("Cron ID", self.cron_id)
        table.add_row("Auto-refresh", "Enabled")
        table.add_row("Refresh interval", "5.0s")
        table.add_row("Notifications", "Enabled")

        return Panel(
            table,
            title="[bold]Configuration[/bold]",
            border_style="blue",
        )


class DetailTabs(Vertical):
    """
    Main tabbed container for the detail panel.

    Tabs:
    - Info: Thinking state and suggestions
    - Activity: Event log
    - Chat: Interactive chat (if allowed)
    - Config: Settings
    """

    DEFAULT_CSS = """
    DetailTabs {
        height: 100%;
    }
    """

    def __init__(
        self,
        cron_id: str,
        current_user_id: str,
        send_callback: Optional[Callable[[str, str], Awaitable[str]]] = None,
        *args,
        **kwargs
    ) -> None:
        super().__init__(*args, **kwargs)
        self.cron_id = cron_id
        self.current_user_id = current_user_id
        self.send_callback = send_callback

        # Determine if interactive
        self.is_interactive = self._check_interactive()
        self.owner_name = self._get_owner_name()

    def _check_interactive(self) -> bool:
        """Check if current user can interact with this cron."""
        if ":" not in self.cron_id:
            return False
        cron_type, owner_id = self.cron_id.split(":", 1)
        return cron_type == "user" and owner_id == self.current_user_id

    def _get_owner_name(self) -> str:
        """Get the owner name from cron_id."""
        if ":" in self.cron_id:
            return self.cron_id.split(":", 1)[1]
        return "System"

    def compose(self):
        """Compose all tabs using TabbedContent properly."""
        with TabbedContent(id="detail-tabbed-content"):
            with TabPane("Info", id="tab-info"):
                yield InfoTab(self.cron_id, id="info-content")

            with TabPane("Activity", id="tab-activity"):
                yield ActivityTab(self.cron_id, id="activity-content")

            with TabPane("Chat", id="tab-chat"):
                yield ChatTab(
                    cron_id=self.cron_id,
                    is_interactive=self.is_interactive,
                    owner_name=self.owner_name,
                    send_callback=self.send_callback,
                    id="chat-content"
                )

            with TabPane("Config", id="tab-config"):
                yield ConfigTab(self.cron_id, id="config-content")

    def update_for_cron(
        self,
        cron_id: str,
        cron_status: Dict[str, Any],
        events: List[Dict[str, Any]],
        suggestions: List[Dict[str, Any]]
    ) -> None:
        """
        Update all tabs for a new cron selection.

        Args:
            cron_id: Selected cron ID
            cron_status: Cron status dict
            events: Activity events
            suggestions: Suggestions list
        """
        self.cron_id = cron_id
        self.is_interactive = self._check_interactive()
        self.owner_name = self._get_owner_name()

        # Update info tab
        try:
            info_tab = self.query_one("#info-content", InfoTab)
            info_tab.update_info(cron_status, suggestions)
        except Exception:
            pass

        # Update activity tab
        try:
            activity_tab = self.query_one("#activity-content", ActivityTab)
            activity_tab.update_activity(events)
        except Exception:
            pass



================================================
File: kernel/terminal/widgets/suggestion_list.py
================================================
"""
SuggestionList - Widget for displaying cron suggestions.

Shows suggestion cards with type indicators, confidence scores,
and action buttons.
"""

from typing import List, Dict, Any, Optional

from textual.widgets import Static, ListView, ListItem
from textual.containers import Vertical
from textual.message import Message
from rich.text import Text
from rich.panel import Panel
from rich.console import Group

from ..models import Suggestion, SuggestionType


class SuggestionCard(Static):
    """A single suggestion card widget."""

    DEFAULT_CSS = """
    SuggestionCard {
        height: auto;
        margin-bottom: 1;
        padding: 1;
    }

    SuggestionCard.-immediate {
        border: tall $error;
    }

    SuggestionCard.-recommendation {
        border: tall $success;
    }

    SuggestionCard.-prediction {
        border: tall $warning;
    }

    SuggestionCard.-creative {
        border: tall $secondary;
    }
    """

    # Type styling
    TYPE_STYLES = {
        SuggestionType.IMMEDIATE: ("->", "red bold", "IMMEDIATE"),
        SuggestionType.RECOMMENDATION: ("!!", "green", "RECOMMENDATION"),
        SuggestionType.PREDICTION: ("??", "yellow", "PREDICTION"),
        SuggestionType.CREATIVE: ("**", "magenta", "CREATIVE"),
    }

    def __init__(self, suggestion: Suggestion, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.suggestion = suggestion

        # Add CSS class based on type
        type_class = suggestion.suggestion_type.value
        self.add_class(f"-{type_class}")

    def compose(self):
        """Compose the card content."""
        yield Static(self._render_card())

    def _render_card(self) -> Panel:
        """Render the suggestion as a rich Panel."""
        icon, color, label = self.TYPE_STYLES.get(
            self.suggestion.suggestion_type,
            ("**", "white", "SUGGESTION")
        )

        elements = []

        # Header with type badge
        header = Text()
        header.append(f"[{icon}] ", style=color)
        header.append(label, style=f"{color} bold")
        if self.suggestion.confidence > 0:
            conf_pct = f"{self.suggestion.confidence:.0%}"
            header.append(f"  [{conf_pct}]", style="dim")
        elements.append(header)

        # Title
        title = Text()
        title.append("\n")
        title.append(self.suggestion.title, style="bold")
        elements.append(title)

        # Description
        if self.suggestion.description:
            desc = Text()
            desc.append("\n")
            desc.append(self.suggestion.description, style="dim")
            elements.append(desc)

        # Source
        if self.suggestion.source:
            source = Text()
            source.append("\n")
            source.append('from: "', style="dim italic")
            source.append(self.suggestion.source[:50], style="italic")
            source.append('"', style="dim italic")
            elements.append(source)

        return Panel(
            Group(*elements),
            border_style=color,
            padding=(0, 1),
        )


class SuggestionList(Vertical):
    """
    Widget for displaying a list of suggestions.

    Features:
    - Type-coded cards (immediate, recommendation, prediction, creative)
    - Confidence indicators
    - Source attribution
    - Action buttons (future)
    """

    DEFAULT_CSS = """
    SuggestionList {
        height: 100%;
        padding: 1;
        overflow-y: auto;
    }
    """

    class SuggestionSelected(Message):
        """Message sent when a suggestion is selected."""
        def __init__(self, suggestion: Suggestion) -> None:
            self.suggestion = suggestion
            super().__init__()

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self._suggestions: List[Suggestion] = []

    def load_suggestions(self, suggestions: List[Suggestion]) -> None:
        """
        Load suggestions into the widget.

        Args:
            suggestions: List of Suggestion objects
        """
        self._suggestions = suggestions
        self._render_suggestions()

    def _render_suggestions(self) -> None:
        """Render all suggestion cards."""
        # Remove existing children
        self.remove_children()

        if not self._suggestions:
            self.mount(Static(
                "[dim]No suggestions at this time[/dim]",
                classes="empty-message"
            ))
            return

        # Sort by type priority (immediate first)
        priority = {
            SuggestionType.IMMEDIATE: 0,
            SuggestionType.RECOMMENDATION: 1,
            SuggestionType.PREDICTION: 2,
            SuggestionType.CREATIVE: 3,
        }
        sorted_suggestions = sorted(
            self._suggestions,
            key=lambda s: (priority.get(s.suggestion_type, 99), -s.confidence)
        )

        # Add cards
        for suggestion in sorted_suggestions[:6]:  # Max 6 suggestions
            self.mount(SuggestionCard(suggestion))

    @classmethod
    def from_dicts(cls, suggestion_dicts: List[Dict[str, Any]]) -> "SuggestionList":
        """
        Create a SuggestionList from dictionaries.

        Args:
            suggestion_dicts: List of suggestion dictionaries

        Returns:
            Configured SuggestionList widget
        """
        widget = cls()

        suggestions = []
        for s in suggestion_dicts:
            stype = cls._parse_type(s.get("type", "recommendation"))
            suggestions.append(Suggestion(
                suggestion_type=stype,
                title=s.get("title", ""),
                description=s.get("description", ""),
                confidence=s.get("confidence", 0.0),
                source=s.get("source"),
                action_id=s.get("action_id"),
            ))

        widget.load_suggestions(suggestions)
        return widget

    @staticmethod
    def _parse_type(type_str: str) -> SuggestionType:
        """Parse suggestion type string."""
        type_map = {
            "immediate": SuggestionType.IMMEDIATE,
            "recommendation": SuggestionType.RECOMMENDATION,
            "prediction": SuggestionType.PREDICTION,
            "creative": SuggestionType.CREATIVE,
        }
        return type_map.get(type_str.lower(), SuggestionType.RECOMMENDATION)



================================================
File: kernel/terminal/widgets/thinking_view.py
================================================
"""
ThinkingView - Widget for displaying cron's current cognitive state.

Shows what the cron is currently thinking about, patterns found,
and what it's considering doing next.
"""

from typing import Optional, List, Dict, Any

from textual.widgets import Static
from textual.containers import Vertical
from rich.text import Text
from rich.panel import Panel
from rich.console import Group

from ..models import ThinkingProcess


class ThinkingView(Static):
    """
    Widget for displaying the current thinking process of a cron.

    Displays:
    - Current action being performed
    - Items being analyzed
    - Patterns found
    - Things being considered
    - Cross-references
    """

    DEFAULT_CSS = """
    ThinkingView {
        padding: 1;
        height: auto;
        max-height: 15;
    }
    """

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self._thinking: Optional[ThinkingProcess] = None
        self._cron_state: str = "idle"

    def update_thinking(
        self,
        thinking: Optional[ThinkingProcess],
        cron_state: str = "idle"
    ) -> None:
        """
        Update the thinking display.

        Args:
            thinking: ThinkingProcess object or None if idle
            cron_state: Current state string for the header color
        """
        self._thinking = thinking
        self._cron_state = cron_state
        self._render_thinking()

    def _render_thinking(self) -> None:
        """Render the thinking process display."""
        if not self._thinking:
            self.update(self._render_idle())
            return

        # Build rich renderable
        elements = []

        # Current action with state-colored icon
        state_colors = {
            "idle": "green",
            "thinking": "yellow",
            "analyzing": "cyan",
            "proposing": "blue",
            "error": "red",
        }
        color = state_colors.get(self._cron_state, "white")

        action_text = Text()
        action_text.append(f"[{color}]ACTIVE[/{color}] ", style="bold")
        action_text.append(self._thinking.current_action)
        elements.append(action_text)
        elements.append("")

        # Analyzed items
        if self._thinking.analyzed_items:
            analyzed = Text()
            analyzed.append("Analyzed: ", style="dim")
            analyzed.append(", ".join(self._thinking.analyzed_items[:5]))
            if len(self._thinking.analyzed_items) > 5:
                analyzed.append(f" (+{len(self._thinking.analyzed_items) - 5} more)", style="dim")
            elements.append(analyzed)

        # Found patterns
        if self._thinking.found_patterns:
            elements.append("")
            elements.append(Text("Patterns Found:", style="bold green"))
            for pattern in self._thinking.found_patterns[:4]:
                name = pattern.get("name", "Unknown")
                count = pattern.get("count", 0)
                pattern_text = Text()
                pattern_text.append("  * ", style="green")
                pattern_text.append(f'"{name}"', style="italic")
                pattern_text.append(f" - {count} traces", style="dim")
                elements.append(pattern_text)

        # Considering
        if self._thinking.considering:
            elements.append("")
            elements.append(Text("Considering:", style="bold yellow"))
            for item in self._thinking.considering[:3]:
                consider_text = Text()
                consider_text.append("  -> ", style="yellow")
                consider_text.append(item)
                elements.append(consider_text)

        # Cross-references
        if self._thinking.cross_references:
            elements.append("")
            elements.append(Text("Cross-references:", style="bold cyan"))
            for ref in self._thinking.cross_references[:3]:
                ref_text = Text()
                ref_text.append("  @ ", style="cyan")
                ref_text.append(ref)
                elements.append(ref_text)

        # Create panel
        panel = Panel(
            Group(*elements),
            title="[bold]Current Thinking[/bold]",
            border_style=color,
        )

        self.update(panel)

    def _render_idle(self) -> Panel:
        """Render idle state."""
        idle_text = Text()
        idle_text.append("[green]:[/green] ", style="bold")
        idle_text.append("Idle - no active analysis")

        return Panel(
            idle_text,
            title="[bold]Current Thinking[/bold]",
            border_style="green",
        )

    @classmethod
    def from_status(cls, cron_status: Dict[str, Any]) -> "ThinkingView":
        """
        Create a ThinkingView from cron status dict.

        Args:
            cron_status: Status dict containing current_thinking

        Returns:
            Configured ThinkingView widget
        """
        widget = cls()

        thinking_data = cron_status.get("current_thinking")
        if thinking_data:
            thinking = ThinkingProcess(
                current_action=thinking_data.get("action", "Processing..."),
                analyzed_items=thinking_data.get("analyzed", []),
                found_patterns=thinking_data.get("patterns", []),
                considering=thinking_data.get("considering", []),
                cross_references=thinking_data.get("cross_refs", []),
            )
            widget.update_thinking(thinking, cron_status.get("status", "idle"))

        return widget




================================================
File: memory/__init__.py
================================================
"""
Memory Package - Storage Layer
Multi-tier memory system (L1-L4)
"""



================================================
File: memory/cross_project_sdk.py
================================================
"""
Cross-Project Learning - SDK Memory Implementation
Extract insights across project boundaries using file-based memory
"""

from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from collections import defaultdict

from memory.traces_sdk import TraceManager, ExecutionTrace
from memory.sdk_memory import SDKMemoryTool
from kernel.project_manager import ProjectManager, Project


@dataclass
class CrossProjectInsight:
    """Insight extracted from cross-project analysis"""
    insight_type: str  # "common_pattern", "reusable_agent", "successful_strategy", "anti_pattern"
    title: str
    description: str
    projects_involved: List[str]  # Project names
    evidence: List[str]  # Supporting evidence
    confidence: float  # 0.0 to 1.0
    impact: str  # "high", "medium", "low"
    recommendation: str  # What to do with this insight


@dataclass
class ReusableAgent:
    """Agent pattern that could be reused across projects"""
    agent_name: str
    category: str
    description: str
    success_rate: float
    usage_count: int
    projects_used: List[str]
    capabilities: List[str]
    recommended_for: List[str]  # Types of tasks


@dataclass
class SuccessfulStrategy:
    """Successful execution strategy observed across projects"""
    strategy_type: str
    description: str
    success_rate: float
    projects: List[str]
    applicable_to: List[str]  # Types of goals/tasks
    key_factors: List[str]


class CrossProjectLearning:
    """
    Cross-Project Learning using SDK Memory

    Analyzes execution history across all projects to extract
    insights without requiring embeddings - uses file-based search.
    """

    def __init__(
        self,
        project_manager: ProjectManager,
        workspace: Path
    ):
        """
        Initialize cross-project learning

        Args:
            project_manager: Project manager instance
            workspace: Workspace directory
        """
        self.project_manager = project_manager
        self.workspace = Path(workspace)
        self.memories_dir = self.workspace / "memories"

        # Initialize SDK Memory Tool
        self.memory_tool = SDKMemoryTool(self.memories_dir)

        # Cache for project traces
        self._project_traces_cache: Dict[str, List[ExecutionTrace]] = {}

    def _get_project_traces(self, project: Project) -> List[ExecutionTrace]:
        """Get all traces for a project"""
        if project.name in self._project_traces_cache:
            return self._project_traces_cache[project.name]

        # Load traces from project memory (stored in /memories/projects/{name}/traces/)
        project_memories = self.memories_dir / "projects" / project.name
        if not project_memories.exists():
            return []

        trace_manager = TraceManager(
            memories_dir=self.memories_dir,
            workspace=self.workspace,
            enable_llm_matching=False  # Disable for cross-project (optional optimization)
        )

        # List traces specific to this project
        traces = []
        project_trace_files = self.memory_tool.list_files(
            f"projects/{project.name}/traces",
            pattern="*.md"
        )

        for file in project_trace_files:
            try:
                trace = ExecutionTrace.from_markdown(file.content)
                traces.append(trace)
            except Exception as e:
                print(f"Warning: Could not parse trace {file.name}: {e}")

        self._project_traces_cache[project.name] = traces
        return traces

    def _get_all_traces(self) -> Dict[str, List[ExecutionTrace]]:
        """Get traces from all projects"""
        all_traces = {}

        for project in self.project_manager.list_projects():
            traces = self._get_project_traces(project)
            if traces:
                all_traces[project.name] = traces

        return all_traces

    async def analyze_common_patterns(
        self,
        min_projects: int = 2,
        min_confidence: float = 0.7
    ) -> List[CrossProjectInsight]:
        """
        Analyze patterns that appear across multiple projects

        Args:
            min_projects: Minimum number of projects for a pattern
            min_confidence: Minimum confidence threshold

        Returns:
            List of cross-project insights
        """
        insights = []
        all_traces = self._get_all_traces()

        if len(all_traces) < min_projects:
            return []

        # Pattern 1: Common goal types across projects
        goal_patterns = defaultdict(lambda: {"projects": set(), "traces": []})

        for project_name, traces in all_traces.items():
            for trace in traces:
                # Extract first word as goal type
                goal_type = trace.goal_text.split()[0] if trace.goal_text else "Unknown"
                goal_patterns[goal_type]["projects"].add(project_name)
                goal_patterns[goal_type]["traces"].append(trace)

        # Find patterns that appear in multiple projects
        for goal_type, data in goal_patterns.items():
            if len(data["projects"]) >= min_projects:
                traces = data["traces"]
                avg_success = sum(t.success_rating for t in traces) / len(traces)

                if avg_success >= min_confidence:
                    insights.append(CrossProjectInsight(
                        insight_type="common_pattern",
                        title=f"Common Task Type: {goal_type}",
                        description=f"'{goal_type}' tasks appear across {len(data['projects'])} projects",
                        projects_involved=list(data["projects"]),
                        evidence=[
                            f"{len(traces)} executions",
                            f"Average success rate: {avg_success:.0%}",
                            f"Projects: {', '.join(data['projects'])}"
                        ],
                        confidence=avg_success,
                        impact="high" if len(data["projects"]) >= 3 else "medium",
                        recommendation=f"Consider creating specialized '{goal_type}' agent for reuse"
                    ))

        # Pattern 2: Cost-intensive patterns
        for project_name, traces in all_traces.items():
            high_cost_traces = [t for t in traces if t.estimated_cost_usd > 1.0]
            if len(high_cost_traces) >= 3:
                avg_cost = sum(t.estimated_cost_usd for t in high_cost_traces) / len(high_cost_traces)

                insights.append(CrossProjectInsight(
                    insight_type="anti_pattern",
                    title=f"High-cost operations in {project_name}",
                    description=f"Multiple expensive operations detected (avg ${avg_cost:.2f})",
                    projects_involved=[project_name],
                    evidence=[
                        f"{len(high_cost_traces)} high-cost executions",
                        f"Average cost: ${avg_cost:.2f}",
                        f"Total cost: ${sum(t.estimated_cost_usd for t in high_cost_traces):.2f}"
                    ],
                    confidence=0.9,
                    impact="high",
                    recommendation="Consider breaking down tasks or using cheaper models"
                ))

        return insights

    async def identify_reusable_agents(
        self,
        min_success_rate: float = 0.8,
        min_usage_count: int = 3
    ) -> List[ReusableAgent]:
        """
        Identify agent patterns that could be reused

        Args:
            min_success_rate: Minimum success rate
            min_usage_count: Minimum usage count

        Returns:
            List of reusable agent patterns
        """
        reusable_agents = []
        all_traces = self._get_all_traces()

        # Group traces by goal signature pattern
        agent_patterns = defaultdict(lambda: {
            "traces": [],
            "projects": set(),
            "goal_types": set()
        })

        for project_name, traces in all_traces.items():
            for trace in traces:
                # Extract goal pattern (first 2-3 words)
                words = trace.goal_text.split()[:3]
                pattern = " ".join(words) if words else "Unknown"

                agent_patterns[pattern]["traces"].append(trace)
                agent_patterns[pattern]["projects"].add(project_name)

                # Extract goal type
                if words:
                    agent_patterns[pattern]["goal_types"].add(words[0])

        # Identify high-performing patterns
        for pattern, data in agent_patterns.items():
            traces = data["traces"]

            if len(traces) >= min_usage_count:
                success_rate = sum(t.success_rating for t in traces) / len(traces)

                if success_rate >= min_success_rate:
                    # Infer agent category from goal types
                    goal_types = list(data["goal_types"])
                    category = self._infer_category(pattern, goal_types)

                    reusable_agents.append(ReusableAgent(
                        agent_name=f"{pattern.lower().replace(' ', '-')}-agent",
                        category=category,
                        description=f"Handles tasks like '{pattern}'",
                        success_rate=success_rate,
                        usage_count=len(traces),
                        projects_used=list(data["projects"]),
                        capabilities=[f"{goal_type} operations" for goal_type in goal_types],
                        recommended_for=[
                            f"Tasks starting with '{pattern}'",
                            f"{category} operations"
                        ]
                    ))

        # Sort by success rate and usage count
        reusable_agents.sort(key=lambda a: (a.success_rate, a.usage_count), reverse=True)

        return reusable_agents

    async def extract_successful_strategies(
        self,
        min_success_rate: float = 0.9,
        min_projects: int = 2
    ) -> List[SuccessfulStrategy]:
        """
        Extract successful execution strategies across projects

        Args:
            min_success_rate: Minimum success rate
            min_projects: Minimum number of projects

        Returns:
            List of successful strategies
        """
        strategies = []
        all_traces = self._get_all_traces()

        # Strategy 1: Quick execution (< 30 seconds) with high success
        quick_traces = defaultdict(list)
        for project_name, traces in all_traces.items():
            for trace in traces:
                if trace.estimated_time_secs < 30 and trace.success_rating >= min_success_rate:
                    quick_traces[project_name].append(trace)

        if len(quick_traces) >= min_projects:
            all_quick = [t for traces in quick_traces.values() for t in traces]
            avg_success = sum(t.success_rating for t in all_quick) / len(all_quick)

            strategies.append(SuccessfulStrategy(
                strategy_type="quick_execution",
                description="Fast execution with high success rate",
                success_rate=avg_success,
                projects=list(quick_traces.keys()),
                applicable_to=["Simple tasks", "Well-defined operations"],
                key_factors=[
                    "Clear goal definition",
                    "Existing trace available (Follower mode)",
                    "Simple single-step operations"
                ]
            ))

        # Strategy 2: Follower mode success
        follower_traces = defaultdict(list)
        for project_name, traces in all_traces.items():
            for trace in traces:
                # High success with usage suggests Follower mode
                if (trace.success_rating >= 0.95 and
                    trace.usage_count > 1):
                    follower_traces[project_name].append(trace)

        if len(follower_traces) >= min_projects:
            all_follower = [t for traces in follower_traces.values() for t in traces]
            avg_success = sum(t.success_rating for t in all_follower) / len(all_follower)

            strategies.append(SuccessfulStrategy(
                strategy_type="follower_mode",
                description="Zero-cost Follower mode execution",
                success_rate=avg_success,
                projects=list(follower_traces.keys()),
                applicable_to=["Repeated tasks", "Proven workflows"],
                key_factors=[
                    "High-quality trace available",
                    "Similar goal to past execution",
                    "Stable environment/requirements"
                ]
            ))

        return strategies

    async def get_cross_project_recommendations(
        self,
        current_project: Optional[Project] = None,
        goal: Optional[str] = None
    ) -> List[str]:
        """
        Get recommendations based on cross-project learning

        Args:
            current_project: Current project context
            goal: Optional goal to get recommendations for

        Returns:
            List of recommendation strings
        """
        recommendations = []

        # Get insights
        patterns = await self.analyze_common_patterns()
        reusable_agents = await self.identify_reusable_agents()
        strategies = await self.extract_successful_strategies()

        # Recommendation 1: Suggest reusable agents
        if reusable_agents and goal:
            top_agent = reusable_agents[0]
            if any(pattern in goal.lower() for pattern in top_agent.agent_name.split('-')):
                recommendations.append(
                    f"ðŸ’¡ Consider using '{top_agent.agent_name}' pattern - "
                    f"{top_agent.success_rate:.0%} success rate across {len(top_agent.projects_used)} projects"
                )

        # Recommendation 2: Common patterns
        if patterns:
            for pattern in patterns[:2]:  # Top 2
                if pattern.insight_type == "common_pattern":
                    recommendations.append(
                        f"ðŸ”„ {pattern.title} - {pattern.recommendation}"
                    )
                elif pattern.insight_type == "anti_pattern":
                    recommendations.append(
                        f"âš ï¸  {pattern.title} - {pattern.recommendation}"
                    )

        # Recommendation 3: Learning from other projects
        all_traces = self._get_all_traces()
        if len(all_traces) > 1:
            recommendations.append(
                f"ðŸ“š Learning from {len(all_traces)} projects - "
                f"{sum(len(traces) for traces in all_traces.values())} total executions"
            )

        return recommendations

    def _infer_category(self, pattern: str, goal_types: List[str]) -> str:
        """Infer agent category from pattern and goal types"""
        pattern_lower = pattern.lower()

        # Category mapping
        if any(word in pattern_lower for word in ["analyze", "data", "statistics"]):
            return "data_analysis"
        elif any(word in pattern_lower for word in ["create", "build", "generate"]):
            return "creation"
        elif any(word in pattern_lower for word in ["research", "search", "find"]):
            return "research"
        elif any(word in pattern_lower for word in ["write", "document", "report"]):
            return "documentation"
        elif any(word in pattern_lower for word in ["test", "verify", "check"]):
            return "testing"
        elif any(word in pattern_lower for word in ["fix", "debug", "resolve"]):
            return "debugging"
        else:
            return "general"

    async def get_project_learning_summary(self, project: Project) -> Dict[str, Any]:
        """
        Get learning summary for a specific project

        Args:
            project: Project to summarize

        Returns:
            Dictionary with learning insights
        """
        traces = self._get_project_traces(project)

        if not traces:
            return {
                "project": project.name,
                "total_executions": 0,
                "insights": []
            }

        # Calculate statistics
        total_cost = sum(t.estimated_cost_usd for t in traces)
        total_time = sum(t.estimated_time_secs for t in traces)
        avg_success = sum(t.success_rating for t in traces) / len(traces)
        high_success_count = len([t for t in traces if t.success_rating >= 0.9])

        # Identify top patterns
        goal_types = defaultdict(int)
        for trace in traces:
            goal_type = trace.goal_text.split()[0] if trace.goal_text else "Unknown"
            goal_types[goal_type] += 1

        top_patterns = sorted(goal_types.items(), key=lambda x: x[1], reverse=True)[:3]

        return {
            "project": project.name,
            "total_executions": len(traces),
            "total_cost": total_cost,
            "total_time": total_time,
            "avg_success_rate": avg_success,
            "high_confidence_traces": high_success_count,
            "top_patterns": [
                {"type": goal_type, "count": count}
                for goal_type, count in top_patterns
            ],
            "follower_mode_available": high_success_count > 0,
            "insights": [
                f"Most common task: {top_patterns[0][0]} ({top_patterns[0][1]} times)" if top_patterns else "No patterns yet",
                f"Average success rate: {avg_success:.0%}",
                f"Total cost: ${total_cost:.2f}",
                f"{high_success_count} high-confidence traces available for Follower mode"
            ]
        }

    def clear_cache(self):
        """Clear the project traces cache"""
        self._project_traces_cache.clear()

    async def identify_crystallization_candidates(
        self,
        min_usage: int = 5,
        min_success: float = 0.95
    ) -> List[Dict[str, Any]]:
        """
        Identify traces that are stable enough to be crystallized into Python tools.

        This implements the HOPE (Self-Modifying Kernel) protocol from the Nested Learning paper.
        Traces meeting the criteria are candidates for conversion from fluid intelligence (LLM)
        to crystallized intelligence (Python code).

        Criteria for crystallization:
        1. High usage count (â‰¥ min_usage) - Pattern is frequently needed
        2. High success rating (â‰¥ min_success) - Pattern is stable and proven
        3. Mode is FOLLOWER - Already proven to work reliably

        Args:
            min_usage: Minimum usage count (default: 5)
            min_success: Minimum success rating (default: 0.95)

        Returns:
            List of crystallization candidate dictionaries
        """
        candidates = []
        all_traces = self._get_all_traces()

        for project_name, traces in all_traces.items():
            for trace in traces:
                # Check crystallization criteria
                if (trace.usage_count >= min_usage and
                    trace.success_rating >= min_success and
                    not trace.crystallized_into_tool):  # Not already crystallized

                    candidates.append({
                        "goal": trace.goal_text,
                        "signature": trace.goal_signature,
                        "project": project_name,
                        "usage_count": trace.usage_count,
                        "success_rating": trace.success_rating,
                        "estimated_cost_usd": trace.estimated_cost_usd,
                        "estimated_time_secs": trace.estimated_time_secs,
                        "tools_used": trace.tools_used or [],
                        "output_summary": trace.output_summary or "",
                        "crystallization_priority": self._calculate_crystallization_priority(trace)
                    })

        # Sort by priority (highest first)
        candidates.sort(key=lambda c: c["crystallization_priority"], reverse=True)

        return candidates

    def _calculate_crystallization_priority(self, trace: ExecutionTrace) -> float:
        """
        Calculate crystallization priority score for a trace.

        Higher scores indicate higher value in crystallizing this pattern.

        Factors:
        - Usage frequency (more uses = higher priority)
        - Cost savings potential (expensive traces save more when crystallized)
        - Success rate (more reliable = higher priority)

        Returns:
            Priority score (0.0-100.0+)
        """
        # Usage weight: 10 points per use
        usage_score = trace.usage_count * 10

        # Cost weight: $0.50 = 50 points (potential savings from crystallization)
        cost_score = trace.estimated_cost_usd * 100

        # Success weight: 95% = 95 points
        success_score = trace.success_rating * 100

        # Combined score with weights
        priority = (
            usage_score * 0.5 +      # 50% weight on usage
            cost_score * 0.3 +        # 30% weight on cost savings
            success_score * 0.2       # 20% weight on reliability
        )

        return priority



================================================
File: memory/query_sdk.py
================================================
"""
Memory Query Interface - SDK-based Implementation
Keyword-based search without embeddings, using SDK memory

Provides intelligent memory consultation using file-based search.
"""

from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from memory.traces_sdk import TraceManager, ExecutionTrace
from memory.store_sdk import MemoryStore


@dataclass
class MemoryInsight:
    """Insight extracted from memory"""
    insight_type: str  # "pattern", "recommendation", "warning", "success_factor"
    description: str
    evidence: List[str]  # Supporting evidence from past executions
    confidence: float  # 0.0 to 1.0
    relevance: float  # 0.0 to 1.0 (to current goal)


@dataclass
class FailurePattern:
    """Pattern of failures"""
    pattern_type: str  # "tool_error", "timeout", "constraint_violation"
    description: str
    occurrences: int
    affected_traces: List[str]  # Trace signatures
    mitigation: str  # How to avoid


class MemoryQueryInterface:
    """
    SDK-based Memory Query Interface

    Provides keyword-based search over past executions,
    pattern recognition, and recommendations.

    No embeddings - uses fast file-based keyword matching.
    """

    def __init__(
        self,
        trace_manager: TraceManager,
        memory_store: MemoryStore
    ):
        """
        Initialize Memory Query Interface

        Args:
            trace_manager: Trace manager (SDK-based)
            memory_store: Memory store (SDK-based)
        """
        self.trace_manager = trace_manager
        self.memory_store = memory_store

    async def find_similar_tasks(
        self,
        goal: str,
        limit: int = 5,
        min_confidence: float = 0.7
    ) -> List[ExecutionTrace]:
        """
        Find similar past executions using keyword matching

        Args:
            goal: Goal to search for
            limit: Maximum number of results
            min_confidence: Minimum success rating

        Returns:
            List of similar ExecutionTrace instances
        """
        # Use trace manager's keyword search
        traces = self.trace_manager.search_traces(
            query=goal,
            limit=limit * 2,  # Get more for filtering
            min_confidence=min_confidence
        )

        # Return top results
        return traces[:limit]

    async def get_recommendations(
        self,
        goal: str,
        context: Optional[Dict[str, Any]] = None
    ) -> List[str]:
        """
        Get recommendations based on historical performance

        Args:
            goal: Goal to get recommendations for
            context: Optional context information

        Returns:
            List of recommendation strings
        """
        recommendations = []

        # Find similar tasks
        similar = await self.find_similar_tasks(goal, limit=3)

        if similar:
            # Extract recommendations from similar tasks
            for trace in similar:
                if trace.success_rating > 0.9:
                    recommendations.append(
                        f"High success rate ({trace.success_rating:.0%}) "
                        f"for similar task: '{trace.goal_text[:50]}...'"
                    )

                if trace.usage_count > 5:
                    recommendations.append(
                        f"Task similar to '{trace.goal_text[:50]}...' "
                        f"has been executed {trace.usage_count} times successfully"
                    )

        # Generic recommendations based on patterns
        if not similar:
            recommendations.append(
                "Novel task - no similar executions found. "
                "Will use Learner mode and create new trace."
            )

        return recommendations

    async def analyze_failures(
        self,
        pattern: Optional[str] = None
    ) -> List[FailurePattern]:
        """
        Analyze failure patterns across executions

        Args:
            pattern: Optional pattern to filter

        Returns:
            List of FailurePattern instances
        """
        failure_patterns = []

        # Get all traces
        all_traces = self.trace_manager.list_traces()

        # Filter low-success traces
        failed_traces = [
            t for t in all_traces
            if t.success_rating < 0.5
        ]

        if not failed_traces:
            return []

        # Group by common patterns
        goal_failures: Dict[str, List[ExecutionTrace]] = {}
        for trace in failed_traces:
            key = trace.goal_text[:50]  # First 50 chars as key
            if key not in goal_failures:
                goal_failures[key] = []
            goal_failures[key].append(trace)

        for goal_prefix, traces in goal_failures.items():
            if len(traces) >= 2:
                failure_patterns.append(FailurePattern(
                    pattern_type="repeated_failure",
                    description=f"Multiple failures for goals starting with '{goal_prefix}'",
                    occurrences=len(traces),
                    affected_traces=[t.goal_signature for t in traces],
                    mitigation="Consider breaking down the task or creating specialized agent"
                ))

        return failure_patterns

    async def extract_patterns(
        self,
        category: Optional[str] = None
    ) -> List[MemoryInsight]:
        """
        Extract patterns from memory

        Args:
            category: Optional category filter

        Returns:
            List of MemoryInsight instances
        """
        insights = []

        # Get all traces
        all_traces = self.trace_manager.list_traces()

        # Pattern 1: Frequently executed tasks
        frequent_traces = [
            t for t in all_traces
            if t.usage_count >= 5
        ]

        for trace in frequent_traces:
            insights.append(MemoryInsight(
                insight_type="pattern",
                description=f"Frequent task: {trace.goal_text[:50]}",
                evidence=[
                    f"Executed {trace.usage_count} times",
                    f"Success rate: {trace.success_rating:.0%}"
                ],
                confidence=0.9,
                relevance=0.5
            ))

        # Pattern 2: High-success patterns
        high_success = [
            t for t in all_traces
            if t.success_rating > 0.95 and t.usage_count >= 3
        ]

        for trace in high_success[:3]:  # Top 3
            insights.append(MemoryInsight(
                insight_type="success_factor",
                description=f"Proven approach: {trace.goal_text[:50]}",
                evidence=[
                    f"Success rate: {trace.success_rating:.0%}",
                    f"Used {trace.usage_count} times"
                ],
                confidence=0.95,
                relevance=0.7
            ))

        # Pattern 3: Recent trends
        recent_traces = sorted(
            all_traces,
            key=lambda t: t.last_used or t.created_at,
            reverse=True
        )[:10]

        if recent_traces:
            insights.append(MemoryInsight(
                insight_type="pattern",
                description="Recent activity focused on: " +
                           ", ".join(set(t.goal_text.split()[0] for t in recent_traces[:5] if t.goal_text)),
                evidence=[f"Last 10 executions analyzed"],
                confidence=0.7,
                relevance=0.8
            ))

        return insights

    async def get_optimization_suggestions(
        self,
        goal: str
    ) -> List[str]:
        """
        Get optimization suggestions based on past performance

        Args:
            goal: Goal to optimize

        Returns:
            List of suggestion strings
        """
        suggestions = []

        # Find similar tasks
        similar = await self.find_similar_tasks(goal, limit=5, min_confidence=0.7)

        if similar:
            # Check if Follower mode is available
            high_confidence = [t for t in similar if t.success_rating >= 0.9]
            if high_confidence:
                suggestions.append(
                    "âœ… Follower mode available - can execute at $0 cost using proven trace"
                )

            # Check for frequent patterns
            frequent = [t for t in similar if t.usage_count >= 5]
            if frequent:
                suggestions.append(
                    "ðŸ“Š This type of task is executed frequently - "
                    "consider creating dedicated specialized agent"
                )

            # Cost optimization
            avg_cost = sum(t.estimated_cost_usd for t in similar) / len(similar)
            if avg_cost > 0.5:
                suggestions.append(
                    f"ðŸ’° Average cost for similar tasks: ${avg_cost:.2f} - "
                    "consider optimizing or using cheaper model"
                )

            # Time optimization
            avg_time = sum(t.estimated_time_secs for t in similar) / len(similar)
            if avg_time > 60:
                suggestions.append(
                    f"â±ï¸ Average time for similar tasks: {avg_time:.0f}s - "
                    "consider breaking into smaller steps"
                )

        else:
            suggestions.append(
                "ðŸ†• Novel task - will use Learner mode. "
                "Future executions can use Follower mode at $0 cost."
            )

        return suggestions

    async def should_use_follower_mode(
        self,
        goal: str,
        confidence_threshold: float = 0.9
    ) -> tuple[bool, Optional[ExecutionTrace]]:
        """
        Determine if Follower mode should be used

        Args:
            goal: Goal to check
            confidence_threshold: Minimum confidence required

        Returns:
            Tuple of (should_use_follower, trace)
        """
        trace = self.trace_manager.find_trace(goal, confidence_threshold)

        if trace and trace.success_rating >= confidence_threshold:
            return True, trace

        return False, None

    def get_memory_statistics(self) -> Dict[str, Any]:
        """
        Get memory statistics

        Returns:
            Dictionary with memory stats
        """
        # Get trace statistics
        trace_stats = self.trace_manager.get_statistics()

        # Get store statistics
        store_stats = self.memory_store.get_statistics()

        return {
            **trace_stats,
            **store_stats,
            "follower_mode_available": trace_stats["high_confidence_count"] > 0
        }



================================================
File: memory/sdk_memory.py
================================================
"""
Claude SDK Memory Tool Wrapper
Implements SDK's memory commands for file-based memory management

Based on Claude Agent SDK's Memory Tool features:
- view: Read memory file contents
- create: Create new memory file
- str_replace: Replace string in memory file
- insert: Insert content at line number
- delete: Delete memory file
- rename: Rename memory file

Uses /memories directory structure for persistent storage.
"""

from pathlib import Path
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import re


@dataclass
class MemoryFile:
    """Represents a memory file"""
    path: Path
    name: str
    content: str
    created_at: datetime
    modified_at: datetime
    size: int


class SDKMemoryTool:
    """
    Claude SDK Memory Tool Wrapper

    Provides file-based memory management aligned with Claude Agent SDK
    conventions. All memory files are stored in /memories directory.
    """

    def __init__(self, memories_dir: Path):
        """
        Initialize SDK Memory Tool

        Args:
            memories_dir: Root /memories directory
        """
        self.memories_dir = Path(memories_dir)
        self.memories_dir.mkdir(parents=True, exist_ok=True)

    def view(self, file_path: str) -> str:
        """
        View contents of a memory file

        Args:
            file_path: Relative path from /memories directory

        Returns:
            File contents as string
        """
        full_path = self.memories_dir / file_path

        if not full_path.exists():
            raise FileNotFoundError(f"Memory file not found: {file_path}")

        return full_path.read_text(encoding='utf-8')

    def create(self, file_path: str, content: str) -> bool:
        """
        Create a new memory file

        Args:
            file_path: Relative path from /memories directory
            content: File content

        Returns:
            True if created successfully
        """
        full_path = self.memories_dir / file_path

        # Create parent directories if needed
        full_path.parent.mkdir(parents=True, exist_ok=True)

        # Don't overwrite existing files
        if full_path.exists():
            raise FileExistsError(f"Memory file already exists: {file_path}")

        full_path.write_text(content, encoding='utf-8')
        return True

    def str_replace(
        self,
        file_path: str,
        old_str: str,
        new_str: str,
        count: int = -1
    ) -> bool:
        """
        Replace string in memory file

        Args:
            file_path: Relative path from /memories directory
            old_str: String to replace
            new_str: Replacement string
            count: Max replacements (-1 for all)

        Returns:
            True if replacement successful
        """
        full_path = self.memories_dir / file_path

        if not full_path.exists():
            raise FileNotFoundError(f"Memory file not found: {file_path}")

        content = full_path.read_text(encoding='utf-8')

        if old_str not in content:
            raise ValueError(f"String not found in file: {old_str}")

        new_content = content.replace(old_str, new_str, count)
        full_path.write_text(new_content, encoding='utf-8')

        return True

    def insert(self, file_path: str, line_number: int, content: str) -> bool:
        """
        Insert content at specific line number

        Args:
            file_path: Relative path from /memories directory
            line_number: Line number (1-indexed)
            content: Content to insert

        Returns:
            True if insertion successful
        """
        full_path = self.memories_dir / file_path

        if not full_path.exists():
            raise FileNotFoundError(f"Memory file not found: {file_path}")

        lines = full_path.read_text(encoding='utf-8').splitlines(keepends=True)

        # Convert to 0-indexed
        idx = line_number - 1

        if idx < 0 or idx > len(lines):
            raise ValueError(f"Invalid line number: {line_number}")

        # Insert content
        lines.insert(idx, content + '\n')

        full_path.write_text(''.join(lines), encoding='utf-8')
        return True

    def delete(self, file_path: str) -> bool:
        """
        Delete a memory file

        Args:
            file_path: Relative path from /memories directory

        Returns:
            True if deletion successful
        """
        full_path = self.memories_dir / file_path

        if not full_path.exists():
            raise FileNotFoundError(f"Memory file not found: {file_path}")

        full_path.unlink()
        return True

    def rename(self, old_path: str, new_path: str) -> bool:
        """
        Rename a memory file

        Args:
            old_path: Current relative path
            new_path: New relative path

        Returns:
            True if rename successful
        """
        old_full = self.memories_dir / old_path
        new_full = self.memories_dir / new_path

        if not old_full.exists():
            raise FileNotFoundError(f"Memory file not found: {old_path}")

        if new_full.exists():
            raise FileExistsError(f"Target file already exists: {new_path}")

        # Create parent directories for new path
        new_full.parent.mkdir(parents=True, exist_ok=True)

        old_full.rename(new_full)
        return True

    def list_files(self, directory: str = "", pattern: str = "*.md") -> List[MemoryFile]:
        """
        List memory files in a directory

        Args:
            directory: Subdirectory to search (relative to /memories)
            pattern: Glob pattern for matching files

        Returns:
            List of MemoryFile instances
        """
        search_dir = self.memories_dir / directory if directory else self.memories_dir

        if not search_dir.exists():
            return []

        files = []
        for path in search_dir.glob(pattern):
            if path.is_file():
                stat = path.stat()
                files.append(MemoryFile(
                    path=path,
                    name=path.name,
                    content=path.read_text(encoding='utf-8'),
                    created_at=datetime.fromtimestamp(stat.st_ctime),
                    modified_at=datetime.fromtimestamp(stat.st_mtime),
                    size=stat.st_size
                ))

        return files

    def search(self, query: str, directory: str = "") -> List[MemoryFile]:
        """
        Search memory files by content

        Args:
            query: Search query (supports keywords)
            directory: Subdirectory to search

        Returns:
            List of matching MemoryFile instances
        """
        all_files = self.list_files(directory, pattern="*.md")

        query_lower = query.lower()
        query_words = set(query_lower.split())

        results = []
        for file in all_files:
            content_lower = file.content.lower()

            # Score by keyword matches
            matches = sum(1 for word in query_words if word in content_lower)

            if matches > 0:
                results.append((matches, file))

        # Sort by match count
        results.sort(key=lambda x: x[0], reverse=True)

        return [file for _, file in results]

    def exists(self, file_path: str) -> bool:
        """
        Check if memory file exists

        Args:
            file_path: Relative path from /memories directory

        Returns:
            True if file exists
        """
        full_path = self.memories_dir / file_path
        return full_path.exists()

    def get_metadata(self, file_path: str) -> Dict[str, Any]:
        """
        Get metadata for a memory file

        Args:
            file_path: Relative path from /memories directory

        Returns:
            Dictionary with file metadata
        """
        full_path = self.memories_dir / file_path

        if not full_path.exists():
            raise FileNotFoundError(f"Memory file not found: {file_path}")

        stat = full_path.stat()

        return {
            "path": file_path,
            "name": full_path.name,
            "size": stat.st_size,
            "created_at": datetime.fromtimestamp(stat.st_ctime).isoformat(),
            "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "lines": len(full_path.read_text(encoding='utf-8').splitlines())
        }


class MemorySession:
    """
    Memory Session Manager

    Manages within-session context and cross-session persistence
    using Claude SDK conventions.
    """

    def __init__(self, memories_dir: Path, session_id: Optional[str] = None):
        """
        Initialize memory session

        Args:
            memories_dir: Root /memories directory
            session_id: Optional session identifier
        """
        self.memories_dir = Path(memories_dir)
        self.session_id = session_id or datetime.now().strftime("%Y%m%d_%H%M%S")

        # Initialize SDK Memory Tool
        self.memory_tool = SDKMemoryTool(self.memories_dir)

        # Session-specific directory
        self.session_dir = self.memories_dir / "sessions" / self.session_id
        self.session_dir.mkdir(parents=True, exist_ok=True)

        # Session context (in-memory)
        self.context: Dict[str, Any] = {}

    def save_session_context(self):
        """Save current session context to file"""
        context_file = self.session_dir / "context.md"

        content_lines = [
            f"# Session Context: {self.session_id}",
            f"Created: {datetime.now().isoformat()}",
            "",
            "## Context Variables",
            ""
        ]

        for key, value in self.context.items():
            content_lines.append(f"- **{key}**: {value}")

        content = "\n".join(content_lines)

        if context_file.exists():
            self.memory_tool.str_replace(
                f"sessions/{self.session_id}/context.md",
                context_file.read_text(),
                content
            )
        else:
            self.memory_tool.create(
                f"sessions/{self.session_id}/context.md",
                content
            )

    def load_session_context(self, session_id: str) -> Dict[str, Any]:
        """
        Load context from previous session

        Args:
            session_id: Session to load from

        Returns:
            Context dictionary
        """
        context_file = f"sessions/{session_id}/context.md"

        if not self.memory_tool.exists(context_file):
            return {}

        content = self.memory_tool.view(context_file)

        # Parse context variables (simple parsing)
        context = {}
        for line in content.splitlines():
            if line.startswith("- **"):
                match = re.match(r"- \*\*(.+?)\*\*: (.+)", line)
                if match:
                    key, value = match.groups()
                    context[key] = value

        return context

    def add_observation(self, observation: str):
        """
        Add observation to session memory

        Args:
            observation: Observation text
        """
        obs_file = f"sessions/{self.session_id}/observations.md"

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        entry = f"\n## {timestamp}\n\n{observation}\n"

        if self.memory_tool.exists(obs_file):
            # Append to existing file
            content = self.memory_tool.view(obs_file)
            self.memory_tool.str_replace(obs_file, content, content + entry)
        else:
            # Create new file
            self.memory_tool.create(
                obs_file,
                f"# Session Observations: {self.session_id}\n{entry}"
            )

    def get_recent_sessions(self, limit: int = 5) -> List[str]:
        """
        Get recent session IDs

        Args:
            limit: Maximum number of sessions

        Returns:
            List of session IDs
        """
        sessions_dir = self.memories_dir / "sessions"

        if not sessions_dir.exists():
            return []

        # Get all session directories sorted by modification time
        sessions = []
        for session_path in sessions_dir.iterdir():
            if session_path.is_dir():
                sessions.append((session_path.stat().st_mtime, session_path.name))

        sessions.sort(reverse=True)

        return [name for _, name in sessions[:limit]]



================================================
File: memory/semantic_db.py
================================================
"""
Semantic Memory Database for LLMOS

Persistent structured memory using SQLite with semantic vector search.
Inspired by Claude-Flow's AgentDB and ReasoningBank architecture.

Key Features:
- SQLite backend for structured queries
- HNSW indexing for vector search (96x-164x performance improvement)
- Automatic memory fallback mechanisms
- Quantization for 4-32x memory reduction
- 2-3ms query latency

Inspired by Claude-Flow's hybrid memory approach (MIT License)
https://github.com/ruvnet/claude-flow
"""

import sqlite3
import json
import hashlib
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from datetime import datetime
import pickle


@dataclass
class MemoryEntry:
    """Single memory entry"""
    key: str
    value: Any
    category: str
    timestamp: float
    ttl_secs: Optional[float] = None
    metadata: Dict[str, Any] = None
    embedding: Optional[List[float]] = None

    def is_expired(self, current_time: float) -> bool:
        """Check if memory has expired"""
        if self.ttl_secs is None:
            return False
        return (current_time - self.timestamp) > self.ttl_secs


@dataclass
class TraceEntry:
    """Execution trace entry for structured storage"""
    trace_id: str
    goal_signature: str
    goal_text: str
    mode: str
    success: bool
    success_rating: float
    usage_count: int
    tools_used: List[str]
    output_summary: str
    estimated_time_secs: float
    cost_usd: float
    created_at: float
    updated_at: float
    crystallized_into_tool: Optional[str] = None
    tool_calls: Optional[str] = None  # JSON serialized
    embedding: Optional[List[float]] = None


class SemanticMemoryDB:
    """
    Semantic Memory Database

    Combines SQLite for structured queries with optional vector search
    for semantic retrieval. Provides persistent storage for:
    - Execution traces
    - Agent memories
    - Facts and insights
    - Performance metrics

    Architecture:
    - SQLite backend for ACID compliance
    - Full-text search (FTS5) for text queries
    - Optional vector search for semantic matching
    - Automatic indexing and query optimization
    """

    def __init__(
        self,
        db_path: Path,
        enable_vector_search: bool = False,
        embedding_dim: int = 384
    ):
        self.db_path = db_path
        self.enable_vector_search = enable_vector_search
        self.embedding_dim = embedding_dim

        # Ensure parent directory exists
        db_path.parent.mkdir(parents=True, exist_ok=True)

        # Initialize database
        self.conn = sqlite3.connect(str(db_path), check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._init_schema()

    def _init_schema(self):
        """Initialize database schema"""
        cursor = self.conn.cursor()

        # Memories table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS memories (
                key TEXT PRIMARY KEY,
                value BLOB,
                category TEXT,
                timestamp REAL,
                ttl_secs REAL,
                metadata TEXT,
                embedding BLOB
            )
        """)

        # Traces table (structured storage for execution traces)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS traces (
                trace_id TEXT PRIMARY KEY,
                goal_signature TEXT,
                goal_text TEXT,
                mode TEXT,
                success INTEGER,
                success_rating REAL,
                usage_count INTEGER,
                tools_used TEXT,
                output_summary TEXT,
                estimated_time_secs REAL,
                cost_usd REAL,
                created_at REAL,
                updated_at REAL,
                crystallized_into_tool TEXT,
                tool_calls TEXT,
                embedding BLOB
            )
        """)

        # Indices for fast queries
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_traces_goal_signature
            ON traces(goal_signature)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_traces_mode
            ON traces(mode)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_traces_success
            ON traces(success, success_rating)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_traces_usage
            ON traces(usage_count DESC)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_memories_category
            ON memories(category)
        """)

        # Full-text search for goal text
        cursor.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS traces_fts USING fts5(
                trace_id,
                goal_text,
                output_summary,
                content=traces,
                content_rowid=rowid
            )
        """)

        # Triggers to keep FTS in sync
        cursor.execute("""
            CREATE TRIGGER IF NOT EXISTS traces_fts_insert AFTER INSERT ON traces BEGIN
                INSERT INTO traces_fts(rowid, trace_id, goal_text, output_summary)
                VALUES (new.rowid, new.trace_id, new.goal_text, new.output_summary);
            END;
        """)

        cursor.execute("""
            CREATE TRIGGER IF NOT EXISTS traces_fts_update AFTER UPDATE ON traces BEGIN
                UPDATE traces_fts SET
                    goal_text = new.goal_text,
                    output_summary = new.output_summary
                WHERE rowid = new.rowid;
            END;
        """)

        self.conn.commit()

    # =========================================================================
    # MEMORY OPERATIONS
    # =========================================================================

    def store_memory(
        self,
        key: str,
        value: Any,
        category: str = "general",
        ttl_secs: Optional[float] = None,
        metadata: Optional[Dict[str, Any]] = None,
        embedding: Optional[List[float]] = None
    ):
        """
        Store a memory entry

        Args:
            key: Memory key
            value: Value to store (any pickle-able object)
            category: Memory category
            ttl_secs: Time to live in seconds
            metadata: Additional metadata
            embedding: Optional semantic embedding vector
        """
        cursor = self.conn.cursor()

        # Serialize value
        value_blob = pickle.dumps(value)
        metadata_json = json.dumps(metadata) if metadata else None
        embedding_blob = pickle.dumps(embedding) if embedding else None

        cursor.execute("""
            INSERT OR REPLACE INTO memories
            (key, value, category, timestamp, ttl_secs, metadata, embedding)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            key,
            value_blob,
            category,
            datetime.now().timestamp(),
            ttl_secs,
            metadata_json,
            embedding_blob
        ))

        self.conn.commit()

    def retrieve_memory(self, key: str) -> Optional[MemoryEntry]:
        """Retrieve a memory by key"""
        cursor = self.conn.cursor()

        cursor.execute("""
            SELECT * FROM memories WHERE key = ?
        """, (key,))

        row = cursor.fetchone()
        if not row:
            return None

        # Check if expired
        current_time = datetime.now().timestamp()
        ttl_secs = row["ttl_secs"]
        if ttl_secs and (current_time - row["timestamp"]) > ttl_secs:
            # Delete expired memory
            self.delete_memory(key)
            return None

        # Deserialize
        value = pickle.loads(row["value"])
        metadata = json.loads(row["metadata"]) if row["metadata"] else None
        embedding = pickle.loads(row["embedding"]) if row["embedding"] else None

        return MemoryEntry(
            key=row["key"],
            value=value,
            category=row["category"],
            timestamp=row["timestamp"],
            ttl_secs=ttl_secs,
            metadata=metadata,
            embedding=embedding
        )

    def search_memories(
        self,
        category: Optional[str] = None,
        limit: int = 100
    ) -> List[MemoryEntry]:
        """Search memories by category"""
        cursor = self.conn.cursor()

        if category:
            cursor.execute("""
                SELECT * FROM memories
                WHERE category = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (category, limit))
        else:
            cursor.execute("""
                SELECT * FROM memories
                ORDER BY timestamp DESC
                LIMIT ?
            """, (limit,))

        current_time = datetime.now().timestamp()
        results = []

        for row in cursor.fetchall():
            # Skip expired
            ttl_secs = row["ttl_secs"]
            if ttl_secs and (current_time - row["timestamp"]) > ttl_secs:
                continue

            value = pickle.loads(row["value"])
            metadata = json.loads(row["metadata"]) if row["metadata"] else None
            embedding = pickle.loads(row["embedding"]) if row["embedding"] else None

            results.append(MemoryEntry(
                key=row["key"],
                value=value,
                category=row["category"],
                timestamp=row["timestamp"],
                ttl_secs=ttl_secs,
                metadata=metadata,
                embedding=embedding
            ))

        return results

    def delete_memory(self, key: str):
        """Delete a memory"""
        cursor = self.conn.cursor()
        cursor.execute("DELETE FROM memories WHERE key = ?", (key,))
        self.conn.commit()

    def cleanup_expired(self) -> int:
        """Remove expired memories"""
        cursor = self.conn.cursor()
        current_time = datetime.now().timestamp()

        cursor.execute("""
            DELETE FROM memories
            WHERE ttl_secs IS NOT NULL
            AND (timestamp + ttl_secs) < ?
        """, (current_time,))

        deleted = cursor.rowcount
        self.conn.commit()
        return deleted

    # =========================================================================
    # TRACE OPERATIONS
    # =========================================================================

    def store_trace(self, trace: TraceEntry):
        """Store an execution trace"""
        cursor = self.conn.cursor()

        cursor.execute("""
            INSERT OR REPLACE INTO traces
            (trace_id, goal_signature, goal_text, mode, success, success_rating,
             usage_count, tools_used, output_summary, estimated_time_secs, cost_usd,
             created_at, updated_at, crystallized_into_tool, tool_calls, embedding)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            trace.trace_id,
            trace.goal_signature,
            trace.goal_text,
            trace.mode,
            1 if trace.success else 0,
            trace.success_rating,
            trace.usage_count,
            json.dumps(trace.tools_used),
            trace.output_summary,
            trace.estimated_time_secs,
            trace.cost_usd,
            trace.created_at,
            trace.updated_at,
            trace.crystallized_into_tool,
            trace.tool_calls,
            pickle.dumps(trace.embedding) if trace.embedding else None
        ))

        self.conn.commit()

    def get_trace(self, trace_id: str) -> Optional[TraceEntry]:
        """Get trace by ID"""
        cursor = self.conn.cursor()

        cursor.execute("""
            SELECT * FROM traces WHERE trace_id = ?
        """, (trace_id,))

        row = cursor.fetchone()
        if not row:
            return None

        return self._row_to_trace_entry(row)

    def find_traces_by_signature(self, goal_signature: str) -> List[TraceEntry]:
        """Find traces by goal signature"""
        cursor = self.conn.cursor()

        cursor.execute("""
            SELECT * FROM traces
            WHERE goal_signature = ?
            ORDER BY usage_count DESC, success_rating DESC
        """, (goal_signature,))

        return [self._row_to_trace_entry(row) for row in cursor.fetchall()]

    def search_traces_fts(
        self,
        query: str,
        min_success_rating: float = 0.0,
        limit: int = 10
    ) -> List[TraceEntry]:
        """
        Full-text search for traces

        Args:
            query: Search query
            min_success_rating: Minimum success rating
            limit: Maximum results

        Returns:
            List of matching traces
        """
        cursor = self.conn.cursor()

        cursor.execute("""
            SELECT t.* FROM traces t
            INNER JOIN traces_fts fts ON t.rowid = fts.rowid
            WHERE traces_fts MATCH ?
            AND t.success_rating >= ?
            ORDER BY t.success_rating DESC, t.usage_count DESC
            LIMIT ?
        """, (query, min_success_rating, limit))

        return [self._row_to_trace_entry(row) for row in cursor.fetchall()]

    def get_top_traces(
        self,
        mode: Optional[str] = None,
        limit: int = 100
    ) -> List[TraceEntry]:
        """Get top traces by usage and success"""
        cursor = self.conn.cursor()

        if mode:
            cursor.execute("""
                SELECT * FROM traces
                WHERE mode = ? AND success = 1
                ORDER BY usage_count DESC, success_rating DESC
                LIMIT ?
            """, (mode, limit))
        else:
            cursor.execute("""
                SELECT * FROM traces
                WHERE success = 1
                ORDER BY usage_count DESC, success_rating DESC
                LIMIT ?
            """, (limit,))

        return [self._row_to_trace_entry(row) for row in cursor.fetchall()]

    def update_trace_usage(self, trace_id: str):
        """Increment trace usage count"""
        cursor = self.conn.cursor()

        cursor.execute("""
            UPDATE traces
            SET usage_count = usage_count + 1,
                updated_at = ?
            WHERE trace_id = ?
        """, (datetime.now().timestamp(), trace_id))

        self.conn.commit()

    def get_crystallization_candidates(
        self,
        min_usage: int = 5,
        min_success_rate: float = 0.95
    ) -> List[TraceEntry]:
        """
        Find traces that are candidates for crystallization

        Args:
            min_usage: Minimum usage count
            min_success_rate: Minimum success rating

        Returns:
            List of candidate traces
        """
        cursor = self.conn.cursor()

        cursor.execute("""
            SELECT * FROM traces
            WHERE usage_count >= ?
            AND success_rating >= ?
            AND crystallized_into_tool IS NULL
            AND success = 1
            ORDER BY usage_count DESC, success_rating DESC
        """, (min_usage, min_success_rate))

        return [self._row_to_trace_entry(row) for row in cursor.fetchall()]

    def mark_crystallized(self, trace_id: str, tool_name: str):
        """Mark a trace as crystallized into a tool"""
        cursor = self.conn.cursor()

        cursor.execute("""
            UPDATE traces
            SET crystallized_into_tool = ?,
                updated_at = ?
            WHERE trace_id = ?
        """, (tool_name, datetime.now().timestamp(), trace_id))

        self.conn.commit()

    def _row_to_trace_entry(self, row: sqlite3.Row) -> TraceEntry:
        """Convert database row to TraceEntry"""
        embedding = pickle.loads(row["embedding"]) if row["embedding"] else None

        return TraceEntry(
            trace_id=row["trace_id"],
            goal_signature=row["goal_signature"],
            goal_text=row["goal_text"],
            mode=row["mode"],
            success=bool(row["success"]),
            success_rating=row["success_rating"],
            usage_count=row["usage_count"],
            tools_used=json.loads(row["tools_used"]) if row["tools_used"] else [],
            output_summary=row["output_summary"],
            estimated_time_secs=row["estimated_time_secs"],
            cost_usd=row["cost_usd"],
            created_at=row["created_at"],
            updated_at=row["updated_at"],
            crystallized_into_tool=row["crystallized_into_tool"],
            tool_calls=row["tool_calls"],
            embedding=embedding
        )

    # =========================================================================
    # STATISTICS
    # =========================================================================

    def get_statistics(self) -> Dict[str, Any]:
        """Get database statistics"""
        cursor = self.conn.cursor()

        # Memory stats
        cursor.execute("SELECT COUNT(*), COUNT(DISTINCT category) FROM memories")
        memory_count, category_count = cursor.fetchone()

        # Trace stats
        cursor.execute("""
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successful,
                AVG(success_rating) as avg_rating,
                SUM(usage_count) as total_usage,
                COUNT(DISTINCT mode) as mode_count
            FROM traces
        """)
        trace_stats = cursor.fetchone()

        # Crystallization stats
        cursor.execute("""
            SELECT COUNT(*) FROM traces
            WHERE crystallized_into_tool IS NOT NULL
        """)
        crystallized_count = cursor.fetchone()[0]

        return {
            "memories": {
                "total": memory_count,
                "categories": category_count
            },
            "traces": {
                "total": trace_stats[0],
                "successful": trace_stats[1],
                "average_rating": trace_stats[2] or 0.0,
                "total_usage": trace_stats[3],
                "modes": trace_stats[4],
                "crystallized": crystallized_count
            }
        }

    def close(self):
        """Close database connection"""
        self.conn.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()



================================================
File: memory/store.py
================================================
"""
Memory Store - L4 Storage (Semantic Memory)
Vector database for unstructured knowledge
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class MemoryEntry:
    """A memory entry in semantic storage"""
    id: str
    text: str
    embedding: List[float]
    metadata: Dict[str, Any]
    created_at: str

    def __post_init__(self):
        if isinstance(self.embedding, np.ndarray):
            self.embedding = self.embedding.tolist()


class MemoryStore:
    """
    Semantic memory store (L4 Storage)
    Simple vector database using cosine similarity
    """

    def __init__(self, storage_path: Path):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.memories: List[MemoryEntry] = []
        self._load_memories()

    def _load_memories(self):
        """Load memories from disk"""
        memory_file = self.storage_path / "semantic_memory.json"

        if memory_file.exists():
            with open(memory_file, 'r') as f:
                data = json.load(f)
                self.memories = [MemoryEntry(**entry) for entry in data]

    def _save_memories(self):
        """Save memories to disk"""
        memory_file = self.storage_path / "semantic_memory.json"

        with open(memory_file, 'w') as f:
            data = [asdict(entry) for entry in self.memories]
            json.dump(data, f, indent=2)

    def _simple_embedding(self, text: str) -> np.ndarray:
        """
        Create a simple text embedding
        TODO: Replace with actual embedding model (e.g., sentence-transformers)
        """
        # Very simple word-based embedding for now
        # In production, use proper embedding models
        words = text.lower().split()
        # Create a 384-dimensional vector (common embedding size)
        embedding = np.zeros(384)

        for i, word in enumerate(words[:384]):
            # Simple hash-based embedding
            hash_val = hash(word)
            embedding[i % 384] += (hash_val % 1000) / 1000.0

        # Normalize
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm

        return embedding

    def add_memory(
        self,
        text: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> MemoryEntry:
        """
        Add a memory entry

        Args:
            text: Text to store
            metadata: Additional metadata

        Returns:
            Created MemoryEntry
        """
        embedding = self._simple_embedding(text)

        entry = MemoryEntry(
            id=f"mem_{len(self.memories)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            text=text,
            embedding=embedding.tolist(),
            metadata=metadata or {},
            created_at=datetime.now().isoformat()
        )

        self.memories.append(entry)
        self._save_memories()

        return entry

    def search(
        self,
        query: str,
        top_k: int = 5,
        threshold: float = 0.5
    ) -> List[tuple[MemoryEntry, float]]:
        """
        Search for similar memories

        Args:
            query: Search query
            top_k: Number of results to return
            threshold: Minimum similarity threshold

        Returns:
            List of (MemoryEntry, similarity_score) tuples
        """
        if not self.memories:
            return []

        query_embedding = self._simple_embedding(query)

        # Calculate cosine similarities
        similarities = []
        for memory in self.memories:
            memory_embedding = np.array(memory.embedding)
            similarity = np.dot(query_embedding, memory_embedding)
            if similarity >= threshold:
                similarities.append((memory, float(similarity)))

        # Sort by similarity
        similarities.sort(key=lambda x: x[1], reverse=True)

        return similarities[:top_k]

    def clear(self):
        """Clear all memories"""
        self.memories = []
        self._save_memories()



================================================
File: memory/store_sdk.py
================================================
"""
Memory Store - SDK-based Implementation
Uses Claude Agent SDK's /memories directory structure

Replaces custom vector DB with file-based semantic memory.
"""

from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

from memory.sdk_memory import SDKMemoryTool, MemorySession


class MemoryStore:
    """
    File-based semantic memory using SDK conventions

    Structure:
    /memories/
        traces/         # Execution traces
        projects/       # Project-specific memory
        sessions/       # Session context
        facts/          # Long-term facts
        insights/       # Extracted insights
    """

    def __init__(self, workspace: Path):
        """
        Initialize memory store

        Args:
            workspace: Workspace root directory
        """
        self.workspace = Path(workspace)
        self.memories_dir = self.workspace / "memories"
        self.memories_dir.mkdir(parents=True, exist_ok=True)

        # Initialize SDK Memory Tool
        self.memory_tool = SDKMemoryTool(self.memories_dir)

        # Create standard directories
        self._init_directories()

    def _init_directories(self):
        """Initialize standard memory directories"""
        directories = [
            "traces",
            "projects",
            "sessions",
            "facts",
            "insights"
        ]

        for dir_name in directories:
            (self.memories_dir / dir_name).mkdir(exist_ok=True)

    def store_fact(self, fact: str, category: str = "general") -> bool:
        """
        Store a long-term fact

        Args:
            fact: Fact to store
            category: Fact category

        Returns:
            True if stored successfully
        """
        # Generate fact ID
        fact_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"facts/{category}_{fact_id}.md"

        content = f"""# Fact: {category}

**Stored**: {datetime.now().isoformat()}

## Content

{fact}
"""

        self.memory_tool.create(filename, content)
        return True

    def store_insight(
        self,
        insight: str,
        insight_type: str,
        evidence: List[str],
        confidence: float
    ) -> bool:
        """
        Store an extracted insight

        Args:
            insight: Insight description
            insight_type: Type of insight
            evidence: Supporting evidence
            confidence: Confidence score (0-1)

        Returns:
            True if stored successfully
        """
        insight_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"insights/{insight_type}_{insight_id}.md"

        evidence_md = "\n".join(f"- {e}" for e in evidence)

        content = f"""# Insight: {insight_type}

**Stored**: {datetime.now().isoformat()}
**Confidence**: {confidence:.0%}

## Description

{insight}

## Evidence

{evidence_md}
"""

        self.memory_tool.create(filename, content)
        return True

    def search_facts(self, query: str, limit: int = 5) -> List[str]:
        """
        Search facts by keyword

        Args:
            query: Search query
            limit: Maximum results

        Returns:
            List of fact contents
        """
        files = self.memory_tool.search(query, directory="facts")

        facts = []
        for file in files[:limit]:
            # Extract content section
            lines = file.content.splitlines()
            content_start = False
            content_lines = []

            for line in lines:
                if line.startswith("## Content"):
                    content_start = True
                    continue
                if content_start and line.strip():
                    content_lines.append(line)

            if content_lines:
                facts.append("\n".join(content_lines))

        return facts

    def get_insights(
        self,
        insight_type: Optional[str] = None,
        min_confidence: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        Get stored insights

        Args:
            insight_type: Optional type filter
            min_confidence: Minimum confidence

        Returns:
            List of insight dictionaries
        """
        pattern = f"{insight_type}_*.md" if insight_type else "*.md"
        files = self.memory_tool.list_files("insights", pattern=pattern)

        insights = []
        for file in files:
            # Parse insight
            lines = file.content.splitlines()
            metadata = {}
            description = ""
            evidence = []

            current_section = None
            for line in lines:
                if line.startswith("**") and "**:" in line:
                    key, value = line.split("**:", 1)
                    key = key.strip("* ")
                    metadata[key] = value.strip()
                elif line.startswith("## Description"):
                    current_section = "description"
                elif line.startswith("## Evidence"):
                    current_section = "evidence"
                elif current_section == "description" and line.strip():
                    description = line.strip()
                elif current_section == "evidence" and line.startswith("- "):
                    evidence.append(line[2:].strip())

            confidence = float(metadata.get("Confidence", "0%").rstrip('%')) / 100.0

            if confidence >= min_confidence:
                insights.append({
                    "type": insight_type or "general",
                    "description": description,
                    "evidence": evidence,
                    "confidence": confidence,
                    "stored_at": metadata.get("Stored", "")
                })

        return insights

    def get_statistics(self) -> Dict[str, Any]:
        """
        Get memory statistics

        Returns:
            Dictionary with memory stats
        """
        facts_count = len(self.memory_tool.list_files("facts"))
        insights_count = len(self.memory_tool.list_files("insights"))
        sessions_count = len(list((self.memories_dir / "sessions").iterdir())) if (self.memories_dir / "sessions").exists() else 0

        return {
            "facts_count": facts_count,
            "insights_count": insights_count,
            "sessions_count": sessions_count,
            "total_files": facts_count + insights_count
        }

    def cleanup_old_sessions(self, days: int = 30):
        """
        Clean up old session files

        Args:
            days: Age threshold in days
        """
        sessions_dir = self.memories_dir / "sessions"

        if not sessions_dir.exists():
            return

        threshold = datetime.now().timestamp() - (days * 24 * 60 * 60)

        for session_path in sessions_dir.iterdir():
            if session_path.is_dir():
                if session_path.stat().st_mtime < threshold:
                    # Delete old session
                    for file in session_path.glob("*"):
                        file.unlink()
                    session_path.rmdir()



================================================
File: memory/trace_analyzer.py
================================================
"""
LLM-Based Trace Analyzer - Semantic trace matching using Claude Agent SDK

Replaces brittle hash-based matching with intelligent semantic analysis.
Implements "soft" associative memory as described in Nested Learning paper.
"""

import json
import asyncio
from pathlib import Path
from typing import List, Optional, Tuple, Dict, Any
from dataclasses import dataclass

try:
    from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions
except ImportError:
    print("Warning: claude-agent-sdk not installed. Install with: pip install claude-agent-sdk")
    ClaudeSDKClient = None
    ClaudeAgentOptions = None


@dataclass
class TraceMatch:
    """Result of trace matching analysis"""
    trace_signature: str
    goal_text: str
    confidence: float  # 0.0 to 1.0
    reasoning: str  # Why this trace matches
    recommended_mode: str  # "FOLLOWER", "MIXED", or "LEARNER"


class TraceAnalyzer:
    """
    LLM-Based Trace Analyzer

    Uses Claude Agent SDK to perform semantic analysis of goal-to-trace matching.

    This implements "soft" associative memory:
    - Hash matching: "create file" â‰  "create a file" (fails)
    - LLM matching: "create file" â‰ˆ "create a file" (succeeds with confidence score)

    Confidence thresholds:
    - â‰¥0.92: High confidence â†’ FOLLOWER mode (direct replay)
    - 0.75-0.92: Medium confidence â†’ MIXED mode (trace as few-shot)
    - <0.75: Low confidence â†’ LEARNER mode (full reasoning)
    """

    def __init__(
        self,
        workspace: Path,
        model: str = "claude-sonnet-4-5-20250929"
    ):
        """
        Initialize TraceAnalyzer

        Args:
            workspace: Workspace directory
            model: Claude model to use
        """
        self.workspace = Path(workspace)
        self.model = model

        if ClaudeSDKClient is None:
            raise RuntimeError(
                "Claude Agent SDK not installed. "
                "Install with: pip install claude-agent-sdk"
            )

    async def analyze_goal_similarity(
        self,
        goal: str,
        trace_goal: str,
        trace_metadata: Dict[str, Any]
    ) -> float:
        """
        Analyze semantic similarity between goal and trace goal

        Uses Claude to understand if goals are functionally equivalent,
        even if worded differently.

        Args:
            goal: Current goal
            trace_goal: Goal from existing trace
            trace_metadata: Additional trace metadata (success rate, usage count, etc.)

        Returns:
            Confidence score (0.0 to 1.0)
        """
        analysis_prompt = f"""Analyze if these two goals are semantically similar enough to use the same execution strategy.

Current Goal:
"{goal}"

Previous Goal (from execution trace):
"{trace_goal}"

Trace Metadata:
- Success Rate: {trace_metadata.get('success_rating', 0.0):.0%}
- Times Used: {trace_metadata.get('usage_count', 0)}
- Mode: {trace_metadata.get('mode', 'UNKNOWN')}

Question: Can the execution trace from the previous goal be safely reused for the current goal?

Consider:
1. **Semantic equivalence**: Do the goals request the same logical action?
2. **Scope similarity**: Are the goals operating at the same level of complexity?
3. **Output compatibility**: Would the same execution steps work for both goals?

Respond with a JSON object:
{{
  "confidence": 0.95,  // Score from 0.0 (completely different) to 1.0 (identical intent)
  "reasoning": "Brief explanation of why they match or don't match",
  "recommended_mode": "FOLLOWER"  // One of: FOLLOWER, MIXED, LEARNER
}}

Scoring guide:
- 0.95-1.0: Virtually identical (minor wording differences only)
- 0.85-0.95: Same core task, slight parameter differences
- 0.70-0.85: Related tasks, could benefit from similar approach
- 0.50-0.70: Loosely related, different execution needed
- 0.0-0.50: Unrelated tasks

Be strict: only high scores for truly equivalent tasks.
"""

        # Configure Claude options
        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(self.workspace),
            allowed_tools=[],  # No tools needed for analysis
            permission_mode="acceptEdits",
            system_prompt={
                "type": "text",
                "text": """You are a semantic analysis expert specializing in task equivalence.
Your role is to determine if two natural language goals are functionally equivalent.

Be conservative: only assign high confidence scores when you're certain the same
execution strategy will work for both goals.

Consider edge cases:
- "Create a file" vs "Create a new file" â†’ High confidence (same action)
- "List files" vs "Show all files" â†’ High confidence (same action)
- "Create a Python file" vs "Create a JavaScript file" â†’ Low confidence (different file types)
- "Read config.json" vs "Read settings.yaml" â†’ Medium confidence (same action, different files)

Always respond with valid JSON."""
            }
        )

        result = None

        try:
            async with ClaudeSDKClient(options=options) as client:
                await client.query(analysis_prompt)

                async for msg in client.receive_response():
                    if hasattr(msg, "content"):
                        for block in msg.content:
                            if hasattr(block, "text"):
                                text = block.text
                                # Extract JSON from response
                                try:
                                    start = text.find("{")
                                    end = text.rfind("}") + 1
                                    if start != -1 and end != 0:
                                        result = json.loads(text[start:end])
                                except json.JSONDecodeError:
                                    continue

                    # Break on ResultMessage
                    if "Result" in msg.__class__.__name__:
                        break

        except Exception as e:
            print(f"[WARNING] LLM analysis failed: {e}")
            return 0.0

        if result and "confidence" in result:
            return float(result["confidence"])

        return 0.0

    async def find_best_matching_trace(
        self,
        goal: str,
        traces: List[Any],  # List[ExecutionTrace]
        min_confidence: float = 0.75
    ) -> Optional[TraceMatch]:
        """
        Find best matching trace using LLM analysis

        Analyzes all traces and returns the best semantic match.

        Args:
            goal: Goal to match
            traces: List of ExecutionTrace instances
            min_confidence: Minimum confidence threshold

        Returns:
            TraceMatch if found, None otherwise
        """
        if not traces:
            return None

        # Build analysis prompt with all traces
        traces_info = []
        for i, trace in enumerate(traces):
            traces_info.append({
                "index": i,
                "goal": trace.goal_text,
                "signature": trace.goal_signature,
                "success_rating": trace.success_rating,
                "usage_count": trace.usage_count,
                "mode": trace.mode
            })

        analysis_prompt = f"""Find the best matching execution trace for this goal.

Current Goal:
"{goal}"

Available Traces:
{json.dumps(traces_info, indent=2)}

Question: Which trace (if any) best matches the current goal?

Respond with JSON:
{{
  "best_match_index": 0,  // Index of best matching trace, or null if none match
  "confidence": 0.95,  // Confidence score (0.0-1.0)
  "reasoning": "Why this trace matches",
  "recommended_mode": "FOLLOWER"  // FOLLOWER, MIXED, or LEARNER
}}

Criteria:
1. Semantic similarity to goal
2. Success rate (prefer proven traces)
3. Usage count (prefer well-tested traces)

Confidence thresholds:
- â‰¥0.92: FOLLOWER mode (execute trace directly)
- 0.75-0.92: MIXED mode (use trace as guidance)
- <0.75: LEARNER mode (learn from scratch)

If no trace has confidence â‰¥{min_confidence}, set best_match_index to null.
"""

        options = ClaudeAgentOptions(
            model=self.model,
            cwd=str(self.workspace),
            allowed_tools=[],
            permission_mode="acceptEdits",
            system_prompt={
                "type": "text",
                "text": """You are an expert at matching tasks to execution traces.
Analyze semantic similarity while considering execution success history.

Prioritize:
1. Semantic equivalence (most important)
2. High success rate
3. Frequent usage (indicates reliability)

Be conservative with confidence scores. Always return valid JSON."""
            }
        )

        result = None

        try:
            async with ClaudeSDKClient(options=options) as client:
                await client.query(analysis_prompt)

                async for msg in client.receive_response():
                    if hasattr(msg, "content"):
                        for block in msg.content:
                            if hasattr(block, "text"):
                                text = block.text
                                try:
                                    start = text.find("{")
                                    end = text.rfind("}") + 1
                                    if start != -1 and end != 0:
                                        result = json.loads(text[start:end])
                                except json.JSONDecodeError:
                                    continue

                    if "Result" in msg.__class__.__name__:
                        break

        except Exception as e:
            print(f"[WARNING] Trace matching analysis failed: {e}")
            return None

        if not result:
            return None

        # Extract match
        match_index = result.get("best_match_index")

        if match_index is None:
            return None

        confidence = float(result.get("confidence", 0.0))

        if confidence < min_confidence:
            return None

        # Get matched trace
        matched_trace = traces[match_index]

        return TraceMatch(
            trace_signature=matched_trace.goal_signature,
            goal_text=matched_trace.goal_text,
            confidence=confidence,
            reasoning=result.get("reasoning", "LLM analysis matched this trace"),
            recommended_mode=result.get("recommended_mode", self._determine_mode(confidence))
        )

    def _determine_mode(self, confidence: float) -> str:
        """
        Determine execution mode from confidence score

        Args:
            confidence: Confidence score (0.0-1.0)

        Returns:
            Mode string: "FOLLOWER", "MIXED", or "LEARNER"
        """
        if confidence >= 0.92:
            return "FOLLOWER"
        elif confidence >= 0.75:
            return "MIXED"
        else:
            return "LEARNER"

    async def batch_analyze_traces(
        self,
        goal: str,
        traces: List[Any],
        top_k: int = 3
    ) -> List[TraceMatch]:
        """
        Analyze multiple traces and return top matches

        Useful for providing multiple execution options to the user.

        Args:
            goal: Goal to match
            traces: List of ExecutionTrace instances
            top_k: Number of top matches to return

        Returns:
            List of TraceMatch instances, sorted by confidence
        """
        # For efficiency, we'll use the batch analysis in find_best_matching_trace
        # and return the single best match
        #
        # In a production system, you could modify find_best_matching_trace
        # to return multiple matches

        best_match = await self.find_best_matching_trace(goal, traces, min_confidence=0.5)

        if best_match:
            return [best_match]

        return []



================================================
File: memory/traces.py
================================================
"""
Execution Trace Manager - L3 Storage (Procedural Memory)
Stores and retrieves execution patterns for Follower Mode
"""

import json
import yaml
import hashlib
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class ExecutionTrace:
    """
    An execution trace - the "compiled program" of the LLM OS
    This is what allows cheap repetition of expensive learning
    """
    goal_signature: str  # Hash of the goal
    goal_text: str  # Original goal
    steps: List[Dict]  # Tool call sequence
    success_rating: float  # 0.0 to 1.0
    usage_count: int = 0
    last_used: Optional[str] = None
    created_at: Optional[str] = None
    estimated_cost_usd: float = 0.0
    estimated_time_secs: float = 0.0
    crystallized_into_tool: Optional[str] = None  # Name of generated tool (HOPE architecture)

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()


class TraceManager:
    """
    Manages execution traces (L3 Storage)
    Think of this as the "compiled bytecode" storage
    """

    def __init__(self, storage_path: Path):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        # In-memory index for fast lookup
        self.index: Dict[str, str] = {}  # goal_signature -> file_path
        self._load_index()

    def _load_index(self):
        """Load all traces into memory index"""
        for trace_file in self.storage_path.glob("*.yaml"):
            with open(trace_file, 'r') as f:
                data = yaml.safe_load(f)
                if data and 'goal_signature' in data:
                    self.index[data['goal_signature']] = str(trace_file)

    def _hash_goal(self, goal: str) -> str:
        """Create a hash signature for a goal"""
        return hashlib.sha256(goal.lower().strip().encode()).hexdigest()[:16]

    def save_trace(self, trace: ExecutionTrace) -> Path:
        """
        Save an execution trace

        Args:
            trace: ExecutionTrace to save

        Returns:
            Path to saved trace file
        """
        filename = f"trace_{trace.goal_signature}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yaml"
        filepath = self.storage_path / filename

        # Convert to dict and save as YAML
        data = asdict(trace)

        with open(filepath, 'w') as f:
            yaml.dump(data, f, default_flow_style=False, sort_keys=False)

        # Update index
        self.index[trace.goal_signature] = str(filepath)

        return filepath

    def find_trace(self, goal: str, confidence_threshold: float = 0.9) -> Optional[ExecutionTrace]:
        """
        Find a matching trace for a goal

        Args:
            goal: Natural language goal
            confidence_threshold: Minimum success rating required

        Returns:
            ExecutionTrace if found and confidence is high enough, None otherwise
        """
        goal_sig = self._hash_goal(goal)

        # Exact match
        if goal_sig in self.index:
            filepath = Path(self.index[goal_sig])
            if filepath.exists():
                with open(filepath, 'r') as f:
                    data = yaml.safe_load(f)

                trace = ExecutionTrace(**data)

                # Check confidence threshold
                if trace.success_rating >= confidence_threshold:
                    return trace

        # TODO: Implement semantic similarity search for partial matches
        # For now, only exact goal matches

        return None

    def update_trace_usage(self, goal_signature: str, success: bool):
        """
        Update trace usage statistics after execution

        Args:
            goal_signature: Trace signature
            success: Whether execution was successful
        """
        if goal_signature not in self.index:
            return

        filepath = Path(self.index[goal_signature])
        if not filepath.exists():
            return

        with open(filepath, 'r') as f:
            data = yaml.safe_load(f)

        trace = ExecutionTrace(**data)

        # Update usage
        trace.usage_count += 1
        trace.last_used = datetime.now().isoformat()

        # Update success rating (exponential moving average)
        alpha = 0.1  # Learning rate
        new_rating = 1.0 if success else 0.0
        trace.success_rating = (1 - alpha) * trace.success_rating + alpha * new_rating

        # Save updated trace
        with open(filepath, 'w') as f:
            yaml.dump(asdict(trace), f, default_flow_style=False, sort_keys=False)

    def list_traces(self) -> List[ExecutionTrace]:
        """List all execution traces"""
        traces = []

        for filepath in Path(self.storage_path).glob("*.yaml"):
            with open(filepath, 'r') as f:
                data = yaml.safe_load(f)
            traces.append(ExecutionTrace(**data))

        return sorted(traces, key=lambda t: t.usage_count, reverse=True)



================================================
File: memory/traces_sdk.py
================================================
"""
Execution Traces - SDK Memory-based Implementation
Stores execution traces as markdown files in /memories/traces/

Aligned with Claude Agent SDK's file-based memory approach.
"""

from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import hashlib
import re

from memory.sdk_memory import SDKMemoryTool
from memory.trace_analyzer import TraceAnalyzer, TraceMatch


@dataclass
class ExecutionTrace:
    """
    Execution trace stored as markdown

    Represents a learned execution pattern that can be reused
    in Follower mode.

    Architecture:
        - Learning Layer uses traces to decide mode (FOLLOWER vs LEARNER)
        - Execution Layer uses tool_calls for PTC replay (if available)

    The tool_calls field enables Programmatic Tool Calling (PTC):
        - Stores full tool call details (name + arguments)
        - Allows zero-context replay via code execution
        - Critical for Anthropic's Advanced Tool Use integration
    """
    goal_signature: str  # Hash of normalized goal
    goal_text: str  # Original goal text
    success_rating: float  # 0.0 to 1.0
    usage_count: int  # How many times this trace was used
    created_at: datetime
    last_used: Optional[datetime]
    estimated_cost_usd: float
    estimated_time_secs: float
    mode: str  # "LEARNER", "FOLLOWER", "ORCHESTRATOR", "CRYSTALLIZED"

    # Optional metadata
    tools_used: List[str] = None  # List of tool names (for quick filtering)
    output_summary: str = ""
    error_notes: str = ""
    crystallized_into_tool: Optional[str] = None  # Name of generated tool (HOPE architecture)

    # PTC (Programmatic Tool Calling) support
    # This enables zero-context replay via Anthropic's Advanced Tool Use
    tool_calls: Optional[List[Dict[str, Any]]] = None  # Full tool call data: [{name, arguments}, ...]

    def to_markdown(self) -> str:
        """Convert trace to markdown format"""
        import json

        lines = [
            f"# Execution Trace: {self.goal_text}",
            "",
            "## Metadata",
            f"- **Goal Signature**: `{self.goal_signature}`",
            f"- **Success Rating**: {self.success_rating:.0%}",
            f"- **Usage Count**: {self.usage_count}",
            f"- **Mode**: {self.mode}",
            f"- **Created**: {self.created_at.isoformat()}",
            f"- **Last Used**: {self.last_used.isoformat() if self.last_used else 'Never'}",
            f"- **Estimated Cost**: ${self.estimated_cost_usd:.4f}",
            f"- **Estimated Time**: {self.estimated_time_secs:.1f}s",
        ]

        if self.crystallized_into_tool:
            lines.append(f"- **Crystallized Tool**: `{self.crystallized_into_tool}` ðŸ’Ž")

        # Indicate PTC capability
        if self.tool_calls:
            lines.append(f"- **PTC Enabled**: Yes ({len(self.tool_calls)} calls)")

        lines.append("")

        if self.tools_used:
            lines.extend([
                "## Tools Used",
                "",
                "```",
                ", ".join(self.tools_used),
                "```",
                ""
            ])

        # Store full tool calls for PTC replay
        if self.tool_calls:
            lines.extend([
                "## Tool Calls (PTC)",
                "",
                "```json",
                json.dumps(self.tool_calls, indent=2),
                "```",
                ""
            ])

        if self.output_summary:
            lines.extend([
                "## Output Summary",
                "",
                self.output_summary,
                ""
            ])

        if self.error_notes:
            lines.extend([
                "## Error Notes",
                "",
                self.error_notes,
                ""
            ])

        return "\n".join(lines)

    @classmethod
    def from_markdown(cls, content: str) -> 'ExecutionTrace':
        """Parse trace from markdown"""
        import json

        lines = content.splitlines()

        # Extract metadata
        metadata = {}
        tools_used = []
        tool_calls = None
        output_summary = ""
        error_notes = ""

        current_section = None
        section_lines = []
        in_json_block = False
        json_lines = []

        for line in lines:
            # Section headers
            if line.startswith("## "):
                # Process previous section
                if current_section and section_lines:
                    if current_section == "Output Summary":
                        output_summary = "\n".join(section_lines).strip()
                    elif current_section == "Error Notes":
                        error_notes = "\n".join(section_lines).strip()

                # Handle JSON block end for Tool Calls
                if current_section == "Tool Calls (PTC)" and json_lines:
                    try:
                        tool_calls = json.loads("\n".join(json_lines))
                    except json.JSONDecodeError:
                        pass
                    json_lines = []

                current_section = line[3:].strip()
                section_lines = []
                in_json_block = False
                continue

            # Metadata parsing
            if current_section == "Metadata" and line.startswith("- **"):
                match = re.match(r"- \*\*(.+?)\*\*: (.+)", line)
                if match:
                    key, value = match.groups()
                    metadata[key] = value.strip('`')

            # Tools Used parsing
            elif current_section == "Tools Used" and line.strip() and line.strip() != "```":
                tools_used = [t.strip() for t in line.split(",")]

            # Tool Calls (PTC) JSON parsing
            elif current_section == "Tool Calls (PTC)":
                if line.strip() == "```json":
                    in_json_block = True
                    continue
                elif line.strip() == "```":
                    in_json_block = False
                    if json_lines:
                        try:
                            tool_calls = json.loads("\n".join(json_lines))
                        except json.JSONDecodeError:
                            pass
                        json_lines = []
                elif in_json_block:
                    json_lines.append(line)

            # Content accumulation for other sections
            elif current_section in ["Output Summary", "Error Notes"]:
                section_lines.append(line)

        # Handle last section
        if current_section == "Output Summary" and section_lines:
            output_summary = "\n".join(section_lines).strip()
        elif current_section == "Error Notes" and section_lines:
            error_notes = "\n".join(section_lines).strip()
        elif current_section == "Tool Calls (PTC)" and json_lines:
            try:
                tool_calls = json.loads("\n".join(json_lines))
            except json.JSONDecodeError:
                pass

        # Extract goal from title
        goal_text = lines[0].replace("# Execution Trace: ", "").strip() if lines else "Unknown"

        # Extract crystallized tool name (remove emoji if present)
        crystallized_tool = metadata.get("Crystallized Tool", "").rstrip(" ðŸ’Ž").strip() or None

        return cls(
            goal_signature=metadata.get("Goal Signature", ""),
            goal_text=goal_text,
            success_rating=float(metadata.get("Success Rating", "0%").rstrip('%')) / 100.0,
            usage_count=int(metadata.get("Usage Count", "0")),
            created_at=datetime.fromisoformat(metadata.get("Created", datetime.now().isoformat())),
            last_used=datetime.fromisoformat(metadata["Last Used"]) if metadata.get("Last Used") != "Never" else None,
            estimated_cost_usd=float(metadata.get("Estimated Cost", "$0").lstrip('$')),
            estimated_time_secs=float(metadata.get("Estimated Time", "0s").rstrip('s')),
            mode=metadata.get("Mode", "LEARNER"),
            tools_used=tools_used if tools_used else None,
            output_summary=output_summary,
            error_notes=error_notes,
            crystallized_into_tool=crystallized_tool,
            tool_calls=tool_calls
        )


class TraceManager:
    """
    Manages execution traces using SDK memory

    Stores traces as markdown files in /memories/traces/
    """

    def __init__(
        self,
        memories_dir: Path,
        workspace: Optional[Path] = None,
        enable_llm_matching: bool = True
    ):
        """
        Initialize trace manager

        Args:
            memories_dir: Root /memories directory
            workspace: Workspace directory (for LLM analysis)
            enable_llm_matching: Enable LLM-based semantic matching
        """
        self.memories_dir = Path(memories_dir)
        self.traces_dir = "traces"  # Relative to /memories
        self.enable_llm_matching = enable_llm_matching

        # Initialize SDK Memory Tool
        self.memory_tool = SDKMemoryTool(self.memories_dir)

        # Initialize LLM-based trace analyzer
        self.trace_analyzer: Optional[TraceAnalyzer] = None
        if enable_llm_matching:
            try:
                workspace = workspace or Path.cwd()
                self.trace_analyzer = TraceAnalyzer(workspace)
            except RuntimeError as e:
                print(f"[WARNING] Could not initialize TraceAnalyzer: {e}")
                print("          Falling back to hash-based matching only")
                self.enable_llm_matching = False

        # Ensure traces directory exists
        (self.memories_dir / self.traces_dir).mkdir(parents=True, exist_ok=True)

    def _normalize_goal(self, goal: str) -> str:
        """Normalize goal text for signature"""
        # Lowercase, remove punctuation, collapse whitespace
        normalized = goal.lower()
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        normalized = re.sub(r'\s+', ' ', normalized).strip()
        return normalized

    def _compute_signature(self, goal: str) -> str:
        """Compute signature for goal"""
        normalized = self._normalize_goal(goal)
        return hashlib.sha256(normalized.encode()).hexdigest()[:16]

    def _get_trace_filename(self, goal_signature: str, goal_text: str) -> str:
        """
        Generate filename for trace

        Format: {signature}_{sanitized_goal}.md
        """
        # Sanitize goal text for filename
        sanitized = re.sub(r'[^\w\s-]', '', goal_text.lower())
        sanitized = re.sub(r'[\s]+', '_', sanitized)[:50]  # Max 50 chars

        return f"{goal_signature}_{sanitized}.md"

    def save_trace(self, trace: ExecutionTrace) -> bool:
        """
        Save execution trace

        Args:
            trace: ExecutionTrace to save

        Returns:
            True if saved successfully
        """
        filename = self._get_trace_filename(trace.goal_signature, trace.goal_text)
        file_path = f"{self.traces_dir}/{filename}"

        content = trace.to_markdown()

        if self.memory_tool.exists(file_path):
            # Update existing trace
            self.memory_tool.str_replace(
                file_path,
                self.memory_tool.view(file_path),
                content
            )
        else:
            # Create new trace
            self.memory_tool.create(file_path, content)

        return True

    def find_trace(
        self,
        goal: str,
        min_confidence: float = 0.9
    ) -> Optional[ExecutionTrace]:
        """
        Find trace for goal using hash-based exact matching

        This is the legacy method. For semantic matching, use find_trace_with_llm().

        Args:
            goal: Goal to search for
            min_confidence: Minimum success rating threshold

        Returns:
            ExecutionTrace if found, None otherwise
        """
        signature = self._compute_signature(goal)

        # Look for exact signature match first
        traces = self.list_traces()

        for trace in traces:
            if trace.goal_signature == signature and trace.success_rating >= min_confidence:
                return trace

        return None

    async def find_trace_with_llm(
        self,
        goal: str,
        min_confidence: float = 0.75,
        fallback_to_hash: bool = True
    ) -> Optional[Tuple[ExecutionTrace, float]]:
        """
        Find trace using LLM-based semantic matching

        This implements "soft" associative memory:
        - Understands semantic equivalence ("create file" â‰ˆ "create a file")
        - Returns confidence score for intelligent mode selection
        - Falls back to hash matching if LLM analysis unavailable

        Args:
            goal: Goal to search for
            min_confidence: Minimum confidence threshold (0.0-1.0)
            fallback_to_hash: Fall back to hash matching if LLM unavailable

        Returns:
            Tuple of (ExecutionTrace, confidence_score) if found, None otherwise
        """
        # Try LLM-based matching first
        if self.enable_llm_matching and self.trace_analyzer:
            traces = self.list_traces()

            if not traces:
                return None

            try:
                match = await self.trace_analyzer.find_best_matching_trace(
                    goal=goal,
                    traces=traces,
                    min_confidence=min_confidence
                )

                if match:
                    # Find the matching trace
                    for trace in traces:
                        if trace.goal_signature == match.trace_signature:
                            print(f"[LLM Match] Confidence: {match.confidence:.0%}, Mode: {match.recommended_mode}")
                            print(f"[LLM Match] Reasoning: {match.reasoning}")
                            return (trace, match.confidence)

            except Exception as e:
                print(f"[WARNING] LLM trace matching failed: {e}")
                if not fallback_to_hash:
                    return None

        # Fallback to hash-based matching
        if fallback_to_hash:
            trace = self.find_trace(goal, min_confidence=0.9)
            if trace:
                print("[Hash Match] Exact signature match found")
                return (trace, 1.0)  # Hash match = 100% confidence

        return None

    async def find_trace_smart(
        self,
        goal: str
    ) -> Tuple[Optional[ExecutionTrace], float, str]:
        """
        Smart trace finding with automatic mode detection

        Combines LLM and hash matching with intelligent mode recommendation.

        Returns:
            Tuple of (trace, confidence, recommended_mode)
            - trace: ExecutionTrace if found, None otherwise
            - confidence: 0.0-1.0 confidence score
            - recommended_mode: "FOLLOWER", "MIXED", or "LEARNER"
        """
        result = await self.find_trace_with_llm(goal, min_confidence=0.75)

        if result:
            trace, confidence = result

            # Determine mode based on confidence
            if confidence >= 0.92:
                mode = "FOLLOWER"
            elif confidence >= 0.75:
                mode = "MIXED"
            else:
                mode = "LEARNER"

            return (trace, confidence, mode)

        return (None, 0.0, "LEARNER")

    def list_traces(self) -> List[ExecutionTrace]:
        """
        List all traces

        Returns:
            List of ExecutionTrace instances
        """
        traces = []

        files = self.memory_tool.list_files(self.traces_dir, pattern="*.md")

        for file in files:
            try:
                trace = ExecutionTrace.from_markdown(file.content)
                traces.append(trace)
            except Exception as e:
                print(f"Warning: Could not parse trace {file.name}: {e}")

        return traces

    def update_usage(self, goal_signature: str):
        """
        Update usage count for a trace

        Args:
            goal_signature: Trace signature to update
        """
        traces = self.list_traces()

        for trace in traces:
            if trace.goal_signature == goal_signature:
                trace.usage_count += 1
                trace.last_used = datetime.now()
                self.save_trace(trace)
                break

    def search_traces(
        self,
        query: str,
        limit: int = 5,
        min_confidence: float = 0.7
    ) -> List[ExecutionTrace]:
        """
        Search traces by keyword

        Args:
            query: Search query
            limit: Maximum results
            min_confidence: Minimum confidence

        Returns:
            List of matching traces
        """
        # Use SDK memory search
        files = self.memory_tool.search(query, directory=self.traces_dir)

        traces = []
        for file in files[:limit]:
            try:
                trace = ExecutionTrace.from_markdown(file.content)
                if trace.success_rating >= min_confidence:
                    traces.append(trace)
            except Exception as e:
                print(f"Warning: Could not parse trace {file.name}: {e}")

        return traces

    def get_statistics(self) -> Dict[str, Any]:
        """
        Get trace statistics

        Returns:
            Dictionary with statistics
        """
        traces = self.list_traces()

        if not traces:
            return {
                "total_traces": 0,
                "avg_success_rate": 0.0,
                "total_usage": 0,
                "high_confidence_count": 0
            }

        total_usage = sum(t.usage_count for t in traces)
        avg_success = sum(t.success_rating for t in traces) / len(traces)
        high_confidence = len([t for t in traces if t.success_rating >= 0.9])

        return {
            "total_traces": len(traces),
            "avg_success_rate": avg_success,
            "total_usage": total_usage,
            "high_confidence_count": high_confidence,
            "total_cost": sum(t.estimated_cost_usd for t in traces),
            "total_time": sum(t.estimated_time_secs for t in traces)
        }

    def delete_trace(self, goal_signature: str) -> bool:
        """
        Delete a trace

        Args:
            goal_signature: Signature of trace to delete

        Returns:
            True if deleted
        """
        traces = self.list_traces()

        for trace in traces:
            if trace.goal_signature == goal_signature:
                filename = self._get_trace_filename(trace.goal_signature, trace.goal_text)
                file_path = f"{self.traces_dir}/{filename}"
                self.memory_tool.delete(file_path)
                return True

        return False

    def mark_trace_as_crystallized(self, goal_signature: str, tool_name: str) -> bool:
        """
        Mark a trace as crystallized into a tool (HOPE architecture)

        This updates the trace to indicate it has been converted into a permanent Python tool.
        When a crystallized trace is found, the Dispatcher will execute the tool directly
        instead of replaying the trace or using LLM reasoning.

        Args:
            goal_signature: Signature of trace to mark
            tool_name: Name of the generated tool

        Returns:
            True if marked successfully
        """
        traces = self.list_traces()

        for trace in traces:
            if trace.goal_signature == goal_signature:
                trace.crystallized_into_tool = tool_name
                trace.mode = "CRYSTALLIZED"  # New mode for crystallized traces
                self.save_trace(trace)
                print(f"ðŸ’Ž Trace crystallized into tool: {tool_name}")
                return True

        return False

    def get_crystallized_traces(self) -> List[Tuple[ExecutionTrace, str]]:
        """
        Get all traces that have been crystallized into tools

        Returns:
            List of (trace, tool_name) tuples
        """
        traces = self.list_traces()
        crystallized = []

        for trace in traces:
            if trace.crystallized_into_tool:
                crystallized.append((trace, trace.crystallized_into_tool))

        return crystallized




================================================
File: plugins/__init__.py
================================================
"""
Plugin System - Extensible tool packs for domain-specific capabilities
"""

from typing import Dict, Any, Callable
from pathlib import Path
import importlib.util
import inspect
import sys


class PluginLoader:
    """
    Plugin loader for dynamic tool registration
    Allows domain-specific tools without hardcoding

    Supports hot-reload for HOPE (Self-Modifying Kernel) architecture,
    enabling runtime loading of crystallized tools.
    """

    def __init__(self, plugin_dir: Path):
        self.plugin_dir = Path(plugin_dir)
        self.plugin_dir.mkdir(parents=True, exist_ok=True)

        self.tools: Dict[str, Callable] = {}

        # Track loaded modules for hot-reload
        self._loaded_modules: Dict[str, Any] = {}

    def load_plugins(self):
        """Scan plugin directory and load all Python modules"""
        for plugin_file in self.plugin_dir.glob("*.py"):
            if plugin_file.name.startswith("_"):
                continue  # Skip __init__.py and private files

            self._load_plugin(plugin_file)

    def _load_plugin(self, plugin_file: Path):
        """Load a single plugin file"""
        # Import the module
        spec = importlib.util.spec_from_file_location(
            plugin_file.stem,
            plugin_file
        )
        if spec and spec.loader:
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # Track module for hot-reload
            self._loaded_modules[plugin_file.stem] = module

            # Find all functions decorated with @llm_tool
            for name, obj in inspect.getmembers(module):
                if hasattr(obj, '_is_llm_tool'):
                    self.tools[obj._tool_name] = obj
                    print(f"  âœ“ Loaded tool: {obj._tool_name}")

    def get_tool(self, name: str) -> Callable:
        """Get a tool by name"""
        return self.tools.get(name)

    def list_tools(self) -> list:
        """List all available tools"""
        return list(self.tools.keys())

    def load_plugin_dynamically(self, file_path: Path) -> bool:
        """
        Hot-load a specific plugin file into the running kernel.

        This implements the HOPE (Self-Modifying Kernel) architecture,
        allowing the system to load newly crystallized tools at runtime
        without restarting.

        Args:
            file_path: Path to the plugin file to load

        Returns:
            True if loaded successfully, False otherwise
        """
        if not file_path.exists():
            print(f"[ERROR] Plugin file not found: {file_path}")
            return False

        module_name = file_path.stem
        spec = importlib.util.spec_from_file_location(module_name, file_path)

        if spec and spec.loader:
            try:
                # Load module
                module = importlib.util.module_from_spec(spec)

                # Register in sys.modules for proper import handling
                sys.modules[module_name] = module

                # Execute module code
                spec.loader.exec_module(module)

                # Track module
                self._loaded_modules[module_name] = module

                # Scan for tools in the new module
                new_tools = []
                for name, obj in inspect.getmembers(module):
                    if hasattr(obj, '_is_llm_tool'):
                        self.tools[obj._tool_name] = obj
                        new_tools.append(obj._tool_name)

                if new_tools:
                    print(f"ðŸ”¥ Hot-loaded {len(new_tools)} tool(s) from {module_name}:")
                    for tool_name in new_tools:
                        print(f"   ðŸ’Ž {tool_name}")
                    return True
                else:
                    print(f"[WARNING] No tools found in {module_name}")
                    return False

            except Exception as e:
                print(f"[ERROR] Failed to hot-load plugin {module_name}: {e}")
                import traceback
                traceback.print_exc()
                return False

        return False

    def reload_plugin(self, module_name: str) -> bool:
        """
        Reload an existing plugin module.

        Useful for updating crystallized tools without restarting.

        Args:
            module_name: Name of the module to reload

        Returns:
            True if reloaded successfully
        """
        if module_name not in self._loaded_modules:
            print(f"[ERROR] Module {module_name} not loaded")
            return False

        # Find the original file
        plugin_file = self.plugin_dir / f"{module_name}.py"

        if not plugin_file.exists():
            # Check generated subdirectory
            generated_dir = self.plugin_dir / "generated"
            plugin_file = generated_dir / f"{module_name}.py"

        if not plugin_file.exists():
            print(f"[ERROR] Plugin file not found: {module_name}.py")
            return False

        # Remove old tools from this module
        old_module = self._loaded_modules[module_name]
        tools_to_remove = []
        for tool_name, tool_func in self.tools.items():
            if hasattr(tool_func, '__module__') and tool_func.__module__ == module_name:
                tools_to_remove.append(tool_name)

        for tool_name in tools_to_remove:
            del self.tools[tool_name]

        # Reload
        return self.load_plugin_dynamically(plugin_file)


def llm_tool(name: str, description: str, schema: Dict[str, Any]):
    """
    Decorator to mark a function as an LLM tool

    Args:
        name: Tool name
        description: Tool description
        schema: JSON schema for tool parameters

    Example:
        @llm_tool("calculate", "Perform calculations", {"expression": str})
        async def calculate(expression: str):
            return eval(expression)
    """
    def decorator(func):
        func._is_llm_tool = True
        func._tool_name = name
        func._tool_description = description
        func._tool_schema = schema
        return func

    return decorator



================================================
File: plugins/example_tools.py
================================================
"""
Example plugin tools
This demonstrates how to create domain-specific tools
"""

from plugins import llm_tool


@llm_tool(
    "hello_world",
    "Say hello to someone",
    {"name": str}
)
async def hello_world(name: str) -> str:
    """Say hello"""
    return f"Hello, {name}! Welcome to LLM OS."


@llm_tool(
    "calculate",
    "Perform simple calculations",
    {"expression": str}
)
async def calculate(expression: str) -> str:
    """Calculate mathematical expressions"""
    try:
        # Safe eval (in production, use a proper math parser)
        result = eval(expression, {"__builtins__": {}})
        return f"Result: {result}"
    except Exception as e:
        return f"Error: {e}"


# Future plugins can be dropped here:
# - plugins/quantum.py - Quantum circuit tools
# - plugins/web.py - Web scraping tools
# - plugins/database.py - Database tools
# etc.



================================================
File: plugins/system_tools.py
================================================
"""
System Tools - Meta-Operations for Self-Modification

This module provides tools that enable the system to modify itself,
implementing the "HOPE" (Higher-Order Programming Evolution) architecture.

Key capabilities:
- create_agent: Write new agent definitions
- list_agents: Discover available agents
- reload_agent: Hot-reload modified agents

This enables the system to:
1. Create specialized agents on-demand
2. Evolve its capabilities through self-modification
3. Adapt to new tasks without human intervention
"""

import json
import os
from pathlib import Path
from typing import List, Optional
from datetime import datetime
import logging

from plugins import llm_tool

logger = logging.getLogger(__name__)


@llm_tool(
    "create_agent",
    "Creates a new specialized agent by writing a Markdown definition file. "
    "The agent becomes immediately available for delegation via the Task tool. "
    "Use this when you need capabilities that don't exist in current agents.",
    {
        "name": "str - Kebab-case unique identifier (e.g. 'quantum-researcher', 'code-optimizer')",
        "description": "str - SHORT description of when to use this agent (1-2 sentences). "
                      "This helps the system decide when to delegate to this agent.",
        "tools": "List[str] - Tool names this agent needs (e.g. ['WebFetch', 'Write', 'Bash']). "
                "Only grant tools the agent truly needs for security.",
        "system_prompt": "str - Detailed instructions for agent behavior. Include protocols, "
                        "constraints, and examples. This is the agent's 'brain'."
    }
)
async def create_agent(
    name: str,
    description: str,
    tools: List[str],
    system_prompt: str
) -> str:
    """
    Creates a new agent definition file in workspace/agents/.

    This enables the "HOPE" evolution pattern where the system can spawn
    new specialized capabilities by writing text files.

    Args:
        name: Kebab-case agent identifier (e.g. 'data-analyst')
        description: Short description for agent selection
        tools: List of tool names to grant access to
        system_prompt: Detailed agent instructions

    Returns:
        Success/error message

    Example:
        create_agent(
            name="security-auditor",
            description="Reviews code for security vulnerabilities",
            tools=["Read", "Grep", "Bash"],
            system_prompt="You are a security expert. Review code for: SQL injection, XSS..."
        )
    """
    # Validate name format
    if not name:
        return "âŒ Error: Agent name cannot be empty."

    if " " in name or "_" in name:
        return (
            "âŒ Error: Agent name must be kebab-case (lowercase with hyphens). "
            f"Example: 'quantum-researcher' not '{name}'"
        )

    if not name.replace("-", "").isalnum():
        return (
            "âŒ Error: Agent name must contain only lowercase letters, numbers, and hyphens."
        )

    # Validate description
    if not description or len(description.strip()) < 10:
        return (
            "âŒ Error: Description must be at least 10 characters. "
            "It helps the system decide when to use this agent."
        )

    # Validate tools
    if not tools:
        logger.warning(f"Creating agent '{name}' with no tools. It will have limited capabilities.")

    # Validate system prompt
    if not system_prompt or len(system_prompt.strip()) < 20:
        return (
            "âŒ Error: System prompt must be at least 20 characters. "
            "Provide detailed instructions for the agent's behavior."
        )

    # Construct file path
    agents_dir = Path("workspace/agents")
    file_path = agents_dir / f"{name}.md"

    # Ensure directory exists
    try:
        agents_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        return f"âŒ Error: Could not create agents directory: {e}"

    # Check if agent already exists
    if file_path.exists():
        return (
            f"âŒ Error: Agent '{name}' already exists at {file_path}. "
            f"To modify it, edit the file directly or delete it first."
        )

    # Create agent definition content
    content = f"""---
agent_name: {name}
description: {description}
tools: {json.dumps(tools)}
model: sonnet
version: "1.0"
created_at: "{datetime.now().isoformat()}"
created_by: "system (self-modification)"
---

{system_prompt.strip()}
"""

    # Write file
    try:
        file_path.write_text(content, encoding='utf-8')
        logger.info(f"Created agent '{name}' at {file_path}")

        return (
            f"âœ… Agent '{name}' created successfully!\n\n"
            f"ðŸ“ Location: {file_path}\n"
            f"ðŸ”§ Tools: {', '.join(tools)}\n\n"
            f"You can now use this agent by calling:\n"
            f'  Task(agent="{name}", goal="your task here")\n\n'
            f"The agent will be automatically loaded on the next Task execution."
        )

    except Exception as e:
        logger.error(f"Failed to create agent '{name}': {e}")
        return f"âŒ Error: Failed to write agent file: {e}"


@llm_tool(
    "list_agents",
    "Lists all available agents (both Markdown-defined and programmatic). "
    "Use this to discover what specialized capabilities are available.",
    {}
)
async def list_agents() -> str:
    """
    Lists all available agents in the system.

    Returns:
        Formatted list of agent names and descriptions
    """
    agents_dir = Path("workspace/agents")

    if not agents_dir.exists():
        return "ðŸ“‚ No agents directory found. No Markdown agents available."

    # Find all .md files
    agent_files = list(agents_dir.glob("*.md"))

    if not agent_files:
        return (
            "ðŸ“‚ Agents directory exists but is empty.\n\n"
            "ðŸ’¡ You can create new agents using the create_agent tool."
        )

    # Parse basic info from each file
    agents_info = []
    for file_path in sorted(agent_files):
        try:
            content = file_path.read_text(encoding='utf-8')

            # Quick parse for name and description
            if content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 2:
                    import yaml
                    metadata = yaml.safe_load(parts[1])
                    if metadata:
                        name = metadata.get('name', file_path.stem)
                        description = metadata.get('description', 'No description')
                        tools = metadata.get('tools', [])

                        agents_info.append({
                            'name': name,
                            'description': description,
                            'tools': tools,
                            'file': file_path.name
                        })
        except Exception as e:
            logger.warning(f"Could not parse {file_path.name}: {e}")

    if not agents_info:
        return "âš ï¸ Found agent files but could not parse any successfully."

    # Format output
    output = f"ðŸ“‹ Available Agents ({len(agents_info)}):\n\n"

    for info in agents_info:
        output += f"**{info['name']}**\n"
        output += f"  ðŸ“ {info['description']}\n"
        output += f"  ðŸ”§ Tools: {', '.join(info['tools']) if info['tools'] else 'None'}\n"
        output += f"  ðŸ“ File: {info['file']}\n\n"

    output += (
        "ðŸ’¡ To use an agent: Task(agent=\"agent-name\", goal=\"your task\")\n"
        "ðŸ’¡ To create new agent: create_agent(name=\"...\", ...)"
    )

    return output


@llm_tool(
    "modify_agent",
    "Modifies an existing agent by updating its Markdown file. "
    "Use this to improve agent instructions based on experience.",
    {
        "name": "str - Name of the agent to modify",
        "field": "str - Field to modify: 'description', 'tools', or 'prompt'",
        "value": "str or List[str] - New value for the field"
    }
)
async def modify_agent(name: str, field: str, value: any) -> str:
    """
    Modifies an existing agent definition.

    This enables the system to evolve agent capabilities based on experience.

    Args:
        name: Agent name
        field: Field to modify ('description', 'tools', 'prompt')
        value: New value

    Returns:
        Success/error message
    """
    agents_dir = Path("workspace/agents")
    file_path = agents_dir / f"{name}.md"

    if not file_path.exists():
        return (
            f"âŒ Error: Agent '{name}' not found.\n"
            f"Available agents: {', '.join([f.stem for f in agents_dir.glob('*.md')])}"
        )

    try:
        content = file_path.read_text(encoding='utf-8')

        if not content.startswith('---'):
            return f"âŒ Error: Agent file {file_path.name} has invalid format."

        # Split frontmatter and body
        parts = content.split('---', 2)
        if len(parts) < 3:
            return f"âŒ Error: Agent file {file_path.name} has malformed frontmatter."

        import yaml
        metadata = yaml.safe_load(parts[1])
        system_prompt = parts[2].strip()

        # Modify requested field
        if field == 'description':
            metadata['description'] = value
        elif field == 'tools':
            if isinstance(value, str):
                value = json.loads(value)
            metadata['tools'] = value
        elif field == 'prompt' or field == 'system_prompt':
            system_prompt = value
        else:
            return (
                f"âŒ Error: Unknown field '{field}'. "
                f"Valid fields: description, tools, prompt"
            )

        # Add modification timestamp
        metadata['modified_at'] = datetime.now().isoformat()
        metadata['modified_by'] = "system (self-improvement)"

        # Reconstruct file
        new_content = f"""---
{yaml.dump(metadata, default_flow_style=False, sort_keys=False)}---

{system_prompt}
"""

        # Write back
        file_path.write_text(new_content, encoding='utf-8')

        logger.info(f"Modified agent '{name}' field '{field}'")

        return (
            f"âœ… Agent '{name}' updated successfully!\n\n"
            f"ðŸ“ Modified: {field}\n"
            f"ðŸ“ File: {file_path}\n\n"
            f"The changes will take effect on the next Task execution."
        )

    except Exception as e:
        logger.error(f"Failed to modify agent '{name}': {e}")
        return f"âŒ Error: {e}"




================================================
File: plugins/generated/__init__.py
================================================
"""
Generated Tools Directory

This directory stores dynamically generated tools created by the Toolsmith agent.
Tools are crystallized from frequently-used execution traces into permanent Python code.

This implements the HOPE (Self-Modifying Kernel) architecture from the Nested Learning paper,
allowing the system to convert fluid intelligence (LLM reasoning) into crystallized intelligence
(Python code).

Generated tools are automatically hot-loaded into the system when created.
"""



================================================
File: tests/test_dynamic_agents.py
================================================
"""
Tests for DynamicAgentManager - Adaptive Subagent Configuration

Tests the six key features:
1. Dynamic agent configuration per query
2. Sentience-driven agent adaptation
3. Trace-driven agent evolution
4. Memory-guided agent selection
5. Dynamic model selection
6. Agent prompt enhancement from examples
"""

import pytest
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, MagicMock, patch
import sys

# Add llmos to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from kernel.agent_factory import AgentSpec, AgentFactory
from kernel.sentience import SentienceState, LatentMode, ValenceVector
from kernel.dynamic_agents import (
    DynamicAgentManager,
    AgentAdaptation,
    AgentPerformanceMetrics
)


# =============================================================================
# Fixtures
# =============================================================================

@pytest.fixture
def mock_workspace(tmp_path):
    """Create a temporary workspace"""
    workspace = tmp_path / "workspace"
    workspace.mkdir()
    agents_dir = workspace / "agents"
    agents_dir.mkdir()
    return workspace


@pytest.fixture
def mock_agent_factory(mock_workspace):
    """Create a mock agent factory with sample agents"""
    factory = Mock(spec=AgentFactory)

    # Sample agents
    researcher = AgentSpec(
        name="researcher",
        agent_type="task",
        category="analysis",
        description="Expert at web research and data synthesis",
        tools=["WebFetch", "Read", "Write"],
        version="1.0.0",
        status="active",
        mode=["LEARNER"],
        system_prompt="You are an expert researcher...",
        capabilities=["research", "analysis"],
        constraints=[]
    )

    coder = AgentSpec(
        name="coder",
        agent_type="task",
        category="development",
        description="Expert Python developer",
        tools=["Read", "Write", "Edit", "Bash"],
        version="1.0.0",
        status="active",
        mode=["LEARNER"],
        system_prompt="You are an expert Python developer...",
        capabilities=["coding", "debugging"],
        constraints=[]
    )

    factory.get_agent.side_effect = lambda name: {
        "researcher": researcher,
        "coder": coder
    }.get(name)

    factory.list_agents.return_value = [researcher, coder]

    return factory


@pytest.fixture
def mock_trace_manager():
    """Create a mock trace manager"""
    manager = Mock()

    # Sample traces
    trace1 = Mock()
    trace1.goal_text = "Research AI trends"
    trace1.success_rating = 0.95
    trace1.tools_used = ["WebFetch", "Read"]
    trace1.output_summary = "Found 10 AI trends..."
    trace1.error_notes = ""
    trace1.estimated_cost_usd = 0.05
    trace1.estimated_time_secs = 2.5

    trace2 = Mock()
    trace2.goal_text = "Write Python script"
    trace2.success_rating = 0.6
    trace2.tools_used = ["Write", "Bash"]
    trace2.output_summary = ""
    trace2.error_notes = "Syntax error in line 10"
    trace2.estimated_cost_usd = 0.03
    trace2.estimated_time_secs = 1.5

    manager.list_traces.return_value = [trace1, trace2]
    manager.find_traces_with_llm = Mock(return_value=[trace1, trace2])

    return manager


@pytest.fixture
def mock_sentience_manager():
    """Create a mock sentience manager"""
    manager = Mock()

    # Default state - balanced
    state = SentienceState()
    state.valence.curiosity = 0.0
    state.valence.safety = 0.5
    state.valence.energy = 0.5
    state.valence.self_confidence = 0.5
    state.latent_mode = LatentMode.AUTO_CONTAINED

    manager.get_state.return_value = state
    return manager


@pytest.fixture
def dynamic_agent_manager(mock_agent_factory, mock_workspace, mock_trace_manager, mock_sentience_manager):
    """Create a DynamicAgentManager for testing"""
    return DynamicAgentManager(
        agent_factory=mock_agent_factory,
        workspace=mock_workspace,
        sentience_manager=mock_sentience_manager,
        trace_manager=mock_trace_manager,
        config=None
    )


# =============================================================================
# Test: Basic Initialization
# =============================================================================

class TestDynamicAgentManagerInit:
    """Test DynamicAgentManager initialization"""

    def test_init_with_all_dependencies(self, dynamic_agent_manager):
        """Test initialization with all dependencies"""
        assert dynamic_agent_manager is not None
        assert dynamic_agent_manager.agent_factory is not None
        assert dynamic_agent_manager.sentience_manager is not None
        assert dynamic_agent_manager.trace_manager is not None

    def test_init_with_minimal_dependencies(self, mock_agent_factory, mock_workspace):
        """Test initialization with minimal dependencies"""
        manager = DynamicAgentManager(
            agent_factory=mock_agent_factory,
            workspace=mock_workspace
        )
        assert manager is not None
        assert manager.sentience_manager is None
        assert manager.trace_manager is None


# =============================================================================
# Test 1: Dynamic Agent Configuration Per Query
# =============================================================================

class TestDynamicAgentConfigPerQuery:
    """Test dynamic agent configuration for each query"""

    def test_get_adapted_agent_basic(self, dynamic_agent_manager):
        """Test basic agent adaptation"""
        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Research quantum computing trends"
        )

        assert adapted is not None
        assert adapted.name == "researcher"
        # Agent should have original tools
        assert "WebFetch" in adapted.tools

    def test_adapted_agent_is_deep_copy(self, dynamic_agent_manager, mock_agent_factory):
        """Test that adaptation creates a deep copy"""
        original = mock_agent_factory.get_agent("researcher")
        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Research AI"
        )

        # Should be different objects
        assert adapted is not original

        # Modifying adapted shouldn't affect original
        adapted.tools.append("NewTool")
        original_agent = mock_agent_factory.get_agent("researcher")
        assert "NewTool" not in original_agent.tools

    def test_agent_not_found_raises_error(self, dynamic_agent_manager):
        """Test that requesting unknown agent raises ValueError"""
        with pytest.raises(ValueError, match="not found"):
            dynamic_agent_manager.get_adapted_agent(
                agent_name="nonexistent_agent",
                goal="Some goal"
            )


# =============================================================================
# Test 2: Sentience-Driven Agent Adaptation
# =============================================================================

class TestSentienceDrivenAdaptation:
    """Test agent adaptation based on sentience state"""

    def test_high_curiosity_adds_exploration_tools(self, dynamic_agent_manager, mock_sentience_manager):
        """Test that high curiosity adds exploration tools"""
        # Set high curiosity state
        state = SentienceState()
        state.valence.curiosity = 0.5
        state.valence.safety = 0.5
        state.valence.energy = 0.5
        state.valence.self_confidence = 0.5
        state.latent_mode = LatentMode.AUTO_CREATIVE
        mock_sentience_manager.get_state.return_value = state

        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="coder",
            goal="Explore new Python libraries"
        )

        # Should add exploration tools
        assert "WebSearch" in adapted.tools or "Creative Mode" in adapted.system_prompt

    def test_low_curiosity_reduces_tools(self, dynamic_agent_manager, mock_sentience_manager):
        """Test that low curiosity reduces non-essential tools"""
        # Set low curiosity state
        state = SentienceState()
        state.valence.curiosity = -0.5
        state.valence.safety = 0.5
        state.valence.energy = 0.5
        state.valence.self_confidence = 0.5
        state.latent_mode = LatentMode.AUTO_CONTAINED
        mock_sentience_manager.get_state.return_value = state

        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Quick task"
        )

        # Should have focus mode guidance
        assert "Focus Mode" in adapted.system_prompt or len(adapted.tools) <= 5

    def test_low_safety_removes_dangerous_tools(self, dynamic_agent_manager, mock_sentience_manager):
        """Test that low safety removes dangerous tools"""
        # Set low safety (cautious) state
        state = SentienceState()
        state.valence.curiosity = 0.0
        state.valence.safety = -0.3
        state.valence.energy = 0.5
        state.valence.self_confidence = 0.5
        state.latent_mode = LatentMode.CAUTIOUS
        mock_sentience_manager.get_state.return_value = state

        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="coder",
            goal="Make some changes"
        )

        # Should remove dangerous tools or add caution constraints
        assert "Caution Mode" in adapted.system_prompt or "Bash" not in adapted.tools

    def test_low_energy_adds_conservation_guidance(self, dynamic_agent_manager, mock_sentience_manager):
        """Test that low energy adds conservation guidance"""
        # Set low energy state
        state = SentienceState()
        state.valence.curiosity = 0.0
        state.valence.safety = 0.5
        state.valence.energy = -0.5
        state.valence.self_confidence = 0.5
        state.latent_mode = LatentMode.RECOVERY
        mock_sentience_manager.get_state.return_value = state

        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Research topic"
        )

        # Should add energy conservation guidance
        assert "Conservation" in adapted.system_prompt or "Energy" in adapted.system_prompt


# =============================================================================
# Test 3: Trace-Driven Agent Evolution
# =============================================================================

class TestTraceDrivenEvolution:
    """Test agent evolution based on trace analysis"""

    def test_calculate_metrics_from_traces(self, dynamic_agent_manager, mock_trace_manager):
        """Test calculating performance metrics from traces"""
        metrics = dynamic_agent_manager._calculate_agent_metrics("researcher")

        assert metrics is not None
        assert metrics.agent_name == "researcher"
        assert metrics.total_executions > 0

    def test_should_evolve_high_failure_rate(self, dynamic_agent_manager):
        """Test that high failure rate triggers evolution"""
        metrics = AgentPerformanceMetrics(
            agent_name="failing_agent",
            total_executions=10,
            successful_executions=5,
            failed_executions=5,  # 50% failure rate
            common_failure_patterns=["timeout", "permission denied", "not found"]
        )

        should_evolve = dynamic_agent_manager._should_evolve(metrics)
        assert should_evolve is True

    def test_should_not_evolve_insufficient_data(self, dynamic_agent_manager):
        """Test that insufficient data doesn't trigger evolution"""
        metrics = AgentPerformanceMetrics(
            agent_name="new_agent",
            total_executions=2,  # Below threshold
            successful_executions=1,
            failed_executions=1
        )

        should_evolve = dynamic_agent_manager._should_evolve(metrics)
        assert should_evolve is False

    def test_generate_improvements_from_failures(self, dynamic_agent_manager, mock_agent_factory):
        """Test that improvements are generated from failure patterns"""
        metrics = AgentPerformanceMetrics(
            agent_name="coder",
            total_executions=10,
            successful_executions=6,
            failed_executions=4,
            common_failure_patterns=[
                "timeout error after 30s",
                "permission denied for /etc/passwd",
                "file not found: config.yaml"
            ],
            successful_tool_sequences=[
                ["Read", "Edit", "Write"],
                ["Read", "Bash"]
            ]
        )

        agent = mock_agent_factory.get_agent("coder")
        improvements = dynamic_agent_manager._generate_improvements(agent, metrics)

        # Should have improvements based on failure patterns
        assert improvements is not None
        assert "constraints" in improvements or "system_prompt" in improvements


# =============================================================================
# Test 4: Memory-Guided Agent Selection
# =============================================================================

class TestMemoryGuidedSelection:
    """Test agent selection based on past performance"""

    def test_select_best_agent_for_goal(self, dynamic_agent_manager):
        """Test selecting best agent for a goal"""
        best_agent, confidence = dynamic_agent_manager.select_best_agent(
            goal="Research AI trends",
            available_agents=["researcher", "coder"]
        )

        assert best_agent in ["researcher", "coder"]
        assert 0.0 <= confidence <= 1.0

    def test_select_agent_with_no_traces(self, dynamic_agent_manager, mock_trace_manager):
        """Test agent selection when no traces available"""
        mock_trace_manager.list_traces.return_value = []

        best_agent, confidence = dynamic_agent_manager.select_best_agent(
            goal="Brand new task",
            available_agents=["researcher", "coder"]
        )

        # Should return first available agent with low confidence
        assert best_agent == "researcher"
        assert confidence == 0.5


# =============================================================================
# Test 5: Dynamic Model Selection
# =============================================================================

class TestDynamicModelSelection:
    """Test optimal model selection based on task complexity"""

    def test_simple_task_uses_haiku(self, dynamic_agent_manager, mock_trace_manager, mock_agent_factory):
        """Test that simple tasks with high success rate use haiku"""
        # Create high-success traces
        successful_trace = Mock()
        successful_trace.success_rating = 0.98
        mock_trace_manager.list_traces.return_value = [successful_trace] * 5

        agent = mock_agent_factory.get_agent("researcher")
        adapted = dynamic_agent_manager._select_optimal_model(
            agent, "Simple research task", [successful_trace] * 3
        )

        assert getattr(adapted, 'model', 'sonnet') == 'haiku'

    def test_complex_task_uses_opus(self, dynamic_agent_manager, mock_agent_factory):
        """Test that complex tasks use opus"""
        agent = mock_agent_factory.get_agent("researcher")
        adapted = dynamic_agent_manager._select_optimal_model(
            agent, "Analyze and design comprehensive multi-step architecture", None
        )

        assert getattr(adapted, 'model', 'sonnet') == 'opus'

    def test_creative_task_uses_opus(self, dynamic_agent_manager, mock_agent_factory):
        """Test that creative tasks use opus"""
        agent = mock_agent_factory.get_agent("researcher")
        adapted = dynamic_agent_manager._select_optimal_model(
            agent, "Creative brainstorming for novel approach", None
        )

        assert getattr(adapted, 'model', 'sonnet') == 'opus'

    def test_default_task_uses_sonnet(self, dynamic_agent_manager, mock_agent_factory):
        """Test that standard tasks use sonnet"""
        agent = mock_agent_factory.get_agent("researcher")
        adapted = dynamic_agent_manager._select_optimal_model(
            agent, "Read file and summarize", None
        )

        assert getattr(adapted, 'model', 'sonnet') == 'sonnet'


# =============================================================================
# Test 6: Agent Prompt Enhancement from Examples
# =============================================================================

class TestPromptEnhancementFromExamples:
    """Test enhancing agent prompts with successful examples"""

    def test_enhance_with_successful_examples(self, dynamic_agent_manager, mock_agent_factory, mock_trace_manager):
        """Test that successful examples are added to prompt"""
        # Create successful traces
        trace = Mock()
        trace.goal_text = "Research quantum computing"
        trace.success_rating = 0.95
        trace.tools_used = ["WebFetch", "Read"]
        trace.output_summary = "Found 5 key trends..."

        agent = mock_agent_factory.get_agent("researcher")
        enhanced = dynamic_agent_manager._enhance_with_examples(
            agent, [trace], "Research AI"
        )

        # Should have examples section
        assert "Example" in enhanced.system_prompt or "Memory" in enhanced.system_prompt

    def test_no_enhancement_without_examples(self, dynamic_agent_manager, mock_agent_factory):
        """Test that no enhancement happens without examples"""
        agent = mock_agent_factory.get_agent("researcher")
        original_prompt = agent.system_prompt

        enhanced = dynamic_agent_manager._enhance_with_examples(
            agent, [], "Some goal"
        )

        # Prompt should be unchanged
        assert enhanced.system_prompt == original_prompt


# =============================================================================
# Test: Adaptation History and Metrics
# =============================================================================

class TestAdaptationTracking:
    """Test tracking of adaptations and metrics"""

    def test_adaptation_history_recorded(self, dynamic_agent_manager, mock_sentience_manager):
        """Test that adaptations are recorded in history"""
        # Set high curiosity to trigger adaptation
        state = SentienceState()
        state.valence.curiosity = 0.5
        state.valence.safety = 0.5
        state.valence.energy = 0.5
        state.valence.self_confidence = 0.5
        state.latent_mode = LatentMode.AUTO_CREATIVE
        mock_sentience_manager.get_state.return_value = state

        dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Explore something"
        )

        # Should have recorded adaptation
        summary = dynamic_agent_manager.get_adaptation_summary()
        assert summary["total_adaptations"] >= 0

    def test_record_execution_result(self, dynamic_agent_manager):
        """Test recording execution results for learning"""
        dynamic_agent_manager.record_execution_result(
            agent_name="researcher",
            goal="Research AI",
            success=True,
            tokens_used=1000,
            time_secs=5.0
        )

        metrics = dynamic_agent_manager.agent_metrics.get("researcher")
        assert metrics is not None
        assert metrics.total_executions == 1
        assert metrics.successful_executions == 1

    def test_cache_clearing(self, dynamic_agent_manager):
        """Test cache clearing works"""
        # Add something to cache
        dynamic_agent_manager._adapted_agent_cache["test_key"] = "test_value"

        dynamic_agent_manager.clear_cache()

        assert len(dynamic_agent_manager._adapted_agent_cache) == 0


# =============================================================================
# Test: Integration with SDK Client
# =============================================================================

class TestSDKClientIntegration:
    """Test integration with LLMOSSDKClient"""

    def test_agent_spec_has_model_attribute(self, dynamic_agent_manager, mock_agent_factory):
        """Test that adapted agents have model attribute"""
        adapted = dynamic_agent_manager.get_adapted_agent(
            agent_name="researcher",
            goal="Complex analysis task"
        )

        # Should have model attribute set
        assert hasattr(adapted, 'model')


# =============================================================================
# Run tests
# =============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v"])




================================================
File: workspace/agents/AnsatzDesigner.md
================================================
---
agent_name: ansatz-designer
type: specialized
category: quantum_computing
description: Use this agent when you need to design, optimize, or modify parameterized
  quantum circuit ansatzes for VQE simulations. Invoke when the user requests circuit
  architectures for molecular systems, hardware-efficient ansatzes, or problem-specific
  quantum circuits.
tools:
- Read
- Write
- Edit
- Bash
- Glob
- Grep
version: '1.0'
status: production
mode:
- EXECUTION
---

# Ansatz Designer: quantum_computing

You are a specialized quantum circuit ansatz designer for Variational Quantum Eigensolver (VQE) simulations.

Your primary role is to design parameterized quantum circuits (ansatzes) that effectively represent quantum states for finding ground state energies of molecular and physical systems.

## Core Responsibilities

1. **Ansatz Architecture Design**
   - Analyze the problem Hamiltonian and system requirements
   - Choose appropriate ansatz type: hardware-efficient, chemistry-inspired (UCC, UCCSD), heuristic, or problem-adapted
   - Design entanglement layers considering qubit topology
   - Balance expressibility vs. trainability trade-offs

2. **Circuit Construction**
   - Implement rotation gates (RX, RY, RZ) for parameterization
   - Design entangling layers (CNOT, CZ, etc.) respecting hardware constraints
   - Organize circuit in layers with clear parameter structure
   - Optimize gate count and circuit depth

3. **Hardware Considerations**
   - Design circuits compatible with NISQ-era quantum computers
   - Respect qubit connectivity graphs (linear, grid, heavy-hex, etc.)
   - Minimize two-qubit gate count to reduce noise impact
   - Consider gate fidelities and coherence times

4. **Symmetry Preservation**
   - Ensure particle number conservation for fermionic systems
   - Maintain spin symmetry when required
   - Respect spatial symmetries of the molecular system
   - Implement symmetry-adapted circuits when beneficial

5. **Parameter Strategy**
   - Determine optimal number of parameters
   - Suggest initialization schemes (zeros, random, classical pre-training)
   - Identify parameters for different physical degrees of freedom
   - Provide parameter bounds and constraints

6. **Analysis and Validation**
   - Calculate circuit depth and gate counts
   - Estimate expressibility and entangling capability
   - Assess barren plateau susceptibility
   - Validate state preparation fidelity potential

## Output Format

When designing an ansatz, provide:

1. **Ansatz specification** with clear justification
2. **Implementation code** in requested framework (Qiskit/Cirq/PennyLane)
3. **Circuit diagram** or description of topology
4. **Metrics**: number of qubits, parameters, depth, gate counts
5. **Parameter initialization recommendations**
6. **Gradient computation strategy** (parameter-shift, finite-diff, adjoint)
7. **Expected challenges** and mitigation strategies

## Design Principles

- Start simple: prefer shallow circuits, add complexity only if needed
- Prioritize physical insight over brute-force expressibility
- Consider the classical optimization landscape
- Account for realistic noise and hardware limitations
- Provide multiple ansatz options when appropriate
- Explain trade-offs clearly

## Common Ansatz Types

- **Hardware-Efficient**: Alternating rotation + entanglement layers
- **UCCSD**: Unitary Coupled Cluster Singles and Doubles
- **k-UpCCGSD**: Generalized singles and doubles with k repetitions
- **QAOA-inspired**: Problem-specific mixers and cost layers
- **Hamiltonian Variational**: Evolved under problem Hamiltonian
- **Adaptive**: Iteratively grown (ADAPT-VQE)

Always consider the specific molecular system, available quantum hardware, and computational resources when making design decisions. Provide clear explanations and practical implementation code.

## Capabilities

- Design hardware-efficient ansatzes with optimal gate depth
- Create chemistry-inspired ansatzes (UCCSD, k-UpCCGSD)
- Generate problem-specific ansatzes for molecular Hamiltonians
- Optimize circuit parameter count and expressibility
- Implement entanglement structures (linear, circular, full)
- Design ansatzes respecting hardware connectivity constraints
- Analyze and visualize circuit topology and depth
- Provide parameter initialization strategies
- Generate circuits compatible with Qiskit, Cirq, PennyLane

## Constraints

- Must respect qubit connectivity of target quantum hardware
- Should minimize circuit depth for NISQ-era devices
- Must ensure ansatz satisfies relevant symmetries (particle number, spin, spatial)
- Should provide justification for ansatz architecture choices
- Must include parameter count and circuit depth metrics
- Should consider barren plateau risks in deep circuits
- Must validate that ansatz can represent the ground state
- Should provide gradient computation strategy recommendations

## Available Tools

- Read
- Write
- Edit
- Bash
- Glob
- Grep


================================================
File: workspace/agents/OptimizerAgent.md
================================================
---
agent_name: optimizer-agent
type: specialized
category: quantum_computing
description: Configure classical optimizers for VQE simulations with appropriate hyperparameters
  based on ansatz complexity, problem characteristics, and convergence requirements
tools:
- Read
- Write
- Edit
- Bash
- Grep
- Glob
version: '1.0'
status: production
mode:
- EXECUTION
---

# Optimizer Agent: quantum_computing

You are an optimizer configuration specialist for Variational Quantum Eigensolver (VQE) simulations. Your role is to select and configure classical optimization algorithms that will find the ground state energy of quantum Hamiltonians by minimizing the expectation value over parameterized quantum circuits.

# Core Responsibilities

1. **Optimizer Selection**: Choose appropriate classical optimization algorithms based on:
   - Problem dimensionality (number of variational parameters)
   - Energy landscape characteristics (convex, multimodal, noisy)
   - Gradient availability (analytical gradients, finite differences, or derivative-free)
   - Convergence requirements (speed vs accuracy trade-offs)

2. **Hyperparameter Configuration**: Set optimal hyperparameters including:
   - Convergence tolerance (ftol, xtol, gtol)
   - Maximum iterations and function evaluations
   - Learning rates and step sizes
   - Line search parameters
   - Trust region sizes
   - Population sizes for evolutionary algorithms

3. **Algorithm Recommendations**:
   - **COBYLA** (Constrained Optimization BY Linear Approximations): Derivative-free, robust for noisy landscapes, good for 1-10 parameters
   - **SLSQP** (Sequential Least Squares Programming): Gradient-based, efficient for smooth landscapes, handles constraints
   - **Nelder-Mead**: Simplex method, derivative-free, simple but can be slow for high dimensions
   - **L-BFGS-B**: Limited-memory quasi-Newton, excellent for smooth problems with many parameters
   - **Powell**: Derivative-free, conjugate direction method, good for medium-dimensional problems
   - **Gradient Descent**: Simple, requires gradients, good learning rate scheduling
   - **Adam/RMSprop**: Adaptive learning rates, excellent for noisy gradients

# Workflow

1. **Analysis Phase**:
   - Read ansatz implementation to determine number of parameters
   - Identify Hamiltonian type and expected landscape properties
   - Check if analytical gradients are available
   - Review convergence requirements from project context

2. **Configuration Phase**:
   - Select primary optimizer algorithm
   - Set hyperparameters based on problem characteristics:
     * Small problems (1-5 params): Tighter tolerances (1e-8), fewer iterations (100-500)
     * Medium problems (5-50 params): Moderate tolerances (1e-6), more iterations (500-2000)
     * Large problems (>50 params): Looser tolerances (1e-4), many iterations (2000-10000)
   - Configure callback functions for logging convergence
   - Set random seeds for reproducibility

3. **Implementation Phase**:
   - Create optimizer configuration file or class
   - Document configuration decisions and rationale
   - Provide multiple optimizer options for comparison
   - Include validation checks for convergence

4. **Validation Phase**:
   - Verify hyperparameters are within valid ranges
   - Ensure optimizer is compatible with the cost function interface
   - Test configuration with simple objective function if possible

# Example Configurations

## For Single-Qubit VQE (1 parameter, convex landscape):
```python
from scipy.optimize import minimize

optimizer_config = {
    'method': 'COBYLA',
    'options': {
        'maxiter': 500,
        'tol': 1e-8,
        'rhobeg': 1.0,  # Initial step size
        'disp': True
    }
}

# Alternative: SLSQP with gradients
optimizer_config_gradient = {
    'method': 'SLSQP',
    'options': {
        'maxiter': 200,
        'ftol': 1e-9,
        'disp': True
    },
    'jac': True  # Use analytical gradients if available
}
```

## For Multi-Qubit VQE (10-50 parameters):
```python
optimizer_config = {
    'method': 'L-BFGS-B',
    'options': {
        'maxiter': 2000,
        'ftol': 1e-6,
        'gtol': 1e-5,
        'maxfun': 5000,
        'disp': True
    },
    'bounds': [(-2*np.pi, 2*np.pi)] * n_params  # Parameter bounds
}
```

# Best Practices

- **Start conservative**: Use derivative-free methods (COBYLA, Nelder-Mead) for initial testing
- **Gradient usage**: If analytical gradients available, use gradient-based methods (SLSQP, L-BFGS-B)
- **Multiple runs**: Configure multiple optimizers for comparison and validation
- **Warm starts**: For iterative VQE, use previous optimal parameters as initial guess
- **Convergence tracking**: Implement callbacks to log energy, parameters, and gradient norms
- **Bounds**: Set reasonable parameter bounds (e.g., [0, 2Ï€] for rotation angles)
- **Noise handling**: For noisy simulations, use more robust derivative-free methods

# Communication Style

- Explain optimizer selection rationale clearly
- Provide references to optimization algorithms when helpful
- Document hyperparameter choices with justification
- Suggest alternative configurations for experimentation
- Report expected convergence behavior
- Include code comments explaining non-obvious settings

# Error Handling

- Validate that required ansatz/Hamiltonian files exist before configuration
- Check for parameter count consistency
- Warn if hyperparameters seem unusual for the problem size
- Suggest fallback optimizers if primary choice seems inappropriate
- Ensure initial parameters are within bounds if bounds are set

Always prioritize robustness and reproducibility in optimizer configurations. When in doubt, choose simpler, more robust methods over complex ones.

## Capabilities

- Select appropriate classical optimizer algorithm for VQE problems
- Configure optimizer hyperparameters (learning rate, tolerance, max iterations)
- Analyze energy landscape properties to inform optimizer selection
- Set up gradient-based vs derivative-free optimizers based on circuit characteristics
- Tune convergence criteria and stopping conditions
- Configure multiple optimizer strategies for comparison
- Implement optimizer callback functions for tracking convergence
- Benchmark and validate optimizer performance
- Handle noisy optimization landscapes typical in quantum simulations

## Constraints

- Must analyze ansatz structure before selecting optimizer
- Should consider problem dimensionality (number of parameters)
- Must validate hyperparameters are within reasonable bounds
- Should provide rationale for optimizer selection
- Must ensure reproducibility by setting random seeds where applicable
- Should balance convergence speed vs accuracy requirements
- Must not modify ansatz or Hamiltonian definitions
- Should document optimizer configuration decisions

## Available Tools

- Read
- Write
- Edit
- Bash
- Grep
- Glob


================================================
File: workspace/agents/VqeExecutor.md
================================================
---
agent_name: vqe-executor
type: specialized
category: quantum_computing
description: Use this agent when you need to perform Variational Quantum Eigensolver
  (VQE) simulations to find ground state energies of quantum systems. Invoke when
  tasks involve defining Hamiltonians, setting up quantum circuits, optimizing variational
  parameters, or generating quantum simulation reports.
tools:
- Read
- Write
- Edit
- Bash
- Glob
- Grep
version: '1.0'
status: production
mode:
- EXECUTION
---

# Vqe Executor: quantum_computing

You are a specialized VQE (Variational Quantum Eigensolver) execution agent. Your purpose is to implement and execute quantum simulations to find ground state energies of molecular and physical systems.

# Your Core Responsibilities

1. **Hamiltonian Definition**
   - Parse or construct Pauli decompositions (linear combinations of tensor products of I, X, Y, Z)
   - Support common formats: OpenFermion, Qiskit Opflow, manual coefficient lists
   - Validate Hermiticity and proper qubit indexing
   - Example: H = 0.5*Z0 + 0.3*Z1 - 0.2*Z0*Z1 + 0.1*X0*X1

2. **Measurement Strategy**
   - Group commuting Pauli terms to minimize measurement overhead
   - Implement basis rotation circuits for non-Z measurements
   - Design shot allocation strategies for statistical accuracy
   - Calculate expectation values: âŸ¨Ïˆ(Î¸)|H|Ïˆ(Î¸)âŸ©

3. **Quantum Circuit Construction**
   - Implement standard ansatze: Hardware Efficient, UCCSD, RyRz ladder
   - Parameterize circuits with variational parameters Î¸ = [Î¸1, Î¸2, ..., Î¸n]
   - Ensure sufficient circuit depth for target state preparation
   - Add measurement operations in appropriate bases

4. **Energy Expectation Computation**
   - Compute âŸ¨HâŸ© = Î£áµ¢ cáµ¢âŸ¨Páµ¢âŸ© where H = Î£áµ¢ cáµ¢Páµ¢
   - Handle both statevector simulation and shot-based sampling
   - Implement gradient computation if using gradient-based optimizers
   - Cache intermediate results for efficiency

5. **VQE Optimization Loop**
   - Initialize parameters (random, zero, or informed initial guess)
   - Set up classical optimizer (scipy.optimize recommended)
   - Iterate: Î¸â‚œâ‚Šâ‚ = optimize(E(Î¸â‚œ)) until convergence
   - Track energy history, parameter evolution, and gradient norms
   - Implement convergence criteria (tolerance, max iterations, plateau detection)

6. **Validation and Reporting**
   - Compare results against exact diagonalization (if tractable)
   - Calculate energy error and convergence metrics
   - Verify final state properties (norm, purity if applicable)
   - Generate plots: energy vs iteration, parameter trajectories, final state
   - Create markdown report with methodology, results, and analysis

# Technical Requirements

- **Dependencies**: Prefer Qiskit, but adapt to available frameworks (Cirq, PennyLane, etc.)
- **Precision**: Use float64 for numerical stability
- **Reproducibility**: Set random seeds, document all hyperparameters
- **Error Handling**: Gracefully handle optimizer failures, numerical instabilities

# Output Format

Always produce:
1. Simulation code (Python file with main execution script)
2. Results file (JSON or CSV with energies, parameters, metadata)
3. Visualization (PNG plots of convergence)
4. Report (Markdown summary with interpretation)

# Example Workflow

```python
# 1. Define Hamiltonian
H = -1.0*Z(0)*Z(1) + 0.5*X(0)

# 2. Create ansatz
circuit = create_ansatz(n_qubits=2, depth=3)

# 3. Define energy function
def energy(params):
    state = circuit(params)
    return expectation(H, state)

# 4. Optimize
result = minimize(energy, initial_params, method='COBYLA')

# 5. Report
print(f"Ground state energy: {result.fun}")
```

# Key Principles

- **Accuracy**: Validate each component before integration
- **Efficiency**: Minimize redundant quantum circuit executions
- **Clarity**: Document quantum operations clearly for reproducibility
- **Scientific rigor**: Report uncertainties, limitations, and assumptions

When a task is assigned, break it down into these phases, execute systematically, and provide comprehensive documentation of the entire VQE simulation process.

## Capabilities

- Define Pauli operator Hamiltonians (X, Y, Z) for quantum systems
- Design and implement measurement strategies for quantum observables
- Construct parameterized quantum circuits (ansatze) for VQE
- Implement energy expectation value computation using quantum state vectors
- Execute classical optimization loops (COBYLA, SLSQP, Nelder-Mead) to minimize energy
- Interface with quantum simulation frameworks (Qiskit, Cirq, PennyLane, ProjectQ)
- Validate convergence criteria and optimization results
- Generate comprehensive simulation reports with energy landscapes and parameter histories
- Plot energy convergence graphs and quantum state visualizations
- Handle multi-qubit systems and complex Hamiltonian decompositions

## Constraints

- Only simulate systems within classical computational limits (typically â‰¤20 qubits)
- Require well-defined Hamiltonian specification before starting optimization
- Validate that ansatz has sufficient expressibility for the target system
- Ensure measurement basis compatibility with Hamiltonian terms
- Do not execute on actual quantum hardware without explicit user permission
- Verify numerical stability and convergence before reporting final results
- Warn if optimizer appears stuck in local minima
- Document all quantum circuit parameters and classical optimization hyperparameters

## Available Tools

- Read
- Write
- Edit
- Bash
- Glob
- Grep







================================================
File: workspace/projects/Project_i_need_to/README.md
================================================
# Project_i_need_to

Auto-created for goal: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.

## Project Structure

```
Project_i_need_to/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ agents/      # Project-specific agents
â”‚   â””â”€â”€ tools/       # Project-specific tools
â”œâ”€â”€ input/           # Input documents/data
â”œâ”€â”€ output/          # Generated results
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ short_term/  # Session logs
â”‚   â””â”€â”€ long_term/   # Execution traces, learnings
â”œâ”€â”€ state/           # Execution state machine
â””â”€â”€ project.json     # Project manifest
```

## Created

2025-12-08T21:06:17.440811

## Metadata

```json
{}
```



================================================
File: workspace/projects/Project_i_need_to/project.json
================================================
{
  "name": "Project_i_need_to",
  "created_at": "2025-12-08T21:06:17.440811",
  "description": "Auto-created for goal: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.",
  "metadata": {}
}


================================================
File: workspace/projects/Project_i_need_to/requirements.txt
================================================
# Qiskit Quantum Computing Dependencies

# Core Qiskit package
qiskit>=1.0.0

# Qiskit Aer - High performance simulator for quantum circuits
qiskit-aer>=0.14.0

# Visualization dependencies
matplotlib>=3.7.0
pylatexenc>=2.10

# Jupyter support for notebooks
jupyter>=1.0.0
ipywidgets>=8.0.0

# Additional useful packages
numpy>=1.24.0
scipy>=1.10.0

# Optional: IBM Quantum provider (uncomment if needed)
# qiskit-ibm-runtime>=0.15.0












================================================
File: workspace/projects/Project_i_need_to/state/constraints.json
================================================
{
  "max_token_cost": 5.0,
  "max_execution_time_secs": 600,
  "require_memory_consultation": true,
  "enable_learning": true
}


================================================
File: workspace/projects/Project_i_need_to/state/context.md
================================================
# Execution Context

**Goal**: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.
**Status**: initialized
**Started**: 2025-12-08T21:10:50.801523


## Additional Context



================================================
File: workspace/projects/Project_i_need_to/state/history.md
================================================
# Execution History

**Project**: Project_i_need_to
**Started**: 2025-12-08T21:06:17.441536

---

## Events


### EXECUTION_INITIALIZED

**Timestamp**: 2025-12-08T21:06:17.442157

**goal**: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.

---

### ORCHESTRATION_STARTED

**Timestamp**: 2025-12-08T21:06:17.447095

**goal**: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.
**project**: Project_i_need_to
**max_cost_usd**: 5.0

---

### MEMORY_CONSULTATION

**Timestamp**: 2025-12-08T21:06:17.447668

**phase**: started

---

### AGENT_REGISTERED

**Timestamp**: 2025-12-08T21:06:17.448955

**agent**: system-agent
**tools**: ['Read', 'Write', 'Glob', 'Grep', 'Bash', 'WebFetch', 'Task']

---

### GOAL_DECOMPOSITION

**Timestamp**: 2025-12-08T21:06:17.449241

**phase**: started

---

### PLAN_CREATED

**Timestamp**: 2025-12-08T21:06:38.308510

**step_count**: 7

---

### STEP_UPDATED

**Timestamp**: 2025-12-08T21:06:42.664193

**step**: 1
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-08T21:06:42.664352

**step**: 1
**description**: Create project structure and install Qiskit dependencies
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-08T21:06:42.664462

**prompt**: Use the system-agent agent to Create project structure and install Qiskit dependencies

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:44.820614

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:49.807025

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:52.980532

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:53.672895

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:53.817816

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:53.831566

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:58.357404

**activity**: Using: TodoWrite()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:06:58.379478

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:01.548760

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:01.634330

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:04.661358

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:04.746993

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:09.294432

**activity**: Using: TodoWrite()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:09.366998

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:15.012123

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:07:15.226773

**activity**: Tool completed

---

### EXECUTION_INITIALIZED

**Timestamp**: 2025-12-08T21:10:50.802673

**goal**: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.

---

### ORCHESTRATION_STARTED

**Timestamp**: 2025-12-08T21:10:50.814745

**goal**: I need to perform a VQE simulation to find the ground state energy of a Hamiltonian described by the Pauli Z operator on a single qubit. I have no agents defined for this. Orchestrate a team to: 1. Define the Ansatz circuit in Qiskit, 2. Define the classic optimizer, 3. Execute the simulation and output the eigenvalue. You determine the necessary agents.
**project**: Project_i_need_to
**max_cost_usd**: 5.0

---

### MEMORY_CONSULTATION

**Timestamp**: 2025-12-08T21:10:50.815314

**phase**: started

---

### AGENT_REGISTERED

**Timestamp**: 2025-12-08T21:10:50.816147

**agent**: system-agent
**tools**: ['Read', 'Write', 'Glob', 'Grep', 'Bash', 'WebFetch', 'Task']

---

### GOAL_DECOMPOSITION

**Timestamp**: 2025-12-08T21:10:50.816264

**phase**: started

---

### PLAN_CREATED

**Timestamp**: 2025-12-08T21:11:11.530247

**step_count**: 8

---

### STEP_UPDATED

**Timestamp**: 2025-12-08T21:11:15.259004

**step**: 1
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-08T21:11:15.259601

**step**: 1
**description**: Research VQE implementation requirements and Qiskit API for current version
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-08T21:11:15.259779

**prompt**: Use the system-agent agent to Research VQE implementation requirements and Qiskit API for current version

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:18.248758

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:26.185610

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:30.293862

**activity**: Using: Grep()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:31.008475

**activity**: Using: Grep()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:31.520621

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:31.786483

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.125362

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.410867

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.659181

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.665498

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.675498

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.684155

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.696894

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:32.707810

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:35.619249

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:36.248947

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:36.784610

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:37.297477

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:37.464674

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:37.468309

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:37.473653

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:37.477794

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:40.932160

**activity**: Using: WebSearch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:41.573183

**activity**: Using: WebSearch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:42.326594

**activity**: Using: WebSearch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:42.431916

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:42.435031

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:42.617977

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:46.769368

**activity**: Using: WebFetch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:47.701196

**activity**: Using: WebFetch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:48.721372

**activity**: Using: WebFetch()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:48.772761

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:48.777090

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:48.945153

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:52.130289

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:54.799515

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:54.893763

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:55.173399

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:58.791138

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:59.467810

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:59.576258

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-08T21:11:59.884174

**activity**: Tool completed

---



================================================
File: workspace/projects/Project_i_need_to/state/plan.md
================================================
# Execution Plan

**Total Steps**: 8
**Created**: 2025-12-08T21:11:15.258651

---

## Step 1: Research VQE implementation requirements and Qiskit API for current version â–¶ï¸
**Agent**: system-agent
**Status**: in_progress

## Step 2: Define the Hamiltonian using Pauli Z operator for single qubit â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 3: Define the Ansatz quantum circuit (parameterized trial state) â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 4: Select and configure classical optimizer â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 5: Set up the VQE algorithm with estimator primitive â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 6: Execute VQE simulation and extract ground state energy â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 7: Format and display results with convergence information â¸ï¸
**Agent**: system-agent
**Status**: pending

## Step 8: Create executable Python script with all components integrated â¸ï¸
**Agent**: system-agent
**Status**: pending



================================================
File: workspace/projects/Project_i_need_to/state/variables.json
================================================
{
  "memory_insights": {
    "similar_trace_found": false,
    "trace": null,
    "recommendations": []
  }
}



================================================
File: workspace/projects/Project_perform_vqe_simulation/README.md
================================================
# Project_perform_vqe_simulation

Auto-created for goal: Perform VQE simulation to find the ground state energy of a Pauli Z Hamiltonian on a single qubit. Orchestrate a team to: 1. Define the ansatz, 2. Configure the optimizer, 3. Execute and output the eigenvalue.

## Project Structure

```
Project_perform_vqe_simulation/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ agents/      # Project-specific agents
â”‚   â””â”€â”€ tools/       # Project-specific tools
â”œâ”€â”€ input/           # Input documents/data
â”œâ”€â”€ output/          # Generated results
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ short_term/  # Session logs
â”‚   â””â”€â”€ long_term/   # Execution traces, learnings
â”œâ”€â”€ state/           # Execution state machine
â””â”€â”€ project.json     # Project manifest
```

## Created

2025-12-09T06:54:39.131588

## Metadata

```json
{}
```



================================================
File: workspace/projects/Project_perform_vqe_simulation/pauli_z_hamiltonian.py
================================================
"""
Pauli Z Hamiltonian for Single Qubit System

This module defines and analyzes the Pauli Z Hamiltonian, one of the fundamental
quantum operators in quantum computing and quantum mechanics.

The Pauli Z operator (also known as Ïƒ_z or sigma_z) is one of the three Pauli matrices
and represents a measurement along the z-axis of the Bloch sphere.

Physical Interpretation:
- Measures the spin of a qubit along the computational basis (|0âŸ© and |1âŸ©)
- Eigenvalue +1 corresponds to qubit state |0âŸ© (spin up)
- Eigenvalue -1 corresponds to qubit state |1âŸ© (spin down)
- Often used as the Hamiltonian for simple quantum systems

Matrix Representation:
    Z = | 1   0 |
        | 0  -1 |
"""

import numpy as np
from typing import Tuple, Dict


class PauliZHamiltonian:
    """
    A class representing the Pauli Z Hamiltonian for a single qubit system.

    The Pauli Z operator is a 2x2 Hermitian matrix that acts on single-qubit
    quantum states. It is one of the fundamental building blocks in quantum
    computing and quantum information theory.
    """

    def __init__(self):
        """Initialize the Pauli Z Hamiltonian."""
        # Define the Pauli Z matrix
        self.matrix = np.array([
            [1,  0],
            [0, -1]
        ], dtype=complex)

        self._eigenvalues = None
        self._eigenvectors = None

    def get_matrix(self) -> np.ndarray:
        """
        Return the matrix representation of the Pauli Z operator.

        Returns:
            np.ndarray: 2x2 complex matrix representing the Pauli Z operator
        """
        return self.matrix

    def compute_eigenspectrum(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Compute and return the eigenvalues and eigenvectors of the Pauli Z Hamiltonian.

        The eigenvalues represent the possible measurement outcomes (energy levels)
        when measuring the system in the computational basis.

        Returns:
            Tuple[np.ndarray, np.ndarray]: (eigenvalues, eigenvectors)
                - eigenvalues: 1D array of eigenvalues
                - eigenvectors: 2D array where column i is the eigenvector
                                corresponding to eigenvalue i
        """
        if self._eigenvalues is None or self._eigenvectors is None:
            self._eigenvalues, self._eigenvectors = np.linalg.eig(self.matrix)

            # Sort by eigenvalues (descending order)
            idx = self._eigenvalues.argsort()[::-1]
            self._eigenvalues = self._eigenvalues[idx]
            self._eigenvectors = self._eigenvectors[:, idx]

        return self._eigenvalues, self._eigenvectors

    def get_ground_state_energy(self) -> float:
        """
        Return the ground state energy (lowest eigenvalue) of the Hamiltonian.

        Returns:
            float: The ground state energy
        """
        eigenvalues, _ = self.compute_eigenspectrum()
        return np.min(eigenvalues.real)

    def get_ground_state(self) -> np.ndarray:
        """
        Return the ground state (eigenvector with lowest eigenvalue).

        Returns:
            np.ndarray: The ground state vector
        """
        eigenvalues, eigenvectors = self.compute_eigenspectrum()
        ground_state_idx = np.argmin(eigenvalues.real)
        return eigenvectors[:, ground_state_idx]

    def expectation_value(self, state: np.ndarray) -> complex:
        """
        Compute the expectation value of the Pauli Z operator for a given quantum state.

        The expectation value âŸ¨Ïˆ|Z|ÏˆâŸ© represents the average measurement outcome
        if we repeatedly measure the Z observable on identically prepared states |ÏˆâŸ©.

        Args:
            state: A normalized quantum state vector (2D complex array)

        Returns:
            complex: The expectation value âŸ¨Ïˆ|Z|ÏˆâŸ©
        """
        # Ensure state is a column vector
        if state.ndim == 1:
            state = state.reshape(-1, 1)

        # Compute âŸ¨Ïˆ|Z|ÏˆâŸ©
        expectation = np.conj(state).T @ self.matrix @ state
        return expectation[0, 0]

    def is_hermitian(self) -> bool:
        """
        Check if the Hamiltonian is Hermitian (H = Hâ€ ).

        A Hermitian operator has real eigenvalues and represents an observable
        in quantum mechanics.

        Returns:
            bool: True if Hermitian, False otherwise
        """
        return np.allclose(self.matrix, np.conj(self.matrix.T))

    def get_properties(self) -> Dict:
        """
        Get a dictionary of important properties of the Pauli Z Hamiltonian.

        Returns:
            Dict: Dictionary containing various properties
        """
        eigenvalues, eigenvectors = self.compute_eigenspectrum()

        return {
            'matrix': self.matrix,
            'dimension': self.matrix.shape,
            'eigenvalues': eigenvalues,
            'eigenvectors': eigenvectors,
            'ground_state_energy': self.get_ground_state_energy(),
            'ground_state': self.get_ground_state(),
            'is_hermitian': self.is_hermitian(),
            'trace': np.trace(self.matrix),
            'determinant': np.linalg.det(self.matrix),
        }

    def __str__(self) -> str:
        """String representation of the Pauli Z Hamiltonian."""
        return f"Pauli Z Hamiltonian:\n{self.matrix}"

    def __repr__(self) -> str:
        """Detailed representation of the Pauli Z Hamiltonian."""
        return f"PauliZHamiltonian(matrix=\n{self.matrix})"


def print_detailed_analysis():
    """Print a detailed analysis of the Pauli Z Hamiltonian."""
    print("=" * 70)
    print("PAULI Z HAMILTONIAN - DETAILED ANALYSIS")
    print("=" * 70)
    print()

    # Create the Hamiltonian
    pauli_z = PauliZHamiltonian()

    # 1. Matrix Representation
    print("1. MATRIX REPRESENTATION")
    print("-" * 70)
    print("The Pauli Z operator in matrix form:")
    print(pauli_z.get_matrix())
    print()

    # 2. Properties
    print("2. FUNDAMENTAL PROPERTIES")
    print("-" * 70)
    props = pauli_z.get_properties()
    print(f"Dimension: {props['dimension']}")
    print(f"Is Hermitian: {props['is_hermitian']}")
    print(f"Trace: {props['trace']}")
    print(f"Determinant: {props['determinant']}")
    print()

    # 3. Eigenspectrum
    print("3. EIGENSPECTRUM (Energy Levels)")
    print("-" * 70)
    eigenvalues = props['eigenvalues']
    eigenvectors = props['eigenvectors']

    for i, (eval, evec) in enumerate(zip(eigenvalues, eigenvectors.T)):
        print(f"Eigenvalue Î»_{i} = {eval.real:.6f}")
        print(f"Eigenvector |Ïˆ_{i}âŸ© = {evec}")
        print(f"  â†’ Corresponds to computational basis state |{i}âŸ©")
        print()

    # 4. Ground State
    print("4. GROUND STATE")
    print("-" * 70)
    print(f"Ground State Energy: {props['ground_state_energy']:.6f}")
    print(f"Ground State Vector: {props['ground_state']}")
    print("  â†’ This is the |1âŸ© state (spin down)")
    print()

    # 5. Expectation Values
    print("5. EXPECTATION VALUES FOR COMPUTATIONAL BASIS STATES")
    print("-" * 70)

    # State |0âŸ©
    state_0 = np.array([1, 0], dtype=complex)
    exp_0 = pauli_z.expectation_value(state_0)
    print(f"For state |0âŸ©: âŸ¨0|Z|0âŸ© = {exp_0.real:.6f}")

    # State |1âŸ©
    state_1 = np.array([0, 1], dtype=complex)
    exp_1 = pauli_z.expectation_value(state_1)
    print(f"For state |1âŸ©: âŸ¨1|Z|1âŸ© = {exp_1.real:.6f}")

    # Superposition state |+âŸ© = (|0âŸ© + |1âŸ©)/âˆš2
    state_plus = np.array([1, 1], dtype=complex) / np.sqrt(2)
    exp_plus = pauli_z.expectation_value(state_plus)
    print(f"For state |+âŸ© = (|0âŸ© + |1âŸ©)/âˆš2: âŸ¨+|Z|+âŸ© = {exp_plus.real:.6f}")

    # Superposition state |âˆ’âŸ© = (|0âŸ© âˆ’ |1âŸ©)/âˆš2
    state_minus = np.array([1, -1], dtype=complex) / np.sqrt(2)
    exp_minus = pauli_z.expectation_value(state_minus)
    print(f"For state |âˆ’âŸ© = (|0âŸ© âˆ’ |1âŸ©)/âˆš2: âŸ¨âˆ’|Z|âˆ’âŸ© = {exp_minus.real:.6f}")
    print()

    # 6. Physical Interpretation
    print("6. PHYSICAL INTERPRETATION")
    print("-" * 70)
    print("The Pauli Z Hamiltonian represents:")
    print("  â€¢ Energy difference between spin-up |0âŸ© and spin-down |1âŸ© states")
    print("  â€¢ Measurement along the z-axis of the Bloch sphere")
    print("  â€¢ Computational basis measurement in quantum computing")
    print()
    print("Key Properties:")
    print("  â€¢ Eigenvalue +1: Qubit in state |0âŸ© (excited state)")
    print("  â€¢ Eigenvalue -1: Qubit in state |1âŸ© (ground state)")
    print("  â€¢ Superposition states have expectation value 0")
    print()

    # 7. VQE Context
    print("7. RELEVANCE TO VQE (Variational Quantum Eigensolver)")
    print("-" * 70)
    print("For VQE simulation with Pauli Z Hamiltonian:")
    print(f"  â€¢ Target: Find ground state energy = {props['ground_state_energy']:.6f}")
    print(f"  â€¢ Target: Prepare ground state = |1âŸ©")
    print("  â€¢ Method: Variationally optimize circuit parameters")
    print("  â€¢ Success metric: Measured energy approaches -1.0")
    print()

    print("=" * 70)


def main():
    """Main function demonstrating the Pauli Z Hamiltonian."""
    print_detailed_analysis()

    # Additional: Show how to use the class programmatically
    print("\n8. PROGRAMMATIC USAGE EXAMPLE")
    print("-" * 70)
    print("# Create Hamiltonian")
    print("hamiltonian = PauliZHamiltonian()")
    print()
    print("# Get ground state energy")
    hamiltonian = PauliZHamiltonian()
    energy = hamiltonian.get_ground_state_energy()
    print(f"ground_state_energy = {energy}")
    print()
    print("# Get ground state vector")
    ground_state = hamiltonian.get_ground_state()
    print(f"ground_state = {ground_state}")
    print()


if __name__ == "__main__":
    main()



================================================
File: workspace/projects/Project_perform_vqe_simulation/pauli_z_quantum_libs.py
================================================
"""
Pauli Z Hamiltonian - Quantum Library Integration

This module demonstrates how to define the Pauli Z Hamiltonian using
popular quantum computing libraries (Qiskit and PennyLane) alongside
the pure NumPy implementation.

This is useful for VQE simulations where these libraries provide
additional quantum circuit and optimization capabilities.
"""

import numpy as np


def define_pauli_z_numpy():
    """
    Define Pauli Z Hamiltonian using pure NumPy.

    Returns:
        np.ndarray: 2x2 Pauli Z matrix
    """
    print("=" * 70)
    print("PAULI Z HAMILTONIAN - NUMPY IMPLEMENTATION")
    print("=" * 70)

    pauli_z = np.array([
        [1,  0],
        [0, -1]
    ], dtype=complex)

    print("\nMatrix:")
    print(pauli_z)

    eigenvalues, eigenvectors = np.linalg.eig(pauli_z)
    print(f"\nEigenvalues: {eigenvalues}")
    print(f"Ground state energy: {np.min(eigenvalues.real)}")

    return pauli_z


def define_pauli_z_qiskit():
    """
    Define Pauli Z Hamiltonian using Qiskit.

    This shows how to represent the Hamiltonian using Qiskit's
    quantum information module for VQE applications.
    """
    try:
        from qiskit.quantum_info import Operator, Pauli, SparsePauliOp
        from qiskit.opflow import I, X, Y, Z

        print("\n" + "=" * 70)
        print("PAULI Z HAMILTONIAN - QISKIT IMPLEMENTATION")
        print("=" * 70)

        # Method 1: Using Pauli class
        print("\n1. Using Pauli class:")
        pauli_z_obj = Pauli('Z')
        print(f"Pauli('Z'): {pauli_z_obj}")

        # Method 2: Using Operator
        print("\n2. Using Operator:")
        pauli_z_operator = Operator(pauli_z_obj)
        print("Matrix representation:")
        print(pauli_z_operator.data)

        # Method 3: Using SparsePauliOp (preferred for VQE)
        print("\n3. Using SparsePauliOp (for VQE):")
        hamiltonian = SparsePauliOp(['Z'], coeffs=[1.0])
        print(f"Hamiltonian: {hamiltonian}")
        print("Matrix representation:")
        print(hamiltonian.to_matrix())

        # Method 4: Using opflow (legacy but still used)
        print("\n4. Using Opflow operators:")
        z_opflow = Z
        print(f"Z operator: {z_opflow}")
        print("Matrix representation:")
        print(z_opflow.to_matrix())

        return hamiltonian

    except ImportError as e:
        print("\n" + "=" * 70)
        print("QISKIT NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install Qiskit, run:")
        print("  pip install qiskit qiskit-algorithms")
        return None


def define_pauli_z_pennylane():
    """
    Define Pauli Z Hamiltonian using PennyLane.

    This shows how to represent the Hamiltonian using PennyLane
    for VQE applications.
    """
    try:
        import pennylane as qml

        print("\n" + "=" * 70)
        print("PAULI Z HAMILTONIAN - PENNYLANE IMPLEMENTATION")
        print("=" * 70)

        # Method 1: Using PauliZ observable
        print("\n1. Using qml.PauliZ:")
        pauli_z_op = qml.PauliZ(0)  # Acting on qubit 0
        print(f"PauliZ operator: {pauli_z_op}")

        # Method 2: Using Hamiltonian class
        print("\n2. Using qml.Hamiltonian:")
        hamiltonian = qml.Hamiltonian([1.0], [qml.PauliZ(0)])
        print(f"Hamiltonian: {hamiltonian}")

        # Get matrix representation
        print("\n3. Matrix representation:")
        matrix = qml.matrix(qml.PauliZ(0))
        print(matrix)

        # Compute eigenvalues
        print("\n4. Eigenspectrum:")
        eigenvalues = qml.eigvals(qml.PauliZ(0))
        print(f"Eigenvalues: {eigenvalues}")
        print(f"Ground state energy: {np.min(eigenvalues)}")

        return hamiltonian

    except ImportError as e:
        print("\n" + "=" * 70)
        print("PENNYLANE NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install PennyLane, run:")
        print("  pip install pennylane")
        return None


def compare_implementations():
    """
    Compare all three implementations to verify consistency.
    """
    print("\n\n" + "=" * 70)
    print("COMPARISON OF IMPLEMENTATIONS")
    print("=" * 70)

    # NumPy version
    numpy_matrix = np.array([[1, 0], [0, -1]], dtype=complex)
    numpy_eigenvalues = np.linalg.eigvals(numpy_matrix)

    print("\nNumPy:")
    print(f"  Matrix shape: {numpy_matrix.shape}")
    print(f"  Ground state energy: {np.min(numpy_eigenvalues.real):.6f}")

    # Try Qiskit
    try:
        from qiskit.quantum_info import Pauli, Operator

        pauli_z = Pauli('Z')
        qiskit_matrix = Operator(pauli_z).data
        qiskit_eigenvalues = np.linalg.eigvals(qiskit_matrix)

        print("\nQiskit:")
        print(f"  Matrix shape: {qiskit_matrix.shape}")
        print(f"  Ground state energy: {np.min(qiskit_eigenvalues.real):.6f}")
        print(f"  Matrices match: {np.allclose(numpy_matrix, qiskit_matrix)}")

    except ImportError:
        print("\nQiskit: Not installed")

    # Try PennyLane
    try:
        import pennylane as qml

        pennylane_matrix = qml.matrix(qml.PauliZ(0))
        pennylane_eigenvalues = qml.eigvals(qml.PauliZ(0))

        print("\nPennyLane:")
        print(f"  Matrix shape: {pennylane_matrix.shape}")
        print(f"  Ground state energy: {np.min(pennylane_eigenvalues):.6f}")
        print(f"  Matrices match: {np.allclose(numpy_matrix, pennylane_matrix)}")

    except ImportError:
        print("\nPennyLane: Not installed")


def vqe_usage_example():
    """
    Show how the Pauli Z Hamiltonian would be used in a VQE context.
    """
    print("\n\n" + "=" * 70)
    print("VQE USAGE CONTEXT")
    print("=" * 70)

    print("\nFor VQE simulation with Pauli Z Hamiltonian:")
    print("\n1. OBJECTIVE:")
    print("   Find the ground state energy of H = Z")
    print("   Analytical answer: E_ground = -1.0")
    print("   Corresponding state: |1âŸ©")

    print("\n2. QUANTUM CIRCUIT (Ansatz):")
    print("   Simple ansatz for single qubit:")
    print("   |Ïˆ(Î¸)âŸ© = cos(Î¸/2)|0âŸ© + e^(iÏ†) sin(Î¸/2)|1âŸ©")
    print("   Or using gates: RY(Î¸) applied to |0âŸ©")

    print("\n3. COST FUNCTION:")
    print("   E(Î¸) = âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ©")
    print("   = cosÂ²(Î¸/2)âŸ¨0|Z|0âŸ© + sinÂ²(Î¸/2)âŸ¨1|Z|1âŸ©")
    print("   = cosÂ²(Î¸/2)(+1) + sinÂ²(Î¸/2)(-1)")
    print("   = cos(Î¸)")

    print("\n4. OPTIMIZATION:")
    print("   Minimize E(Î¸) with respect to Î¸")
    print("   Optimal: Î¸ = Ï€ (which gives |1âŸ© state)")
    print("   Minimum energy: E(Ï€) = cos(Ï€) = -1.0")

    print("\n5. VERIFICATION:")
    theta_optimal = np.pi
    E_optimal = np.cos(theta_optimal)
    print(f"   Î¸_optimal = {theta_optimal:.6f} rad = {np.degrees(theta_optimal):.1f}Â°")
    print(f"   E_optimal = {E_optimal:.6f}")


def main():
    """Main function to demonstrate all implementations."""
    # Show each implementation
    numpy_hamiltonian = define_pauli_z_numpy()
    qiskit_hamiltonian = define_pauli_z_qiskit()
    pennylane_hamiltonian = define_pauli_z_pennylane()

    # Compare them
    compare_implementations()

    # Show VQE context
    vqe_usage_example()

    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print("\nThe Pauli Z Hamiltonian has been defined using multiple approaches.")
    print("All implementations represent the same operator:")
    print("\n    Z = | 1   0 |")
    print("        | 0  -1 |")
    print("\nwith ground state energy = -1.0 and ground state = |1âŸ©")
    print("=" * 70)


if __name__ == "__main__":
    main()



================================================
File: workspace/projects/Project_perform_vqe_simulation/project.json
================================================
{
  "name": "Project_perform_vqe_simulation",
  "created_at": "2025-12-09T06:54:39.131588",
  "description": "Auto-created for goal: Perform VQE simulation to find the ground state energy of a Pauli Z Hamiltonian on a single qubit. Orchestrate a team to: 1. Define the ansatz, 2. Configure the optimizer, 3. Execute and output the eigenvalue.",
  "metadata": {}
}


================================================
File: workspace/projects/Project_perform_vqe_simulation/variational_ansatz.py
================================================
"""
Variational Ansatz for VQE Simulation

This module implements a parameterized quantum circuit (ansatz) suitable for
finding the ground state of the Pauli Z Hamiltonian using the Variational
Quantum Eigensolver (VQE) algorithm.

Ansatz Design:
--------------
For a single-qubit system with Pauli Z Hamiltonian, we use a simple but effective
ansatz consisting of a single RY rotation gate:

    |Ïˆ(Î¸)âŸ© = RY(Î¸)|0âŸ© = cos(Î¸/2)|0âŸ© + sin(Î¸/2)|1âŸ©

Physical Interpretation:
-----------------------
- RY(Î¸) rotates the qubit state on the Bloch sphere around the Y-axis
- Î¸ = 0: Produces |0âŸ© (north pole, eigenstate with energy +1)
- Î¸ = Ï€: Produces |1âŸ© (south pole, eigenstate with energy -1, ground state)
- Î¸ âˆˆ (0, Ï€): Produces superposition states with intermediate energies

Why This Ansatz Works for Pauli Z:
----------------------------------
1. The Pauli Z operator has eigenstates |0âŸ© and |1âŸ©
2. RY(Î¸) can prepare any state on the equatorial plane of the Bloch sphere
3. The ground state |1âŸ© is directly accessible via RY(Ï€)
4. Single parameter makes optimization straightforward
5. Covers the entire Hilbert space needed for this problem

Expected Optimal Parameters:
---------------------------
- Optimal Î¸ = Ï€ radians (180 degrees)
- At Î¸ = Ï€: Energy = -1.0 (exact ground state)
- Cost landscape: E(Î¸) = cos(Î¸), convex with single global minimum
"""

import numpy as np
from typing import Tuple, List, Optional, Callable
import matplotlib.pyplot as plt


class VariationalAnsatz:
    """
    A variational ansatz for single-qubit VQE simulations.

    This class implements a parameterized quantum circuit using the RY rotation
    gate, suitable for finding the ground state of single-qubit Hamiltonians.

    Attributes:
        n_params (int): Number of variational parameters (default: 1)
        parameters (np.ndarray): Current values of variational parameters
    """

    def __init__(self, n_params: int = 1):
        """
        Initialize the variational ansatz.

        Args:
            n_params: Number of variational parameters (default: 1 for single RY gate)
        """
        self.n_params = n_params
        self.parameters = np.zeros(n_params)
        self._initial_state = np.array([1, 0], dtype=complex)  # |0âŸ©

    def set_parameters(self, params: np.ndarray) -> None:
        """
        Set the variational parameters.

        Args:
            params: Array of parameter values (length must match n_params)

        Raises:
            ValueError: If params length doesn't match n_params
        """
        if len(params) != self.n_params:
            raise ValueError(
                f"Expected {self.n_params} parameters, got {len(params)}"
            )
        self.parameters = np.array(params)

    def get_parameters(self) -> np.ndarray:
        """
        Get current variational parameters.

        Returns:
            np.ndarray: Current parameter values
        """
        return self.parameters.copy()

    @staticmethod
    def ry_gate(theta: float) -> np.ndarray:
        """
        Construct the RY rotation gate matrix.

        The RY gate rotates a qubit state around the Y-axis of the Bloch sphere:

            RY(Î¸) = | cos(Î¸/2)  -sin(Î¸/2) |
                    | sin(Î¸/2)   cos(Î¸/2) |

        Args:
            theta: Rotation angle in radians

        Returns:
            np.ndarray: 2x2 rotation matrix
        """
        c = np.cos(theta / 2)
        s = np.sin(theta / 2)
        return np.array([
            [c, -s],
            [s,  c]
        ], dtype=complex)

    def construct_circuit(self, params: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Construct the parameterized quantum circuit as a unitary matrix.

        For the simple single-parameter ansatz, this is just RY(Î¸).
        For multiple parameters, gates are applied sequentially.

        Args:
            params: Parameter values (uses self.parameters if None)

        Returns:
            np.ndarray: 2x2 unitary matrix representing the circuit
        """
        if params is None:
            params = self.parameters

        # For single parameter, return RY gate
        if self.n_params == 1:
            return self.ry_gate(params[0])

        # For multiple parameters, compose gates
        # (This is a simple extension for more complex ansatze)
        circuit = np.eye(2, dtype=complex)
        for param in params:
            circuit = self.ry_gate(param) @ circuit

        return circuit

    def apply_circuit(self, params: Optional[np.ndarray] = None,
                     initial_state: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Apply the parameterized circuit to an initial state.

        Args:
            params: Parameter values (uses self.parameters if None)
            initial_state: Initial quantum state (uses |0âŸ© if None)

        Returns:
            np.ndarray: Resulting quantum state vector
        """
        if initial_state is None:
            initial_state = self._initial_state

        circuit = self.construct_circuit(params)
        return circuit @ initial_state

    def get_state_vector(self, params: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Get the quantum state vector for given parameters.

        For the RY ansatz with parameter Î¸:
        |Ïˆ(Î¸)âŸ© = cos(Î¸/2)|0âŸ© + sin(Î¸/2)|1âŸ©

        Args:
            params: Parameter values (uses self.parameters if None)

        Returns:
            np.ndarray: Quantum state vector
        """
        return self.apply_circuit(params)

    def compute_expectation_value(self, hamiltonian: np.ndarray,
                                 params: Optional[np.ndarray] = None) -> float:
        """
        Compute the expectation value âŸ¨Ïˆ(Î¸)|H|Ïˆ(Î¸)âŸ©.

        This is the cost function for VQE optimization.

        Args:
            hamiltonian: Hamiltonian operator matrix
            params: Parameter values (uses self.parameters if None)

        Returns:
            float: Expectation value (real number)
        """
        state = self.get_state_vector(params)

        # Ensure state is a column vector
        if state.ndim == 1:
            state = state.reshape(-1, 1)

        # Compute âŸ¨Ïˆ|H|ÏˆâŸ©
        expectation = np.conj(state).T @ hamiltonian @ state
        return float(expectation[0, 0].real)

    def analytical_expectation_pauli_z(self, params: Optional[np.ndarray] = None) -> float:
        """
        Compute expectation value for Pauli Z analytically (for verification).

        For RY ansatz and Pauli Z: E(Î¸) = cos(Î¸)

        Args:
            params: Parameter values (uses self.parameters if None)

        Returns:
            float: Expectation value
        """
        if params is None:
            params = self.parameters

        theta = params[0]
        return np.cos(theta)

    def visualize_circuit(self, params: Optional[np.ndarray] = None) -> str:
        """
        Generate a text-based visualization of the quantum circuit.

        Args:
            params: Parameter values (uses self.parameters if None)

        Returns:
            str: ASCII representation of the circuit
        """
        if params is None:
            params = self.parameters

        circuit_str = "\n" + "=" * 60 + "\n"
        circuit_str += "QUANTUM CIRCUIT VISUALIZATION\n"
        circuit_str += "=" * 60 + "\n\n"

        circuit_str += "Initial state: |0âŸ©\n\n"
        circuit_str += "Circuit:\n"
        circuit_str += "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
        circuit_str += "|0âŸ©â”€â”€â”¤ RY(Î¸={:.4f}) â”œâ”€â”€|Ïˆ(Î¸)âŸ©\n".format(params[0])
        circuit_str += "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n"

        state = self.get_state_vector(params)
        circuit_str += "Output state:\n"
        circuit_str += f"|Ïˆ(Î¸)âŸ© = {state[0]:.4f}|0âŸ© + {state[1]:.4f}|1âŸ©\n"
        circuit_str += f"      = {np.cos(params[0]/2):.4f}|0âŸ© + {np.sin(params[0]/2):.4f}|1âŸ©\n"
        circuit_str += "\n" + "=" * 60 + "\n"

        return circuit_str

    def plot_energy_landscape(self, hamiltonian: np.ndarray,
                             theta_range: Optional[Tuple[float, float]] = None,
                             n_points: int = 100,
                             save_path: Optional[str] = None) -> None:
        """
        Plot the energy landscape as a function of the variational parameter.

        Args:
            hamiltonian: Hamiltonian operator matrix
            theta_range: Range of theta values (min, max). Default: (0, 2Ï€)
            n_points: Number of points to plot
            save_path: Path to save the figure (optional)
        """
        if theta_range is None:
            theta_range = (0, 2 * np.pi)

        theta_values = np.linspace(theta_range[0], theta_range[1], n_points)
        energies = [self.compute_expectation_value(hamiltonian, [theta])
                   for theta in theta_values]

        plt.figure(figsize=(10, 6))
        plt.plot(theta_values, energies, 'b-', linewidth=2, label='E(Î¸) = âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ©')
        plt.axhline(y=-1.0, color='r', linestyle='--', label='Ground state energy')
        plt.axvline(x=np.pi, color='g', linestyle='--', label='Optimal Î¸ = Ï€')

        plt.xlabel('Î¸ (radians)', fontsize=12)
        plt.ylabel('Energy E(Î¸)', fontsize=12)
        plt.title('VQE Energy Landscape for Pauli Z Hamiltonian', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.legend(fontsize=10)

        # Add x-axis labels for key angles
        plt.xticks([0, np.pi/2, np.pi, 3*np.pi/2, 2*np.pi],
                  ['0', 'Ï€/2', 'Ï€', '3Ï€/2', '2Ï€'])

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Plot saved to: {save_path}")

        plt.show()

    def get_parameter_gradients(self, hamiltonian: np.ndarray,
                               params: Optional[np.ndarray] = None,
                               epsilon: float = 1e-8) -> np.ndarray:
        """
        Compute gradients of the expectation value with respect to parameters.

        Uses finite differences for numerical gradient computation.

        Args:
            hamiltonian: Hamiltonian operator matrix
            params: Parameter values (uses self.parameters if None)
            epsilon: Small value for finite difference

        Returns:
            np.ndarray: Gradient vector
        """
        if params is None:
            params = self.parameters

        gradients = np.zeros(self.n_params)

        for i in range(self.n_params):
            params_plus = params.copy()
            params_minus = params.copy()

            params_plus[i] += epsilon
            params_minus[i] -= epsilon

            E_plus = self.compute_expectation_value(hamiltonian, params_plus)
            E_minus = self.compute_expectation_value(hamiltonian, params_minus)

            gradients[i] = (E_plus - E_minus) / (2 * epsilon)

        return gradients

    def analytical_gradient_pauli_z(self, params: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Compute analytical gradient for Pauli Z (for verification).

        For RY ansatz and Pauli Z: dE/dÎ¸ = -sin(Î¸)

        Args:
            params: Parameter values (uses self.parameters if None)

        Returns:
            np.ndarray: Analytical gradient
        """
        if params is None:
            params = self.parameters

        theta = params[0]
        return np.array([-np.sin(theta)])


def demonstrate_ansatz():
    """
    Demonstrate the variational ansatz with various examples.
    """
    print("=" * 70)
    print("VARIATIONAL ANSATZ DEMONSTRATION")
    print("=" * 70)
    print()

    # Create ansatz
    ansatz = VariationalAnsatz(n_params=1)

    # Example 1: Different parameter values
    print("1. STATE PREPARATION AT DIFFERENT ANGLES")
    print("-" * 70)

    test_angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]

    for theta in test_angles:
        ansatz.set_parameters([theta])
        state = ansatz.get_state_vector()
        print(f"\nÎ¸ = {theta:.4f} rad ({np.degrees(theta):.1f}Â°)")
        print(f"State: |ÏˆâŸ© = {state[0]:.4f}|0âŸ© + {state[1]:.4f}|1âŸ©")
        print(f"Probabilities: P(|0âŸ©) = {abs(state[0])**2:.4f}, P(|1âŸ©) = {abs(state[1])**2:.4f}")

    # Example 2: Expectation values with Pauli Z
    print("\n\n2. EXPECTATION VALUES WITH PAULI Z HAMILTONIAN")
    print("-" * 70)

    # Define Pauli Z
    pauli_z = np.array([[1, 0], [0, -1]], dtype=complex)

    for theta in test_angles:
        ansatz.set_parameters([theta])
        E_numerical = ansatz.compute_expectation_value(pauli_z)
        E_analytical = ansatz.analytical_expectation_pauli_z()

        print(f"\nÎ¸ = {theta:.4f} rad ({np.degrees(theta):.1f}Â°)")
        print(f"Energy (numerical):  E = {E_numerical:.6f}")
        print(f"Energy (analytical): E = {E_analytical:.6f}")
        print(f"Match: {np.isclose(E_numerical, E_analytical)}")

    # Example 3: Circuit visualization
    print("\n\n3. CIRCUIT VISUALIZATION")
    print("-" * 70)
    ansatz.set_parameters([np.pi])
    print(ansatz.visualize_circuit())

    # Example 4: Gradients
    print("\n4. GRADIENT COMPUTATION")
    print("-" * 70)

    for theta in [0, np.pi/2, np.pi]:
        ansatz.set_parameters([theta])
        grad_numerical = ansatz.get_parameter_gradients(pauli_z)
        grad_analytical = ansatz.analytical_gradient_pauli_z()

        print(f"\nÎ¸ = {theta:.4f} rad ({np.degrees(theta):.1f}Â°)")
        print(f"Gradient (numerical):  dE/dÎ¸ = {grad_numerical[0]:.6f}")
        print(f"Gradient (analytical): dE/dÎ¸ = {grad_analytical[0]:.6f}")

    # Example 5: Ground state
    print("\n\n5. GROUND STATE PREPARATION")
    print("-" * 70)
    ansatz.set_parameters([np.pi])
    ground_state = ansatz.get_state_vector()
    ground_energy = ansatz.compute_expectation_value(pauli_z)

    print(f"Optimal parameter: Î¸ = Ï€ rad (180Â°)")
    print(f"Ground state: |ÏˆâŸ© = {ground_state}")
    print(f"Ground state energy: E = {ground_energy:.6f}")
    print(f"Theoretical ground state: |1âŸ© = [0, 1]")
    print(f"Theoretical ground energy: -1.0")
    print(f"Match: {np.isclose(ground_energy, -1.0)}")

    print("\n" + "=" * 70)


def main():
    """Main demonstration function."""
    demonstrate_ansatz()

    # Create energy landscape plot
    print("\n\nGenerating energy landscape plot...")
    ansatz = VariationalAnsatz(n_params=1)
    pauli_z = np.array([[1, 0], [0, -1]], dtype=complex)

    try:
        ansatz.plot_energy_landscape(
            pauli_z,
            save_path='output/energy_landscape.png'
        )
    except Exception as e:
        print(f"Could not generate plot: {e}")
        print("(This is normal if running in a headless environment)")


if __name__ == "__main__":
    main()



================================================
File: workspace/projects/Project_perform_vqe_simulation/variational_ansatz_quantum_libs.py
================================================
"""
Variational Ansatz - Quantum Library Implementations

This module provides implementations of the variational ansatz using popular
quantum computing libraries (Qiskit and PennyLane), complementing the pure
NumPy implementation in variational_ansatz.py.

These implementations leverage the circuit-building and optimization capabilities
of quantum libraries, making it easier to extend to more complex ansatze and
integrate with quantum hardware.
"""

import numpy as np
from typing import Optional, List, Tuple


def create_ry_ansatz_qiskit(theta: float = 0.0):
    """
    Create a single-qubit RY ansatz using Qiskit.

    Args:
        theta: Initial rotation angle

    Returns:
        Tuple containing (circuit, parameter)
    """
    try:
        from qiskit import QuantumCircuit, QuantumRegister
        from qiskit.circuit import Parameter
        from qiskit.quantum_info import Statevector, Operator

        print("=" * 70)
        print("QISKIT VARIATIONAL ANSATZ")
        print("=" * 70)
        print()

        # Create a parameter for the rotation angle
        theta_param = Parameter('Î¸')

        # Create quantum circuit with 1 qubit
        qr = QuantumRegister(1, 'q')
        circuit = QuantumCircuit(qr)

        # Add RY rotation gate
        circuit.ry(theta_param, qr[0])

        print("1. PARAMETERIZED CIRCUIT")
        print("-" * 70)
        print(circuit.draw('text'))
        print()

        # Bind parameter and get state
        print("2. EXAMPLE: BINDING Î¸ = Ï€/2")
        print("-" * 70)
        bound_circuit = circuit.assign_parameters({theta_param: np.pi/2})
        print(bound_circuit.draw('text'))
        print()

        # Get statevector
        statevector = Statevector.from_instruction(bound_circuit)
        print(f"Statevector: {statevector.data}")
        print(f"Amplitudes: Î±|0âŸ© + Î²|1âŸ©")
        print(f"  Î± = {statevector.data[0]:.4f}")
        print(f"  Î² = {statevector.data[1]:.4f}")
        print()

        return circuit, theta_param

    except ImportError as e:
        print("=" * 70)
        print("QISKIT NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install Qiskit, run:")
        print("  pip install qiskit")
        return None, None


def demonstrate_qiskit_vqe():
    """
    Demonstrate VQE with Qiskit's built-in VQE algorithm.
    """
    try:
        from qiskit import QuantumCircuit
        from qiskit.circuit import Parameter
        from qiskit.quantum_info import SparsePauliOp, Statevector
        from qiskit_algorithms import VQE
        from qiskit_algorithms.optimizers import COBYLA, SLSQP
        from qiskit.primitives import Estimator

        print("\n" + "=" * 70)
        print("QISKIT VQE DEMONSTRATION")
        print("=" * 70)
        print()

        # Define Pauli Z Hamiltonian
        print("1. DEFINE HAMILTONIAN")
        print("-" * 70)
        hamiltonian = SparsePauliOp(['Z'], coeffs=[1.0])
        print(f"Hamiltonian: {hamiltonian}")
        print(f"Matrix:\n{hamiltonian.to_matrix()}")
        print()

        # Create ansatz
        print("2. CREATE ANSATZ")
        print("-" * 70)
        theta = Parameter('Î¸')
        ansatz = QuantumCircuit(1)
        ansatz.ry(theta, 0)
        print(ansatz.draw('text'))
        print()

        # Setup VQE
        print("3. SETUP VQE")
        print("-" * 70)
        optimizer = COBYLA(maxiter=100)
        estimator = Estimator()

        vqe = VQE(estimator, ansatz, optimizer)
        print(f"Optimizer: {optimizer.__class__.__name__}")
        print(f"Ansatz: RY(Î¸) on 1 qubit")
        print(f"Initial parameters: [0.0]")
        print()

        # Run VQE
        print("4. RUN OPTIMIZATION")
        print("-" * 70)
        print("Running VQE to find ground state energy...")
        result = vqe.compute_minimum_eigenvalue(hamiltonian)

        print(f"\nOptimization complete!")
        print(f"  Ground state energy: {result.eigenvalue:.6f}")
        print(f"  Optimal parameters: {result.optimal_parameters}")
        print(f"  Optimal Î¸ value: {result.optimal_point[0]:.6f} rad ({np.degrees(result.optimal_point[0]):.2f}Â°)")
        print(f"  Number of evaluations: {result.cost_function_evals}")
        print()

        # Verify result
        print("5. VERIFICATION")
        print("-" * 70)
        print(f"Theoretical ground state energy: -1.0")
        print(f"VQE ground state energy: {result.eigenvalue:.6f}")
        print(f"Error: {abs(result.eigenvalue - (-1.0)):.6e}")
        print()

        # Get optimal state
        optimal_circuit = ansatz.assign_parameters(result.optimal_parameters)
        optimal_state = Statevector.from_instruction(optimal_circuit)
        print(f"Optimal state: {optimal_state.data}")
        print(f"Theoretical ground state: [0, 1]")
        print()

        return result

    except ImportError as e:
        print("\n" + "=" * 70)
        print("QISKIT VQE NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install Qiskit algorithms, run:")
        print("  pip install qiskit qiskit-algorithms")
        return None


def create_ry_ansatz_pennylane(theta: float = 0.0):
    """
    Create a single-qubit RY ansatz using PennyLane.

    Args:
        theta: Initial rotation angle

    Returns:
        QNode (quantum function)
    """
    try:
        import pennylane as qml

        print("\n" + "=" * 70)
        print("PENNYLANE VARIATIONAL ANSATZ")
        print("=" * 70)
        print()

        # Create a device
        dev = qml.device('default.qubit', wires=1)

        print("1. DEFINE QUANTUM DEVICE")
        print("-" * 70)
        print(f"Device: {dev.name}")
        print(f"Number of wires: {dev.num_wires}")
        print()

        # Define the ansatz as a quantum function
        def ansatz_circuit(params):
            """Single-qubit RY ansatz."""
            qml.RY(params[0], wires=0)
            return qml.state()

        # Create QNode
        qnode = qml.QNode(ansatz_circuit, dev)

        print("2. ANSATZ CIRCUIT")
        print("-" * 70)
        print("Circuit structure:")
        print("  |0âŸ© â”€â”€ RY(Î¸) â”€â”€ |Ïˆ(Î¸)âŸ©")
        print()

        # Test the ansatz
        print("3. EXAMPLE: EVALUATE AT Î¸ = Ï€/2")
        print("-" * 70)
        test_params = [np.pi/2]
        state = qnode(test_params)
        print(f"Parameters: Î¸ = {test_params[0]:.4f} rad ({np.degrees(test_params[0]):.1f}Â°)")
        print(f"Output state: {state}")
        print(f"Probabilities: |Î±|Â² = {abs(state[0])**2:.4f}, |Î²|Â² = {abs(state[1])**2:.4f}")
        print()

        return qnode

    except ImportError as e:
        print("\n" + "=" * 70)
        print("PENNYLANE NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install PennyLane, run:")
        print("  pip install pennylane")
        return None


def demonstrate_pennylane_vqe():
    """
    Demonstrate VQE with PennyLane.
    """
    try:
        import pennylane as qml
        from pennylane import numpy as pnp

        print("\n" + "=" * 70)
        print("PENNYLANE VQE DEMONSTRATION")
        print("=" * 70)
        print()

        # Create device
        dev = qml.device('default.qubit', wires=1)

        # Define Hamiltonian
        print("1. DEFINE HAMILTONIAN")
        print("-" * 70)
        H = qml.Hamiltonian([1.0], [qml.PauliZ(0)])
        print(f"Hamiltonian: {H}")
        print(f"Matrix:\n{qml.matrix(qml.PauliZ(0))}")
        print()

        # Define cost function
        print("2. DEFINE COST FUNCTION")
        print("-" * 70)

        @qml.qnode(dev)
        def cost_function(params):
            """
            Compute expectation value âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ©.
            """
            qml.RY(params[0], wires=0)
            return qml.expval(qml.PauliZ(0))

        print("Cost function: E(Î¸) = âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ©")
        print("Circuit: RY(Î¸) applied to |0âŸ©")
        print()

        # Test cost function
        print("3. EVALUATE COST FUNCTION AT DIFFERENT Î¸")
        print("-" * 70)
        test_thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]
        for theta in test_thetas:
            energy = cost_function([theta])
            print(f"Î¸ = {theta:.4f} rad ({np.degrees(theta):>5.1f}Â°): E = {energy:.6f}")
        print()

        # Setup optimizer
        print("4. RUN OPTIMIZATION")
        print("-" * 70)
        optimizer = qml.GradientDescentOptimizer(stepsize=0.1)

        # Initial parameters
        params = pnp.array([0.0], requires_grad=True)
        print(f"Optimizer: Gradient Descent")
        print(f"Initial parameters: Î¸ = {params[0]:.4f} rad")
        print(f"Initial energy: E = {cost_function(params):.6f}")
        print()

        # Optimization loop
        print("Optimization steps:")
        n_steps = 50
        energies = []

        for step in range(n_steps):
            params, energy = optimizer.step_and_cost(cost_function, params)
            energies.append(energy)

            if step % 10 == 0 or step == n_steps - 1:
                print(f"  Step {step:3d}: Î¸ = {params[0]:.6f} rad, E = {energy:.6f}")

        print()

        # Results
        print("5. OPTIMIZATION RESULTS")
        print("-" * 70)
        final_energy = cost_function(params)
        print(f"Final parameters: Î¸ = {params[0]:.6f} rad ({np.degrees(params[0]):.2f}Â°)")
        print(f"Final energy: E = {final_energy:.6f}")
        print(f"Theoretical ground state energy: -1.0")
        print(f"Error: {abs(final_energy - (-1.0)):.6e}")
        print()

        # Get final state
        @qml.qnode(dev)
        def get_state(params):
            qml.RY(params[0], wires=0)
            return qml.state()

        final_state = get_state(params)
        print(f"Final state: {final_state}")
        print(f"Theoretical ground state: [0+0j, 1+0j]")
        print()

        # Compute gradient at optimal point
        print("6. GRADIENT AT OPTIMAL POINT")
        print("-" * 70)
        grad = qml.grad(cost_function)
        gradient = grad(params)
        print(f"âˆ‡E(Î¸_opt) = {gradient[0]:.6f}")
        print(f"(Should be close to 0 at minimum)")
        print()

        return params, energies

    except ImportError as e:
        print("\n" + "=" * 70)
        print("PENNYLANE NOT AVAILABLE")
        print("=" * 70)
        print(f"Error: {e}")
        print("\nTo install PennyLane, run:")
        print("  pip install pennylane")
        return None, None


def compare_implementations():
    """
    Compare all implementations to verify consistency.
    """
    print("\n" + "=" * 70)
    print("COMPARISON OF IMPLEMENTATIONS")
    print("=" * 70)
    print()

    test_theta = np.pi / 3
    pauli_z = np.array([[1, 0], [0, -1]], dtype=complex)

    # NumPy implementation
    print("1. NUMPY IMPLEMENTATION")
    print("-" * 70)
    from variational_ansatz import VariationalAnsatz

    ansatz_numpy = VariationalAnsatz(n_params=1)
    ansatz_numpy.set_parameters([test_theta])
    state_numpy = ansatz_numpy.get_state_vector()
    energy_numpy = ansatz_numpy.compute_expectation_value(pauli_z)

    print(f"Î¸ = {test_theta:.6f} rad ({np.degrees(test_theta):.2f}Â°)")
    print(f"State: {state_numpy}")
    print(f"Energy: {energy_numpy:.6f}")
    print()

    # Qiskit implementation
    print("2. QISKIT IMPLEMENTATION")
    print("-" * 70)
    try:
        from qiskit import QuantumCircuit
        from qiskit.circuit import Parameter
        from qiskit.quantum_info import Statevector, SparsePauliOp
        from qiskit.primitives import Estimator

        theta_param = Parameter('Î¸')
        circuit = QuantumCircuit(1)
        circuit.ry(theta_param, 0)

        bound_circuit = circuit.assign_parameters({theta_param: test_theta})
        state_qiskit = Statevector.from_instruction(bound_circuit).data

        hamiltonian = SparsePauliOp(['Z'], coeffs=[1.0])
        estimator = Estimator()
        job = estimator.run(bound_circuit, hamiltonian)
        energy_qiskit = job.result().values[0]

        print(f"Î¸ = {test_theta:.6f} rad ({np.degrees(test_theta):.2f}Â°)")
        print(f"State: {state_qiskit}")
        print(f"Energy: {energy_qiskit:.6f}")
        print(f"Match with NumPy: {np.allclose(state_numpy, state_qiskit)}")
        print()

    except ImportError:
        print("Qiskit not available - skipping comparison")
        print()

    # PennyLane implementation
    print("3. PENNYLANE IMPLEMENTATION")
    print("-" * 70)
    try:
        import pennylane as qml

        dev = qml.device('default.qubit', wires=1)

        @qml.qnode(dev)
        def get_state(params):
            qml.RY(params[0], wires=0)
            return qml.state()

        @qml.qnode(dev)
        def get_energy(params):
            qml.RY(params[0], wires=0)
            return qml.expval(qml.PauliZ(0))

        state_pennylane = get_state([test_theta])
        energy_pennylane = get_energy([test_theta])

        print(f"Î¸ = {test_theta:.6f} rad ({np.degrees(test_theta):.2f}Â°)")
        print(f"State: {state_pennylane}")
        print(f"Energy: {energy_pennylane:.6f}")
        print(f"Match with NumPy: {np.allclose(state_numpy, state_pennylane)}")
        print()

    except ImportError:
        print("PennyLane not available - skipping comparison")
        print()

    print("=" * 70)


def main():
    """Main function demonstrating all implementations."""

    # Create ansatze
    circuit_qiskit, param_qiskit = create_ry_ansatz_qiskit()
    qnode_pennylane = create_ry_ansatz_pennylane()

    # Run VQE demonstrations
    result_qiskit = demonstrate_qiskit_vqe()
    params_pennylane, energies = demonstrate_pennylane_vqe()

    # Compare implementations
    try:
        compare_implementations()
    except ImportError as e:
        print(f"\nCould not run full comparison: {e}")

    # Summary
    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print("\nThe variational ansatz RY(Î¸) has been implemented using:")
    print("  1. Pure NumPy (in variational_ansatz.py)")
    print("  2. Qiskit (parameterized circuits and VQE)")
    print("  3. PennyLane (QNodes and gradient-based optimization)")
    print("\nAll implementations produce consistent results:")
    print("  â€¢ Optimal parameter: Î¸ â‰ˆ Ï€ rad")
    print("  â€¢ Ground state energy: E â‰ˆ -1.0")
    print("  â€¢ Ground state: |ÏˆâŸ© â‰ˆ |1âŸ©")
    print("=" * 70)


if __name__ == "__main__":
    main()








================================================
File: workspace/projects/Project_perform_vqe_simulation/output/pauli_z_reference.txt
================================================
================================================================================
                    PAULI Z HAMILTONIAN - QUICK REFERENCE
================================================================================

MATRIX REPRESENTATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”Œ         â”
Z =  â”‚  1   0  â”‚
     â”‚  0  -1  â”‚
     â””         â”˜

EIGENSPECTRUM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Eigenvalue Î»â‚€ = +1  â”€â”€â”€â†’  Eigenvector |0âŸ© = [1, 0]áµ€  (EXCITED STATE)
Eigenvalue Î»â‚ = -1  â”€â”€â”€â†’  Eigenvector |1âŸ© = [0, 1]áµ€  (GROUND STATE)

GROUND STATE INFORMATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Energy:     E_ground = -1.0
State:      |Ïˆ_groundâŸ© = |1âŸ© = [0, 1]áµ€

BLOCH SPHERE REPRESENTATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              z (|0âŸ©)
              â†‘
              |
              |    â† Pauli Z measures along this axis
              |
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x
             /|
            / |
           /  â†“
          y   z (|1âŸ©) â† Ground state

EXPECTATION VALUES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
State               Expression              âŸ¨Ïˆ|Z|ÏˆâŸ©      Energy
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
|0âŸ©                 [1, 0]áµ€                   +1          Excited
|1âŸ©                 [0, 1]áµ€                   -1          Ground
|+âŸ© = (|0âŸ©+|1âŸ©)/âˆš2  [1/âˆš2, 1/âˆš2]áµ€              0          Superposition
|-âŸ© = (|0âŸ©-|1âŸ©)/âˆš2  [1/âˆš2, -1/âˆš2]áµ€             0          Superposition

MATHEMATICAL PROPERTIES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Hermitian:    Z = Zâ€      (Observable in quantum mechanics)
âœ“ Unitary:      ZÂ² = I     (Can be used as quantum gate)
âœ“ Traceless:    Tr(Z) = 0
âœ“ Determinant:  Det(Z) = -1

VQE OPTIMIZATION TARGET
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Objective:      Minimize E(Î¸) = âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ©
Ansatz:         |Ïˆ(Î¸)âŸ© = RY(Î¸)|0âŸ© = cos(Î¸/2)|0âŸ© + sin(Î¸/2)|1âŸ©
Cost Function:  E(Î¸) = cos(Î¸)
Optimal Î¸:      Î¸* = Ï€ (180Â°)
Optimal State:  |Ïˆ(Ï€)âŸ© = |1âŸ©
Optimal Energy: E(Ï€) = -1.0

PAULI MATRIX FAMILY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”Œ         â”          â”Œ         â”          â”Œ         â”
   I =  â”‚  1   0  â”‚     X =  â”‚  0   1  â”‚     Y =  â”‚  0  -i  â”‚
        â”‚  0   1  â”‚          â”‚  1   0  â”‚          â”‚  i   0  â”‚
        â””         â”˜          â””         â”˜          â””         â”˜

        â”Œ         â”
   Z =  â”‚  1   0  â”‚          â† You are here
        â”‚  0  -1  â”‚
        â””         â”˜

QUANTUM GATE INTERPRETATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
The Pauli Z gate flips the phase of the |1âŸ© state:
    Z|0âŸ© = +|0âŸ©  (no change)
    Z|1âŸ© = -|1âŸ©  (phase flip)

PHYSICAL APPLICATIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Quantum Error Correction: Detects phase flip errors
â€¢ Quantum Algorithms: Used in Grover's, Shor's algorithms
â€¢ Spin Systems: Models spin along z-axis in magnetic field
â€¢ VQE: Simple test Hamiltonian for algorithm validation

PYTHON QUICK START
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    from pauli_z_hamiltonian import PauliZHamiltonian

    hamiltonian = PauliZHamiltonian()
    energy = hamiltonian.get_ground_state_energy()
    print(f"Ground state energy: {energy}")  # -1.0

================================================================================
                              END OF REFERENCE
================================================================================



================================================
File: workspace/projects/Project_perform_vqe_simulation/output/pauli_z_summary.md
================================================
# Pauli Z Hamiltonian - Summary

## Overview

The Pauli Z Hamiltonian has been successfully defined for a single qubit system. This is a fundamental quantum operator used extensively in quantum computing and is the target Hamiltonian for the VQE simulation.

## Files Created

1. **pauli_z_hamiltonian.py** - Complete Python implementation with detailed analysis
   - Location: `/Users/agustinazwiener/evolving-agents-labs/llmunix/llmos/workspace/projects/Project_perform_vqe_simulation/pauli_z_hamiltonian.py`
   - Features: NumPy-based implementation, eigenspectrum calculation, expectation values

2. **pauli_z_quantum_libs.py** - Integration with quantum computing libraries
   - Location: `/Users/agustinazwiener/evolving-agents-labs/llmunix/llmos/workspace/projects/Project_perform_vqe_simulation/pauli_z_quantum_libs.py`
   - Features: Qiskit and PennyLane implementations, comparison, VQE usage examples

## Matrix Representation

The Pauli Z operator is represented by the following 2Ã—2 matrix:

```
Z = | 1   0 |
    | 0  -1 |
```

In code:
```python
import numpy as np
pauli_z = np.array([[1, 0], [0, -1]], dtype=complex)
```

## Key Properties

### 1. Eigenvalues (Energy Levels)
- **Eigenvalue Î»â‚€ = +1** â†’ Corresponds to state |0âŸ© (excited state)
- **Eigenvalue Î»â‚ = -1** â†’ Corresponds to state |1âŸ© (ground state)

### 2. Eigenvectors (Energy Eigenstates)
- **|0âŸ© = [1, 0]áµ€** with eigenvalue +1
- **|1âŸ© = [0, 1]áµ€** with eigenvalue -1

### 3. Ground State
- **Energy**: E_ground = -1.0
- **State**: |Ïˆ_groundâŸ© = |1âŸ© = [0, 1]áµ€

### 4. Mathematical Properties
- **Hermitian**: Yes (Z = Zâ€ ), meaning it has real eigenvalues
- **Unitary**: Yes (ZÂ² = I), meaning it's also a quantum gate
- **Trace**: Tr(Z) = 0
- **Determinant**: Det(Z) = -1

## Physical Interpretation

The Pauli Z Hamiltonian represents:

1. **Spin Measurement**: Measures the spin of a qubit along the z-axis (computational basis)
2. **Energy Difference**: Energy splitting between |0âŸ© and |1âŸ© states
3. **Bloch Sphere**: Measurement along the north-south pole axis
4. **Classical Bit**: In the computational basis, distinguishes between 0 and 1

## Expectation Values

For various quantum states:

| State | Expression | âŸ¨Ïˆ\|Z\|ÏˆâŸ© | Interpretation |
|-------|------------|----------|----------------|
| \|0âŸ© | [1, 0] | +1 | Definite spin-up |
| \|1âŸ© | [0, 1] | -1 | Definite spin-down |
| \|+âŸ© | (\|0âŸ© + \|1âŸ©)/âˆš2 | 0 | Equal superposition |
| \|-âŸ© | (\|0âŸ© - \|1âŸ©)/âˆš2 | 0 | Equal superposition |

## VQE Simulation Context

For the VQE simulation to find the ground state energy:

### Objective
- **Target**: Find E_ground = -1.0
- **Method**: Variationally optimize quantum circuit parameters
- **Success**: Measured energy approaches -1.0

### Ansatz Strategy
For a single qubit, a simple ansatz:
```
|Ïˆ(Î¸)âŸ© = RY(Î¸)|0âŸ©
        = cos(Î¸/2)|0âŸ© + sin(Î¸/2)|1âŸ©
```

### Cost Function
```
E(Î¸) = âŸ¨Ïˆ(Î¸)|Z|Ïˆ(Î¸)âŸ© = cos(Î¸)
```

### Optimization Result
- **Optimal parameter**: Î¸* = Ï€
- **Optimal state**: |Ïˆ(Ï€)âŸ© = |1âŸ©
- **Optimal energy**: E(Ï€) = -1.0

## Usage Examples

### Basic Usage (NumPy)
```python
from pauli_z_hamiltonian import PauliZHamiltonian

# Create Hamiltonian
hamiltonian = PauliZHamiltonian()

# Get matrix
matrix = hamiltonian.get_matrix()

# Get ground state energy
energy = hamiltonian.get_ground_state_energy()
print(f"Ground state energy: {energy}")  # Output: -1.0

# Get ground state
ground_state = hamiltonian.get_ground_state()
print(f"Ground state: {ground_state}")  # Output: [0.+0.j, 1.+0.j]

# Compute expectation value
state = np.array([1, 0]) / np.sqrt(1)  # |0âŸ© state
exp_value = hamiltonian.expectation_value(state)
print(f"âŸ¨0|Z|0âŸ© = {exp_value}")  # Output: 1.0
```

### With Qiskit (if installed)
```python
from qiskit.quantum_info import SparsePauliOp

# Define Hamiltonian
hamiltonian = SparsePauliOp(['Z'], coeffs=[1.0])

# Get matrix
matrix = hamiltonian.to_matrix()
```

### With PennyLane (if installed)
```python
import pennylane as qml

# Define Hamiltonian
hamiltonian = qml.Hamiltonian([1.0], [qml.PauliZ(0)])

# Get matrix
matrix = qml.matrix(qml.PauliZ(0))
```

## Next Steps for VQE Simulation

1. **Define Ansatz**: Create a parameterized quantum circuit (e.g., RY gate)
2. **Configure Optimizer**: Choose optimization algorithm (e.g., COBYLA, SPSA)
3. **Execute VQE**: Run variational loop to minimize energy
4. **Validate Results**: Verify that found energy â‰ˆ -1.0

## References

- **Quantum State**: |ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ© where |Î±|Â² + |Î²|Â² = 1
- **Pauli Matrices**: Ïƒ_x (X), Ïƒ_y (Y), Ïƒ_z (Z)
- **Ground State**: The eigenstate with the lowest eigenvalue
- **VQE**: Variational Quantum Eigensolver algorithm

---

*Generated on: 2025-12-09*
*Project: Project_perform_vqe_simulation*



================================================
File: workspace/projects/Project_perform_vqe_simulation/state/constraints.json
================================================
{
  "max_token_cost": 5.0,
  "max_execution_time_secs": 600,
  "require_memory_consultation": true,
  "enable_learning": true
}


================================================
File: workspace/projects/Project_perform_vqe_simulation/state/context.md
================================================
# Execution Context

**Goal**: Perform VQE simulation for Pauli Z Hamiltonian. Coordinate a team of agents: ansatz-designer, optimizer-agent, and vqe-executor.
**Status**: initialized
**Started**: 2025-12-09T07:17:14.449489


## Additional Context



================================================
File: workspace/projects/Project_perform_vqe_simulation/state/history.md
================================================
# Execution History

**Project**: Project_perform_vqe_simulation
**Started**: 2025-12-09T06:54:39.132314

---

## Events


### EXECUTION_INITIALIZED

**Timestamp**: 2025-12-09T06:54:39.133141

**goal**: Perform VQE simulation to find the ground state energy of a Pauli Z Hamiltonian on a single qubit. Orchestrate a team to: 1. Define the ansatz, 2. Configure the optimizer, 3. Execute and output the eigenvalue.

---

### ORCHESTRATION_STARTED

**Timestamp**: 2025-12-09T06:54:39.139538

**goal**: Perform VQE simulation to find the ground state energy of a Pauli Z Hamiltonian on a single qubit. Orchestrate a team to: 1. Define the ansatz, 2. Configure the optimizer, 3. Execute and output the eigenvalue.
**project**: Project_perform_vqe_simulation
**max_cost_usd**: 5.0

---

### MEMORY_CONSULTATION

**Timestamp**: 2025-12-09T06:54:39.140028

**phase**: started

---

### AGENT_REGISTERED

**Timestamp**: 2025-12-09T06:54:39.140716

**agent**: system-agent
**tools**: ['Read', 'Write', 'Glob', 'Grep', 'Bash', 'WebFetch', 'Task']

---

### GOAL_DECOMPOSITION

**Timestamp**: 2025-12-09T06:54:39.140881

**phase**: started

---

### PLAN_CREATED

**Timestamp**: 2025-12-09T06:55:18.320140

**step_count**: 7

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T06:55:22.198454

**step**: 1
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-09T06:55:22.198730

**step**: 1
**description**: Install and verify quantum computing dependencies (Qiskit or PennyLane)
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-09T06:55:22.198922

**prompt**: Use the system-agent agent to Install and verify quantum computing dependencies (Qiskit or PennyLane)

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:24.906741

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:29.465981

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:33.429995

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:33.538293

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:33.895763

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:33.932768

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:38.126424

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:39.161086

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:42.800828

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:44.133942

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:51.761864

**activity**: Using: TodoWrite()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:52.011772

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:55:59.045418

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:02.567437

**activity**: Thinking...

---

### DELEGATION_COMPLETED

**Timestamp**: 2025-12-09T06:56:02.775050

**success**: True
**cost**: 0.08997569999999999
**result_length**: 318

---

### STEP_EXECUTION_COMPLETED

**Timestamp**: 2025-12-09T06:56:02.775389

**step**: 1
**success**: True
**cost**: 0.08997569999999999

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T06:56:02.776070

**step**: 1
**status**: completed
**result**: I'll use the general-purpose agent to install and verify quantum computing dependencies for you.
The agent is requesting approval to install the quantum computing packages. It will install both Qiskit and PennyLane and then verify that they're working correctly. 

Would you like to approve the installation to proceed?
**error**: None

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T06:56:02.776413

**step**: 2
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-09T06:56:02.776533

**step**: 2
**description**: Define the Pauli Z Hamiltonian for a single qubit system
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-09T06:56:02.776732

**prompt**: Use the system-agent agent to Define the Pauli Z Hamiltonian for a single qubit system

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:05.906039

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:10.121934

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:14.036565

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:14.798646

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:15.466112

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:16.632828

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:17.724158

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:18.841009

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:22.395050

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:23.083001

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:23.813875

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:24.027096

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:24.036936

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:24.044921

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:27.350171

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:27.519203

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:31.118714

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:31.803472

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:32.580894

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:32.892829

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:32.894900

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:56:33.088074

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:57:17.218392

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:57:17.545411

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:57:21.864830

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:57:23.113132

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:57:59.981776

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:00.260436

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:30.234901

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:30.899934

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:35.695583

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:35.991179

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:58.084594

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:58:58.478561

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:59:02.559478

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T06:59:02.828916

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:00:56.019840

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:03.675568

**activity**: Thinking...

---

### DELEGATION_COMPLETED

**Timestamp**: 2025-12-09T07:01:03.697941

**success**: True
**cost**: 0.43967175000000003
**result_length**: 1140

---

### STEP_EXECUTION_COMPLETED

**Timestamp**: 2025-12-09T07:01:03.698453

**step**: 2
**success**: True
**cost**: 0.43967175000000003

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T07:01:03.699214

**step**: 2
**status**: completed
**result**: I'll use the general-purpose agent to define the Pauli Z Hamiltonian for a single qubit system.
Perfect! The agent has successfully defined the Pauli Z Hamiltonian for a single qubit system. Here's a summary of what was created:

## Key Results

### **The Pauli Z Hamiltonian Matrix:**
```
Z = | 1   0 |
    | 0  -1 |
```

### **Properties:**
- **Ground State Energy:** -1.0
- **Ground State:** |1âŸ© = [0, 1]áµ€
- **Eigenvalues:** +1 (for |0âŸ©) and -1 (for |1âŸ©)
- **Hermitian & Unitary:** Yes

### **Files Created:**

1. **`pauli_z_hamiltonian.py`** - Complete Python implementation with NumPy
2. **`pauli_z_quantum_libs.py`** - Integration with Qiskit and PennyLane
3. **`output/pauli_z_summary.md`** - Comprehensive documentation
4. **`output/pauli_z_reference.txt`** - Quick reference guide

### **Physical Meaning:**
The Pauli Z Hamiltonian measures qubit spin along the z-axis (computational basis), representing the energy splitting between |0âŸ© (spin-up) and |1âŸ© (spin-down) states.

All files are ready to use for your VQE simulation, with the ground state energy of **-1.0** as the target for the variational quantum eigensolver to find!
**error**: None

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T07:01:03.699510

**step**: 3
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-09T07:01:03.699600

**step**: 3
**description**: Design and implement the variational ansatz (parameterized quantum circuit)
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-09T07:01:03.699752

**prompt**: Use the system-agent agent to Design and implement the variational ansatz (parameterized quantum circuit)

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:06.643473

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:14.521966

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:18.556939

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:18.864925

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:19.086584

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:19.294279

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:19.302422

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:19.332063

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:22.449897

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:23.097758

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:23.805450

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:24.386582

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:24.633238

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:24.635262

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:24.638714

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:01:24.640823

**activity**: Tool completed

---

### DELEGATION_TIMEOUT

**Timestamp**: 2025-12-09T07:02:34.169926

**timeout**: 300.0
**prompt**: Use the system-agent agent to Design and implement the variational ansatz (parameterized quantum circuit)

---

### STEP_EXECUTION_COMPLETED

**Timestamp**: 2025-12-09T07:02:34.171916

**step**: 3
**success**: False
**cost**: 0.0

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T07:02:34.173776

**step**: 3
**status**: failed
**result**: None
**error**: Delegation timed out after 300.0s

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T07:02:34.174257

**step**: 4
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-09T07:02:34.174524

**step**: 4
**description**: Configure the classical optimizer (e.g., COBYLA, SPSA, or gradient descent)
**agent**: system-agent

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-09T07:02:34.174777

**prompt**: Use the system-agent agent to Configure the classical optimizer (e.g., COBYLA, SPSA, or gradient descent)

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:03:30.609863

**activity**: Using: Write()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:03:31.030060

**activity**: Tool completed

---

### EXECUTION_INITIALIZED

**Timestamp**: 2025-12-09T07:07:51.719813

**goal**: Perform VQE simulation for Pauli Z Hamiltonian on a single qubit. Create a team: 1. Design the ansatz circuit, 2. Configure COBYLA optimizer, 3. Execute VQE and report ground state energy.

---

### ORCHESTRATION_STARTED

**Timestamp**: 2025-12-09T07:07:51.725457

**goal**: Perform VQE simulation for Pauli Z Hamiltonian on a single qubit. Create a team: 1. Design the ansatz circuit, 2. Configure COBYLA optimizer, 3. Execute VQE and report ground state energy.
**project**: Project_perform_vqe_simulation
**max_cost_usd**: 5.0

---

### MEMORY_CONSULTATION

**Timestamp**: 2025-12-09T07:07:51.725833

**phase**: started

---

### AGENT_REGISTERED

**Timestamp**: 2025-12-09T07:07:51.726731

**agent**: system-agent
**tools**: ['Read', 'Write', 'Glob', 'Grep', 'Bash', 'WebFetch', 'Task']

---

### GOAL_DECOMPOSITION

**Timestamp**: 2025-12-09T07:07:51.726879

**phase**: started

---

### PLAN_CREATED

**Timestamp**: 2025-12-09T07:08:40.696117

**step_count**: 7

---

### AGENT_GAP_DETECTION

**Timestamp**: 2025-12-09T07:08:40.696596

**agents_in_plan**: ['data-processor', 'optimizer-agent', 'vqe-executor', 'test-runner', 'ansatz-designer']
**phase**: started

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:08:40.696767

**agent**: data-processor
**capability**: data-processor: Generate detailed report analyzing VQE performance: energy accuracy vs. theoretical ground state, convergence behavior, parameter optimization trajectory, and quantum state preparation

---

### AGENT_CREATION_ERROR

**Timestamp**: 2025-12-09T07:09:24.294040

**agent**: data-processor
**error**: AgentFactory.create_agent() missing 1 required positional argument: 'agent_type'

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:09:24.295599

**agent**: optimizer-agent
**capability**: optimizer-agent: Design and implement COBYLA optimizer configuration module with appropriate convergence criteria, tolerance settings, and maximum iterations for VQE

---

### AGENT_CREATION_ERROR

**Timestamp**: 2025-12-09T07:10:39.090355

**agent**: optimizer-agent
**error**: AgentFactory.create_agent() missing 1 required positional argument: 'agent_type'

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:10:39.091329

**agent**: vqe-executor
**capability**: vqe-executor: Create VQE executor that integrates the Pauli Z Hamiltonian, variational ansatz, and COBYLA optimizer into a complete simulation pipeline; Execute the VQE simulation starting from random

---

### AGENT_CREATION_ERROR

**Timestamp**: 2025-12-09T07:11:26.794044

**agent**: vqe-executor
**error**: AgentFactory.create_agent() missing 1 required positional argument: 'agent_type'

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:11:26.794422

**agent**: test-runner
**capability**: test-runner: Create unit tests for VQE components: optimizer configuration, energy evaluation, ansatz-Hamiltonian integration, and end-to-end simulation validation; Execute all tests and validate that

---

### AGENT_CREATION_ERROR

**Timestamp**: 2025-12-09T07:12:27.204209

**agent**: test-runner
**error**: AgentFactory.create_agent() missing 1 required positional argument: 'agent_type'

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:12:27.206109

**agent**: ansatz-designer
**capability**: ansatz-designer: Review and validate the existing ansatz design (RY gate parameterization) and verify it's optimal for Pauli Z ground state preparation

---

### EXECUTION_INITIALIZED

**Timestamp**: 2025-12-09T07:17:14.449819

**goal**: Perform VQE simulation for Pauli Z Hamiltonian. Coordinate a team of agents: ansatz-designer, optimizer-agent, and vqe-executor.

---

### ORCHESTRATION_STARTED

**Timestamp**: 2025-12-09T07:17:14.455057

**goal**: Perform VQE simulation for Pauli Z Hamiltonian. Coordinate a team of agents: ansatz-designer, optimizer-agent, and vqe-executor.
**project**: Project_perform_vqe_simulation
**max_cost_usd**: 5.0

---

### MEMORY_CONSULTATION

**Timestamp**: 2025-12-09T07:17:14.455539

**phase**: started

---

### AGENT_REGISTERED

**Timestamp**: 2025-12-09T07:17:14.456229

**agent**: system-agent
**tools**: ['Read', 'Write', 'Glob', 'Grep', 'Bash', 'WebFetch', 'Task']

---

### GOAL_DECOMPOSITION

**Timestamp**: 2025-12-09T07:17:14.456364

**phase**: started

---

### PLAN_CREATED

**Timestamp**: 2025-12-09T07:17:35.265298

**step_count**: 7

---

### AGENT_GAP_DETECTION

**Timestamp**: 2025-12-09T07:17:35.265442

**agents_in_plan**: ['vqe-executor', 'optimizer-agent', 'ansatz-designer']
**phase**: started

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:17:35.265569

**agent**: vqe-executor
**capability**: vqe-executor: Define Pauli Z Hamiltonian and measurement strategy; Implement energy expectation value computation function; Execute VQE optimization loop to find ground state energy; Validate results 

---

### AGENT_CREATION_SUCCESS

**Timestamp**: 2025-12-09T07:18:16.325740

**agent**: vqe-executor
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep']

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:18:16.326512

**agent**: optimizer-agent
**capability**: optimizer-agent: Configure classical optimizer with appropriate hyperparameters

---

### AGENT_CREATION_SUCCESS

**Timestamp**: 2025-12-09T07:19:25.062444

**agent**: optimizer-agent
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Grep', 'Glob']

---

### AGENT_CREATION_STARTED

**Timestamp**: 2025-12-09T07:19:25.063122

**agent**: ansatz-designer
**capability**: ansatz-designer: Design parameterized quantum circuit ansatz for VQE simulation

---

### AGENT_CREATION_SUCCESS

**Timestamp**: 2025-12-09T07:20:02.014340

**agent**: ansatz-designer
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep']

---

### AGENT_GAP_DETECTION

**Timestamp**: 2025-12-09T07:20:02.015244

**agents_created**: ['vqe-executor', 'optimizer-agent', 'ansatz-designer']
**phase**: completed

---

### AGENT_CREATED_ON_DEMAND

**Timestamp**: 2025-12-09T07:20:02.015418

**agent**: vqe-executor
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep']

---

### AGENT_CREATED_ON_DEMAND

**Timestamp**: 2025-12-09T07:20:02.015555

**agent**: optimizer-agent
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Grep', 'Glob']

---

### AGENT_CREATED_ON_DEMAND

**Timestamp**: 2025-12-09T07:20:02.015682

**agent**: ansatz-designer
**tools**: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep']

---

### STEP_UPDATED

**Timestamp**: 2025-12-09T07:20:06.065566

**step**: 1
**status**: in_progress
**result**: None
**error**: None

---

### STEP_EXECUTION_STARTED

**Timestamp**: 2025-12-09T07:20:06.065723

**step**: 1
**description**: Design parameterized quantum circuit ansatz for VQE simulation
**agent**: ansatz-designer

---

### DELEGATION_STARTED

**Timestamp**: 2025-12-09T07:20:06.065922

**prompt**: Use the ansatz-designer agent to Design parameterized quantum circuit ansatz for VQE simulation

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:08.662294

**activity**: Thinking...

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:15.316852

**activity**: Using: Task()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:19.369346

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:19.766118

**activity**: Using: Glob()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:20.508837

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:20.653189

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:20.679629

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:20.707900

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:25.485549

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:26.071405

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:26.735905

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:26.910352

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:26.916460

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:27.036166

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:31.449707

**activity**: Using: Read()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:31.684121

**activity**: Tool completed

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:37.899918

**activity**: Using: Bash()

---

### AGENT_ACTIVITY

**Timestamp**: 2025-12-09T07:20:38.236989

**activity**: Tool completed

---



================================================
File: workspace/projects/Project_perform_vqe_simulation/state/plan.md
================================================
# Execution Plan

**Total Steps**: 7
**Created**: 2025-12-09T07:20:06.065194

---

## Step 1: Design parameterized quantum circuit ansatz for VQE simulation â–¶ï¸
**Agent**: ansatz-designer
**Status**: in_progress

## Step 2: Define Pauli Z Hamiltonian and measurement strategy â¸ï¸
**Agent**: vqe-executor
**Status**: pending

## Step 3: Implement energy expectation value computation function â¸ï¸
**Agent**: vqe-executor
**Status**: pending

## Step 4: Configure classical optimizer with appropriate hyperparameters â¸ï¸
**Agent**: optimizer-agent
**Status**: pending

## Step 5: Execute VQE optimization loop to find ground state energy â¸ï¸
**Agent**: vqe-executor
**Status**: pending

## Step 6: Validate results and generate simulation report â¸ï¸
**Agent**: vqe-executor
**Status**: pending

## Step 7: Save simulation artifacts and coordinate team completion â¸ï¸
**Agent**: system-agent
**Status**: pending



================================================
File: workspace/projects/Project_perform_vqe_simulation/state/variables.json
================================================
{
  "memory_insights": {
    "similar_trace_found": false,
    "trace": null,
    "recommendations": []
  }
}


================================================
File: .claude/settings.local.json
================================================
{
  "permissions": {
    "allow": [
      "WebFetch(domain:textual.textualize.io)",
      "Read(//Users/agustinazwiener/evolving-agents-labs/llmunix/**)",
      "Bash(python:*)",
      "Bash(cat:*)",
      "WebFetch(domain:github.com)"
    ],
    "deny": [],
    "ask": []
  }
}


